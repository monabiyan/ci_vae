{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhV9PPiQKgSg"
   },
   "source": [
    "# Generate Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9HIiKcw_PCm5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "#Generate 5 random numbers between 10 and 30\n",
    "np.random.seed(0)\n",
    "n_samples=1000\n",
    "n_features = 5\n",
    "df_XY=pd.DataFrame(data = np.random.normal(0,1, size=(n_samples, n_features)), columns = ['A','B','C','D','E'])\n",
    "df_XY['Y']=list(np.random.randint(2, size=n_samples))\n",
    "df_XY['YY']=list(np.random.randint(2, size=n_samples))\n",
    "df_XY\n",
    "\n",
    "##############################################################   \n",
    "df_XY.shape\n",
    "df_XY.head()\n",
    "df_XY.to_csv('df_XY.csv',index=False)\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "31zCNsOv0BoE",
    "outputId": "b7af009e-8ad8-463e-805d-07a8d5e7e082"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>Y</th>\n",
       "      <th>YY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>2.240893</td>\n",
       "      <td>1.867558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.977278</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144044</td>\n",
       "      <td>1.454274</td>\n",
       "      <td>0.761038</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.443863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333674</td>\n",
       "      <td>1.494079</td>\n",
       "      <td>-0.205158</td>\n",
       "      <td>0.313068</td>\n",
       "      <td>-0.854096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.552990</td>\n",
       "      <td>0.653619</td>\n",
       "      <td>0.864436</td>\n",
       "      <td>-0.742165</td>\n",
       "      <td>2.269755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.711489</td>\n",
       "      <td>-1.820816</td>\n",
       "      <td>0.163495</td>\n",
       "      <td>-0.813117</td>\n",
       "      <td>-0.605355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.327524</td>\n",
       "      <td>-0.644172</td>\n",
       "      <td>1.908883</td>\n",
       "      <td>-0.563545</td>\n",
       "      <td>1.082473</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.951911</td>\n",
       "      <td>2.441216</td>\n",
       "      <td>-0.017285</td>\n",
       "      <td>0.912282</td>\n",
       "      <td>1.239658</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.573367</td>\n",
       "      <td>0.424889</td>\n",
       "      <td>-0.271260</td>\n",
       "      <td>-0.683568</td>\n",
       "      <td>-1.537438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.101374</td>\n",
       "      <td>0.746666</td>\n",
       "      <td>0.929182</td>\n",
       "      <td>0.229418</td>\n",
       "      <td>0.414406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C         D         E  Y  YY\n",
       "0    1.764052  0.400157  0.978738  2.240893  1.867558  1   1\n",
       "1   -0.977278  0.950088 -0.151357 -0.103219  0.410599  0   0\n",
       "2    0.144044  1.454274  0.761038  0.121675  0.443863  0   0\n",
       "3    0.333674  1.494079 -0.205158  0.313068 -0.854096  1   0\n",
       "4   -2.552990  0.653619  0.864436 -0.742165  2.269755  0   1\n",
       "..        ...       ...       ...       ...       ... ..  ..\n",
       "995  1.711489 -1.820816  0.163495 -0.813117 -0.605355  0   0\n",
       "996 -1.327524 -0.644172  1.908883 -0.563545  1.082473  1   0\n",
       "997 -1.951911  2.441216 -0.017285  0.912282  1.239658  1   1\n",
       "998 -0.573367  0.424889 -0.271260 -0.683568 -1.537438  1   1\n",
       "999 -0.101374  0.746666  0.929182  0.229418  0.414406  0   1\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y77NKQyeKwIj"
   },
   "source": [
    "# Download CI-VAE, other necessary packages and Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cAuVLcUNETr7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: df_reconstructed.csv: No such file or directory\n",
      "rm: df_reconstructed_decoder.csv: No such file or directory\n",
      "rm: results_dict.pkl: No such file or directory\n",
      "rm: df_latent.csv: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! rm -rf ci_vae\n",
    "! rm bb.pt\n",
    "! rm bb_residuals.pkl\n",
    "! rm df_reconstructed.csv\n",
    "! rm df_reconstructed_decoder.csv\n",
    "! rm residuals.pdf\n",
    "! rm results_dict.pkl\n",
    "! rm df_latent.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "18S0saDPLp0X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ci_vae'...\n",
      "remote: Enumerating objects: 349, done.\u001b[K\n",
      "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
      "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
      "remote: Total 349 (delta 53), reused 77 (delta 27), pack-reused 245\u001b[K\n",
      "Receiving objects: 100% (349/349), 47.32 MiB | 14.21 MiB/s, done.\n",
      "Resolving deltas: 100% (209/209), done.\n",
      "Requirement already satisfied: umap-learn in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (0.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (1.5.2)\n",
      "Requirement already satisfied: numba>=0.49 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (0.51.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (0.5.8)\n",
      "Requirement already satisfied: tqdm in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (4.50.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22->umap-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22->umap-learn) (1.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from numba>=0.49->umap-learn) (50.3.1.post20201107)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from numba>=0.49->umap-learn) (0.34.0)\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/monabiyan/ci_vae.git\n",
    "! pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kzwk1I17VAQx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ci_vae import ivae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPVcV9thL8SP"
   },
   "source": [
    "# Set Necessary Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KAVb-irtbIpc"
   },
   "outputs": [],
   "source": [
    "model_init=True\n",
    "model_tobe_trained=True\n",
    "save_address=\"bb\"\n",
    "\n",
    "kl_coef = 0.0001\n",
    "reconst_coef = 1\n",
    "classifier_coef = 0.1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRIfHjpSMKF5"
   },
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ll0w2DunMJei"
   },
   "outputs": [],
   "source": [
    "obj1 = ivae.IVAE(df_XY = df_XY,\n",
    "               latent_size = 10,\n",
    "               reconst_coef = reconst_coef,\n",
    "               kl_coef = kl_coef,\n",
    "               classifier_coef = classifier_coef,\n",
    "               test_ratio = 1)\n",
    "\n",
    "if model_init:\n",
    "    obj1.model_initialiaze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT-AB_8-M-tD"
   },
   "source": [
    "## See The Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJXlsM8Uk2Ry",
    "outputId": "129babee-fc0e-48c5-9262-08404a9b89c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVAE_ARCH(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.05, inplace=False)\n",
      "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.05, inplace=False)\n",
      "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.05, inplace=False)\n",
      "    (12): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (15): Dropout(p=0.05, inplace=False)\n",
      "    (16): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (19): Dropout(p=0.05, inplace=False)\n",
      "    (20): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (21): ReLU()\n",
      "    (22): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (23): Dropout(p=0.05, inplace=False)\n",
      "    (24): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (25): ReLU()\n",
      "    (26): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (27): Dropout(p=0.05, inplace=False)\n",
      "    (28): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (29): ReLU()\n",
      "    (30): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (31): Dropout(p=0.05, inplace=False)\n",
      "    (32): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (33): ReLU()\n",
      "    (34): BatchNorm1d(10, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (35): Dropout(p=0.05, inplace=False)\n",
      "    (36): Linear(in_features=10, out_features=20, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.05, inplace=False)\n",
      "    (4): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.05, inplace=False)\n",
      "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.05, inplace=False)\n",
      "    (12): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (15): Dropout(p=0.05, inplace=False)\n",
      "    (16): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (19): Dropout(p=0.05, inplace=False)\n",
      "    (20): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (21): ReLU()\n",
      "    (22): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (23): Dropout(p=0.05, inplace=False)\n",
      "    (24): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (25): ReLU()\n",
      "    (26): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (27): Dropout(p=0.05, inplace=False)\n",
      "    (28): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (29): ReLU()\n",
      "    (30): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (31): Dropout(p=0.05, inplace=False)\n",
      "    (32): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (33): ReLU()\n",
      "    (34): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (35): Dropout(p=0.05, inplace=False)\n",
      "    (36): Linear(in_features=20, out_features=5, bias=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "    (1): Dropout(p=0.8, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(obj1.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSj9WT_mNHNl"
   },
   "source": [
    "## See the Initialized Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUFyVcu4ldFH",
    "outputId": "5a470060-626d-4602-dcf4-78d601febd3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1424,  0.0664, -0.0965,  0.1646,  0.2640],\n",
      "        [-0.0476,  0.3125,  0.3737, -0.1541, -0.1036],\n",
      "        [ 0.1287, -0.0847, -0.1403,  0.4251,  0.2863],\n",
      "        [-0.4365,  0.3215,  0.3000,  0.0955,  0.4236],\n",
      "        [-0.0062, -0.2413,  0.0304, -0.0109,  0.0527],\n",
      "        [ 0.4258,  0.3198,  0.0723,  0.2268, -0.1648],\n",
      "        [ 0.0251, -0.3015,  0.0916, -0.0205, -0.4170],\n",
      "        [ 0.2164, -0.3819,  0.1006, -0.4042, -0.1077],\n",
      "        [ 0.3434, -0.0119, -0.3739,  0.4114,  0.0953],\n",
      "        [ 0.2157,  0.1486, -0.0704,  0.4245,  0.0029],\n",
      "        [ 0.3339,  0.2354, -0.1250, -0.0008,  0.2527],\n",
      "        [-0.2057,  0.0031, -0.4050,  0.3786, -0.2125],\n",
      "        [ 0.2136, -0.1749, -0.3011,  0.2325, -0.3028],\n",
      "        [-0.1992, -0.2421, -0.3499,  0.1653, -0.0067],\n",
      "        [ 0.2618, -0.2680,  0.0324,  0.1459,  0.4336],\n",
      "        [ 0.3962,  0.1804,  0.4054,  0.3693, -0.3493],\n",
      "        [-0.1669,  0.1923, -0.4162,  0.0365,  0.4081],\n",
      "        [ 0.4469, -0.1421,  0.1284, -0.2480, -0.2776],\n",
      "        [ 0.2602, -0.1571,  0.0319,  0.4055, -0.2542],\n",
      "        [-0.0253,  0.2754, -0.0720, -0.3648, -0.2141]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2032, -0.0072,  0.2168, -0.3722, -0.2920, -0.1945, -0.3179, -0.3425,\n",
      "        -0.2285, -0.1487, -0.4285,  0.4339, -0.0709, -0.4196,  0.0192, -0.0079,\n",
      "        -0.4098, -0.0730,  0.3188,  0.0976], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 6.7003e-02,  1.8914e-01, -2.0277e-01,  2.4723e-02, -1.7105e-01,\n",
      "         -8.7432e-02, -6.4518e-02, -8.7873e-02,  3.2345e-02, -5.7748e-02,\n",
      "          1.9478e-01, -1.0744e-01,  1.9003e-01, -1.9815e-01, -7.7501e-02,\n",
      "          1.1311e-01,  9.7203e-02, -2.2246e-01, -4.4436e-02, -7.4406e-02],\n",
      "        [-8.5743e-03, -1.3208e-01,  1.7469e-01, -7.3731e-02, -2.1133e-01,\n",
      "         -6.0324e-02, -1.4193e-01,  8.1998e-02, -1.3089e-01, -1.2577e-01,\n",
      "          1.4713e-01,  1.5542e-02, -9.3722e-02, -1.4150e-01, -1.4768e-01,\n",
      "          1.0473e-01, -1.2857e-02,  1.0700e-01, -9.1164e-02,  1.4715e-01],\n",
      "        [-6.6650e-02, -1.5019e-01, -3.9112e-02, -1.2940e-01,  2.1637e-01,\n",
      "          1.9123e-01,  6.3225e-02,  2.0798e-01, -8.3805e-02,  9.7844e-02,\n",
      "         -1.8032e-01, -1.4944e-01, -4.0497e-03, -6.4853e-02, -4.1271e-02,\n",
      "         -1.9059e-01, -1.2497e-02,  3.9020e-02, -2.2080e-01,  1.5746e-01],\n",
      "        [-5.4779e-02,  6.3151e-03,  1.9149e-01,  1.7386e-01,  1.7169e-01,\n",
      "          7.9024e-02,  1.6418e-02, -1.5400e-01,  1.6447e-01, -4.1873e-02,\n",
      "          1.5888e-01, -1.3645e-01, -3.6073e-02, -2.0690e-01, -1.3843e-01,\n",
      "         -9.2238e-02, -1.8428e-01,  2.2271e-01, -1.9293e-02, -2.1831e-01],\n",
      "        [ 3.5518e-02, -9.6510e-02, -1.8049e-01, -2.1491e-01, -1.8318e-02,\n",
      "          2.6238e-02,  9.1724e-02, -5.5254e-02, -9.2220e-02,  1.3548e-01,\n",
      "         -1.4855e-01,  1.0353e-01,  1.3775e-01, -2.0283e-03, -4.0821e-02,\n",
      "          2.3169e-02, -1.4996e-01,  1.4360e-01, -1.7409e-01,  1.9449e-01],\n",
      "        [ 1.6372e-02,  3.9386e-02,  1.1756e-01,  1.9771e-01, -1.2856e-01,\n",
      "         -1.5268e-01, -1.4761e-01,  1.5353e-01,  1.7306e-02,  5.8163e-02,\n",
      "          1.8812e-01, -1.0325e-01,  1.4333e-01, -1.4740e-01, -1.6365e-01,\n",
      "          3.1268e-02,  8.2940e-02, -6.7715e-02, -1.8050e-01,  1.1695e-01],\n",
      "        [-2.2048e-01, -5.8841e-02,  2.0524e-01, -8.0143e-02, -2.0580e-01,\n",
      "          1.9610e-01,  2.1173e-01,  1.6562e-01, -1.3762e-01,  6.0535e-02,\n",
      "          2.8627e-02,  6.5758e-03,  1.5837e-01, -1.5133e-01, -1.7697e-01,\n",
      "         -2.1182e-01,  1.9903e-01,  9.7636e-03, -1.5854e-01,  6.8003e-03],\n",
      "        [-3.6065e-02,  4.7764e-02,  4.8523e-02, -2.1086e-01,  2.0365e-01,\n",
      "         -1.2879e-01,  9.0135e-02,  8.6061e-02, -1.3169e-01,  1.3941e-01,\n",
      "          1.3624e-01,  6.6344e-02, -9.6944e-02,  2.6509e-02, -4.9366e-02,\n",
      "          5.5756e-02, -6.8739e-02, -1.1853e-01, -1.2629e-01,  5.0072e-02],\n",
      "        [-8.1888e-02,  1.3621e-01, -3.0803e-02,  9.6576e-02, -5.5882e-02,\n",
      "          1.6222e-01, -1.0146e-01,  8.0701e-02,  5.6645e-02, -1.7555e-01,\n",
      "          2.6255e-02,  2.0708e-01,  2.1376e-01, -2.0222e-01, -1.8810e-01,\n",
      "         -2.6014e-02, -1.5213e-01,  2.1356e-01,  8.0432e-02, -1.9080e-01],\n",
      "        [-1.7418e-01, -1.6624e-01, -7.0641e-02,  6.1421e-02,  1.1848e-01,\n",
      "         -1.4858e-01, -1.3983e-01,  9.5611e-02,  2.0717e-01, -5.6506e-02,\n",
      "          1.4899e-01, -4.6524e-02, -1.5527e-02,  1.8310e-01, -3.1397e-02,\n",
      "          6.5524e-02,  1.3139e-01, -3.7274e-02,  1.5915e-01, -1.9870e-01],\n",
      "        [ 8.9280e-02, -1.9440e-01,  9.0014e-02,  1.8755e-01, -6.2678e-03,\n",
      "          2.0193e-01, -8.5278e-02,  1.0666e-01, -1.9877e-01,  7.4006e-03,\n",
      "          2.1791e-02,  2.2123e-01,  1.8711e-01, -1.1540e-01,  1.0135e-01,\n",
      "         -5.6953e-02, -1.3054e-01,  2.1513e-01,  1.1691e-01,  1.7126e-01],\n",
      "        [ 1.7200e-01, -2.1091e-01, -1.5262e-01,  8.7336e-02,  1.0074e-01,\n",
      "         -4.7871e-02,  1.0608e-01,  2.2125e-01, -2.0027e-01,  1.4638e-01,\n",
      "          1.6196e-01,  5.1614e-02,  2.0211e-01,  1.4477e-02,  9.4272e-02,\n",
      "          1.2642e-01,  2.0351e-01,  5.1246e-02,  7.9473e-02, -6.3552e-02],\n",
      "        [-1.1399e-01, -1.3741e-01, -9.9341e-02,  2.1064e-01, -5.9978e-02,\n",
      "          4.5904e-02,  9.6734e-02, -1.8095e-02,  1.5500e-01,  2.1461e-01,\n",
      "         -1.7752e-01, -1.8550e-01, -1.7398e-01,  4.1940e-02,  9.4597e-02,\n",
      "          9.2324e-02, -2.8019e-02, -1.8615e-01,  1.5507e-03,  1.4860e-01],\n",
      "        [ 1.9208e-01,  1.7285e-01, -1.0584e-01, -1.8388e-01, -1.3915e-01,\n",
      "         -8.4283e-02, -1.1608e-01, -1.3915e-01, -3.1222e-03,  8.6309e-02,\n",
      "         -8.8747e-02, -2.0040e-01, -7.1890e-02,  1.4560e-02, -1.6154e-01,\n",
      "          3.7317e-02,  1.1690e-01, -1.3703e-01,  4.7655e-02,  6.7900e-02],\n",
      "        [ 1.8968e-01,  4.3458e-02, -3.0598e-02,  2.1969e-01, -2.2350e-01,\n",
      "         -5.0868e-02,  1.8500e-01,  1.0683e-01,  1.7006e-01, -3.3783e-02,\n",
      "          1.4661e-02, -7.6083e-02,  8.8890e-02,  9.3245e-02, -2.1251e-01,\n",
      "          4.6228e-02, -1.7787e-01,  3.7527e-02,  2.0918e-01, -1.2642e-01],\n",
      "        [ 5.1262e-03, -1.4932e-01, -1.7853e-01,  9.1010e-02,  2.0621e-01,\n",
      "         -6.4513e-02, -8.3339e-02,  1.7610e-01,  6.0307e-02, -1.5930e-01,\n",
      "          1.1968e-01,  1.8224e-01, -1.4972e-01, -5.3611e-02, -1.8603e-01,\n",
      "          7.2207e-02, -1.8373e-01,  1.7136e-01,  1.6997e-01,  6.1304e-02],\n",
      "        [-6.5543e-02,  1.3147e-01,  3.4332e-02, -2.1462e-01,  2.0244e-01,\n",
      "          1.2030e-01, -2.8911e-02,  1.2154e-01,  4.3194e-02, -6.3369e-02,\n",
      "          1.0070e-01,  1.7130e-01, -1.8717e-01, -1.7868e-02, -9.6717e-02,\n",
      "         -1.1363e-01, -1.5813e-01, -1.5899e-03, -5.0627e-02,  9.5721e-02],\n",
      "        [-5.5985e-02, -1.0839e-01,  8.8353e-02,  1.2957e-01,  1.3042e-01,\n",
      "         -6.9661e-02,  5.7018e-02, -8.6100e-02,  1.7370e-01,  1.7260e-01,\n",
      "         -3.1060e-02,  5.6696e-02, -1.2441e-01,  7.1895e-02,  1.6593e-01,\n",
      "          1.0496e-01, -2.1751e-01, -1.1587e-01,  6.8703e-02, -2.0892e-01],\n",
      "        [ 9.8721e-02, -7.2131e-02, -1.9812e-01, -5.0822e-02,  6.1668e-02,\n",
      "         -1.0209e-02,  1.3487e-01,  1.2527e-01,  3.2345e-02,  1.3876e-01,\n",
      "         -1.2223e-01, -2.0446e-01, -1.9467e-01, -1.9308e-01,  1.0400e-01,\n",
      "          4.5872e-02, -1.4901e-05,  1.3801e-01, -1.1614e-01, -1.7602e-01],\n",
      "        [ 5.2886e-02, -2.1653e-01,  8.2137e-02,  1.0985e-01,  1.9014e-01,\n",
      "         -4.9044e-02, -8.5357e-02, -1.8693e-01,  1.9000e-01,  4.3045e-02,\n",
      "         -1.0063e-02, -1.0011e-01, -4.2098e-02, -1.3331e-01,  2.4241e-02,\n",
      "         -1.0438e-01, -8.6735e-02,  1.6360e-01, -1.2255e-01, -1.3469e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1950,  0.0387, -0.1680, -0.1006, -0.1448,  0.1621, -0.0274, -0.0712,\n",
      "         0.0702, -0.1404,  0.1564,  0.1507, -0.0409,  0.0583,  0.0661, -0.0265,\n",
      "         0.2082,  0.1759, -0.0407,  0.0020], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9855e-01,  1.3337e-01, -7.4088e-02,  1.3869e-01, -1.4253e-01,\n",
      "         -2.1591e-01, -2.1221e-01, -9.6205e-03, -1.3859e-01, -1.5350e-01,\n",
      "          1.7653e-01, -2.0876e-01, -1.8883e-01, -3.3254e-02,  4.1893e-02,\n",
      "         -1.3647e-01,  7.7320e-02, -1.9840e-01, -1.9718e-01,  4.8960e-03],\n",
      "        [-1.0182e-01,  7.2264e-02,  1.2992e-01,  1.5422e-01,  1.0986e-01,\n",
      "          1.4874e-01,  2.2053e-01,  2.0079e-01,  1.6771e-01, -7.5851e-02,\n",
      "         -4.9165e-02, -3.7324e-02,  8.1491e-02,  3.9160e-02, -3.7878e-02,\n",
      "         -1.7905e-04,  1.8321e-01, -3.5233e-02,  2.1557e-03, -1.0682e-01],\n",
      "        [-1.4754e-01, -1.2033e-01,  3.8478e-02,  2.3710e-02,  2.1473e-01,\n",
      "         -1.5983e-02, -1.6362e-01,  1.4837e-01,  1.4874e-01, -1.5275e-01,\n",
      "         -6.5564e-02,  6.6352e-02,  3.6774e-02,  5.2945e-02,  1.4801e-01,\n",
      "          1.8180e-01,  1.1749e-01,  2.0029e-01, -1.0331e-01,  1.4665e-01],\n",
      "        [-1.1575e-01, -1.1778e-01,  8.1497e-02, -9.5254e-02,  1.8930e-01,\n",
      "          3.6538e-03,  1.9124e-01,  1.8141e-01,  1.9428e-01, -1.7564e-01,\n",
      "         -6.9056e-02, -8.0685e-02,  1.5973e-01, -9.8695e-02, -2.1475e-01,\n",
      "         -7.5125e-02,  2.5014e-02,  2.0054e-01,  1.9595e-01,  1.8908e-01],\n",
      "        [-7.6964e-02,  6.7951e-02,  1.6248e-01, -1.5080e-01,  2.0085e-01,\n",
      "         -1.1098e-01,  2.2305e-02, -6.3339e-02, -2.1106e-02,  1.2086e-01,\n",
      "          1.7053e-02,  2.8228e-02,  6.5516e-02,  2.9122e-02, -1.5014e-01,\n",
      "         -1.0504e-01, -1.2409e-01, -1.8407e-01,  1.2603e-01,  4.3882e-02],\n",
      "        [ 1.8552e-01, -3.7739e-02, -2.1568e-01,  8.8555e-02,  1.8315e-01,\n",
      "          6.7107e-02,  1.0467e-01,  3.8747e-02, -6.6513e-02,  4.7760e-02,\n",
      "          1.6668e-01, -3.4333e-02, -1.3583e-01,  3.4284e-03, -6.0367e-02,\n",
      "         -7.5158e-02, -5.7883e-02,  5.8606e-03,  1.8370e-01, -1.5788e-01],\n",
      "        [-1.0858e-02, -4.6574e-02, -1.6644e-01, -1.6282e-01, -1.5629e-01,\n",
      "          1.7685e-01, -2.1727e-01, -6.4528e-02, -2.1973e-02, -1.9411e-01,\n",
      "          5.8404e-02,  1.0077e-01, -1.8721e-01,  1.8689e-01,  9.4930e-02,\n",
      "          1.4822e-01,  1.4939e-01,  9.1289e-03,  2.1095e-02,  1.6300e-01],\n",
      "        [ 4.9316e-02, -2.3351e-02, -3.3828e-02, -1.4845e-01, -9.7676e-02,\n",
      "         -1.1991e-01, -5.3373e-02,  1.3278e-01,  6.3278e-02, -1.9246e-01,\n",
      "          1.1992e-01, -1.6859e-01,  1.7509e-01, -5.7971e-02, -1.4801e-01,\n",
      "         -1.2385e-01, -1.9948e-01,  1.3538e-01,  1.3320e-01,  1.6819e-01],\n",
      "        [ 1.6081e-01, -1.2211e-01, -1.4198e-01,  2.5808e-03,  1.2127e-03,\n",
      "         -8.3906e-02, -2.0631e-01,  1.5203e-01,  2.2432e-03,  5.0478e-02,\n",
      "         -2.1397e-01, -1.3466e-01,  3.5190e-02,  2.1489e-01, -2.0218e-01,\n",
      "          1.6416e-01, -2.2327e-01,  1.4631e-01,  8.6215e-02, -1.4599e-02],\n",
      "        [-2.2091e-01,  1.0007e-01,  1.8745e-01,  2.3122e-02,  2.2289e-01,\n",
      "         -1.3382e-01,  2.0975e-01,  5.8745e-02,  6.1111e-02, -5.7415e-03,\n",
      "         -1.2281e-01,  7.5570e-02,  3.6333e-02,  1.2361e-01,  1.6761e-01,\n",
      "         -2.4818e-02, -6.2570e-02, -3.5862e-02,  6.3351e-02, -1.8054e-01],\n",
      "        [ 7.1629e-02,  4.9083e-02, -1.1787e-01,  1.1429e-01, -2.0877e-01,\n",
      "         -1.1112e-01, -1.8497e-01,  4.4561e-02, -8.0143e-02, -4.4722e-02,\n",
      "          6.1009e-02, -9.5778e-02, -3.5960e-02, -2.4586e-02, -2.1605e-01,\n",
      "         -1.2769e-02, -1.2633e-01, -1.2204e-01, -1.4764e-01,  1.9937e-01],\n",
      "        [ 1.7467e-01,  2.0650e-01, -8.4754e-03, -4.0919e-02, -8.5397e-03,\n",
      "         -6.4495e-02, -9.8208e-02, -1.8735e-02,  7.4563e-02,  1.5862e-01,\n",
      "          9.4723e-02,  1.4957e-01,  1.0520e-02, -1.8203e-02,  3.4508e-02,\n",
      "         -7.5574e-02, -9.4482e-02,  2.1010e-01, -3.0580e-02, -5.0542e-02],\n",
      "        [ 3.0177e-02, -1.5378e-02, -4.4252e-02,  2.8600e-02, -5.7645e-02,\n",
      "         -6.4042e-02, -5.0856e-02, -2.1085e-01,  1.8516e-01, -1.5754e-01,\n",
      "         -2.0629e-01, -2.6919e-02, -1.4049e-01,  2.1015e-01, -6.2746e-02,\n",
      "          1.3206e-01,  1.4953e-01, -8.5548e-02, -1.4797e-01, -1.6204e-01],\n",
      "        [-1.5445e-01,  3.3380e-02, -1.2943e-01,  4.1505e-02, -3.3465e-02,\n",
      "          7.0292e-02, -2.8851e-02, -3.8021e-02, -2.5081e-03, -9.8065e-02,\n",
      "         -7.8677e-02, -3.2040e-02, -1.9841e-01, -6.5495e-02,  6.5773e-02,\n",
      "         -1.4254e-01,  3.1449e-02, -1.1511e-01, -1.8190e-01, -1.2249e-02],\n",
      "        [ 1.2534e-02,  2.7101e-02, -2.2007e-01,  3.5344e-02, -6.7677e-02,\n",
      "          1.3136e-01,  5.8634e-02, -1.3707e-01, -2.1737e-01, -1.2155e-01,\n",
      "         -2.1504e-01,  2.8842e-02,  2.1299e-01,  9.3372e-03, -3.6621e-02,\n",
      "          2.5584e-02,  9.1810e-02, -9.2531e-02, -1.6363e-01, -6.9499e-02],\n",
      "        [-1.3732e-01,  1.6545e-02, -3.1957e-02,  2.0492e-01,  1.9901e-01,\n",
      "         -1.3684e-01,  1.7042e-01, -1.3400e-01,  2.1924e-02,  1.0039e-01,\n",
      "          5.5854e-02,  5.3550e-02,  1.7311e-01,  1.9349e-01, -1.0298e-01,\n",
      "          5.8003e-02, -2.0755e-01, -1.9554e-01, -1.3261e-01, -8.7861e-02],\n",
      "        [ 3.2102e-02,  6.8986e-02,  1.1681e-01,  3.3611e-02, -5.9003e-03,\n",
      "          4.9780e-02, -2.2168e-02,  8.6020e-02,  4.3427e-02,  8.5344e-02,\n",
      "          4.6143e-02,  9.0054e-02,  2.2064e-01, -2.5187e-02, -1.0952e-01,\n",
      "          1.6292e-01, -1.9880e-01, -8.4297e-02,  1.4759e-01,  1.5110e-01],\n",
      "        [-8.9630e-02,  8.7160e-02,  1.5270e-01, -1.9960e-01,  1.8336e-01,\n",
      "          1.1424e-01,  9.3644e-02, -1.2784e-01,  1.3679e-01, -4.0349e-02,\n",
      "         -9.9537e-02, -1.2464e-01,  6.1361e-03, -1.7322e-01, -4.1751e-02,\n",
      "          3.9587e-02, -2.0195e-01, -1.7550e-01,  2.0201e-01,  2.9662e-03],\n",
      "        [-1.3559e-01, -1.9068e-01, -1.6652e-01,  1.3503e-01, -2.1412e-01,\n",
      "          7.2491e-02,  7.3029e-02, -3.2298e-02,  8.1830e-02,  5.5735e-02,\n",
      "          1.2235e-01, -1.4430e-01, -1.8427e-01,  1.4361e-01,  4.6375e-02,\n",
      "          2.0187e-01,  1.7885e-01,  2.9773e-02, -1.7499e-01,  1.0875e-01],\n",
      "        [ 1.6294e-02, -2.1995e-01, -4.8530e-02,  1.2430e-01, -4.9118e-02,\n",
      "          1.4042e-01, -1.0718e-01,  9.2001e-02,  2.1068e-01, -3.9400e-02,\n",
      "         -2.0282e-01, -2.0781e-01, -9.6781e-02, -1.1645e-01, -1.6410e-01,\n",
      "          1.4488e-02, -9.8905e-02,  8.9915e-02,  5.4315e-02,  2.0074e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1581,  0.2043, -0.1154, -0.0931, -0.1882,  0.1688, -0.1393,  0.1111,\n",
      "         0.0634, -0.0105, -0.1194,  0.0962, -0.0117, -0.1667, -0.0914, -0.1506,\n",
      "         0.1524, -0.1301, -0.0364,  0.0647], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 2.0494e-01,  1.3183e-01, -2.0491e-01, -9.1492e-02, -1.1545e-01,\n",
      "         -7.6174e-03,  1.2858e-02, -3.9458e-02,  7.6201e-02, -3.5758e-02,\n",
      "          1.0946e-01, -1.4560e-02,  1.1176e-01,  1.1906e-01, -1.4197e-01,\n",
      "         -1.5971e-01, -1.5851e-01,  1.8667e-01, -1.1453e-01, -7.0391e-02],\n",
      "        [-1.5003e-01, -1.4154e-01,  1.1654e-01, -1.4281e-01,  3.7281e-02,\n",
      "         -1.5872e-01, -4.6474e-02,  8.5811e-03, -2.0436e-01, -9.3180e-02,\n",
      "          9.5808e-02,  1.7327e-01,  1.6577e-01, -1.7535e-01, -6.1642e-02,\n",
      "          6.2589e-02,  5.0786e-02, -2.0191e-01,  2.0032e-01, -1.9415e-01],\n",
      "        [ 1.6695e-01,  1.1897e-01,  1.2944e-01,  1.9562e-01, -1.4016e-01,\n",
      "          1.2578e-01, -4.4524e-02, -1.8240e-01, -1.4466e-01, -2.0874e-01,\n",
      "          5.5410e-02, -1.9931e-01, -1.2080e-01, -7.6615e-02, -1.0298e-01,\n",
      "         -1.3854e-01,  1.4826e-02,  3.5024e-03,  2.4313e-02, -1.5297e-01],\n",
      "        [ 1.7320e-01, -1.8408e-01, -2.1101e-01,  7.7831e-02,  1.5945e-01,\n",
      "         -6.0581e-02,  1.6352e-01, -1.2682e-01,  1.8252e-02, -7.9540e-02,\n",
      "          5.6208e-02, -1.8931e-01, -9.3487e-02, -5.8778e-02, -1.9231e-01,\n",
      "         -1.6206e-01,  7.0227e-02, -1.9320e-01, -1.9167e-01,  1.0705e-01],\n",
      "        [-1.7996e-01,  1.7608e-01,  2.5622e-02,  1.0415e-01, -1.5497e-01,\n",
      "          1.8028e-01,  1.8190e-01, -1.3188e-01, -5.8022e-03,  1.2455e-01,\n",
      "         -2.2225e-01,  8.3309e-02,  1.1228e-01, -1.5675e-01, -2.4038e-03,\n",
      "          1.0807e-01, -8.3023e-03,  1.2297e-01, -1.4518e-01, -4.2549e-03],\n",
      "        [-8.5664e-02,  4.9269e-02,  1.3730e-01,  2.1236e-01, -3.0516e-02,\n",
      "          3.6097e-02, -1.3353e-01, -1.6990e-01,  2.6383e-03, -9.7025e-02,\n",
      "         -3.1709e-03, -8.2813e-02,  4.6081e-02, -2.0627e-01,  4.5715e-02,\n",
      "          1.0922e-01,  1.0768e-01, -1.0782e-02, -1.6327e-01,  1.3163e-01],\n",
      "        [ 2.1279e-01,  9.3167e-02, -2.9622e-02,  1.9726e-01,  1.1843e-01,\n",
      "          1.2322e-01,  1.8613e-01, -1.1066e-01, -1.0273e-01,  1.2455e-02,\n",
      "         -6.7240e-02, -1.5556e-01,  4.0352e-02,  1.5597e-01,  2.1448e-01,\n",
      "          8.7061e-02, -2.3584e-02, -7.6834e-02,  1.6514e-01, -2.1004e-01],\n",
      "        [-9.8839e-02, -4.8321e-02, -2.0298e-01,  2.0217e-02,  4.6040e-02,\n",
      "         -9.9518e-03, -3.7058e-04,  3.1238e-02, -1.1131e-01,  2.5023e-02,\n",
      "          3.1244e-02,  3.4806e-02, -7.5416e-02, -4.4831e-02, -3.4873e-02,\n",
      "          8.2915e-02, -1.7722e-01, -1.6953e-01, -6.7537e-02, -1.8992e-02],\n",
      "        [-2.0411e-01,  1.7963e-02,  6.0977e-02,  3.3689e-02, -2.2158e-01,\n",
      "         -8.2664e-02, -1.8701e-01, -1.6563e-01,  7.1277e-02,  1.0918e-01,\n",
      "         -4.2159e-02,  1.2626e-01,  9.3942e-02, -1.1852e-01,  3.4229e-02,\n",
      "         -1.1619e-01,  9.5541e-02,  1.0048e-01, -1.2619e-01, -1.9982e-02],\n",
      "        [-1.8791e-01, -2.2163e-01,  2.1024e-01, -1.7058e-01,  1.3905e-01,\n",
      "         -1.2240e-01, -3.7834e-02,  1.5441e-01,  1.3722e-01, -4.3075e-02,\n",
      "         -3.4881e-02,  1.1281e-01,  1.9678e-01, -6.6635e-02,  1.8621e-01,\n",
      "          2.1379e-01,  1.1462e-01,  3.3840e-02,  1.8976e-01,  1.9629e-01],\n",
      "        [-1.2218e-01,  1.7619e-01,  1.1613e-01, -8.8063e-02,  1.6145e-01,\n",
      "         -5.4482e-02, -1.6800e-01, -5.3253e-02, -2.1609e-01,  1.0468e-02,\n",
      "          3.1921e-03, -1.7619e-01,  1.0389e-01,  1.1609e-01,  1.4059e-02,\n",
      "          3.3828e-02, -1.7190e-01, -2.0520e-01, -1.1082e-01,  2.0135e-01],\n",
      "        [-5.0203e-02, -7.8112e-02,  9.1810e-02,  4.2157e-02,  1.5864e-02,\n",
      "          4.6694e-02, -1.1780e-01,  2.0797e-01, -2.5051e-02,  9.5329e-02,\n",
      "          6.1260e-02,  1.8844e-01, -6.7382e-02, -1.5924e-01,  1.4597e-04,\n",
      "         -1.7064e-01, -8.2421e-02, -1.9746e-01,  1.8659e-01,  9.0207e-03],\n",
      "        [-1.1496e-01, -1.3077e-01, -1.1666e-01,  1.1066e-01, -1.9460e-01,\n",
      "          1.9392e-02, -1.3730e-01,  9.2401e-02,  1.3924e-02,  5.4925e-02,\n",
      "          1.0184e-01,  6.2918e-02,  9.8509e-02, -2.6966e-02, -7.8956e-02,\n",
      "          2.1453e-01, -2.1866e-01, -1.8906e-01,  1.9404e-01, -8.5719e-02],\n",
      "        [-5.4493e-02, -2.0530e-01,  1.9593e-01, -5.9392e-02,  2.7141e-02,\n",
      "         -2.5885e-02, -2.0143e-01, -1.9557e-01,  1.1360e-01,  3.6584e-02,\n",
      "         -1.1041e-01,  8.6533e-02,  1.6420e-01,  8.3291e-02, -1.2668e-01,\n",
      "          1.6327e-01,  5.6242e-02,  2.0717e-01, -3.8089e-03, -2.2864e-02],\n",
      "        [ 1.0873e-01,  7.6353e-02, -1.6780e-01,  8.6361e-02,  1.1213e-01,\n",
      "          6.2462e-02,  6.9470e-02,  1.4777e-01,  1.6735e-01, -7.2010e-02,\n",
      "          2.0972e-01, -1.7144e-01,  1.6376e-01,  2.0568e-01, -2.5163e-02,\n",
      "         -4.6649e-02, -6.5636e-02,  1.7915e-02, -2.2104e-02,  2.0336e-01],\n",
      "        [-1.6452e-01, -1.5020e-01, -1.7645e-02,  1.5957e-01, -6.4347e-02,\n",
      "          4.2341e-02, -7.8420e-02, -1.1849e-01, -1.7600e-01, -6.2879e-03,\n",
      "          1.8086e-01, -1.6704e-01,  7.9991e-02, -1.9623e-01, -2.4251e-02,\n",
      "          2.1584e-01,  1.2203e-01, -1.6964e-01,  1.5820e-01,  3.2227e-03],\n",
      "        [-1.3237e-01, -1.6726e-01, -9.6444e-02,  1.7028e-01,  1.9081e-01,\n",
      "         -1.8443e-01, -2.1185e-01,  8.1248e-02, -2.0890e-02,  1.6935e-01,\n",
      "          1.4533e-01, -5.4179e-03, -9.9372e-02,  8.9216e-02, -5.1910e-02,\n",
      "          1.1503e-01,  1.7055e-02, -8.2032e-02, -1.0831e-01,  1.9132e-01],\n",
      "        [-1.6824e-01, -9.1891e-02,  1.4902e-01,  1.4877e-01,  1.0209e-01,\n",
      "         -1.7520e-01, -1.9092e-01,  1.7864e-01, -1.5426e-01, -1.4148e-01,\n",
      "         -2.0349e-01, -1.9235e-01, -4.8700e-02,  1.6180e-02, -1.2584e-02,\n",
      "          1.0718e-01,  1.8107e-01,  2.2189e-02, -9.5898e-02, -3.7636e-02],\n",
      "        [ 1.7055e-01, -8.6736e-02,  9.9841e-02,  1.3456e-01, -1.0668e-01,\n",
      "         -1.6408e-01, -1.5602e-01, -3.7784e-02,  2.1961e-01,  5.7971e-02,\n",
      "          1.5264e-02,  2.5589e-02,  3.8605e-02,  6.6921e-02,  1.7498e-01,\n",
      "          1.5841e-01,  9.4020e-02,  1.3453e-01,  1.6742e-01,  1.5264e-01],\n",
      "        [ 2.1117e-01,  1.3565e-01,  1.4187e-01,  6.7595e-02,  6.1009e-02,\n",
      "          4.9301e-02,  1.2971e-01,  1.0019e-01, -5.9166e-03, -1.1080e-02,\n",
      "          7.7530e-02,  9.6719e-02,  1.1995e-01,  1.7233e-01,  1.4713e-01,\n",
      "         -7.6735e-03,  1.0256e-01, -1.7342e-02, -1.7308e-01,  6.7669e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2042,  0.0202, -0.1189, -0.1262,  0.1692,  0.1860, -0.0408,  0.0210,\n",
      "        -0.1826, -0.0497, -0.0963, -0.1966, -0.1586,  0.1833,  0.1299, -0.1542,\n",
      "        -0.0475,  0.1724,  0.2230, -0.1136], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1893, -0.2206,  0.1240, -0.1726, -0.0603, -0.0782, -0.1283,  0.1737,\n",
      "          0.0348, -0.0476,  0.0853,  0.1012, -0.0815, -0.0950, -0.1448,  0.0179,\n",
      "         -0.0924, -0.1987,  0.1260,  0.1920],\n",
      "        [-0.0130,  0.0157,  0.2093,  0.2153, -0.1789, -0.0469,  0.0798, -0.1872,\n",
      "          0.0970,  0.1052,  0.0074,  0.0830,  0.0413,  0.2079, -0.2166,  0.1691,\n",
      "          0.0089,  0.0601,  0.1948, -0.2072],\n",
      "        [-0.0282,  0.0596,  0.1592,  0.1693,  0.1202, -0.2077,  0.1197, -0.1314,\n",
      "         -0.1713, -0.2147,  0.1592, -0.1479,  0.0539,  0.1927, -0.0223, -0.0482,\n",
      "         -0.0045,  0.0154,  0.0082,  0.2144],\n",
      "        [ 0.1910,  0.1755,  0.0322, -0.1242,  0.1444, -0.1886, -0.2138,  0.1660,\n",
      "          0.0125,  0.0980,  0.1429,  0.1463, -0.0831,  0.0085, -0.1935,  0.0118,\n",
      "          0.0686, -0.0716,  0.1945, -0.0641],\n",
      "        [ 0.0947,  0.1410, -0.0803,  0.0270, -0.0505, -0.0494, -0.1581,  0.1309,\n",
      "          0.0117,  0.1881, -0.2172, -0.1909,  0.0860, -0.0145,  0.0742,  0.1678,\n",
      "         -0.1278, -0.0734,  0.0133,  0.0270],\n",
      "        [-0.0280, -0.1708,  0.1344, -0.0610, -0.1278, -0.1096,  0.2222, -0.2074,\n",
      "         -0.0365,  0.0183,  0.1016, -0.1211,  0.0975, -0.2206, -0.1795, -0.1675,\n",
      "         -0.0586, -0.1500,  0.2223,  0.0893],\n",
      "        [ 0.0589, -0.1769,  0.2040,  0.0535,  0.1989, -0.0678, -0.2069,  0.0788,\n",
      "          0.1875,  0.1498, -0.1182,  0.0178,  0.0670,  0.0251,  0.1731, -0.0030,\n",
      "          0.1544,  0.1592, -0.1546,  0.1601],\n",
      "        [ 0.0268, -0.1492,  0.0457,  0.1531,  0.1953,  0.0851,  0.0420,  0.0518,\n",
      "          0.1032, -0.0440,  0.1730,  0.0355,  0.1477,  0.1093, -0.1351,  0.0400,\n",
      "         -0.0672, -0.0510, -0.1550, -0.1781],\n",
      "        [ 0.2094, -0.0171, -0.0931,  0.0821,  0.1581,  0.0353, -0.1357, -0.0117,\n",
      "          0.1415,  0.0118, -0.2185, -0.1231,  0.2161, -0.0616, -0.1097, -0.1681,\n",
      "         -0.1930, -0.0153,  0.1946,  0.1083],\n",
      "        [ 0.0260,  0.0131,  0.0608, -0.2166, -0.2172,  0.0010,  0.0471, -0.1638,\n",
      "          0.1869,  0.0875,  0.1471, -0.0164,  0.1225, -0.1277, -0.2093,  0.0923,\n",
      "          0.0370,  0.0133, -0.1742,  0.1451],\n",
      "        [ 0.0230, -0.0344,  0.1886,  0.0876,  0.2026,  0.1621, -0.0593, -0.1085,\n",
      "          0.1583, -0.1469,  0.0710, -0.1811, -0.0482, -0.1995,  0.1304,  0.1813,\n",
      "         -0.1243, -0.0363,  0.0732,  0.1389],\n",
      "        [ 0.0050, -0.2114, -0.1840,  0.0184,  0.1781,  0.0116,  0.0114,  0.0231,\n",
      "         -0.0444,  0.1344,  0.1248,  0.1948, -0.0530, -0.0672, -0.0178, -0.0661,\n",
      "         -0.1535, -0.1175, -0.1432, -0.0503],\n",
      "        [ 0.0439,  0.1082,  0.1085,  0.0582, -0.1507, -0.0837,  0.0322,  0.1209,\n",
      "         -0.0812, -0.0013,  0.0706,  0.0332,  0.0321, -0.1011,  0.1241,  0.0104,\n",
      "          0.0840, -0.0622,  0.1529,  0.2125],\n",
      "        [-0.0903, -0.2138, -0.1971,  0.0343,  0.2196, -0.1387,  0.0505,  0.1512,\n",
      "          0.1557, -0.0545,  0.0614, -0.2033, -0.2216,  0.1836,  0.0033,  0.2063,\n",
      "         -0.0697,  0.0531, -0.1012, -0.1530],\n",
      "        [-0.0213,  0.2162, -0.0931,  0.1954,  0.2187, -0.1929, -0.0022, -0.0464,\n",
      "         -0.1673, -0.0252,  0.0628, -0.1160, -0.0819,  0.1968, -0.1868, -0.0919,\n",
      "          0.0392,  0.1100, -0.1566,  0.1836],\n",
      "        [ 0.1498,  0.1005, -0.0639,  0.1019, -0.2203,  0.0684,  0.1131, -0.1511,\n",
      "         -0.1597,  0.1108, -0.1145, -0.2173, -0.0113, -0.1284, -0.2128, -0.0632,\n",
      "         -0.1929, -0.0495, -0.0231, -0.1783],\n",
      "        [-0.0814, -0.0412, -0.1865, -0.1645, -0.1536,  0.0528, -0.1214, -0.0791,\n",
      "          0.1075, -0.1985,  0.1060,  0.1729,  0.1397,  0.0446, -0.2151, -0.2060,\n",
      "          0.2116, -0.0793,  0.1059, -0.0784],\n",
      "        [-0.0437,  0.1205,  0.1917,  0.1254,  0.0714,  0.0991, -0.0320,  0.0317,\n",
      "         -0.0911, -0.0833, -0.0210, -0.1735, -0.1103,  0.1652,  0.1006, -0.0515,\n",
      "          0.1700,  0.1868,  0.0354,  0.1529],\n",
      "        [-0.2156,  0.2133,  0.2062, -0.1852, -0.0479, -0.0548, -0.1458,  0.1745,\n",
      "         -0.0518,  0.0874,  0.1977,  0.0259,  0.1674, -0.0930,  0.0520, -0.2050,\n",
      "         -0.0267, -0.0300, -0.0187, -0.0241],\n",
      "        [ 0.1828,  0.0614,  0.1819,  0.1020,  0.0240, -0.0884, -0.1470, -0.1464,\n",
      "         -0.0431,  0.0591, -0.0887,  0.0112,  0.1018, -0.0940, -0.0226, -0.1548,\n",
      "         -0.1523,  0.0631, -0.1769, -0.0837]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0978, -0.1869,  0.1660, -0.0654, -0.2144, -0.1102,  0.0984,  0.1659,\n",
      "         0.1423, -0.0920,  0.0400, -0.1002, -0.0176,  0.0759, -0.2140,  0.2058,\n",
      "        -0.0180, -0.1187,  0.2141,  0.0808], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0659,  0.0756, -0.2166, -0.1721,  0.2092,  0.1131, -0.1074,  0.1464,\n",
      "         -0.0298,  0.0337, -0.0662,  0.0021, -0.1539, -0.0033,  0.1852, -0.0929,\n",
      "         -0.0385,  0.1845, -0.0636, -0.0268],\n",
      "        [ 0.1175,  0.0672,  0.1728, -0.1541,  0.0091,  0.1818, -0.0441,  0.0721,\n",
      "         -0.1893,  0.0604,  0.0182, -0.2145,  0.0100, -0.0837, -0.1383, -0.1915,\n",
      "          0.0889, -0.1424, -0.0260, -0.1849],\n",
      "        [-0.1269, -0.0618,  0.1177, -0.1065,  0.2049, -0.1639, -0.2069, -0.2062,\n",
      "         -0.1189, -0.1060,  0.1019,  0.0858, -0.0163,  0.1144,  0.0435,  0.0102,\n",
      "         -0.0456,  0.1580,  0.2105, -0.0077],\n",
      "        [-0.2046,  0.1010,  0.1124,  0.0842,  0.1070,  0.1948,  0.1399,  0.0955,\n",
      "         -0.1028, -0.0530, -0.0879,  0.0255, -0.0606,  0.1441,  0.1698,  0.1479,\n",
      "         -0.1232, -0.1153,  0.0970, -0.1829],\n",
      "        [ 0.1022,  0.1174, -0.0468, -0.0171, -0.1039, -0.2141, -0.1840, -0.2125,\n",
      "         -0.1623,  0.1550, -0.1899,  0.0274, -0.1846, -0.1971,  0.1841, -0.2005,\n",
      "          0.1163,  0.1771, -0.1867,  0.0906],\n",
      "        [-0.0422, -0.1584,  0.2019, -0.2192,  0.1736, -0.1791, -0.0467,  0.0063,\n",
      "         -0.0428,  0.0600,  0.1007,  0.1624, -0.1029,  0.0956, -0.1525, -0.1448,\n",
      "          0.0319, -0.2199,  0.1778, -0.0281],\n",
      "        [ 0.0396, -0.2076,  0.1582, -0.1761, -0.1754,  0.1801,  0.1226, -0.1065,\n",
      "          0.1541,  0.0800, -0.1580, -0.1075,  0.2101, -0.1905,  0.0082, -0.0611,\n",
      "          0.2232,  0.1443,  0.1797, -0.0201],\n",
      "        [ 0.1672, -0.0637, -0.1706,  0.0634,  0.0166,  0.2131, -0.1484,  0.0983,\n",
      "         -0.0102,  0.0268, -0.2105,  0.1605, -0.1763,  0.2072, -0.1728,  0.2230,\n",
      "          0.1753, -0.0986, -0.0288, -0.0695],\n",
      "        [-0.0367, -0.1070, -0.1546,  0.2117, -0.1379, -0.1549, -0.1125,  0.0155,\n",
      "         -0.1088, -0.1649,  0.0153,  0.1346,  0.0818, -0.0494,  0.0701, -0.0992,\n",
      "          0.0947,  0.1463, -0.0766,  0.0137],\n",
      "        [ 0.0356,  0.1459, -0.0666,  0.0419, -0.0991,  0.2055, -0.1538,  0.2015,\n",
      "         -0.0886, -0.0960, -0.1565, -0.0713, -0.2135,  0.0869,  0.0113,  0.1250,\n",
      "         -0.2001, -0.1000,  0.1382,  0.1251],\n",
      "        [-0.1597, -0.1736, -0.1532, -0.0236,  0.0980, -0.2050, -0.0876, -0.0533,\n",
      "         -0.1408, -0.1844,  0.0031, -0.1709, -0.0448, -0.0525,  0.1550, -0.0974,\n",
      "          0.2032, -0.1656,  0.0389,  0.2131],\n",
      "        [ 0.1638,  0.0038, -0.0121, -0.1246, -0.0742, -0.1704,  0.0050,  0.1375,\n",
      "         -0.0132,  0.1922, -0.1454,  0.0378, -0.1552, -0.0134,  0.1007,  0.1752,\n",
      "         -0.0242,  0.0750, -0.0777,  0.2199],\n",
      "        [ 0.0561, -0.0793, -0.1361,  0.1196, -0.2005,  0.0197, -0.1552, -0.1003,\n",
      "          0.1841, -0.0779,  0.2028, -0.1250, -0.2078,  0.0720, -0.0942,  0.0730,\n",
      "         -0.0253, -0.1269,  0.1739, -0.1474],\n",
      "        [ 0.0770,  0.0032,  0.2209,  0.2124, -0.0918, -0.2098,  0.2176,  0.1159,\n",
      "         -0.1431, -0.1679,  0.1063,  0.0515,  0.1324,  0.1211,  0.0471,  0.0193,\n",
      "         -0.0314,  0.1140,  0.1982, -0.2151],\n",
      "        [ 0.0533,  0.1957, -0.1045,  0.1461, -0.1890,  0.1019,  0.0271,  0.1273,\n",
      "          0.1056,  0.1411,  0.0786,  0.1206, -0.0788, -0.0028, -0.0895, -0.1628,\n",
      "          0.1342,  0.1042,  0.1331,  0.2200],\n",
      "        [-0.2023,  0.2197,  0.1421, -0.2102, -0.1122, -0.2144, -0.1956, -0.0491,\n",
      "          0.1170, -0.1927,  0.0766, -0.0480,  0.1283, -0.1714,  0.2139, -0.0676,\n",
      "         -0.0189, -0.1176, -0.0945,  0.1381],\n",
      "        [ 0.1453,  0.0568, -0.2072,  0.0995, -0.0619, -0.1310, -0.2190,  0.0550,\n",
      "          0.1331, -0.0357, -0.2134, -0.0069,  0.1516, -0.2043,  0.1772, -0.0699,\n",
      "         -0.0604,  0.0375,  0.0160, -0.0599],\n",
      "        [ 0.1402, -0.0065, -0.1487,  0.0302, -0.0419,  0.1488,  0.0397,  0.1771,\n",
      "         -0.1332, -0.2108,  0.0865,  0.1515, -0.0837,  0.1125,  0.0009,  0.1388,\n",
      "         -0.1494, -0.0283, -0.0385,  0.0739],\n",
      "        [ 0.0076, -0.1499, -0.1032,  0.0254, -0.0934, -0.0062, -0.0234, -0.0736,\n",
      "         -0.1717,  0.0228,  0.1345, -0.1072,  0.1952, -0.1362,  0.0081, -0.0021,\n",
      "         -0.0120,  0.1355,  0.1797,  0.1134],\n",
      "        [-0.0708, -0.2030,  0.2024, -0.1929, -0.0537,  0.1800, -0.0090,  0.1357,\n",
      "         -0.2007,  0.0445,  0.1281, -0.1151,  0.1506,  0.1092,  0.1304, -0.1577,\n",
      "          0.1393, -0.1504,  0.1774,  0.1252]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0376, -0.1442,  0.2192,  0.1591, -0.1409,  0.0996, -0.0869, -0.1425,\n",
      "         0.0710,  0.0480,  0.1396,  0.0696,  0.2116,  0.0687,  0.1560, -0.0080,\n",
      "        -0.0678, -0.0197,  0.0656,  0.0509], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0228, -0.2088,  0.0375, -0.0316,  0.0311, -0.0302, -0.2025, -0.0756,\n",
      "          0.1738, -0.0034,  0.1798, -0.2090,  0.1874,  0.1093, -0.0842, -0.1289,\n",
      "         -0.0684, -0.1042,  0.0620,  0.0720],\n",
      "        [ 0.1870, -0.1940,  0.0887, -0.0753,  0.1728,  0.1884, -0.1551, -0.2210,\n",
      "          0.1012, -0.0927, -0.1433, -0.0317, -0.2154, -0.1030, -0.0504,  0.0695,\n",
      "          0.2050, -0.1474,  0.0757,  0.1436],\n",
      "        [-0.1071,  0.1714,  0.1582,  0.1491, -0.1804, -0.0158, -0.0204,  0.0831,\n",
      "          0.1253,  0.0530, -0.0710, -0.1003, -0.0795,  0.1846, -0.2149,  0.1783,\n",
      "          0.1286, -0.1195,  0.0720,  0.2048],\n",
      "        [ 0.1455,  0.1925,  0.0593, -0.2071, -0.0113,  0.0574,  0.0886,  0.1755,\n",
      "         -0.0055, -0.0314, -0.1010, -0.0975, -0.1661,  0.0592,  0.0160,  0.0222,\n",
      "         -0.0337, -0.1217,  0.1088, -0.0916],\n",
      "        [-0.1639,  0.0290,  0.0655,  0.2103,  0.0967,  0.0626, -0.0792,  0.0345,\n",
      "          0.2018,  0.0832, -0.0877, -0.2152,  0.1119, -0.2135, -0.1130,  0.0988,\n",
      "         -0.1492, -0.1460,  0.2078, -0.0085],\n",
      "        [ 0.0756, -0.0884,  0.0215,  0.1592,  0.1747, -0.1181, -0.0387, -0.1378,\n",
      "         -0.0603,  0.1356,  0.1924, -0.1385, -0.0224, -0.0380, -0.1838, -0.0956,\n",
      "         -0.0503, -0.2048, -0.1977,  0.1654],\n",
      "        [-0.0561,  0.0605, -0.0816,  0.0085, -0.1815,  0.1144,  0.1801, -0.1296,\n",
      "         -0.1099, -0.1216, -0.1541,  0.1493, -0.1999, -0.0170,  0.1359,  0.1810,\n",
      "         -0.2020, -0.0379, -0.1618, -0.2058],\n",
      "        [ 0.1755,  0.0357, -0.1444, -0.0028,  0.0352,  0.1312,  0.0265, -0.1807,\n",
      "          0.1625,  0.0925, -0.1431, -0.0814,  0.1308, -0.1115, -0.0576, -0.2126,\n",
      "          0.2028,  0.0492,  0.0589, -0.0850],\n",
      "        [-0.2141, -0.1171, -0.1815, -0.0869, -0.0441, -0.1696, -0.2223, -0.0884,\n",
      "         -0.1333, -0.1147, -0.1652, -0.0381, -0.1828,  0.0036, -0.0444, -0.0863,\n",
      "         -0.1213, -0.2136,  0.1772,  0.2111],\n",
      "        [ 0.1564,  0.0157,  0.1349,  0.1278,  0.0491,  0.1175, -0.2095,  0.2143,\n",
      "         -0.1152,  0.0101, -0.0566,  0.0533,  0.0879, -0.2136, -0.1635, -0.2108,\n",
      "         -0.0615,  0.1003,  0.1135, -0.1899],\n",
      "        [-0.0763,  0.1325, -0.1728, -0.0315,  0.0501,  0.2081, -0.0260,  0.1566,\n",
      "          0.0427,  0.1086, -0.2065, -0.0760,  0.0645, -0.0825,  0.0896,  0.0485,\n",
      "          0.1469,  0.1279, -0.0830, -0.0748],\n",
      "        [-0.1022, -0.2114, -0.2167, -0.1932, -0.1822, -0.0955,  0.0059,  0.0240,\n",
      "          0.1440,  0.1666, -0.1633, -0.1500,  0.1831,  0.0954, -0.1217,  0.1267,\n",
      "          0.1094, -0.1219, -0.0312,  0.0998],\n",
      "        [-0.1160, -0.1162,  0.1474,  0.1886,  0.1866, -0.1049,  0.0277, -0.1028,\n",
      "         -0.0024, -0.0860, -0.0059,  0.0464, -0.1991,  0.0981,  0.0159, -0.0700,\n",
      "          0.0297, -0.0200,  0.0694, -0.0178],\n",
      "        [ 0.1063,  0.1120,  0.0839, -0.0642,  0.0153,  0.1855,  0.1156, -0.0736,\n",
      "          0.0903, -0.1366, -0.0160, -0.0583,  0.0790, -0.1423,  0.1215, -0.1978,\n",
      "          0.1522, -0.1793,  0.1835, -0.0162],\n",
      "        [-0.0078, -0.0551, -0.2163, -0.1293, -0.1321, -0.1854, -0.1023, -0.0595,\n",
      "         -0.0416,  0.1483, -0.1095, -0.1274, -0.1240,  0.1118,  0.1453,  0.1079,\n",
      "          0.1294, -0.1283, -0.0513,  0.0148],\n",
      "        [ 0.2195, -0.1314,  0.2123, -0.0889,  0.1333,  0.1629, -0.0221,  0.1216,\n",
      "         -0.0174,  0.0381, -0.1738, -0.0683, -0.2163, -0.0391,  0.0459,  0.0985,\n",
      "          0.2069, -0.1313,  0.0880,  0.2031],\n",
      "        [ 0.2212, -0.0690,  0.2091,  0.1830,  0.0956, -0.1713, -0.2082,  0.1261,\n",
      "          0.1971,  0.0365,  0.0134,  0.1364, -0.1276, -0.1449,  0.0597,  0.1950,\n",
      "         -0.1965,  0.0291, -0.1524, -0.1988],\n",
      "        [ 0.1086, -0.1180,  0.1246,  0.0207,  0.1011,  0.0022,  0.1136,  0.0935,\n",
      "         -0.0883,  0.0396, -0.1256,  0.1473, -0.0912, -0.2025, -0.0520, -0.1646,\n",
      "         -0.1768, -0.0129, -0.0879, -0.1680],\n",
      "        [ 0.0537, -0.0112, -0.0964,  0.1604, -0.1970, -0.1294, -0.0155,  0.0430,\n",
      "          0.0130,  0.1245, -0.0520,  0.1705, -0.1662,  0.1061, -0.1429,  0.1568,\n",
      "          0.1669,  0.1009,  0.0203, -0.2095],\n",
      "        [ 0.1134, -0.1003, -0.0354, -0.0924,  0.1596, -0.0471,  0.1807, -0.0444,\n",
      "          0.1076, -0.0212,  0.0107,  0.1842, -0.0701, -0.0666,  0.0671,  0.1812,\n",
      "         -0.1637,  0.1619, -0.1717, -0.0209]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1002, -0.1551,  0.0445, -0.2061,  0.2136, -0.0299, -0.1188, -0.0158,\n",
      "        -0.0653, -0.1222,  0.2224, -0.0703,  0.0575, -0.0581, -0.1774,  0.1931,\n",
      "         0.0690,  0.1232,  0.0440, -0.1400], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1878, -0.2012,  0.1804,  0.0954,  0.1488, -0.0468,  0.1055,  0.1838,\n",
      "         -0.0778, -0.0666,  0.1368,  0.1312,  0.1398,  0.1905,  0.0917,  0.1283,\n",
      "          0.0958,  0.1273, -0.1880,  0.0350],\n",
      "        [ 0.1986, -0.1542, -0.1539, -0.1485, -0.0480,  0.0669,  0.0847, -0.0915,\n",
      "          0.1781,  0.1778,  0.0012,  0.1337,  0.1926, -0.0639, -0.1739, -0.0436,\n",
      "         -0.0955,  0.1760,  0.0776, -0.2230],\n",
      "        [-0.1263,  0.1470,  0.1492,  0.0660, -0.0556,  0.0043, -0.0979,  0.1370,\n",
      "          0.1617, -0.2170,  0.0069, -0.2185,  0.2103, -0.0849,  0.2115, -0.0812,\n",
      "         -0.0287,  0.2078,  0.1280,  0.0005],\n",
      "        [ 0.0023, -0.0282,  0.0104,  0.1481, -0.1100, -0.1459, -0.1712, -0.1860,\n",
      "          0.0771,  0.1717, -0.2115,  0.1021,  0.0401, -0.0249, -0.1238, -0.0067,\n",
      "          0.0918, -0.0863,  0.1715,  0.1345],\n",
      "        [-0.0821,  0.1147,  0.0911,  0.0671,  0.1040,  0.2026, -0.1183, -0.1683,\n",
      "          0.0986,  0.2222, -0.1691,  0.1849, -0.0479, -0.0217,  0.0140,  0.2187,\n",
      "          0.1110, -0.1564, -0.0517,  0.0268],\n",
      "        [-0.0147, -0.1755, -0.2066, -0.0453, -0.0282, -0.0194,  0.1739,  0.0722,\n",
      "          0.0269,  0.2198,  0.0370, -0.0280, -0.1657,  0.1929, -0.1915,  0.0754,\n",
      "          0.1049,  0.1940,  0.1697, -0.0798],\n",
      "        [-0.1473, -0.0335,  0.0549, -0.0228, -0.1913, -0.1919, -0.1869,  0.1961,\n",
      "         -0.1177, -0.1538, -0.1460,  0.2005, -0.1439, -0.2225, -0.1561,  0.1002,\n",
      "          0.0584,  0.0925, -0.1755,  0.0588],\n",
      "        [ 0.1040,  0.2096, -0.1922, -0.1247,  0.1540, -0.0727,  0.0653,  0.2215,\n",
      "          0.2035, -0.1794, -0.0732,  0.1105, -0.0484,  0.1512, -0.0427, -0.1093,\n",
      "         -0.0512, -0.1424,  0.1513, -0.2220],\n",
      "        [ 0.0665,  0.2051,  0.2148, -0.0461,  0.1648, -0.1813,  0.0704,  0.0803,\n",
      "         -0.0263, -0.2184, -0.1199,  0.1172, -0.0953, -0.0319, -0.1486,  0.1488,\n",
      "         -0.2070,  0.0855,  0.1682,  0.1158],\n",
      "        [ 0.0245,  0.1242, -0.0457, -0.0865, -0.1829,  0.0974,  0.1251,  0.1216,\n",
      "          0.1839, -0.2121,  0.0138,  0.0959, -0.0354,  0.0959, -0.0805,  0.1849,\n",
      "         -0.2124, -0.0731,  0.2127,  0.1612],\n",
      "        [ 0.1027, -0.0108,  0.1089, -0.1731, -0.1882,  0.0915, -0.2102, -0.0941,\n",
      "         -0.0806, -0.0779,  0.1312, -0.1446,  0.0759, -0.1481, -0.0742,  0.2235,\n",
      "         -0.0464, -0.1530, -0.1378,  0.1362],\n",
      "        [ 0.0565, -0.1684, -0.1922,  0.0165,  0.1940, -0.1325,  0.1785,  0.0456,\n",
      "          0.1588,  0.2042,  0.0644,  0.0271, -0.1962,  0.0753, -0.1988, -0.1728,\n",
      "          0.1444,  0.1681,  0.0589, -0.0890],\n",
      "        [-0.1856,  0.1532,  0.0588, -0.0596,  0.0857, -0.0575, -0.2153,  0.1747,\n",
      "         -0.0014,  0.2059,  0.0981,  0.1983, -0.1282,  0.0403,  0.0114, -0.1126,\n",
      "         -0.1706, -0.1280,  0.0454, -0.1195],\n",
      "        [ 0.0634,  0.1533, -0.2123, -0.1768, -0.1319,  0.0956, -0.1829,  0.1867,\n",
      "         -0.1257,  0.1995, -0.0562, -0.0268, -0.0355, -0.1916, -0.0713, -0.1671,\n",
      "         -0.2137, -0.0628, -0.2181, -0.1464],\n",
      "        [-0.0393,  0.0939,  0.1680, -0.1634, -0.2126, -0.0149,  0.0357,  0.1578,\n",
      "         -0.0503,  0.0452,  0.0879,  0.0403, -0.0077,  0.1455,  0.1336,  0.1914,\n",
      "          0.0391,  0.0524,  0.0689, -0.0181],\n",
      "        [-0.1906, -0.0317,  0.1165, -0.1213, -0.2230,  0.0415, -0.0062, -0.1621,\n",
      "         -0.0885,  0.0262, -0.2204,  0.1654, -0.0972, -0.0657,  0.1905,  0.0530,\n",
      "         -0.2092,  0.1017, -0.0800, -0.1383],\n",
      "        [-0.0154,  0.1389,  0.0491, -0.1376, -0.1494,  0.0256, -0.0388,  0.1943,\n",
      "          0.1174,  0.0347,  0.2211,  0.1727, -0.0175,  0.2017, -0.2089, -0.0480,\n",
      "         -0.2072,  0.1066,  0.2067,  0.0585],\n",
      "        [-0.2230, -0.0947,  0.0439, -0.0387,  0.2233,  0.0719,  0.2087,  0.2003,\n",
      "         -0.0191,  0.1931,  0.1463, -0.1378,  0.1311,  0.2164, -0.0616, -0.2230,\n",
      "         -0.1262, -0.0948,  0.0657, -0.0661],\n",
      "        [-0.0416, -0.0300, -0.1206,  0.2140, -0.2038, -0.1166, -0.1173,  0.1758,\n",
      "         -0.1080, -0.2106,  0.1812,  0.2101,  0.2053,  0.1788, -0.0940, -0.2145,\n",
      "          0.1073,  0.0171,  0.0318, -0.2175],\n",
      "        [ 0.1495, -0.0315, -0.2129,  0.1824,  0.1807,  0.0681, -0.1841,  0.2156,\n",
      "         -0.0200,  0.1737,  0.0331,  0.1955,  0.1890,  0.1625, -0.1178, -0.1205,\n",
      "         -0.0559, -0.0917, -0.0102,  0.2035]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0363, -0.0686, -0.0296, -0.0438,  0.1224,  0.1282, -0.2187,  0.0447,\n",
      "        -0.0498,  0.0963, -0.0530, -0.1325,  0.0219, -0.1977, -0.0043,  0.2092,\n",
      "        -0.0410, -0.2224, -0.1428,  0.1185], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1939,  0.1024,  0.0578,  0.1244,  0.2226, -0.2094, -0.0364,  0.1943,\n",
      "         -0.0923, -0.0825,  0.1264, -0.1477, -0.0258,  0.1318, -0.0758, -0.2011,\n",
      "          0.2199, -0.2221, -0.1496,  0.2172],\n",
      "        [ 0.0749,  0.0170,  0.0858, -0.0142, -0.0807, -0.0239, -0.1745, -0.0453,\n",
      "         -0.1944, -0.1192, -0.1454, -0.1669, -0.1252, -0.1067,  0.1261, -0.0731,\n",
      "         -0.1808,  0.0230, -0.0490,  0.1221],\n",
      "        [ 0.1664,  0.1887, -0.0265,  0.1478,  0.1925,  0.1986,  0.1960, -0.1577,\n",
      "          0.1921, -0.0200, -0.1982,  0.2174, -0.1954,  0.0551, -0.2001,  0.0281,\n",
      "          0.0022, -0.0374,  0.0128, -0.1418],\n",
      "        [-0.0105,  0.0110, -0.0486,  0.1831, -0.0301,  0.0736,  0.1584, -0.0078,\n",
      "          0.1207,  0.1538, -0.0392,  0.1396, -0.2167,  0.1529, -0.0918,  0.0572,\n",
      "          0.0214, -0.0007,  0.1106, -0.0274],\n",
      "        [-0.1045, -0.0354, -0.2043,  0.1711,  0.0209, -0.0123,  0.1878,  0.1994,\n",
      "         -0.1788,  0.1634, -0.1471,  0.0065, -0.0479, -0.2142, -0.0927, -0.0442,\n",
      "          0.0975, -0.0585, -0.0012, -0.0633],\n",
      "        [-0.0387,  0.1883,  0.1574,  0.0419,  0.0988,  0.1922,  0.0996,  0.0613,\n",
      "          0.2129,  0.1897, -0.0987, -0.1721,  0.1443, -0.1598, -0.0261, -0.0072,\n",
      "         -0.2007, -0.0421,  0.0638,  0.1598],\n",
      "        [-0.0103,  0.1136, -0.0921,  0.2057,  0.0303,  0.0162,  0.1795, -0.0186,\n",
      "         -0.1375,  0.1677, -0.0190,  0.1087, -0.1239,  0.0139, -0.1110,  0.2109,\n",
      "          0.0677, -0.0291,  0.1100, -0.0018],\n",
      "        [ 0.2177,  0.1071, -0.1946,  0.1604,  0.1621,  0.1438, -0.1966,  0.1799,\n",
      "         -0.0938,  0.0666, -0.1209,  0.0403,  0.0653,  0.2129,  0.2124,  0.1243,\n",
      "          0.0163, -0.0051, -0.1171, -0.0485],\n",
      "        [-0.0824, -0.0121,  0.1770, -0.1143, -0.1434,  0.2226,  0.0254, -0.0233,\n",
      "         -0.0109, -0.0595,  0.0654, -0.0042,  0.1052,  0.1361,  0.0298, -0.1016,\n",
      "         -0.1827,  0.0177, -0.1005, -0.1569],\n",
      "        [ 0.1027, -0.1104, -0.0259, -0.2163, -0.1093, -0.0284, -0.2043, -0.1440,\n",
      "         -0.1347,  0.0062, -0.0079,  0.0994,  0.0096,  0.1500, -0.1018,  0.0897,\n",
      "          0.1418,  0.0361,  0.0151, -0.2027]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1481,  0.1114, -0.2173,  0.1205,  0.0235,  0.1211,  0.1249,  0.0977,\n",
      "        -0.1345,  0.2124], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3129,  0.2982, -0.1266,  0.1923,  0.0646, -0.0689,  0.0641,  0.3099,\n",
      "         -0.0665,  0.1607],\n",
      "        [ 0.1245, -0.0721,  0.2062, -0.1039, -0.3084,  0.0686, -0.0079, -0.2774,\n",
      "         -0.2183,  0.0138],\n",
      "        [-0.2481,  0.2855, -0.3051,  0.2105,  0.2614, -0.0656, -0.1336,  0.2827,\n",
      "          0.1823, -0.2302],\n",
      "        [ 0.0770,  0.2083, -0.2624,  0.2649, -0.2789, -0.2913,  0.2869,  0.2250,\n",
      "          0.1770, -0.2195],\n",
      "        [-0.1928,  0.1975, -0.0023,  0.0843,  0.1543,  0.1828,  0.0694,  0.0449,\n",
      "         -0.2717,  0.1002],\n",
      "        [-0.1198,  0.0229, -0.0231, -0.1018, -0.1094, -0.0029, -0.0526,  0.0606,\n",
      "          0.2394, -0.2252],\n",
      "        [ 0.3022,  0.0499, -0.2312, -0.1403, -0.0772, -0.1585, -0.0309,  0.2821,\n",
      "          0.0571, -0.1611],\n",
      "        [-0.2638, -0.2831,  0.2099,  0.2499, -0.2586, -0.2903, -0.1401, -0.1215,\n",
      "          0.1297, -0.1368],\n",
      "        [ 0.0528,  0.0297,  0.0501, -0.1429, -0.1789, -0.0196, -0.1579, -0.0362,\n",
      "         -0.0040,  0.0626],\n",
      "        [-0.2209, -0.0050, -0.2068,  0.1233, -0.2899, -0.3120, -0.2261, -0.0646,\n",
      "         -0.2713,  0.0190],\n",
      "        [ 0.1810, -0.0170, -0.1150, -0.0440,  0.0123,  0.1689, -0.2041, -0.1541,\n",
      "         -0.1280, -0.0749],\n",
      "        [-0.2385,  0.1449,  0.1299,  0.2073,  0.2625, -0.3105,  0.1711,  0.0538,\n",
      "         -0.0971, -0.1630],\n",
      "        [-0.0697, -0.1892,  0.0421,  0.1421,  0.0626,  0.2549, -0.2701,  0.2881,\n",
      "          0.0363,  0.1503],\n",
      "        [-0.2727,  0.2562, -0.2327,  0.0071,  0.3090,  0.1692, -0.1612, -0.1079,\n",
      "          0.0158,  0.2855],\n",
      "        [ 0.0265,  0.3065, -0.0468,  0.0129, -0.0738,  0.1036, -0.1091,  0.2433,\n",
      "          0.0689, -0.2814],\n",
      "        [-0.2066,  0.2666,  0.2387,  0.1531, -0.2863,  0.2566,  0.1374, -0.0862,\n",
      "          0.0872,  0.2915],\n",
      "        [ 0.0051,  0.2371, -0.2699,  0.1584, -0.1861,  0.1996, -0.2562, -0.1097,\n",
      "         -0.1613, -0.1054],\n",
      "        [-0.2523, -0.2676,  0.2004,  0.2495, -0.1978, -0.1345,  0.2147, -0.3046,\n",
      "         -0.2996, -0.0958],\n",
      "        [-0.0502, -0.0471, -0.1868,  0.0803, -0.0043,  0.0836, -0.2906, -0.2227,\n",
      "          0.2704, -0.2062],\n",
      "        [-0.1592, -0.1895,  0.2569, -0.1627, -0.1361,  0.0729,  0.1902, -0.0175,\n",
      "         -0.0358, -0.1239]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0516, -0.2438, -0.1262,  0.1353,  0.2660, -0.0175,  0.1266, -0.3107,\n",
      "         0.2365, -0.2706,  0.0134,  0.3061, -0.2873, -0.1542, -0.2299,  0.0422,\n",
      "        -0.0017, -0.0712,  0.2607, -0.0474], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1104, -0.2268, -0.0465,  0.1339,  0.0838, -0.0074, -0.1355,  0.1297,\n",
      "         -0.0831, -0.2420],\n",
      "        [ 0.0459,  0.2679, -0.1651,  0.0147,  0.1565, -0.2074,  0.2505, -0.1409,\n",
      "          0.1665, -0.3056],\n",
      "        [-0.1247,  0.0149, -0.0152, -0.0822,  0.2246,  0.2812,  0.0783,  0.1224,\n",
      "         -0.0906,  0.0806],\n",
      "        [-0.2884, -0.1426, -0.0253, -0.1195,  0.1870,  0.0567,  0.2721,  0.2905,\n",
      "          0.2276,  0.1066],\n",
      "        [-0.2961,  0.2059, -0.2639, -0.2596, -0.1173, -0.1676,  0.3086,  0.1922,\n",
      "         -0.1283,  0.1332],\n",
      "        [ 0.1259, -0.1115,  0.1702,  0.0087, -0.2846, -0.0403, -0.1014,  0.2227,\n",
      "         -0.0446, -0.0290],\n",
      "        [-0.1121, -0.0938,  0.0487,  0.1235,  0.0573,  0.3045, -0.1920,  0.0084,\n",
      "          0.1981, -0.1585],\n",
      "        [ 0.2025, -0.0368,  0.1378,  0.0328, -0.1879, -0.0924,  0.1942,  0.0035,\n",
      "          0.1406, -0.2424],\n",
      "        [-0.2553,  0.2330,  0.0528,  0.0240,  0.2190,  0.1390, -0.2544,  0.2009,\n",
      "         -0.1347, -0.0969],\n",
      "        [ 0.1174, -0.0582, -0.0818, -0.0664,  0.0449,  0.2047,  0.1206,  0.3002,\n",
      "         -0.2737,  0.1364]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0412,  0.0094,  0.1697,  0.0939, -0.1802, -0.0542,  0.2466, -0.2259,\n",
      "        -0.1962, -0.1868], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0099,  0.0047, -0.0443, -0.1054, -0.2653,  0.2041,  0.1147,  0.1939,\n",
      "         -0.1745, -0.2354],\n",
      "        [ 0.0118,  0.3097,  0.2351,  0.2707,  0.2333, -0.0140, -0.2342, -0.1313,\n",
      "         -0.2784,  0.2153],\n",
      "        [-0.1604,  0.1370, -0.1578, -0.3086, -0.2754,  0.2805, -0.2592, -0.1283,\n",
      "         -0.1712, -0.2708],\n",
      "        [-0.1791,  0.2501, -0.1381,  0.0966,  0.3001,  0.0009, -0.0362,  0.0430,\n",
      "         -0.2923, -0.2274],\n",
      "        [-0.0140, -0.0507,  0.0357,  0.1779, -0.2993, -0.1312,  0.2698,  0.2774,\n",
      "         -0.1670,  0.0033],\n",
      "        [ 0.2704,  0.0215, -0.1622,  0.0654,  0.1234,  0.0073,  0.2690, -0.2195,\n",
      "          0.0113,  0.2706],\n",
      "        [-0.2203, -0.1214, -0.0603,  0.2344,  0.0101, -0.0232,  0.1953,  0.0996,\n",
      "         -0.0851,  0.0093],\n",
      "        [ 0.0639, -0.2963,  0.3080, -0.2186,  0.0493,  0.2002,  0.0466,  0.2439,\n",
      "         -0.1015,  0.1596],\n",
      "        [ 0.0972,  0.3117,  0.1175, -0.2151, -0.1818,  0.2577,  0.2601, -0.1492,\n",
      "          0.1780,  0.0406],\n",
      "        [-0.1704, -0.2442,  0.1649, -0.1537,  0.1555,  0.2937, -0.1938, -0.2606,\n",
      "          0.0468, -0.2285],\n",
      "        [-0.2010, -0.1387, -0.2147,  0.1022,  0.2656, -0.2680,  0.0275,  0.1547,\n",
      "         -0.3153, -0.0454],\n",
      "        [-0.0060, -0.1575,  0.0978, -0.2715,  0.2832, -0.0193,  0.0597,  0.0725,\n",
      "         -0.0175, -0.0644],\n",
      "        [ 0.1506, -0.1401,  0.0270,  0.2703,  0.0987,  0.0422,  0.2023,  0.2643,\n",
      "          0.1310,  0.1736],\n",
      "        [ 0.0792,  0.0870,  0.0140, -0.0613,  0.2949, -0.0387, -0.3093,  0.0556,\n",
      "         -0.1324,  0.1521],\n",
      "        [ 0.0112, -0.2389,  0.0724,  0.2247, -0.1857,  0.0656, -0.3065,  0.2249,\n",
      "         -0.0484,  0.1484],\n",
      "        [-0.1592,  0.2367,  0.2330,  0.0227,  0.1465,  0.2531,  0.1686,  0.0152,\n",
      "         -0.0640, -0.2601],\n",
      "        [-0.1232, -0.1316,  0.0134, -0.0236,  0.1474, -0.2760,  0.2842,  0.2532,\n",
      "          0.2603,  0.0684],\n",
      "        [ 0.2381, -0.2431, -0.2326,  0.2355,  0.2864, -0.1569,  0.1709, -0.0369,\n",
      "         -0.0954, -0.1615],\n",
      "        [ 0.1301, -0.0988, -0.1588, -0.2892,  0.0309,  0.0887,  0.2503, -0.1709,\n",
      "         -0.2854,  0.0935],\n",
      "        [ 0.1679, -0.0540,  0.1564,  0.1865, -0.1360, -0.1302, -0.2972, -0.3087,\n",
      "         -0.1622, -0.2123]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0954, -0.0213,  0.1184,  0.2872,  0.1010,  0.2182,  0.1101,  0.0798,\n",
      "         0.0065,  0.0897,  0.0111, -0.2914, -0.2397, -0.0603, -0.1337,  0.2707,\n",
      "        -0.0096, -0.1960,  0.0739, -0.0394], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.9156e-02, -1.6240e-01, -1.2317e-01, -1.7907e-01,  8.7106e-03,\n",
      "          1.9949e-01,  1.6163e-02,  2.3937e-02,  9.1552e-02,  8.4857e-02,\n",
      "         -2.1498e-01,  5.2412e-02,  9.7397e-02, -1.1696e-01, -4.2050e-04,\n",
      "          1.8137e-02,  8.8629e-02,  1.6961e-01, -2.0263e-01, -1.2191e-01],\n",
      "        [ 5.7175e-02, -8.4966e-02,  2.1743e-01,  1.3343e-01,  1.6053e-01,\n",
      "          8.7710e-02, -7.0877e-02,  1.8392e-01,  1.7307e-01,  1.1602e-01,\n",
      "         -7.1704e-02, -5.8777e-02, -5.7409e-02,  1.9092e-01, -1.8601e-01,\n",
      "          2.1711e-01,  1.5802e-01, -8.5697e-02, -6.6245e-02,  5.7822e-03],\n",
      "        [-8.6476e-02,  5.1883e-03,  1.7462e-01,  9.3128e-02,  5.9937e-02,\n",
      "          1.7728e-01, -1.8386e-01, -1.6192e-01, -5.0080e-02,  1.3039e-01,\n",
      "          2.0972e-01, -9.7499e-02,  1.5314e-01,  2.0390e-01, -8.6956e-02,\n",
      "         -9.4710e-02,  1.6225e-01, -1.3118e-01,  1.7675e-01,  1.0205e-01],\n",
      "        [ 1.1740e-01, -4.7072e-02, -6.8501e-02,  2.0022e-01, -4.5642e-02,\n",
      "          4.2982e-02, -1.7877e-01,  1.2872e-01, -2.1401e-01, -1.0021e-01,\n",
      "          4.3753e-02,  8.6619e-02,  2.9686e-02,  1.9996e-01,  1.7927e-01,\n",
      "         -1.6528e-01,  8.5349e-02,  1.7545e-01,  2.1481e-01,  1.6805e-01],\n",
      "        [-3.8918e-02,  1.9557e-02, -1.0332e-01, -8.1795e-02, -1.8893e-01,\n",
      "         -1.1785e-01, -1.6209e-01,  9.4716e-02, -2.2336e-01, -9.5273e-02,\n",
      "          6.1940e-02,  1.5155e-01, -1.6726e-01, -1.2784e-01,  8.3872e-02,\n",
      "         -2.0532e-01, -1.5551e-01, -6.1402e-02, -1.7345e-01,  2.1893e-01],\n",
      "        [ 1.4101e-01,  1.4356e-01,  9.3262e-02,  2.0437e-01, -1.9734e-02,\n",
      "         -7.5601e-02, -1.5546e-01, -1.2917e-01, -1.9284e-01, -1.4332e-01,\n",
      "         -1.8517e-01, -3.1060e-02,  2.5444e-02,  1.9558e-01, -1.0215e-01,\n",
      "          5.0173e-02, -4.4316e-02,  1.3844e-01,  1.0442e-01, -8.3699e-02],\n",
      "        [-1.3806e-01,  4.1191e-02, -6.7127e-02,  1.5215e-01, -5.2290e-02,\n",
      "          1.3554e-01, -5.3434e-02, -1.4490e-01,  2.8091e-02,  1.5049e-01,\n",
      "         -1.6866e-01, -3.4015e-02,  4.9808e-02,  5.7197e-02,  7.3117e-02,\n",
      "          1.7043e-01,  1.1191e-01,  7.0031e-02, -1.4316e-01,  8.4744e-02],\n",
      "        [ 1.0376e-02, -1.4056e-01,  7.8753e-02,  1.9484e-01, -1.1824e-01,\n",
      "         -1.6810e-02, -1.8007e-02,  2.5424e-02, -2.5369e-02,  2.6958e-02,\n",
      "          1.8640e-01, -1.8221e-01, -2.0893e-01,  7.3510e-02,  6.5890e-02,\n",
      "         -2.2437e-02,  1.6043e-01, -1.3881e-01, -4.8850e-04,  1.3588e-01],\n",
      "        [ 6.4679e-02, -4.6561e-02, -4.3624e-02, -5.5227e-02,  4.4613e-03,\n",
      "         -1.1459e-03, -2.0725e-01, -8.1788e-02,  7.3771e-02, -5.2815e-02,\n",
      "          1.3984e-01,  1.2487e-01, -4.4690e-03, -1.2562e-01, -1.8512e-01,\n",
      "          7.3333e-02,  8.4793e-02,  2.0618e-01, -1.8200e-01, -1.6406e-01],\n",
      "        [-1.4156e-01,  4.1833e-02,  3.9832e-02, -3.2148e-02,  2.0860e-01,\n",
      "         -8.1347e-02,  4.2847e-02, -1.6487e-01,  1.3020e-01, -1.2308e-01,\n",
      "          1.0967e-01,  1.9735e-01, -2.5218e-02, -6.5768e-02, -1.7848e-01,\n",
      "          8.2947e-03,  2.2105e-01, -4.1811e-02,  2.2060e-02, -1.2430e-01],\n",
      "        [-1.5828e-01, -1.1499e-01,  1.4376e-01, -8.8132e-02, -2.0168e-01,\n",
      "         -1.6190e-01,  1.4365e-01, -1.9233e-01,  2.1623e-02, -1.0855e-02,\n",
      "          3.8340e-02,  1.7859e-01,  8.9531e-02, -2.0517e-02, -5.3266e-02,\n",
      "         -3.0776e-03,  2.5994e-03, -1.8673e-01,  3.2273e-02,  1.5738e-01],\n",
      "        [ 4.8873e-02, -1.5974e-01, -1.1589e-01,  4.3626e-02, -1.6909e-01,\n",
      "          1.0096e-01,  1.6576e-01, -2.0405e-01,  6.7977e-02,  3.6420e-02,\n",
      "          1.5730e-01, -1.4043e-01, -1.4968e-01, -3.5264e-02, -3.6243e-02,\n",
      "         -7.7468e-02,  1.8291e-01,  1.0689e-01, -3.9448e-03,  1.8369e-01],\n",
      "        [-1.2319e-01, -6.3687e-02, -1.2513e-01, -2.5863e-02, -2.9342e-02,\n",
      "          4.5902e-02, -1.2030e-01, -1.9534e-01,  1.7846e-01,  4.4554e-06,\n",
      "         -1.1372e-01, -4.1114e-02,  1.5524e-01, -3.3206e-02,  7.2261e-02,\n",
      "         -8.4552e-02, -5.5498e-02, -1.3973e-01,  1.2194e-01,  8.8486e-02],\n",
      "        [ 1.5677e-01, -1.9347e-01, -2.8900e-02, -1.1355e-01,  1.0974e-01,\n",
      "         -2.0682e-01, -5.4252e-02, -6.1051e-02,  1.7541e-01, -1.9864e-01,\n",
      "          7.6318e-02,  1.3916e-01, -3.5441e-02,  8.9368e-02,  1.0086e-01,\n",
      "          5.6114e-02,  2.0955e-01,  1.6785e-01, -2.2023e-01, -1.4248e-01],\n",
      "        [ 1.6463e-01,  9.3699e-02,  1.0080e-01, -9.2164e-02, -5.7480e-02,\n",
      "          1.1463e-01, -1.9197e-01, -4.5448e-02, -2.5893e-03,  5.2654e-03,\n",
      "         -2.1926e-02,  3.6389e-02, -1.9580e-01,  1.9026e-01,  1.2421e-01,\n",
      "         -1.5606e-01, -2.0026e-01, -9.9366e-03, -1.2409e-01,  1.8864e-01],\n",
      "        [-2.0719e-01, -1.3936e-02,  1.6319e-01,  1.1403e-01, -1.0438e-01,\n",
      "          6.7633e-02,  5.7158e-02,  2.6872e-02, -1.6351e-01, -1.2171e-01,\n",
      "          1.4536e-01,  3.3422e-02,  1.9657e-01,  1.5935e-01,  4.4457e-02,\n",
      "          1.5807e-01,  9.9569e-02, -2.0931e-02,  9.7073e-02, -1.3068e-02],\n",
      "        [-4.3118e-02, -2.8675e-02,  1.3899e-01, -1.1221e-01,  4.1927e-02,\n",
      "          1.6700e-01,  1.3223e-01,  1.2059e-01, -1.2046e-01,  6.2888e-02,\n",
      "         -7.5751e-02, -1.5521e-02,  1.1373e-02,  1.8743e-01,  1.4857e-01,\n",
      "         -3.9634e-02,  4.6781e-02,  1.4634e-01,  1.0463e-01,  6.0869e-02],\n",
      "        [ 2.0092e-01,  1.5430e-01,  2.2069e-01, -1.9605e-01,  1.1510e-01,\n",
      "          4.7636e-02,  2.1489e-01, -9.7272e-02, -6.5197e-02,  1.2938e-01,\n",
      "         -2.0595e-01,  7.0443e-02, -1.5015e-01,  7.7774e-02,  3.6910e-02,\n",
      "         -1.9175e-01, -4.0502e-02,  1.8125e-01, -1.7766e-01, -1.0691e-01],\n",
      "        [-1.6237e-01,  3.6291e-02,  1.6539e-01,  4.3708e-02, -1.1872e-01,\n",
      "          7.3042e-02,  1.2706e-01,  1.1253e-01, -2.5856e-02, -5.1290e-02,\n",
      "          1.9996e-01,  2.0749e-01, -8.3551e-02, -1.0993e-01, -4.9803e-02,\n",
      "          2.9419e-02, -1.9860e-02, -4.0426e-02,  9.4201e-03, -8.9490e-02],\n",
      "        [-7.3015e-02,  2.8985e-02, -4.1895e-02,  2.0748e-02,  1.3994e-01,\n",
      "          4.3049e-02, -1.4354e-01, -1.8514e-01, -2.2359e-01,  3.9666e-02,\n",
      "          1.6217e-01,  7.5604e-02,  3.9890e-02,  1.9836e-01,  1.7744e-01,\n",
      "         -2.7678e-02, -1.3962e-01,  1.6374e-01, -9.0467e-03, -1.3500e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0419,  0.1462,  0.1410,  0.0227, -0.0733,  0.0692, -0.1494, -0.0895,\n",
      "        -0.1230,  0.2113, -0.0327,  0.1156,  0.0114, -0.1226,  0.0272, -0.1163,\n",
      "         0.1350, -0.0196,  0.1929,  0.1650], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9787e-01,  1.0712e-01, -2.1157e-01,  2.1250e-01, -1.4714e-01,\n",
      "          8.4830e-02, -1.6386e-01,  1.9060e-01,  1.8073e-01,  2.0097e-01,\n",
      "          7.4120e-02, -1.0098e-03,  2.1356e-02,  2.2604e-02, -2.4303e-02,\n",
      "          1.4170e-01,  1.4053e-01,  1.3024e-01,  2.0665e-01,  5.4262e-02],\n",
      "        [ 1.4669e-01, -1.7170e-01,  7.1103e-02,  1.7590e-01, -1.9861e-01,\n",
      "         -1.4650e-01,  2.4991e-02,  7.7988e-02,  1.7785e-02,  1.1804e-01,\n",
      "         -1.3067e-01,  6.6680e-02, -7.1475e-02,  9.4602e-02,  9.7236e-02,\n",
      "          1.7110e-01, -8.6640e-02,  5.1065e-02,  1.0717e-01,  1.9463e-01],\n",
      "        [ 1.0558e-01,  1.4774e-01,  6.5575e-02,  2.1065e-03,  2.1769e-01,\n",
      "          3.8473e-02,  9.2645e-02,  1.2331e-01, -9.5331e-02,  2.5378e-02,\n",
      "         -2.1297e-01, -1.5303e-01, -1.8480e-01, -1.8597e-01,  6.3843e-02,\n",
      "         -8.2123e-02, -1.7551e-01, -4.0733e-02,  4.5303e-02, -1.1687e-01],\n",
      "        [ 1.0050e-03,  1.6730e-01,  1.7328e-01,  1.3341e-01,  1.7719e-01,\n",
      "          1.5719e-01, -1.6795e-01,  9.0208e-02,  3.2280e-02,  3.2425e-02,\n",
      "         -1.0795e-01,  1.7965e-01, -5.1283e-02, -6.1084e-02,  1.4927e-01,\n",
      "         -1.0684e-01, -8.0653e-02,  1.3373e-01, -4.2013e-02,  1.5773e-01],\n",
      "        [ 9.9927e-02, -6.5405e-02,  1.7987e-01,  3.3000e-02, -1.0266e-01,\n",
      "         -7.4889e-02,  8.9543e-02, -1.0867e-01, -7.7265e-02,  1.9129e-01,\n",
      "          8.4230e-02, -1.1883e-01, -6.5998e-03, -2.5238e-02, -2.1586e-01,\n",
      "          9.1964e-02, -1.8630e-01,  1.0157e-01, -1.3651e-01, -1.1158e-01],\n",
      "        [ 1.6791e-01, -2.9768e-02, -2.1717e-03,  1.8993e-01,  1.2166e-02,\n",
      "         -2.1229e-01,  2.1167e-01,  8.7944e-02, -1.5457e-02, -7.5967e-02,\n",
      "          2.0442e-01, -3.0997e-02, -3.6126e-02,  2.0765e-02, -1.5463e-01,\n",
      "         -6.8976e-03, -8.8622e-02,  9.9716e-02, -1.6777e-01,  1.2916e-01],\n",
      "        [ 9.4488e-02, -5.4180e-02, -1.3472e-01, -3.2312e-02,  1.8118e-01,\n",
      "         -4.1270e-02,  2.8918e-02, -1.0232e-02, -9.5412e-02, -1.2162e-01,\n",
      "          5.5229e-02,  9.3397e-02,  1.0937e-01, -1.3418e-02,  7.8792e-02,\n",
      "         -1.4538e-01,  8.9069e-02,  9.9998e-02, -1.0969e-01, -1.4035e-01],\n",
      "        [ 1.6171e-01, -2.1612e-01,  5.7466e-02,  1.6519e-01,  7.2552e-02,\n",
      "         -9.0303e-02,  2.7521e-02,  1.3963e-01,  1.3197e-01, -1.7912e-01,\n",
      "          7.3915e-03, -1.3201e-01, -9.4740e-02,  3.5184e-02, -1.7315e-01,\n",
      "         -8.6136e-02,  4.8288e-02,  1.4640e-01,  1.6498e-01,  3.1856e-02],\n",
      "        [-1.7638e-01,  7.8849e-02,  9.9217e-02, -9.5498e-03,  1.0254e-01,\n",
      "          2.0727e-01,  4.0943e-03,  8.3129e-02,  2.1858e-01, -9.5827e-02,\n",
      "         -6.9338e-02,  5.9052e-02, -7.3740e-03, -1.7566e-02,  1.3728e-01,\n",
      "          1.5287e-01, -1.8418e-01, -6.1262e-02, -1.1734e-01, -4.4988e-02],\n",
      "        [-1.7220e-01, -7.8509e-02,  7.9927e-02,  1.6626e-01, -1.7337e-01,\n",
      "         -1.4926e-01,  1.1265e-01, -5.8149e-03,  6.7785e-05, -1.5076e-02,\n",
      "         -1.6091e-01,  1.1456e-01,  9.5303e-02, -1.1668e-03, -1.7331e-01,\n",
      "          2.0135e-02,  6.6305e-02, -1.8683e-01,  2.0785e-01,  1.5770e-01],\n",
      "        [-8.3497e-02,  1.3347e-01, -4.4936e-02,  5.6157e-02,  4.5398e-02,\n",
      "         -6.1192e-02, -2.5939e-02, -1.9866e-01, -1.4971e-01,  2.9230e-02,\n",
      "         -1.1414e-01,  2.4101e-02,  1.1114e-01, -3.6671e-02, -4.3865e-02,\n",
      "         -1.9396e-01,  1.3105e-01, -1.4384e-01,  1.1070e-01,  1.7349e-01],\n",
      "        [ 1.2710e-01,  2.8777e-02,  1.3826e-02,  4.2290e-02,  1.4325e-02,\n",
      "         -1.1206e-01,  1.9605e-01,  5.9737e-02,  2.1808e-01,  3.5897e-02,\n",
      "          1.5073e-01,  1.3675e-01,  9.1827e-02, -1.9484e-02,  3.7123e-02,\n",
      "          2.1346e-01, -3.8375e-02,  2.3824e-02,  5.0215e-03,  5.4159e-02],\n",
      "        [ 2.1532e-01, -8.7908e-02,  3.0413e-02, -1.5822e-01, -7.9473e-02,\n",
      "          6.3199e-02, -1.3812e-01, -1.8903e-01,  7.3479e-02, -1.4562e-01,\n",
      "         -1.2731e-01,  6.0149e-03, -9.6651e-02, -1.8857e-01,  5.2429e-02,\n",
      "          1.1040e-01,  4.3878e-02, -2.2865e-02, -4.2929e-03,  1.3656e-01],\n",
      "        [ 1.6582e-01, -1.8935e-01, -1.5771e-01,  2.2306e-01,  2.1589e-01,\n",
      "          2.0705e-01,  1.1109e-01, -1.1562e-01, -2.9742e-02,  1.3963e-01,\n",
      "         -2.1031e-01,  1.8068e-01,  1.0599e-01,  2.1116e-01,  3.8657e-02,\n",
      "         -7.0348e-02,  2.5045e-02,  1.6175e-02,  8.8386e-02, -1.3122e-01],\n",
      "        [-7.9971e-02,  8.7183e-02,  1.3714e-01, -8.9056e-02,  9.9332e-02,\n",
      "         -8.7955e-02, -1.0170e-01,  8.0449e-02, -2.0790e-01, -1.0632e-01,\n",
      "          6.0455e-02,  1.3202e-01, -1.0136e-01, -3.9461e-02,  1.1922e-01,\n",
      "          6.4850e-02,  8.4859e-02,  1.4335e-01, -4.6024e-03,  1.6543e-01],\n",
      "        [ 1.0756e-01, -1.3709e-01,  8.6044e-02,  1.4923e-01, -1.1968e-01,\n",
      "          6.7427e-02,  1.4086e-01,  2.1429e-02, -1.7931e-01,  2.0079e-01,\n",
      "          1.2640e-02,  4.1332e-03, -6.2329e-02,  3.4085e-02, -1.5443e-01,\n",
      "         -1.7094e-01, -2.0704e-01, -3.4679e-03, -9.3000e-02,  2.1076e-01],\n",
      "        [-1.8147e-03, -3.6580e-02, -2.0564e-01, -2.0845e-01, -3.3270e-03,\n",
      "          2.0463e-02,  1.4760e-01,  5.1112e-03,  2.9845e-02, -1.8924e-01,\n",
      "         -1.9887e-02, -1.6107e-01,  6.4485e-02,  8.7870e-02,  5.9481e-02,\n",
      "         -1.0329e-01, -8.9580e-02,  6.9597e-02, -9.5772e-02,  1.0326e-01],\n",
      "        [-2.1242e-01, -1.8413e-01, -1.6624e-02,  2.2335e-01, -1.6804e-03,\n",
      "          1.3744e-01,  8.8716e-02, -1.6526e-02, -2.1365e-01,  1.2213e-01,\n",
      "         -2.1418e-01,  1.0795e-01,  4.3441e-03,  5.7731e-02, -1.1778e-01,\n",
      "         -1.8763e-03, -2.5903e-02,  1.5978e-01, -8.2576e-02, -1.5114e-01],\n",
      "        [-1.6874e-01, -1.5446e-01,  7.4094e-02, -8.2946e-02,  1.1902e-01,\n",
      "          7.3059e-03,  1.0157e-02,  2.0126e-01, -1.4103e-01, -1.3491e-01,\n",
      "         -1.1908e-01,  8.4755e-02, -1.6111e-01,  3.7355e-02, -6.0251e-02,\n",
      "         -1.5722e-01,  5.6096e-02, -1.6781e-01, -3.5587e-02, -1.9197e-01],\n",
      "        [ 1.6399e-01, -5.8049e-02, -1.9559e-01,  1.5808e-01, -1.7079e-01,\n",
      "         -4.9654e-02, -2.0340e-01,  4.1325e-02, -1.9673e-01, -2.2134e-02,\n",
      "          1.7558e-02, -1.6290e-01, -8.3567e-02,  2.1551e-01,  7.3956e-02,\n",
      "          7.0103e-02,  1.4408e-01, -1.3515e-02, -1.0512e-01,  9.4338e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0438, -0.0674, -0.1101,  0.0927, -0.0727, -0.0182, -0.1872, -0.0557,\n",
      "        -0.0074, -0.2018,  0.0504,  0.1697,  0.0747,  0.2115, -0.0699,  0.2033,\n",
      "         0.0385,  0.1298, -0.1367,  0.0480], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 7.8929e-02, -2.1927e-01, -1.2553e-01,  1.5142e-02,  4.2425e-02,\n",
      "         -1.2952e-01,  1.0042e-01, -7.4711e-02,  1.9212e-01,  7.5035e-02,\n",
      "          1.2418e-01,  1.7783e-02, -1.9169e-01, -4.4178e-02, -1.1475e-01,\n",
      "         -7.4970e-02,  8.1633e-02,  1.0143e-03, -7.1763e-02,  2.2079e-02],\n",
      "        [-4.4356e-02, -1.9406e-01, -9.9282e-02,  1.4344e-01, -1.4283e-01,\n",
      "         -2.4353e-02,  4.5829e-02,  1.8484e-01, -1.5566e-01,  2.1393e-01,\n",
      "          1.1609e-01,  8.3691e-03,  5.9809e-03, -1.5235e-03,  8.4976e-02,\n",
      "         -1.5873e-01,  4.5160e-02,  1.4867e-01, -1.6064e-01,  1.1943e-01],\n",
      "        [ 5.1427e-02, -8.5538e-02,  2.0207e-01, -1.0868e-01, -1.8237e-01,\n",
      "         -8.3710e-02,  3.9148e-03, -1.4055e-02, -7.8582e-02,  1.5976e-01,\n",
      "          1.5113e-02,  2.1013e-01,  5.6064e-02, -5.9410e-02,  6.0684e-02,\n",
      "          2.2037e-01, -2.0667e-02, -1.5452e-01,  2.1645e-02, -1.8489e-01],\n",
      "        [-1.5766e-01, -1.1459e-01,  2.1402e-01, -9.9118e-02, -9.7651e-02,\n",
      "         -1.9001e-01, -1.5746e-02, -1.4643e-01, -5.0121e-02,  1.1337e-01,\n",
      "         -1.7302e-01, -8.2409e-02,  2.0371e-01,  6.5668e-02, -7.5243e-02,\n",
      "          1.1537e-01,  9.6436e-02,  1.2268e-01,  7.5241e-02,  1.6758e-01],\n",
      "        [-1.6327e-02, -1.0522e-01,  1.8694e-01, -1.9695e-01,  1.1920e-01,\n",
      "          8.4285e-02,  1.2459e-01, -4.7309e-02, -2.9802e-02,  2.1180e-01,\n",
      "         -1.3761e-01,  1.2569e-01,  2.7957e-03,  5.5715e-02, -1.6131e-01,\n",
      "          1.8066e-02,  1.7125e-01, -7.4045e-02,  1.5942e-01, -5.4794e-02],\n",
      "        [-4.3572e-02, -1.1844e-01,  1.5681e-01,  1.9235e-01, -1.2843e-01,\n",
      "         -1.6865e-01,  2.6351e-02, -1.2916e-01, -2.1364e-01,  7.2954e-02,\n",
      "          1.9705e-01,  1.4446e-02, -6.2668e-02, -8.4054e-02, -2.2118e-01,\n",
      "          5.0093e-02, -2.0809e-01, -1.9266e-01, -9.6280e-02,  6.3118e-02],\n",
      "        [ 2.0637e-01, -1.2779e-01,  2.0356e-01,  1.9295e-01,  1.1895e-01,\n",
      "          1.0626e-01, -1.0619e-01, -4.2781e-02, -9.1780e-02, -2.0337e-01,\n",
      "         -3.3972e-02,  1.0496e-01,  2.7074e-02,  7.9789e-02,  1.3927e-01,\n",
      "          8.3818e-02, -4.2853e-02, -1.7891e-02,  1.7499e-01, -1.0702e-01],\n",
      "        [ 1.8031e-01, -6.8228e-02,  1.5582e-01, -2.2219e-01, -1.9009e-01,\n",
      "          9.5167e-02, -1.0642e-01,  7.0994e-02,  1.6816e-01,  8.0450e-02,\n",
      "         -5.6179e-02, -2.0428e-01,  2.1651e-05,  8.5580e-02,  1.0306e-01,\n",
      "          5.3070e-02, -9.4032e-02, -1.5693e-02,  2.1732e-01, -2.8397e-02],\n",
      "        [-2.7264e-02,  1.9826e-01,  2.0609e-01,  7.3904e-02, -1.3103e-01,\n",
      "         -9.1231e-02, -1.8314e-01, -3.0732e-02, -9.9713e-02,  3.9904e-02,\n",
      "         -5.8119e-02, -1.7166e-01,  4.9645e-02, -6.0490e-03, -1.9865e-01,\n",
      "          1.5872e-01,  3.2046e-02,  1.7126e-01, -1.2407e-02, -2.2074e-01],\n",
      "        [ 7.6966e-02, -8.3592e-02, -6.5779e-02,  1.7273e-01,  2.1439e-01,\n",
      "         -1.0314e-01,  1.3282e-01, -1.2707e-01, -1.1278e-01,  2.4177e-02,\n",
      "         -1.6404e-01, -4.6672e-02,  5.9872e-02,  3.7554e-02, -1.9777e-01,\n",
      "          2.1244e-01, -2.1513e-01, -1.8519e-02, -8.2159e-02, -1.1245e-01],\n",
      "        [-1.6527e-01, -1.3060e-01,  2.1878e-01, -6.0910e-02, -5.1919e-02,\n",
      "          1.1831e-01,  4.2078e-02, -1.1022e-01,  1.3534e-01, -2.2310e-01,\n",
      "         -8.3222e-02,  3.2563e-02, -4.3374e-02,  1.4645e-02, -8.6960e-02,\n",
      "          1.0172e-01, -7.5465e-02, -1.5598e-01,  2.2270e-01,  1.7287e-01],\n",
      "        [ 1.8627e-01,  2.0753e-01,  1.5557e-01,  2.1692e-01,  1.7750e-01,\n",
      "         -1.0598e-01,  1.6352e-01, -1.4439e-01,  8.3378e-03,  1.6696e-02,\n",
      "         -1.3283e-01,  2.0292e-01,  1.7440e-01,  4.5871e-02,  1.1320e-01,\n",
      "          1.1063e-01,  1.5937e-01, -1.3178e-01,  2.2279e-02, -1.2104e-01],\n",
      "        [ 1.1646e-01, -2.3840e-02,  7.9163e-02, -6.3199e-03, -9.6897e-02,\n",
      "          1.0307e-01,  1.3930e-01, -1.8363e-01,  9.0217e-02, -1.0524e-01,\n",
      "         -1.7903e-01, -1.2481e-01, -1.9077e-01, -1.7499e-01,  1.8457e-01,\n",
      "         -8.6655e-02, -1.2008e-01,  5.5107e-02, -1.2055e-01,  2.1085e-01],\n",
      "        [ 2.0605e-01,  7.2265e-02,  1.6100e-01, -1.3810e-01, -5.3019e-02,\n",
      "          1.2234e-01, -7.6852e-02, -1.2740e-01,  7.7035e-02, -3.4638e-02,\n",
      "         -1.3724e-01, -1.5847e-01,  1.0562e-01, -3.0275e-02,  1.6271e-01,\n",
      "         -1.4907e-01,  2.4166e-02, -1.6356e-01,  4.6855e-02, -8.9687e-03],\n",
      "        [ 7.4481e-02, -1.4812e-01, -2.1017e-01,  1.3877e-01, -1.6155e-02,\n",
      "          2.2091e-01,  2.0040e-01,  8.9442e-03, -1.7917e-01,  1.9699e-01,\n",
      "         -6.6190e-02,  3.4894e-02,  2.0376e-01, -1.7813e-01, -1.1676e-01,\n",
      "          3.8629e-02, -3.4893e-02, -3.9795e-02, -1.7632e-01,  1.3691e-01],\n",
      "        [ 1.1424e-01,  5.9892e-02,  2.1791e-01, -1.7403e-02, -6.3017e-02,\n",
      "          3.5305e-02,  1.5919e-01,  1.1462e-01, -1.9143e-01,  1.7657e-01,\n",
      "          5.7067e-02, -2.1910e-01,  1.0990e-01, -8.6969e-02, -1.9891e-01,\n",
      "          1.0339e-01,  2.4309e-02, -2.1557e-01, -2.0627e-02, -1.4354e-01],\n",
      "        [ 1.1617e-01,  1.9789e-02,  3.7561e-02, -4.4915e-02, -1.5914e-01,\n",
      "          8.3465e-02,  1.7753e-01,  1.5309e-02,  1.7969e-01, -1.5828e-01,\n",
      "         -2.0728e-03,  2.0526e-01,  7.4561e-03,  1.0033e-01, -6.8516e-02,\n",
      "          1.3882e-01,  1.5694e-01, -2.0510e-02,  2.0254e-01,  1.0949e-01],\n",
      "        [ 3.8133e-02,  1.7944e-01, -1.2511e-01, -1.6180e-01, -2.4077e-02,\n",
      "         -1.3299e-01,  6.2267e-02, -1.1121e-01,  8.7780e-02,  1.0319e-02,\n",
      "          1.5170e-01, -6.1461e-02, -8.4539e-02, -8.4187e-03, -7.6021e-03,\n",
      "         -8.5997e-02,  1.7994e-01, -1.7556e-01, -1.2822e-01, -1.8709e-01],\n",
      "        [ 2.0672e-02,  4.1625e-02,  7.2475e-04,  6.3207e-02,  3.5287e-02,\n",
      "          2.0637e-01, -1.9292e-01, -1.0245e-01,  2.4490e-02,  8.5534e-02,\n",
      "          1.2093e-01, -1.3855e-01,  1.1627e-01, -2.7299e-02,  2.0654e-01,\n",
      "          9.5033e-02, -1.1004e-02,  1.6003e-01,  1.8388e-01, -8.7059e-02],\n",
      "        [-1.7715e-01,  2.1540e-02,  2.2176e-02, -5.6914e-02,  1.7456e-01,\n",
      "          6.6521e-02, -2.0814e-01,  3.5498e-02, -3.7473e-02, -1.0425e-01,\n",
      "         -1.2867e-01, -1.3576e-01,  6.1321e-02,  1.3998e-01,  1.5614e-01,\n",
      "          3.6432e-02,  2.2270e-01,  2.2321e-01,  1.9261e-01, -1.8811e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1031,  0.0169,  0.1801,  0.1417, -0.0172,  0.0157,  0.0653,  0.0272,\n",
      "         0.0821,  0.1338,  0.1439,  0.0055, -0.1577,  0.0532, -0.1741, -0.0606,\n",
      "         0.1503,  0.0755,  0.1529, -0.1579], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-5.3454e-02, -2.1631e-01, -4.2786e-02, -1.5961e-01,  9.6679e-02,\n",
      "          1.7170e-01,  6.6043e-02,  1.8876e-01, -8.3792e-02, -1.6458e-01,\n",
      "          1.7261e-01,  4.1813e-03,  1.5346e-02, -7.2584e-02, -1.4158e-01,\n",
      "          1.0865e-01, -1.0469e-01,  1.3290e-01,  4.1713e-02, -1.5728e-01],\n",
      "        [ 1.9496e-01,  1.3992e-02,  1.4384e-01,  1.9483e-01, -6.9924e-02,\n",
      "         -6.6968e-02, -2.4302e-02, -4.3604e-04, -7.8808e-02,  1.1978e-01,\n",
      "          7.1523e-02, -8.2204e-02,  8.6799e-03,  1.7776e-01, -2.1883e-01,\n",
      "         -2.0731e-01, -2.8491e-02, -9.5312e-02, -2.4563e-02,  1.7747e-01],\n",
      "        [-7.0715e-02,  1.5397e-01, -2.8413e-02, -2.0402e-02,  1.1325e-01,\n",
      "         -2.0893e-01, -2.0352e-02,  1.6047e-01, -1.4392e-01, -4.3530e-02,\n",
      "         -1.4403e-01, -2.5807e-02, -1.5819e-01, -1.9877e-02,  5.6511e-02,\n",
      "          6.1735e-02, -1.2576e-01,  2.2359e-01,  1.2724e-01,  1.9761e-01],\n",
      "        [ 2.1918e-01, -1.5404e-01,  1.6605e-01,  1.3664e-01,  2.0399e-01,\n",
      "         -8.7752e-02,  4.3901e-02,  5.3195e-02,  1.8479e-01, -1.3070e-01,\n",
      "          1.3500e-01, -2.8361e-02,  1.3622e-01,  1.4389e-01, -5.3595e-02,\n",
      "          1.7481e-01,  6.7326e-02, -2.1950e-01,  2.0753e-01, -1.1349e-01],\n",
      "        [-3.1114e-02,  1.9963e-01, -5.1247e-02, -1.6170e-03, -2.1332e-01,\n",
      "          1.9321e-01, -1.6632e-01,  1.5314e-01,  1.5124e-01,  5.5400e-02,\n",
      "         -1.3314e-01,  6.4008e-02, -1.1263e-01,  1.7355e-01,  1.5395e-01,\n",
      "          4.7222e-02, -8.3344e-02,  5.9342e-02, -1.2232e-01,  3.3998e-02],\n",
      "        [-2.5533e-02,  1.6934e-01, -1.9592e-01,  1.0781e-01,  1.3551e-01,\n",
      "          1.8489e-01, -2.1460e-02, -6.4950e-02, -1.1338e-02, -1.4301e-01,\n",
      "         -2.1273e-01, -6.5740e-02, -1.6764e-01,  2.1466e-01,  1.5469e-01,\n",
      "         -1.5686e-01,  8.7612e-02,  4.5845e-02, -1.8573e-02, -1.2635e-01],\n",
      "        [-6.8088e-02, -2.5872e-03, -1.6090e-01, -1.9046e-01,  1.4398e-01,\n",
      "         -2.1118e-02,  2.0092e-01,  1.2159e-01, -7.7356e-02, -3.7453e-02,\n",
      "          2.0373e-01,  1.8043e-01, -2.2180e-01,  1.3921e-01, -1.5640e-01,\n",
      "         -4.5195e-02,  2.7452e-02,  5.9218e-02,  5.6859e-02, -1.6992e-01],\n",
      "        [ 4.0344e-02, -1.3499e-02, -9.9625e-02,  1.1592e-01,  1.8852e-01,\n",
      "          2.0981e-01,  1.9733e-01, -8.0122e-03,  6.4173e-02, -1.2509e-03,\n",
      "          1.6187e-01, -4.6526e-02, -4.6114e-02,  2.2155e-01,  1.5353e-01,\n",
      "         -1.3626e-02, -2.1599e-01, -1.8603e-01,  1.9654e-01,  1.0727e-02],\n",
      "        [-2.0762e-02, -1.5374e-01,  1.9709e-01,  1.5859e-01,  2.0433e-01,\n",
      "          9.9783e-02, -5.9871e-02, -5.2442e-02,  1.8237e-01,  7.1341e-02,\n",
      "         -1.2778e-02, -4.9716e-02, -1.2303e-01,  4.8751e-03,  1.2330e-01,\n",
      "         -1.9444e-01,  1.4804e-01, -1.1465e-01,  3.0154e-02,  1.6226e-01],\n",
      "        [ 2.9018e-02, -2.6071e-02,  1.6388e-01, -2.8320e-03,  7.7251e-02,\n",
      "         -2.0076e-01,  1.0073e-01,  7.9067e-02,  8.9613e-02, -1.4555e-01,\n",
      "          2.5945e-02,  7.9259e-02,  1.6143e-01,  3.0139e-02,  8.8121e-02,\n",
      "          1.4116e-01, -3.2195e-02,  4.3894e-02, -1.9145e-01, -3.5677e-02],\n",
      "        [-2.0530e-01,  1.5206e-01,  1.2031e-01, -1.9836e-01, -1.9822e-02,\n",
      "          5.8086e-02, -9.9548e-02, -3.7891e-02,  1.2407e-01, -2.1917e-01,\n",
      "         -4.8287e-02,  1.7249e-03, -1.1482e-01, -6.2158e-03,  1.6358e-01,\n",
      "          1.8018e-02,  8.6979e-02, -5.3122e-02, -6.1301e-02,  1.6107e-01],\n",
      "        [-1.1513e-01,  8.3610e-02, -3.2420e-02, -7.0057e-02,  1.9109e-01,\n",
      "         -1.8450e-01,  4.6293e-02, -2.0311e-01, -1.3143e-01,  2.0566e-01,\n",
      "         -5.2765e-02,  1.8111e-02, -5.5068e-02, -2.0408e-01,  7.9454e-02,\n",
      "         -1.6952e-01, -2.0691e-01,  8.5978e-03, -1.8077e-01, -2.1355e-01],\n",
      "        [ 8.8547e-02,  8.2996e-02,  9.7977e-02, -9.8705e-02,  1.2999e-01,\n",
      "         -8.2195e-02, -1.4184e-01, -1.1570e-01,  1.6526e-01,  4.0539e-02,\n",
      "          1.4870e-02,  1.0947e-01,  1.4597e-01,  1.7280e-01, -5.3886e-02,\n",
      "         -1.2442e-01, -1.3509e-01, -5.3796e-02, -4.3056e-02,  1.9729e-05],\n",
      "        [ 2.0806e-01, -9.9790e-02, -7.6574e-03,  9.3027e-02,  2.4503e-02,\n",
      "         -1.6004e-01,  1.8459e-01, -1.8341e-01, -3.0049e-02,  7.2007e-02,\n",
      "          1.6702e-01, -1.3453e-01, -2.8707e-02, -1.1063e-01,  1.2693e-02,\n",
      "          2.0621e-01, -2.0214e-01, -1.2932e-01, -9.6881e-03,  1.2015e-01],\n",
      "        [-2.2142e-01, -8.5938e-02,  9.5375e-02, -4.4441e-02, -8.0403e-02,\n",
      "          2.0993e-02,  2.0130e-01, -3.9116e-02, -6.4349e-03, -9.5371e-02,\n",
      "          1.5811e-01,  1.5635e-01,  9.6641e-02, -2.0937e-02, -2.5326e-02,\n",
      "         -1.5869e-01,  2.6144e-02, -3.5162e-02, -9.4133e-03, -6.2914e-02],\n",
      "        [ 1.7082e-02, -1.5241e-01,  1.3789e-01,  1.4107e-01,  1.5617e-01,\n",
      "          1.7715e-01,  1.3375e-01,  4.5235e-03, -2.5691e-02,  7.4792e-02,\n",
      "         -5.4747e-03, -1.7020e-01, -2.7720e-02, -1.1767e-01,  4.0864e-02,\n",
      "         -2.0397e-01,  2.9954e-02,  1.7808e-01, -6.6612e-02, -1.2444e-01],\n",
      "        [ 1.0774e-01, -7.1665e-03,  1.0877e-01, -7.3061e-02, -2.1918e-01,\n",
      "         -7.0448e-02,  1.6980e-01, -1.4773e-02, -2.2347e-01,  1.4782e-01,\n",
      "         -1.2768e-02, -8.0103e-02,  1.0063e-01,  1.3722e-01, -4.8008e-02,\n",
      "          9.7535e-02,  1.9222e-05,  6.3700e-02,  1.8100e-01,  2.0478e-01],\n",
      "        [-4.8697e-02, -2.6040e-03,  1.1618e-01, -1.4496e-01, -9.5737e-02,\n",
      "          4.2738e-02,  1.0597e-01, -2.4661e-02, -1.7455e-02, -1.5330e-01,\n",
      "         -1.1763e-01,  1.4888e-01, -1.8913e-01, -6.8284e-02,  7.4491e-02,\n",
      "         -1.1684e-01,  1.7712e-01, -6.6033e-02,  1.4483e-01,  9.7441e-02],\n",
      "        [ 1.8178e-01,  3.5627e-02, -1.6410e-01,  9.7378e-02, -6.9752e-02,\n",
      "          1.2550e-01, -1.8787e-02,  2.1445e-01, -1.1333e-01,  1.6411e-01,\n",
      "         -1.3282e-01, -2.1054e-01,  2.1431e-01, -4.1621e-02, -7.3253e-02,\n",
      "         -1.6848e-01,  1.7943e-02, -1.7186e-01,  2.1979e-01, -8.0949e-02],\n",
      "        [-1.5028e-01, -1.1715e-01, -1.7170e-01,  7.1323e-04, -1.2798e-01,\n",
      "         -2.0257e-01,  1.8596e-02,  2.0240e-01,  1.0057e-02,  1.5940e-02,\n",
      "         -1.6487e-01, -1.2051e-01,  2.0776e-02, -8.5599e-02,  9.4009e-02,\n",
      "          2.0588e-01, -8.0490e-02,  2.0854e-01,  1.9768e-01,  8.6907e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2139,  0.0695,  0.1178,  0.1356,  0.0153,  0.0284,  0.0351,  0.0997,\n",
      "        -0.0022,  0.1644,  0.1839,  0.0186, -0.0230,  0.0794,  0.0770, -0.0741,\n",
      "         0.1729,  0.2181, -0.1426, -0.0034], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.1376e-01,  1.9615e-01, -1.1046e-01,  1.3075e-02, -1.4777e-02,\n",
      "         -6.4257e-02,  4.8085e-02, -1.4995e-01, -2.1315e-01, -2.1894e-01,\n",
      "          1.3570e-01,  1.9889e-01,  1.2251e-01, -7.3480e-02, -3.9718e-02,\n",
      "         -8.4653e-05,  1.5311e-01, -1.1128e-01,  4.9740e-02,  1.4306e-01],\n",
      "        [ 1.1329e-01,  2.2915e-03,  1.6274e-02, -7.0199e-02, -2.1188e-01,\n",
      "         -4.3722e-02,  8.4380e-02, -1.0065e-01,  2.4313e-04, -5.8140e-02,\n",
      "          1.7097e-01,  2.1123e-01,  1.8695e-01, -1.3260e-01, -5.8473e-02,\n",
      "          6.8318e-02, -9.6961e-02,  3.3733e-02,  8.6527e-02, -1.4786e-01],\n",
      "        [-1.8632e-01,  1.8123e-03,  2.0199e-01, -1.1735e-01,  8.1663e-02,\n",
      "          1.8215e-01,  3.4946e-03, -4.9316e-02,  1.9704e-01,  1.7747e-01,\n",
      "         -3.6758e-02, -1.5904e-01,  1.3181e-01, -8.7650e-02,  2.1762e-01,\n",
      "          8.7303e-02, -2.1782e-01,  2.7505e-02,  6.9045e-02,  1.7656e-01],\n",
      "        [ 1.9710e-03,  1.5837e-01, -1.4537e-01,  2.0576e-01, -4.2169e-02,\n",
      "         -2.3365e-02,  1.9925e-01, -9.7725e-03,  1.3046e-01,  1.6549e-01,\n",
      "         -2.1062e-01,  1.9472e-01, -1.0057e-01, -9.0848e-02,  7.2244e-02,\n",
      "         -4.3469e-02, -1.5887e-01,  8.7745e-02,  1.8167e-01, -2.3142e-02],\n",
      "        [ 1.4522e-01,  2.1297e-01, -1.5526e-01,  2.1189e-01,  1.9506e-01,\n",
      "         -1.5537e-01,  1.3228e-02, -9.3738e-03,  2.6801e-03, -6.7816e-02,\n",
      "         -1.9259e-02, -1.5107e-01, -1.7733e-01,  1.7053e-01, -8.7899e-02,\n",
      "          1.9879e-01,  7.2196e-02, -9.9989e-03, -1.3387e-01, -1.8125e-01],\n",
      "        [-1.5586e-01,  1.6940e-01, -5.3948e-02, -4.8225e-02, -4.1123e-02,\n",
      "         -1.2511e-01, -1.0904e-01,  4.5409e-02, -6.3133e-02, -1.3664e-01,\n",
      "          1.7194e-01,  1.0237e-01, -4.3329e-03, -6.2427e-02, -2.1313e-01,\n",
      "          9.7327e-02,  1.7110e-01,  1.2839e-01,  2.2159e-01,  1.9079e-01],\n",
      "        [ 2.2231e-01,  1.8799e-01,  1.0968e-02, -2.0908e-01,  9.8990e-02,\n",
      "         -2.0474e-01, -1.2331e-01, -1.2524e-02, -2.0903e-01, -8.4658e-02,\n",
      "          1.4378e-01, -1.7949e-01, -5.0885e-02, -3.3240e-02, -2.5036e-02,\n",
      "          9.1018e-02, -1.3510e-01,  9.0729e-02, -2.0121e-01, -9.6048e-02],\n",
      "        [ 4.3721e-02,  7.2525e-02,  3.2567e-02, -1.1745e-01, -6.3111e-02,\n",
      "          7.1143e-02,  9.7997e-02, -8.4936e-02, -1.0485e-01, -2.0604e-01,\n",
      "         -1.9651e-01, -1.4791e-02, -1.5201e-01, -1.6319e-02, -1.8654e-01,\n",
      "         -6.4862e-03,  1.2207e-01,  9.7863e-02,  1.3285e-01,  1.9668e-01],\n",
      "        [-7.3708e-02, -2.1680e-01, -6.9380e-03,  1.0166e-01,  2.2852e-02,\n",
      "          1.4131e-01,  2.2292e-02,  1.4385e-01, -3.3688e-02, -1.7826e-01,\n",
      "         -1.8849e-02, -1.5081e-01,  1.5439e-01,  1.8678e-01,  1.6904e-01,\n",
      "          1.8215e-01, -6.1055e-02,  1.0338e-01,  2.2354e-01,  1.4406e-01],\n",
      "        [ 1.6898e-01,  1.0631e-01,  2.1475e-01,  1.5117e-01,  1.7335e-01,\n",
      "         -1.5122e-01,  2.1365e-02,  4.9838e-02, -1.7838e-03,  2.1944e-01,\n",
      "         -3.3895e-03,  7.3067e-03, -1.6052e-01,  1.1408e-02, -1.5556e-01,\n",
      "          1.3355e-01, -1.4676e-01,  2.1891e-01,  1.1236e-01,  7.8737e-02],\n",
      "        [ 9.0311e-02, -5.4399e-02, -1.9512e-01,  6.0925e-02, -1.6791e-01,\n",
      "          8.0168e-02,  3.7736e-02, -2.7818e-02, -5.4294e-02, -7.7374e-02,\n",
      "          1.5068e-01, -5.5139e-02, -2.1880e-01, -9.0660e-02,  1.4079e-01,\n",
      "          3.1949e-02,  1.3008e-01, -1.6844e-01,  1.4335e-01, -1.8863e-01],\n",
      "        [ 5.0485e-02, -1.4561e-01, -1.9594e-01,  1.6847e-01,  2.2733e-02,\n",
      "         -1.7969e-01,  2.2060e-01, -1.4835e-01, -8.7160e-02, -1.6997e-01,\n",
      "         -1.1498e-01, -2.1315e-02, -1.3997e-01, -2.1931e-01,  1.4595e-01,\n",
      "         -1.1804e-01,  1.2244e-01,  9.0014e-02, -2.1479e-01,  2.1696e-01],\n",
      "        [ 1.7749e-01,  4.6080e-02, -1.5510e-01, -1.8291e-01, -7.4587e-02,\n",
      "          1.1295e-01, -1.1161e-01,  2.2541e-02, -1.9967e-01, -1.0680e-01,\n",
      "          2.1772e-01, -1.8865e-01, -1.9653e-01, -1.4059e-01, -8.0948e-02,\n",
      "         -2.6361e-02, -1.5004e-02,  1.1292e-01, -1.8607e-01,  5.7711e-02],\n",
      "        [ 2.5060e-03, -3.8633e-02,  7.7372e-02, -1.4500e-01, -8.9048e-02,\n",
      "         -1.8221e-01, -1.8883e-01,  1.7116e-03, -1.3611e-01,  1.8937e-01,\n",
      "          2.8939e-02, -1.7342e-01,  1.5565e-01,  8.4690e-02, -1.1871e-01,\n",
      "         -1.4413e-01,  3.8930e-03, -7.7922e-02,  1.1974e-02, -1.6361e-01],\n",
      "        [ 1.6437e-01, -1.5572e-01, -4.3131e-02, -1.3616e-01, -2.0807e-01,\n",
      "         -5.0743e-02,  5.1594e-02, -1.4789e-01,  4.5878e-02,  2.0891e-01,\n",
      "         -1.0101e-01, -4.2744e-02,  1.0490e-01,  9.1114e-02,  2.2196e-01,\n",
      "          1.7037e-01, -1.0858e-01, -1.9260e-01, -3.9974e-03,  3.3008e-02],\n",
      "        [-1.8417e-01,  3.9745e-02, -1.1810e-01, -1.8710e-01, -5.8450e-02,\n",
      "         -7.8772e-02,  1.3230e-01,  1.7372e-01,  2.0166e-01,  1.0755e-01,\n",
      "         -1.7909e-01, -3.7848e-02, -8.9847e-02, -1.7266e-01, -1.0324e-01,\n",
      "         -1.7758e-01,  8.9194e-02, -1.3248e-01,  1.7379e-01, -1.3799e-01],\n",
      "        [ 1.3699e-01,  1.6983e-01,  1.9626e-01, -1.5810e-01,  1.6892e-01,\n",
      "          2.0071e-01,  1.7662e-01, -1.3102e-01,  1.1910e-03,  5.7261e-02,\n",
      "          5.3079e-03, -1.7899e-01,  7.3177e-02, -2.1746e-01,  2.6896e-03,\n",
      "          2.2074e-01, -1.1240e-01,  9.2473e-02, -1.7066e-01, -1.8440e-01],\n",
      "        [-4.4512e-02, -6.5626e-02,  6.0701e-02,  1.9826e-02,  5.8813e-03,\n",
      "         -1.4054e-01, -8.2487e-02,  1.7485e-01,  1.5537e-01, -2.0983e-01,\n",
      "          5.6101e-02,  1.5932e-01,  1.9245e-01,  1.6516e-01, -1.8656e-02,\n",
      "          1.0861e-01, -9.9874e-02,  3.9077e-02,  1.5307e-01,  1.3027e-01],\n",
      "        [-2.1099e-01, -9.9858e-02,  1.9345e-01, -1.7867e-01,  1.6308e-01,\n",
      "         -6.1903e-02, -3.4941e-02,  1.7565e-02, -1.6393e-01, -1.1333e-01,\n",
      "         -2.1717e-01, -1.4864e-01, -1.3942e-01, -1.0112e-01,  2.8971e-02,\n",
      "          6.5940e-03,  3.6655e-02, -1.3851e-01, -9.9145e-02,  1.0403e-01],\n",
      "        [ 2.2005e-01, -1.1265e-01, -1.1279e-01, -1.8611e-01,  9.2153e-02,\n",
      "          6.9030e-02, -7.3645e-02, -1.6735e-01,  1.9564e-01, -1.3229e-01,\n",
      "          1.4976e-01, -8.5575e-02,  7.2341e-02, -3.2277e-02, -1.2044e-01,\n",
      "         -1.5817e-01,  2.0395e-01, -5.3172e-02, -3.8470e-02,  7.8186e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0836, -0.1066,  0.1629,  0.1139,  0.1631,  0.1036, -0.1241, -0.1915,\n",
      "        -0.1769,  0.0146,  0.0455, -0.2103,  0.1703,  0.0365, -0.0317, -0.0998,\n",
      "        -0.1977, -0.0361, -0.1307, -0.1727], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.3086e-01, -3.1472e-02, -2.0190e-01,  2.0423e-01,  1.1149e-02,\n",
      "         -1.3191e-01, -2.1922e-01,  1.2368e-01, -4.7568e-02,  1.9693e-01,\n",
      "          2.0309e-01,  1.4148e-01, -8.9822e-02, -1.4672e-01,  9.2398e-02,\n",
      "         -2.0314e-01, -2.1731e-01, -1.6073e-01,  1.9485e-01,  1.7676e-02],\n",
      "        [ 1.1376e-02, -4.3901e-02,  4.6580e-02, -1.2942e-01, -9.8350e-02,\n",
      "         -1.2535e-01,  1.1515e-01,  8.5550e-02,  4.6400e-02,  1.6551e-01,\n",
      "         -2.0032e-01,  5.6269e-02, -1.3744e-01,  5.6724e-02, -1.5513e-01,\n",
      "         -1.2540e-01,  2.1799e-01, -9.9541e-02, -8.3008e-02, -6.0784e-02],\n",
      "        [ 7.0310e-02, -6.1626e-02, -1.8573e-02, -5.1561e-02, -6.4038e-02,\n",
      "         -7.4656e-02, -1.3068e-01,  1.0190e-01,  9.5434e-02, -7.5680e-02,\n",
      "         -2.0058e-01, -6.2677e-02, -4.4586e-02,  8.8418e-02,  9.5913e-02,\n",
      "          1.0510e-01,  1.4483e-01,  1.0004e-01, -7.7943e-02, -1.9850e-02],\n",
      "        [ 7.8677e-02,  1.4884e-01, -9.4198e-02, -1.4964e-01,  1.9854e-01,\n",
      "          2.1444e-01,  1.4883e-01,  1.8325e-01, -1.2475e-01, -1.8934e-01,\n",
      "         -1.0395e-01,  8.6868e-02,  1.5670e-01, -9.2800e-02,  3.9752e-02,\n",
      "          1.3960e-01, -2.0397e-01, -5.4755e-02,  2.1417e-01, -1.1658e-01],\n",
      "        [ 1.9279e-02,  1.8000e-01, -8.6583e-02, -1.3078e-01,  1.8929e-01,\n",
      "         -1.1917e-02, -6.7970e-02,  1.6524e-01,  1.7676e-02,  5.3474e-02,\n",
      "          1.4345e-01, -1.5511e-01,  1.5973e-01,  4.6295e-03,  7.8980e-02,\n",
      "          8.3304e-02,  4.1069e-03, -1.3157e-01,  1.0293e-01, -1.4711e-01],\n",
      "        [ 1.4347e-01, -9.9312e-02,  4.2003e-02,  1.9562e-01,  1.4340e-01,\n",
      "         -1.1182e-01,  5.3826e-02,  3.4719e-02,  2.9668e-02, -1.4732e-01,\n",
      "          2.0367e-01,  2.8393e-02, -8.1658e-04,  1.7659e-01,  1.0130e-01,\n",
      "         -5.9188e-02,  4.7798e-03,  1.7478e-01, -2.0803e-01,  1.2695e-02],\n",
      "        [ 1.3770e-01,  1.0016e-01,  1.0085e-01, -1.1393e-01,  5.4735e-02,\n",
      "         -9.3265e-02, -1.7833e-01,  1.6320e-01,  2.2125e-02, -9.4202e-02,\n",
      "         -3.5405e-02,  1.4396e-01, -1.2471e-01, -1.6270e-01,  2.2109e-01,\n",
      "          7.2011e-02,  2.8767e-02,  2.0398e-03,  3.5518e-02,  1.3714e-01],\n",
      "        [-1.8686e-01, -2.2985e-02,  9.4541e-02, -2.1985e-01,  2.0877e-02,\n",
      "          6.3834e-02,  2.1212e-01,  1.7103e-01, -1.8029e-01,  1.4821e-01,\n",
      "          1.7664e-01, -1.3634e-01,  1.1669e-01, -2.8918e-02,  1.0224e-03,\n",
      "         -2.6406e-02, -8.5741e-02, -1.5559e-01,  2.9422e-02,  5.8237e-02],\n",
      "        [-7.5857e-03,  1.1089e-01, -1.5306e-02, -1.6384e-01, -3.0959e-02,\n",
      "          1.2967e-01,  4.9695e-02,  7.8401e-02,  8.4511e-02,  9.2038e-02,\n",
      "          8.9116e-03, -9.7824e-02, -1.8109e-01,  1.3345e-01, -9.3479e-02,\n",
      "          7.2690e-02, -1.9655e-01,  2.3325e-02, -1.2323e-01,  2.0628e-01],\n",
      "        [ 6.7814e-02, -1.2494e-01, -1.5872e-01,  1.5060e-01, -1.1103e-01,\n",
      "         -1.8065e-01,  6.6906e-06,  8.9271e-02, -2.0007e-01, -5.2428e-02,\n",
      "          5.1312e-02,  2.7990e-02, -6.4602e-02,  1.3506e-01, -7.0824e-02,\n",
      "         -1.6598e-01, -2.1541e-01, -1.8266e-01, -2.1170e-01,  4.1856e-02],\n",
      "        [ 1.5863e-01,  7.5137e-02, -1.4520e-01,  9.1703e-02, -4.9326e-02,\n",
      "          1.0972e-01, -1.3589e-01,  7.9612e-02, -6.7057e-02, -1.7762e-01,\n",
      "          3.0080e-02, -1.5632e-01, -3.5276e-02,  1.5361e-01,  1.5037e-01,\n",
      "         -1.5242e-01, -1.9584e-01, -1.2213e-01,  2.2151e-01, -8.7427e-02],\n",
      "        [-1.7379e-01,  1.5344e-01,  1.0291e-01, -7.4149e-02,  3.2662e-02,\n",
      "         -1.6224e-01, -1.5531e-01,  4.7890e-02,  1.8756e-01,  1.9521e-01,\n",
      "         -1.1817e-01, -1.0911e-01,  1.1293e-01, -1.8035e-01,  5.5768e-02,\n",
      "         -1.0253e-01, -1.1454e-01, -1.0387e-01,  5.3619e-02,  1.2286e-01],\n",
      "        [ 2.1071e-01,  1.3775e-02,  3.4336e-02,  1.3551e-01, -1.8821e-01,\n",
      "         -6.9486e-02, -2.0731e-01, -1.2206e-01, -6.7783e-02,  1.4155e-01,\n",
      "          7.2370e-02,  9.8151e-03,  1.5336e-01, -1.2882e-01,  9.0957e-02,\n",
      "         -4.2014e-03,  7.0961e-02, -1.5757e-01,  1.3713e-01,  1.0524e-02],\n",
      "        [ 1.8915e-01, -1.7348e-01,  1.8591e-01,  1.7305e-01, -1.3189e-01,\n",
      "          3.3646e-02,  1.5250e-01, -6.2907e-02, -1.9479e-02,  1.0994e-01,\n",
      "          3.7857e-02,  8.2445e-02,  1.3446e-01,  2.1102e-01, -6.5652e-03,\n",
      "          2.7619e-02,  3.2724e-03, -8.1426e-02, -5.4462e-02, -6.4521e-02],\n",
      "        [ 1.0572e-01, -5.4783e-03,  1.9682e-01,  2.2281e-01, -1.7269e-01,\n",
      "          2.0053e-01,  1.3049e-01,  8.1996e-02,  7.8751e-02, -9.4845e-02,\n",
      "         -4.3431e-02, -7.6928e-02, -7.6418e-02, -5.2502e-02,  2.1904e-01,\n",
      "          1.4228e-01,  2.1320e-01, -8.3555e-02, -8.0858e-02,  2.2371e-02],\n",
      "        [-2.5369e-02,  9.1939e-02, -4.8251e-02, -1.5454e-01, -1.6249e-01,\n",
      "          1.2327e-01,  6.1457e-02, -1.4491e-01,  7.5383e-02,  1.5178e-01,\n",
      "          1.0023e-01, -1.1929e-01,  2.0534e-01,  1.8410e-01, -1.1538e-01,\n",
      "         -1.8601e-02, -1.4210e-01, -7.0208e-02, -2.1709e-01,  1.9883e-01],\n",
      "        [-2.7861e-02,  1.5024e-01,  1.9963e-01, -1.9005e-01,  4.0078e-03,\n",
      "          1.5248e-02,  2.1048e-01, -1.9339e-01,  9.2015e-02, -8.8775e-02,\n",
      "          1.0226e-01, -1.7984e-01,  8.9845e-02,  1.8051e-01, -6.0757e-02,\n",
      "         -1.7422e-01, -1.8442e-01,  9.8546e-02,  4.8426e-02,  6.2325e-02],\n",
      "        [-3.1602e-02, -1.0137e-03,  1.9868e-01,  1.0269e-01, -2.2658e-02,\n",
      "          1.0521e-01, -8.5724e-02, -8.1763e-04,  9.1775e-02,  1.7343e-01,\n",
      "         -5.4415e-02,  1.0717e-01, -1.5620e-01,  8.8974e-03,  1.8296e-01,\n",
      "          2.0003e-01, -7.9222e-03,  1.9667e-01, -2.0258e-01, -1.7371e-01],\n",
      "        [-2.1269e-01, -1.9559e-01, -9.0320e-02,  1.2676e-01,  1.7649e-01,\n",
      "         -2.1856e-01, -1.4395e-01, -1.3332e-01,  3.2394e-02, -2.0473e-01,\n",
      "         -1.4246e-01, -1.8510e-02,  1.0983e-02, -1.5041e-01, -1.8920e-01,\n",
      "          1.4072e-01,  3.4245e-02,  1.3813e-01,  7.3076e-02,  8.6054e-02],\n",
      "        [-1.1375e-01,  1.7552e-01,  7.6808e-02,  1.0786e-01, -3.8900e-02,\n",
      "         -2.0692e-01,  1.4526e-02,  7.1676e-02,  2.1172e-01,  7.4191e-02,\n",
      "          1.0876e-01,  1.4220e-01, -8.1442e-02,  3.8983e-02, -8.0529e-02,\n",
      "         -9.4522e-02, -2.0873e-01,  4.9322e-02, -1.7235e-01,  2.5662e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1149,  0.1533, -0.1130, -0.1188,  0.0859, -0.1159,  0.1577,  0.1615,\n",
      "        -0.0458,  0.0835,  0.0146,  0.1292,  0.0549, -0.1574,  0.1419, -0.0406,\n",
      "        -0.1641, -0.0508, -0.2075, -0.0912], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 4.3421e-02, -2.1975e-01,  2.9644e-02,  5.1060e-02,  1.8816e-01,\n",
      "         -1.5805e-01, -5.8823e-02, -5.2256e-03, -1.5601e-01, -1.1783e-02,\n",
      "         -9.1842e-02,  1.2563e-01,  2.7358e-02,  4.0698e-04,  1.9695e-02,\n",
      "         -1.6091e-01,  1.0040e-01,  9.8422e-02, -7.9374e-02, -5.9473e-02],\n",
      "        [ 1.5865e-01,  1.4961e-01,  2.3017e-03, -1.8301e-01, -8.5343e-02,\n",
      "         -1.8518e-01,  1.1849e-01, -1.6704e-02, -1.8589e-01,  1.0816e-01,\n",
      "          8.4582e-04,  1.5847e-01, -2.1071e-02, -2.2316e-01, -1.3515e-01,\n",
      "         -1.3017e-01,  1.0984e-01,  9.8384e-02,  1.3747e-01, -1.5335e-01],\n",
      "        [-1.0832e-01, -2.0320e-01,  2.1338e-01,  1.8803e-01, -1.7711e-01,\n",
      "          1.8684e-01, -6.7044e-02,  1.4029e-01,  2.1366e-01, -1.5667e-01,\n",
      "         -1.0514e-01, -4.1882e-03, -1.8255e-01, -1.7049e-01, -1.1855e-01,\n",
      "         -2.0478e-02, -5.4615e-02,  7.5687e-03, -2.5425e-02,  1.2868e-01],\n",
      "        [-1.5730e-01,  1.2853e-01,  1.5063e-01, -3.9287e-02,  1.1020e-01,\n",
      "          1.4783e-02, -2.0502e-01,  1.8443e-01, -1.8121e-04, -1.0054e-01,\n",
      "          1.2826e-01,  2.0514e-01,  1.5272e-01,  1.4716e-02, -6.2773e-02,\n",
      "          2.1396e-01,  1.8528e-01,  1.1371e-01, -1.8566e-01,  1.9895e-01],\n",
      "        [ 1.5974e-01,  3.6943e-02,  6.6652e-02,  1.4961e-01, -8.9797e-02,\n",
      "         -1.1786e-01, -1.6766e-01,  7.9045e-02,  7.6312e-02, -1.0962e-02,\n",
      "          5.5720e-02, -1.9870e-01,  1.6410e-01,  1.1223e-01, -1.9086e-01,\n",
      "         -1.7558e-01,  1.0657e-02, -7.1187e-02,  2.7350e-02, -8.9057e-03],\n",
      "        [-1.5542e-01, -2.0826e-01, -1.1885e-01,  1.2462e-01, -1.3565e-01,\n",
      "          1.0440e-01, -3.1423e-02,  1.7921e-02, -7.6969e-02,  7.0569e-02,\n",
      "          2.1576e-01, -9.2936e-02,  2.7702e-02, -3.6176e-03, -1.6506e-01,\n",
      "         -8.8565e-02,  1.6436e-01, -1.7046e-01, -1.0594e-01,  1.8747e-01],\n",
      "        [ 1.6082e-01,  7.5108e-02, -2.2043e-01,  1.0581e-02, -6.2695e-02,\n",
      "         -1.7523e-01, -1.8028e-01, -2.0135e-01, -7.2756e-03, -1.4850e-01,\n",
      "         -7.0103e-02,  2.0878e-01, -5.3515e-02,  1.8230e-01,  1.1550e-01,\n",
      "         -8.3559e-02,  1.9117e-01, -1.8055e-01, -3.4064e-02,  1.9294e-02],\n",
      "        [ 7.2985e-02,  8.5561e-02, -3.7431e-02,  1.5671e-01, -1.9582e-01,\n",
      "         -1.2910e-01, -1.4316e-01,  1.1144e-01,  1.3836e-02, -2.8493e-02,\n",
      "         -1.0888e-01,  1.8466e-01, -1.7846e-01, -1.5029e-01, -1.5081e-01,\n",
      "          5.9734e-02,  1.6028e-01, -7.2356e-02, -2.1937e-01,  9.1786e-02],\n",
      "        [ 1.6042e-03, -1.1446e-01, -1.3752e-01, -1.6643e-01,  2.2326e-01,\n",
      "          3.3683e-02,  1.0658e-01,  8.9783e-02,  4.7849e-02,  1.1217e-01,\n",
      "         -1.7783e-01, -1.1655e-01,  1.5194e-01, -1.7054e-01,  1.3059e-01,\n",
      "          1.1836e-01, -6.6584e-02,  1.8555e-01,  4.1249e-02,  1.5945e-01],\n",
      "        [ 1.6653e-01,  1.5881e-01, -2.1093e-01, -1.3388e-01, -4.7284e-02,\n",
      "          1.3966e-01, -6.7846e-02,  1.5616e-01,  1.3632e-01, -1.1496e-01,\n",
      "         -8.7975e-02,  8.5313e-02,  1.9356e-01, -1.5357e-01, -2.4248e-02,\n",
      "         -1.7019e-01, -2.0836e-01, -1.7928e-01,  6.9805e-02, -1.5986e-02],\n",
      "        [ 2.0238e-02,  1.4926e-01,  2.6762e-02,  9.4411e-02,  1.7655e-01,\n",
      "         -1.1196e-01,  1.4107e-01,  9.1241e-02,  1.9356e-01, -1.8032e-02,\n",
      "          9.4185e-02, -7.1661e-02, -4.1493e-02, -1.2314e-01, -1.7982e-01,\n",
      "          2.0740e-01, -1.6078e-01, -1.8655e-01,  6.3399e-02, -1.4973e-01],\n",
      "        [ 8.8631e-03, -1.3077e-01, -2.0474e-02, -5.3732e-02,  1.4524e-01,\n",
      "         -1.6053e-01,  1.4989e-01, -5.1953e-03, -1.3812e-01, -4.3315e-02,\n",
      "          2.0732e-01, -4.3852e-02,  1.5438e-01, -8.9453e-02, -1.0718e-01,\n",
      "         -2.0645e-01, -1.3524e-01,  2.1127e-01, -1.1053e-01,  2.1004e-02],\n",
      "        [-1.7260e-01,  5.4099e-02, -5.6400e-02, -1.7125e-01,  8.8814e-02,\n",
      "          1.2600e-01,  5.4029e-03,  4.3608e-02, -2.5121e-02, -2.9050e-02,\n",
      "          1.1437e-01, -9.2263e-02, -1.7070e-01,  1.3745e-01,  5.0392e-02,\n",
      "          8.3110e-02,  4.6521e-02, -1.4263e-01,  1.6249e-01, -8.3787e-02],\n",
      "        [ 3.5109e-02,  3.7892e-02,  7.1761e-02,  8.6715e-02, -5.1422e-02,\n",
      "          1.0545e-01, -1.0542e-02,  9.4736e-02,  3.5377e-02,  6.7244e-02,\n",
      "         -6.4734e-04,  1.9140e-03,  2.0923e-01,  1.2983e-01,  1.7811e-01,\n",
      "         -1.4742e-01,  4.8544e-02,  1.0768e-01,  1.9995e-01,  2.0865e-01],\n",
      "        [ 3.1309e-02,  5.5560e-02, -4.5872e-02,  9.9485e-02, -6.1507e-02,\n",
      "         -1.0258e-01, -1.1463e-01, -2.1300e-01, -1.9294e-01, -1.8298e-01,\n",
      "         -1.1654e-01,  1.6371e-01, -1.2361e-01, -1.9899e-01,  5.7704e-02,\n",
      "          4.4031e-03, -1.7469e-01, -4.7340e-02, -2.0236e-01,  4.1885e-02],\n",
      "        [ 4.4984e-02, -6.0577e-02, -8.9639e-02,  1.4766e-01, -2.0580e-01,\n",
      "         -2.0439e-01, -1.3588e-02, -2.0422e-01, -1.6505e-01,  1.5425e-01,\n",
      "          1.1662e-01,  1.4783e-01,  2.9412e-02, -1.3749e-01,  5.5151e-03,\n",
      "         -2.1687e-01,  2.1787e-02,  1.6840e-01,  1.3121e-01, -3.7015e-02],\n",
      "        [-9.8892e-02, -1.0723e-01, -1.1828e-02,  4.5357e-02, -2.2092e-01,\n",
      "         -5.6641e-03, -1.4490e-01,  9.2523e-02,  1.5668e-01,  1.4465e-01,\n",
      "          1.6711e-01, -1.1903e-02,  6.2975e-02, -1.6055e-01, -5.6268e-02,\n",
      "          1.5013e-01, -1.1742e-01,  5.3122e-02, -1.2404e-01,  9.0992e-02],\n",
      "        [ 2.0501e-01, -1.5950e-01, -2.2175e-01,  1.2758e-01,  1.1608e-01,\n",
      "         -1.5776e-01,  1.4429e-01, -1.8911e-01,  1.2324e-01,  1.5138e-01,\n",
      "          1.2670e-02, -1.3566e-01,  1.6343e-01,  3.6415e-02,  1.5710e-01,\n",
      "         -1.8354e-01,  1.8072e-01, -4.4741e-02,  1.5831e-02, -7.0471e-02],\n",
      "        [ 4.4402e-02,  8.3716e-02,  6.9274e-02, -1.9928e-01,  5.4525e-02,\n",
      "          1.4866e-01, -2.1739e-01, -1.9738e-01, -2.0871e-01, -6.4360e-02,\n",
      "         -1.8894e-01, -1.6745e-01, -1.0674e-01,  1.8327e-02, -1.4173e-01,\n",
      "          1.1529e-01,  1.8265e-01, -1.4662e-02,  1.6950e-02, -1.4303e-01],\n",
      "        [ 5.1754e-02, -2.2120e-01,  9.6394e-02,  1.5069e-01, -1.6839e-01,\n",
      "          2.0176e-01,  2.1242e-04,  1.5993e-01, -1.2971e-02,  1.6729e-03,\n",
      "          2.4724e-02,  7.6497e-02,  1.7698e-01, -1.8038e-01, -1.8768e-01,\n",
      "          2.1758e-01,  4.3249e-02, -4.3621e-03,  2.4473e-02, -1.2453e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1644, -0.0956, -0.1990, -0.1175,  0.0667,  0.0791, -0.1878, -0.1217,\n",
      "        -0.1385,  0.2038, -0.0967,  0.0513,  0.0588,  0.2015,  0.0424, -0.2220,\n",
      "         0.1208, -0.1456,  0.0666, -0.2011], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1376, -0.1959,  0.1488, -0.0615, -0.0848,  0.2017,  0.1039, -0.1543,\n",
      "         -0.1843,  0.1438, -0.1916, -0.0483,  0.1631, -0.1102,  0.0177,  0.0556,\n",
      "          0.1943,  0.1855, -0.1450, -0.1891],\n",
      "        [-0.1827,  0.2224,  0.1662, -0.1631,  0.0696,  0.0710,  0.0893,  0.1949,\n",
      "         -0.1443,  0.1759,  0.2143,  0.2086,  0.2068,  0.1584, -0.0748, -0.2032,\n",
      "         -0.1487,  0.1383,  0.1746,  0.1938],\n",
      "        [-0.1745,  0.1001,  0.0837, -0.1081,  0.2186,  0.1865,  0.2024,  0.1423,\n",
      "          0.0807,  0.0810,  0.1676,  0.2045, -0.0391, -0.0378,  0.1784, -0.1011,\n",
      "          0.1591,  0.1922, -0.0463,  0.0918],\n",
      "        [ 0.0929,  0.0887, -0.1715, -0.0632,  0.2116, -0.0392, -0.1772,  0.0037,\n",
      "          0.1160,  0.0755, -0.1432,  0.0127, -0.0527,  0.0937,  0.1147, -0.0199,\n",
      "         -0.0543, -0.1474, -0.1194,  0.1382],\n",
      "        [ 0.1107,  0.1983,  0.1619,  0.1720, -0.1024, -0.1653, -0.1623, -0.1231,\n",
      "         -0.1060,  0.0103,  0.0756, -0.1790,  0.0602, -0.0871,  0.1632,  0.0095,\n",
      "         -0.0976,  0.0344,  0.1450,  0.1419]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1066, -0.2134,  0.1480,  0.0016,  0.1422], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2373, -0.0581,  0.0688,  0.0273,  0.1523, -0.0840, -0.0747,  0.2421,\n",
      "         -0.1934, -0.0868],\n",
      "        [-0.2723,  0.2124, -0.2399, -0.2345, -0.1605,  0.0148,  0.0988, -0.2857,\n",
      "          0.2391,  0.1391]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0914, 0.1178], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in obj1.model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59iLYeT-NRsG"
   },
   "source": [
    "# RUN for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ekz8oACnb3tA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "====> Epoch: 1 total_train_loss: 1.000880 Total_test_loss: 0.870857 Total_BCE_test_loss: 0.793625 Total_KLD_test_loss: 0.000060 Total_CEP_test_loss: 0.077172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohsennabian/Desktop/ci_vae/example/ci_vae/ivae.py:372: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(torch.reshape(y, (-1,)), dtype=torch.long)\n",
      "/Users/mohsennabian/Desktop/ci_vae/example/ci_vae/ivae.py:400: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(torch.reshape(y, (-1,)), dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 total_train_loss: 0.936869 Total_test_loss: 0.867478 Total_BCE_test_loss: 0.790890 Total_KLD_test_loss: 0.000061 Total_CEP_test_loss: 0.076527\n",
      "====> Epoch: 3 total_train_loss: 0.915077 Total_test_loss: 0.862164 Total_BCE_test_loss: 0.789154 Total_KLD_test_loss: 0.000076 Total_CEP_test_loss: 0.072934\n",
      "====> Epoch: 4 total_train_loss: 0.906228 Total_test_loss: 0.862140 Total_BCE_test_loss: 0.788404 Total_KLD_test_loss: 0.000116 Total_CEP_test_loss: 0.073620\n",
      "====> Epoch: 5 total_train_loss: 0.903028 Total_test_loss: 0.862206 Total_BCE_test_loss: 0.788800 Total_KLD_test_loss: 0.000183 Total_CEP_test_loss: 0.073223\n",
      "====> Epoch: 6 total_train_loss: 0.884127 Total_test_loss: 0.860501 Total_BCE_test_loss: 0.788520 Total_KLD_test_loss: 0.000245 Total_CEP_test_loss: 0.071736\n",
      "====> Epoch: 7 total_train_loss: 0.878501 Total_test_loss: 0.861922 Total_BCE_test_loss: 0.789539 Total_KLD_test_loss: 0.000269 Total_CEP_test_loss: 0.072114\n",
      "====> Epoch: 8 total_train_loss: 0.874775 Total_test_loss: 0.858357 Total_BCE_test_loss: 0.787098 Total_KLD_test_loss: 0.000326 Total_CEP_test_loss: 0.070933\n",
      "====> Epoch: 9 total_train_loss: 0.870346 Total_test_loss: 0.856657 Total_BCE_test_loss: 0.786463 Total_KLD_test_loss: 0.000395 Total_CEP_test_loss: 0.069799\n",
      "====> Epoch: 10 total_train_loss: 0.866520 Total_test_loss: 0.852968 Total_BCE_test_loss: 0.782858 Total_KLD_test_loss: 0.000482 Total_CEP_test_loss: 0.069628\n",
      "====> Epoch: 11 total_train_loss: 0.862224 Total_test_loss: 0.850120 Total_BCE_test_loss: 0.779795 Total_KLD_test_loss: 0.000565 Total_CEP_test_loss: 0.069760\n",
      "====> Epoch: 12 total_train_loss: 0.858980 Total_test_loss: 0.846109 Total_BCE_test_loss: 0.775741 Total_KLD_test_loss: 0.000661 Total_CEP_test_loss: 0.069707\n",
      "====> Epoch: 13 total_train_loss: 0.853989 Total_test_loss: 0.842848 Total_BCE_test_loss: 0.772476 Total_KLD_test_loss: 0.000741 Total_CEP_test_loss: 0.069631\n",
      "====> Epoch: 14 total_train_loss: 0.854683 Total_test_loss: 0.831603 Total_BCE_test_loss: 0.761321 Total_KLD_test_loss: 0.000825 Total_CEP_test_loss: 0.069457\n",
      "====> Epoch: 15 total_train_loss: 0.844496 Total_test_loss: 0.826499 Total_BCE_test_loss: 0.756154 Total_KLD_test_loss: 0.000893 Total_CEP_test_loss: 0.069452\n",
      "====> Epoch: 16 total_train_loss: 0.841402 Total_test_loss: 0.822342 Total_BCE_test_loss: 0.752068 Total_KLD_test_loss: 0.000961 Total_CEP_test_loss: 0.069313\n",
      "====> Epoch: 17 total_train_loss: 0.840651 Total_test_loss: 0.819057 Total_BCE_test_loss: 0.748170 Total_KLD_test_loss: 0.001012 Total_CEP_test_loss: 0.069876\n",
      "====> Epoch: 18 total_train_loss: 0.836882 Total_test_loss: 0.817141 Total_BCE_test_loss: 0.746423 Total_KLD_test_loss: 0.001074 Total_CEP_test_loss: 0.069644\n",
      "====> Epoch: 19 total_train_loss: 0.836755 Total_test_loss: 0.809365 Total_BCE_test_loss: 0.738694 Total_KLD_test_loss: 0.001173 Total_CEP_test_loss: 0.069498\n",
      "====> Epoch: 20 total_train_loss: 0.833784 Total_test_loss: 0.809473 Total_BCE_test_loss: 0.738793 Total_KLD_test_loss: 0.001265 Total_CEP_test_loss: 0.069415\n",
      "====> Epoch: 21 total_train_loss: 0.823059 Total_test_loss: 0.803735 Total_BCE_test_loss: 0.732930 Total_KLD_test_loss: 0.001347 Total_CEP_test_loss: 0.069457\n",
      "====> Epoch: 22 total_train_loss: 0.822726 Total_test_loss: 0.803945 Total_BCE_test_loss: 0.733005 Total_KLD_test_loss: 0.001435 Total_CEP_test_loss: 0.069505\n",
      "====> Epoch: 23 total_train_loss: 0.815405 Total_test_loss: 0.801140 Total_BCE_test_loss: 0.730226 Total_KLD_test_loss: 0.001497 Total_CEP_test_loss: 0.069417\n",
      "====> Epoch: 24 total_train_loss: 0.814154 Total_test_loss: 0.793445 Total_BCE_test_loss: 0.722234 Total_KLD_test_loss: 0.001659 Total_CEP_test_loss: 0.069552\n",
      "====> Epoch: 25 total_train_loss: 0.808796 Total_test_loss: 0.787979 Total_BCE_test_loss: 0.716892 Total_KLD_test_loss: 0.001723 Total_CEP_test_loss: 0.069364\n",
      "====> Epoch: 26 total_train_loss: 0.804373 Total_test_loss: 0.784437 Total_BCE_test_loss: 0.713208 Total_KLD_test_loss: 0.001792 Total_CEP_test_loss: 0.069437\n",
      "====> Epoch: 27 total_train_loss: 0.802265 Total_test_loss: 0.785483 Total_BCE_test_loss: 0.714194 Total_KLD_test_loss: 0.001842 Total_CEP_test_loss: 0.069447\n",
      "====> Epoch: 28 total_train_loss: 0.804626 Total_test_loss: 0.786624 Total_BCE_test_loss: 0.715402 Total_KLD_test_loss: 0.001866 Total_CEP_test_loss: 0.069356\n",
      "====> Epoch: 29 total_train_loss: 0.797655 Total_test_loss: 0.779661 Total_BCE_test_loss: 0.708618 Total_KLD_test_loss: 0.001915 Total_CEP_test_loss: 0.069128\n",
      "====> Epoch: 30 total_train_loss: 0.792821 Total_test_loss: 0.779976 Total_BCE_test_loss: 0.708420 Total_KLD_test_loss: 0.001963 Total_CEP_test_loss: 0.069594\n",
      "====> Epoch: 31 total_train_loss: 0.788676 Total_test_loss: 0.770615 Total_BCE_test_loss: 0.699200 Total_KLD_test_loss: 0.002058 Total_CEP_test_loss: 0.069358\n",
      "====> Epoch: 32 total_train_loss: 0.789315 Total_test_loss: 0.765291 Total_BCE_test_loss: 0.693799 Total_KLD_test_loss: 0.002145 Total_CEP_test_loss: 0.069348\n",
      "====> Epoch: 33 total_train_loss: 0.781894 Total_test_loss: 0.762917 Total_BCE_test_loss: 0.691405 Total_KLD_test_loss: 0.002183 Total_CEP_test_loss: 0.069329\n",
      "====> Epoch: 34 total_train_loss: 0.778844 Total_test_loss: 0.757882 Total_BCE_test_loss: 0.686318 Total_KLD_test_loss: 0.002248 Total_CEP_test_loss: 0.069316\n",
      "====> Epoch: 35 total_train_loss: 0.773778 Total_test_loss: 0.755917 Total_BCE_test_loss: 0.684302 Total_KLD_test_loss: 0.002247 Total_CEP_test_loss: 0.069368\n",
      "====> Epoch: 36 total_train_loss: 0.776364 Total_test_loss: 0.746669 Total_BCE_test_loss: 0.674984 Total_KLD_test_loss: 0.002267 Total_CEP_test_loss: 0.069418\n",
      "====> Epoch: 37 total_train_loss: 0.767278 Total_test_loss: 0.741837 Total_BCE_test_loss: 0.670139 Total_KLD_test_loss: 0.002364 Total_CEP_test_loss: 0.069334\n",
      "====> Epoch: 38 total_train_loss: 0.765887 Total_test_loss: 0.737608 Total_BCE_test_loss: 0.665777 Total_KLD_test_loss: 0.002462 Total_CEP_test_loss: 0.069369\n",
      "====> Epoch: 39 total_train_loss: 0.762156 Total_test_loss: 0.739580 Total_BCE_test_loss: 0.667749 Total_KLD_test_loss: 0.002585 Total_CEP_test_loss: 0.069247\n",
      "====> Epoch: 40 total_train_loss: 0.758520 Total_test_loss: 0.737960 Total_BCE_test_loss: 0.666012 Total_KLD_test_loss: 0.002700 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 41 total_train_loss: 0.756165 Total_test_loss: 0.737082 Total_BCE_test_loss: 0.664976 Total_KLD_test_loss: 0.002837 Total_CEP_test_loss: 0.069269\n",
      "====> Epoch: 42 total_train_loss: 0.754836 Total_test_loss: 0.733007 Total_BCE_test_loss: 0.660826 Total_KLD_test_loss: 0.002967 Total_CEP_test_loss: 0.069214\n",
      "====> Epoch: 43 total_train_loss: 0.748488 Total_test_loss: 0.729367 Total_BCE_test_loss: 0.656966 Total_KLD_test_loss: 0.003027 Total_CEP_test_loss: 0.069374\n",
      "====> Epoch: 44 total_train_loss: 0.747774 Total_test_loss: 0.726622 Total_BCE_test_loss: 0.654161 Total_KLD_test_loss: 0.003091 Total_CEP_test_loss: 0.069369\n",
      "====> Epoch: 45 total_train_loss: 0.750409 Total_test_loss: 0.728694 Total_BCE_test_loss: 0.656146 Total_KLD_test_loss: 0.003147 Total_CEP_test_loss: 0.069401\n",
      "====> Epoch: 46 total_train_loss: 0.747712 Total_test_loss: 0.726663 Total_BCE_test_loss: 0.654012 Total_KLD_test_loss: 0.003258 Total_CEP_test_loss: 0.069393\n",
      "====> Epoch: 47 total_train_loss: 0.743774 Total_test_loss: 0.726729 Total_BCE_test_loss: 0.654036 Total_KLD_test_loss: 0.003336 Total_CEP_test_loss: 0.069357\n",
      "====> Epoch: 48 total_train_loss: 0.744219 Total_test_loss: 0.725007 Total_BCE_test_loss: 0.652418 Total_KLD_test_loss: 0.003328 Total_CEP_test_loss: 0.069260\n",
      "====> Epoch: 49 total_train_loss: 0.739528 Total_test_loss: 0.719685 Total_BCE_test_loss: 0.647173 Total_KLD_test_loss: 0.003319 Total_CEP_test_loss: 0.069194\n",
      "====> Epoch: 50 total_train_loss: 0.741582 Total_test_loss: 0.721969 Total_BCE_test_loss: 0.649265 Total_KLD_test_loss: 0.003393 Total_CEP_test_loss: 0.069310\n",
      "====> Epoch: 51 total_train_loss: 0.741349 Total_test_loss: 0.719543 Total_BCE_test_loss: 0.646875 Total_KLD_test_loss: 0.003385 Total_CEP_test_loss: 0.069284\n",
      "====> Epoch: 52 total_train_loss: 0.743232 Total_test_loss: 0.717861 Total_BCE_test_loss: 0.645172 Total_KLD_test_loss: 0.003409 Total_CEP_test_loss: 0.069280\n",
      "====> Epoch: 53 total_train_loss: 0.738986 Total_test_loss: 0.714014 Total_BCE_test_loss: 0.641388 Total_KLD_test_loss: 0.003423 Total_CEP_test_loss: 0.069203\n",
      "====> Epoch: 54 total_train_loss: 0.734051 Total_test_loss: 0.713811 Total_BCE_test_loss: 0.641063 Total_KLD_test_loss: 0.003446 Total_CEP_test_loss: 0.069301\n",
      "====> Epoch: 55 total_train_loss: 0.731618 Total_test_loss: 0.709564 Total_BCE_test_loss: 0.636800 Total_KLD_test_loss: 0.003535 Total_CEP_test_loss: 0.069229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 56 total_train_loss: 0.732513 Total_test_loss: 0.708396 Total_BCE_test_loss: 0.635541 Total_KLD_test_loss: 0.003568 Total_CEP_test_loss: 0.069286\n",
      "====> Epoch: 57 total_train_loss: 0.732083 Total_test_loss: 0.704336 Total_BCE_test_loss: 0.631740 Total_KLD_test_loss: 0.003559 Total_CEP_test_loss: 0.069037\n",
      "====> Epoch: 58 total_train_loss: 0.726961 Total_test_loss: 0.703630 Total_BCE_test_loss: 0.630929 Total_KLD_test_loss: 0.003580 Total_CEP_test_loss: 0.069120\n",
      "====> Epoch: 59 total_train_loss: 0.725546 Total_test_loss: 0.700837 Total_BCE_test_loss: 0.628032 Total_KLD_test_loss: 0.003593 Total_CEP_test_loss: 0.069212\n",
      "====> Epoch: 60 total_train_loss: 0.725944 Total_test_loss: 0.701423 Total_BCE_test_loss: 0.628599 Total_KLD_test_loss: 0.003594 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 61 total_train_loss: 0.729759 Total_test_loss: 0.703653 Total_BCE_test_loss: 0.630709 Total_KLD_test_loss: 0.003620 Total_CEP_test_loss: 0.069324\n",
      "====> Epoch: 62 total_train_loss: 0.722182 Total_test_loss: 0.700399 Total_BCE_test_loss: 0.627259 Total_KLD_test_loss: 0.003693 Total_CEP_test_loss: 0.069447\n",
      "====> Epoch: 63 total_train_loss: 0.722932 Total_test_loss: 0.700257 Total_BCE_test_loss: 0.627037 Total_KLD_test_loss: 0.003701 Total_CEP_test_loss: 0.069518\n",
      "====> Epoch: 64 total_train_loss: 0.720360 Total_test_loss: 0.699826 Total_BCE_test_loss: 0.626535 Total_KLD_test_loss: 0.003784 Total_CEP_test_loss: 0.069507\n",
      "====> Epoch: 65 total_train_loss: 0.719766 Total_test_loss: 0.695981 Total_BCE_test_loss: 0.622830 Total_KLD_test_loss: 0.003859 Total_CEP_test_loss: 0.069293\n",
      "====> Epoch: 66 total_train_loss: 0.717801 Total_test_loss: 0.695596 Total_BCE_test_loss: 0.622677 Total_KLD_test_loss: 0.003901 Total_CEP_test_loss: 0.069018\n",
      "====> Epoch: 67 total_train_loss: 0.722262 Total_test_loss: 0.693163 Total_BCE_test_loss: 0.619948 Total_KLD_test_loss: 0.003994 Total_CEP_test_loss: 0.069221\n",
      "====> Epoch: 68 total_train_loss: 0.716539 Total_test_loss: 0.690078 Total_BCE_test_loss: 0.616947 Total_KLD_test_loss: 0.004048 Total_CEP_test_loss: 0.069084\n",
      "====> Epoch: 69 total_train_loss: 0.714248 Total_test_loss: 0.686864 Total_BCE_test_loss: 0.613453 Total_KLD_test_loss: 0.004032 Total_CEP_test_loss: 0.069378\n",
      "====> Epoch: 70 total_train_loss: 0.710274 Total_test_loss: 0.681966 Total_BCE_test_loss: 0.608326 Total_KLD_test_loss: 0.004071 Total_CEP_test_loss: 0.069569\n",
      "====> Epoch: 71 total_train_loss: 0.710461 Total_test_loss: 0.681664 Total_BCE_test_loss: 0.608182 Total_KLD_test_loss: 0.004075 Total_CEP_test_loss: 0.069406\n",
      "====> Epoch: 72 total_train_loss: 0.710353 Total_test_loss: 0.678971 Total_BCE_test_loss: 0.605666 Total_KLD_test_loss: 0.004089 Total_CEP_test_loss: 0.069216\n",
      "====> Epoch: 73 total_train_loss: 0.704781 Total_test_loss: 0.679685 Total_BCE_test_loss: 0.606327 Total_KLD_test_loss: 0.004106 Total_CEP_test_loss: 0.069252\n",
      "====> Epoch: 74 total_train_loss: 0.707928 Total_test_loss: 0.676616 Total_BCE_test_loss: 0.603315 Total_KLD_test_loss: 0.004165 Total_CEP_test_loss: 0.069136\n",
      "====> Epoch: 75 total_train_loss: 0.706041 Total_test_loss: 0.675044 Total_BCE_test_loss: 0.601723 Total_KLD_test_loss: 0.004181 Total_CEP_test_loss: 0.069139\n",
      "====> Epoch: 76 total_train_loss: 0.705295 Total_test_loss: 0.675686 Total_BCE_test_loss: 0.602338 Total_KLD_test_loss: 0.004254 Total_CEP_test_loss: 0.069094\n",
      "====> Epoch: 77 total_train_loss: 0.704750 Total_test_loss: 0.672651 Total_BCE_test_loss: 0.599133 Total_KLD_test_loss: 0.004297 Total_CEP_test_loss: 0.069222\n",
      "====> Epoch: 78 total_train_loss: 0.703830 Total_test_loss: 0.672496 Total_BCE_test_loss: 0.598761 Total_KLD_test_loss: 0.004329 Total_CEP_test_loss: 0.069406\n",
      "====> Epoch: 79 total_train_loss: 0.702982 Total_test_loss: 0.670437 Total_BCE_test_loss: 0.596509 Total_KLD_test_loss: 0.004426 Total_CEP_test_loss: 0.069501\n",
      "====> Epoch: 80 total_train_loss: 0.700186 Total_test_loss: 0.666212 Total_BCE_test_loss: 0.592421 Total_KLD_test_loss: 0.004475 Total_CEP_test_loss: 0.069316\n",
      "====> Epoch: 81 total_train_loss: 0.701419 Total_test_loss: 0.664468 Total_BCE_test_loss: 0.590778 Total_KLD_test_loss: 0.004576 Total_CEP_test_loss: 0.069114\n",
      "====> Epoch: 82 total_train_loss: 0.694849 Total_test_loss: 0.662502 Total_BCE_test_loss: 0.588825 Total_KLD_test_loss: 0.004616 Total_CEP_test_loss: 0.069061\n",
      "====> Epoch: 83 total_train_loss: 0.696831 Total_test_loss: 0.658522 Total_BCE_test_loss: 0.584716 Total_KLD_test_loss: 0.004680 Total_CEP_test_loss: 0.069126\n",
      "====> Epoch: 84 total_train_loss: 0.698440 Total_test_loss: 0.656789 Total_BCE_test_loss: 0.582935 Total_KLD_test_loss: 0.004731 Total_CEP_test_loss: 0.069123\n",
      "====> Epoch: 85 total_train_loss: 0.696368 Total_test_loss: 0.656846 Total_BCE_test_loss: 0.582917 Total_KLD_test_loss: 0.004731 Total_CEP_test_loss: 0.069198\n",
      "====> Epoch: 86 total_train_loss: 0.692656 Total_test_loss: 0.659527 Total_BCE_test_loss: 0.585630 Total_KLD_test_loss: 0.004731 Total_CEP_test_loss: 0.069166\n",
      "====> Epoch: 87 total_train_loss: 0.688440 Total_test_loss: 0.659471 Total_BCE_test_loss: 0.585482 Total_KLD_test_loss: 0.004769 Total_CEP_test_loss: 0.069220\n",
      "====> Epoch: 88 total_train_loss: 0.691582 Total_test_loss: 0.651231 Total_BCE_test_loss: 0.577179 Total_KLD_test_loss: 0.004818 Total_CEP_test_loss: 0.069234\n",
      "====> Epoch: 89 total_train_loss: 0.688858 Total_test_loss: 0.655561 Total_BCE_test_loss: 0.581412 Total_KLD_test_loss: 0.004738 Total_CEP_test_loss: 0.069411\n",
      "====> Epoch: 90 total_train_loss: 0.688531 Total_test_loss: 0.650892 Total_BCE_test_loss: 0.576932 Total_KLD_test_loss: 0.004797 Total_CEP_test_loss: 0.069162\n",
      "====> Epoch: 91 total_train_loss: 0.686981 Total_test_loss: 0.646402 Total_BCE_test_loss: 0.572356 Total_KLD_test_loss: 0.004860 Total_CEP_test_loss: 0.069185\n",
      "====> Epoch: 92 total_train_loss: 0.686361 Total_test_loss: 0.642673 Total_BCE_test_loss: 0.568294 Total_KLD_test_loss: 0.004920 Total_CEP_test_loss: 0.069459\n",
      "====> Epoch: 93 total_train_loss: 0.684659 Total_test_loss: 0.645417 Total_BCE_test_loss: 0.570915 Total_KLD_test_loss: 0.004991 Total_CEP_test_loss: 0.069512\n",
      "====> Epoch: 94 total_train_loss: 0.679783 Total_test_loss: 0.645468 Total_BCE_test_loss: 0.571143 Total_KLD_test_loss: 0.005036 Total_CEP_test_loss: 0.069289\n",
      "====> Epoch: 95 total_train_loss: 0.682520 Total_test_loss: 0.643099 Total_BCE_test_loss: 0.568748 Total_KLD_test_loss: 0.005077 Total_CEP_test_loss: 0.069274\n",
      "====> Epoch: 96 total_train_loss: 0.678988 Total_test_loss: 0.640512 Total_BCE_test_loss: 0.566183 Total_KLD_test_loss: 0.005130 Total_CEP_test_loss: 0.069199\n",
      "====> Epoch: 97 total_train_loss: 0.686374 Total_test_loss: 0.643522 Total_BCE_test_loss: 0.568862 Total_KLD_test_loss: 0.005290 Total_CEP_test_loss: 0.069369\n",
      "====> Epoch: 98 total_train_loss: 0.675082 Total_test_loss: 0.638398 Total_BCE_test_loss: 0.563657 Total_KLD_test_loss: 0.005333 Total_CEP_test_loss: 0.069408\n",
      "====> Epoch: 99 total_train_loss: 0.675657 Total_test_loss: 0.635940 Total_BCE_test_loss: 0.561299 Total_KLD_test_loss: 0.005260 Total_CEP_test_loss: 0.069381\n",
      "====> Epoch: 100 total_train_loss: 0.674866 Total_test_loss: 0.632060 Total_BCE_test_loss: 0.557519 Total_KLD_test_loss: 0.005222 Total_CEP_test_loss: 0.069319\n",
      "0.001\n",
      "0.001\n",
      "0.001\n",
      "0.0005\n",
      "====> Epoch: 1 total_train_loss: 0.674956 Total_test_loss: 0.630033 Total_BCE_test_loss: 0.555474 Total_KLD_test_loss: 0.005227 Total_CEP_test_loss: 0.069332\n",
      "====> Epoch: 2 total_train_loss: 0.673187 Total_test_loss: 0.629275 Total_BCE_test_loss: 0.554852 Total_KLD_test_loss: 0.005162 Total_CEP_test_loss: 0.069260\n",
      "====> Epoch: 3 total_train_loss: 0.672665 Total_test_loss: 0.629573 Total_BCE_test_loss: 0.555049 Total_KLD_test_loss: 0.005172 Total_CEP_test_loss: 0.069352\n",
      "====> Epoch: 4 total_train_loss: 0.666381 Total_test_loss: 0.628616 Total_BCE_test_loss: 0.554106 Total_KLD_test_loss: 0.005187 Total_CEP_test_loss: 0.069322\n",
      "====> Epoch: 5 total_train_loss: 0.671201 Total_test_loss: 0.627615 Total_BCE_test_loss: 0.553190 Total_KLD_test_loss: 0.005177 Total_CEP_test_loss: 0.069247\n",
      "====> Epoch: 6 total_train_loss: 0.671952 Total_test_loss: 0.627676 Total_BCE_test_loss: 0.553263 Total_KLD_test_loss: 0.005151 Total_CEP_test_loss: 0.069261\n",
      "====> Epoch: 7 total_train_loss: 0.672834 Total_test_loss: 0.627188 Total_BCE_test_loss: 0.552737 Total_KLD_test_loss: 0.005152 Total_CEP_test_loss: 0.069299\n",
      "====> Epoch: 8 total_train_loss: 0.666568 Total_test_loss: 0.626876 Total_BCE_test_loss: 0.552499 Total_KLD_test_loss: 0.005119 Total_CEP_test_loss: 0.069258\n",
      "====> Epoch: 9 total_train_loss: 0.669501 Total_test_loss: 0.626719 Total_BCE_test_loss: 0.552390 Total_KLD_test_loss: 0.005090 Total_CEP_test_loss: 0.069239\n",
      "====> Epoch: 10 total_train_loss: 0.669587 Total_test_loss: 0.626564 Total_BCE_test_loss: 0.552165 Total_KLD_test_loss: 0.005078 Total_CEP_test_loss: 0.069321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 11 total_train_loss: 0.671057 Total_test_loss: 0.627102 Total_BCE_test_loss: 0.552781 Total_KLD_test_loss: 0.005125 Total_CEP_test_loss: 0.069196\n",
      "====> Epoch: 12 total_train_loss: 0.666172 Total_test_loss: 0.626093 Total_BCE_test_loss: 0.551717 Total_KLD_test_loss: 0.005140 Total_CEP_test_loss: 0.069236\n",
      "====> Epoch: 13 total_train_loss: 0.666923 Total_test_loss: 0.625615 Total_BCE_test_loss: 0.551252 Total_KLD_test_loss: 0.005114 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 14 total_train_loss: 0.665132 Total_test_loss: 0.624622 Total_BCE_test_loss: 0.550204 Total_KLD_test_loss: 0.005129 Total_CEP_test_loss: 0.069289\n",
      "====> Epoch: 15 total_train_loss: 0.666590 Total_test_loss: 0.625310 Total_BCE_test_loss: 0.550955 Total_KLD_test_loss: 0.005102 Total_CEP_test_loss: 0.069253\n",
      "====> Epoch: 16 total_train_loss: 0.668312 Total_test_loss: 0.622812 Total_BCE_test_loss: 0.548387 Total_KLD_test_loss: 0.005106 Total_CEP_test_loss: 0.069319\n",
      "====> Epoch: 17 total_train_loss: 0.664379 Total_test_loss: 0.623296 Total_BCE_test_loss: 0.548997 Total_KLD_test_loss: 0.005069 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 18 total_train_loss: 0.667961 Total_test_loss: 0.622925 Total_BCE_test_loss: 0.548552 Total_KLD_test_loss: 0.005129 Total_CEP_test_loss: 0.069244\n",
      "====> Epoch: 19 total_train_loss: 0.665366 Total_test_loss: 0.622197 Total_BCE_test_loss: 0.547798 Total_KLD_test_loss: 0.005088 Total_CEP_test_loss: 0.069311\n",
      "====> Epoch: 20 total_train_loss: 0.669751 Total_test_loss: 0.624404 Total_BCE_test_loss: 0.549988 Total_KLD_test_loss: 0.005083 Total_CEP_test_loss: 0.069333\n",
      "====> Epoch: 21 total_train_loss: 0.669262 Total_test_loss: 0.623360 Total_BCE_test_loss: 0.549013 Total_KLD_test_loss: 0.005142 Total_CEP_test_loss: 0.069204\n",
      "====> Epoch: 22 total_train_loss: 0.666460 Total_test_loss: 0.622395 Total_BCE_test_loss: 0.547974 Total_KLD_test_loss: 0.005176 Total_CEP_test_loss: 0.069246\n",
      "====> Epoch: 23 total_train_loss: 0.665246 Total_test_loss: 0.621690 Total_BCE_test_loss: 0.547202 Total_KLD_test_loss: 0.005240 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 24 total_train_loss: 0.668050 Total_test_loss: 0.620822 Total_BCE_test_loss: 0.546312 Total_KLD_test_loss: 0.005248 Total_CEP_test_loss: 0.069262\n",
      "====> Epoch: 25 total_train_loss: 0.666182 Total_test_loss: 0.621219 Total_BCE_test_loss: 0.546711 Total_KLD_test_loss: 0.005313 Total_CEP_test_loss: 0.069195\n",
      "====> Epoch: 26 total_train_loss: 0.663054 Total_test_loss: 0.621642 Total_BCE_test_loss: 0.547127 Total_KLD_test_loss: 0.005253 Total_CEP_test_loss: 0.069262\n",
      "====> Epoch: 27 total_train_loss: 0.661395 Total_test_loss: 0.622670 Total_BCE_test_loss: 0.548190 Total_KLD_test_loss: 0.005265 Total_CEP_test_loss: 0.069215\n",
      "====> Epoch: 28 total_train_loss: 0.662306 Total_test_loss: 0.622355 Total_BCE_test_loss: 0.547912 Total_KLD_test_loss: 0.005202 Total_CEP_test_loss: 0.069241\n",
      "====> Epoch: 29 total_train_loss: 0.664713 Total_test_loss: 0.620111 Total_BCE_test_loss: 0.545629 Total_KLD_test_loss: 0.005233 Total_CEP_test_loss: 0.069249\n",
      "====> Epoch: 30 total_train_loss: 0.665210 Total_test_loss: 0.619772 Total_BCE_test_loss: 0.545270 Total_KLD_test_loss: 0.005289 Total_CEP_test_loss: 0.069213\n",
      "====> Epoch: 31 total_train_loss: 0.663215 Total_test_loss: 0.621089 Total_BCE_test_loss: 0.546534 Total_KLD_test_loss: 0.005324 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 32 total_train_loss: 0.663043 Total_test_loss: 0.619632 Total_BCE_test_loss: 0.545153 Total_KLD_test_loss: 0.005275 Total_CEP_test_loss: 0.069205\n",
      "====> Epoch: 33 total_train_loss: 0.664795 Total_test_loss: 0.620052 Total_BCE_test_loss: 0.545564 Total_KLD_test_loss: 0.005280 Total_CEP_test_loss: 0.069208\n",
      "====> Epoch: 34 total_train_loss: 0.661201 Total_test_loss: 0.618752 Total_BCE_test_loss: 0.544274 Total_KLD_test_loss: 0.005267 Total_CEP_test_loss: 0.069211\n",
      "====> Epoch: 35 total_train_loss: 0.660993 Total_test_loss: 0.619967 Total_BCE_test_loss: 0.545435 Total_KLD_test_loss: 0.005308 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 36 total_train_loss: 0.665479 Total_test_loss: 0.619155 Total_BCE_test_loss: 0.544578 Total_KLD_test_loss: 0.005301 Total_CEP_test_loss: 0.069276\n",
      "====> Epoch: 37 total_train_loss: 0.664413 Total_test_loss: 0.618465 Total_BCE_test_loss: 0.543925 Total_KLD_test_loss: 0.005316 Total_CEP_test_loss: 0.069224\n",
      "====> Epoch: 38 total_train_loss: 0.661225 Total_test_loss: 0.617680 Total_BCE_test_loss: 0.543226 Total_KLD_test_loss: 0.005270 Total_CEP_test_loss: 0.069184\n",
      "====> Epoch: 39 total_train_loss: 0.664688 Total_test_loss: 0.619751 Total_BCE_test_loss: 0.545246 Total_KLD_test_loss: 0.005275 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 40 total_train_loss: 0.667125 Total_test_loss: 0.618558 Total_BCE_test_loss: 0.544061 Total_KLD_test_loss: 0.005251 Total_CEP_test_loss: 0.069246\n",
      "====> Epoch: 41 total_train_loss: 0.661636 Total_test_loss: 0.616187 Total_BCE_test_loss: 0.541776 Total_KLD_test_loss: 0.005225 Total_CEP_test_loss: 0.069187\n",
      "====> Epoch: 42 total_train_loss: 0.660974 Total_test_loss: 0.617131 Total_BCE_test_loss: 0.542693 Total_KLD_test_loss: 0.005223 Total_CEP_test_loss: 0.069215\n",
      "====> Epoch: 43 total_train_loss: 0.661772 Total_test_loss: 0.617007 Total_BCE_test_loss: 0.542582 Total_KLD_test_loss: 0.005219 Total_CEP_test_loss: 0.069206\n",
      "====> Epoch: 44 total_train_loss: 0.660438 Total_test_loss: 0.617417 Total_BCE_test_loss: 0.542939 Total_KLD_test_loss: 0.005266 Total_CEP_test_loss: 0.069212\n",
      "====> Epoch: 45 total_train_loss: 0.661755 Total_test_loss: 0.616727 Total_BCE_test_loss: 0.542224 Total_KLD_test_loss: 0.005282 Total_CEP_test_loss: 0.069222\n",
      "====> Epoch: 46 total_train_loss: 0.661845 Total_test_loss: 0.616758 Total_BCE_test_loss: 0.542240 Total_KLD_test_loss: 0.005270 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 47 total_train_loss: 0.663027 Total_test_loss: 0.616976 Total_BCE_test_loss: 0.542422 Total_KLD_test_loss: 0.005311 Total_CEP_test_loss: 0.069243\n",
      "====> Epoch: 48 total_train_loss: 0.663017 Total_test_loss: 0.617831 Total_BCE_test_loss: 0.543283 Total_KLD_test_loss: 0.005308 Total_CEP_test_loss: 0.069241\n",
      "====> Epoch: 49 total_train_loss: 0.660665 Total_test_loss: 0.616758 Total_BCE_test_loss: 0.542274 Total_KLD_test_loss: 0.005262 Total_CEP_test_loss: 0.069222\n",
      "====> Epoch: 50 total_train_loss: 0.659117 Total_test_loss: 0.615584 Total_BCE_test_loss: 0.541017 Total_KLD_test_loss: 0.005312 Total_CEP_test_loss: 0.069255\n",
      "1e-05\n",
      "====> Epoch: 1 total_train_loss: 0.660568 Total_test_loss: 0.616072 Total_BCE_test_loss: 0.541578 Total_KLD_test_loss: 0.005266 Total_CEP_test_loss: 0.069228\n",
      "====> Epoch: 2 total_train_loss: 0.661386 Total_test_loss: 0.617610 Total_BCE_test_loss: 0.543142 Total_KLD_test_loss: 0.005222 Total_CEP_test_loss: 0.069245\n",
      "====> Epoch: 3 total_train_loss: 0.661673 Total_test_loss: 0.616933 Total_BCE_test_loss: 0.542432 Total_KLD_test_loss: 0.005244 Total_CEP_test_loss: 0.069258\n",
      "====> Epoch: 4 total_train_loss: 0.657977 Total_test_loss: 0.616452 Total_BCE_test_loss: 0.541949 Total_KLD_test_loss: 0.005247 Total_CEP_test_loss: 0.069255\n",
      "====> Epoch: 5 total_train_loss: 0.662500 Total_test_loss: 0.616321 Total_BCE_test_loss: 0.541737 Total_KLD_test_loss: 0.005325 Total_CEP_test_loss: 0.069259\n",
      "====> Epoch: 6 total_train_loss: 0.663235 Total_test_loss: 0.616214 Total_BCE_test_loss: 0.541655 Total_KLD_test_loss: 0.005306 Total_CEP_test_loss: 0.069252\n",
      "====> Epoch: 7 total_train_loss: 0.665737 Total_test_loss: 0.616159 Total_BCE_test_loss: 0.541614 Total_KLD_test_loss: 0.005275 Total_CEP_test_loss: 0.069270\n",
      "====> Epoch: 8 total_train_loss: 0.664626 Total_test_loss: 0.616015 Total_BCE_test_loss: 0.541524 Total_KLD_test_loss: 0.005237 Total_CEP_test_loss: 0.069253\n",
      "====> Epoch: 9 total_train_loss: 0.660023 Total_test_loss: 0.616852 Total_BCE_test_loss: 0.542397 Total_KLD_test_loss: 0.005250 Total_CEP_test_loss: 0.069205\n",
      "====> Epoch: 10 total_train_loss: 0.664737 Total_test_loss: 0.616606 Total_BCE_test_loss: 0.542144 Total_KLD_test_loss: 0.005228 Total_CEP_test_loss: 0.069234\n",
      "====> Epoch: 11 total_train_loss: 0.660724 Total_test_loss: 0.616508 Total_BCE_test_loss: 0.542027 Total_KLD_test_loss: 0.005249 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 12 total_train_loss: 0.661568 Total_test_loss: 0.617022 Total_BCE_test_loss: 0.542497 Total_KLD_test_loss: 0.005273 Total_CEP_test_loss: 0.069252\n",
      "====> Epoch: 13 total_train_loss: 0.656768 Total_test_loss: 0.616921 Total_BCE_test_loss: 0.542388 Total_KLD_test_loss: 0.005280 Total_CEP_test_loss: 0.069254\n",
      "====> Epoch: 14 total_train_loss: 0.662912 Total_test_loss: 0.616222 Total_BCE_test_loss: 0.541737 Total_KLD_test_loss: 0.005242 Total_CEP_test_loss: 0.069243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 15 total_train_loss: 0.662921 Total_test_loss: 0.615461 Total_BCE_test_loss: 0.540937 Total_KLD_test_loss: 0.005276 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 16 total_train_loss: 0.663402 Total_test_loss: 0.616017 Total_BCE_test_loss: 0.541428 Total_KLD_test_loss: 0.005346 Total_CEP_test_loss: 0.069243\n",
      "====> Epoch: 17 total_train_loss: 0.659355 Total_test_loss: 0.617635 Total_BCE_test_loss: 0.543090 Total_KLD_test_loss: 0.005297 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 18 total_train_loss: 0.661492 Total_test_loss: 0.616238 Total_BCE_test_loss: 0.541694 Total_KLD_test_loss: 0.005303 Total_CEP_test_loss: 0.069241\n",
      "====> Epoch: 19 total_train_loss: 0.661938 Total_test_loss: 0.615897 Total_BCE_test_loss: 0.541327 Total_KLD_test_loss: 0.005304 Total_CEP_test_loss: 0.069265\n",
      "====> Epoch: 20 total_train_loss: 0.659069 Total_test_loss: 0.616219 Total_BCE_test_loss: 0.541689 Total_KLD_test_loss: 0.005289 Total_CEP_test_loss: 0.069241\n",
      "====> Epoch: 21 total_train_loss: 0.659797 Total_test_loss: 0.615986 Total_BCE_test_loss: 0.541452 Total_KLD_test_loss: 0.005302 Total_CEP_test_loss: 0.069233\n",
      "====> Epoch: 22 total_train_loss: 0.659533 Total_test_loss: 0.616600 Total_BCE_test_loss: 0.542141 Total_KLD_test_loss: 0.005226 Total_CEP_test_loss: 0.069234\n",
      "====> Epoch: 23 total_train_loss: 0.659547 Total_test_loss: 0.616314 Total_BCE_test_loss: 0.541879 Total_KLD_test_loss: 0.005180 Total_CEP_test_loss: 0.069254\n",
      "====> Epoch: 24 total_train_loss: 0.658379 Total_test_loss: 0.617152 Total_BCE_test_loss: 0.542702 Total_KLD_test_loss: 0.005229 Total_CEP_test_loss: 0.069221\n",
      "====> Epoch: 25 total_train_loss: 0.657557 Total_test_loss: 0.617453 Total_BCE_test_loss: 0.542972 Total_KLD_test_loss: 0.005234 Total_CEP_test_loss: 0.069246\n",
      "====> Epoch: 26 total_train_loss: 0.659189 Total_test_loss: 0.616826 Total_BCE_test_loss: 0.542367 Total_KLD_test_loss: 0.005267 Total_CEP_test_loss: 0.069191\n",
      "====> Epoch: 27 total_train_loss: 0.663307 Total_test_loss: 0.616877 Total_BCE_test_loss: 0.542350 Total_KLD_test_loss: 0.005276 Total_CEP_test_loss: 0.069251\n",
      "====> Epoch: 28 total_train_loss: 0.661360 Total_test_loss: 0.616137 Total_BCE_test_loss: 0.541671 Total_KLD_test_loss: 0.005248 Total_CEP_test_loss: 0.069218\n",
      "====> Epoch: 29 total_train_loss: 0.661652 Total_test_loss: 0.615407 Total_BCE_test_loss: 0.540878 Total_KLD_test_loss: 0.005268 Total_CEP_test_loss: 0.069262\n",
      "====> Epoch: 30 total_train_loss: 0.662557 Total_test_loss: 0.615647 Total_BCE_test_loss: 0.541093 Total_KLD_test_loss: 0.005265 Total_CEP_test_loss: 0.069289\n",
      "====> Epoch: 31 total_train_loss: 0.662717 Total_test_loss: 0.615196 Total_BCE_test_loss: 0.540626 Total_KLD_test_loss: 0.005281 Total_CEP_test_loss: 0.069288\n",
      "====> Epoch: 32 total_train_loss: 0.663969 Total_test_loss: 0.614783 Total_BCE_test_loss: 0.540279 Total_KLD_test_loss: 0.005268 Total_CEP_test_loss: 0.069235\n",
      "====> Epoch: 33 total_train_loss: 0.657559 Total_test_loss: 0.617223 Total_BCE_test_loss: 0.542677 Total_KLD_test_loss: 0.005297 Total_CEP_test_loss: 0.069249\n",
      "====> Epoch: 34 total_train_loss: 0.661148 Total_test_loss: 0.615339 Total_BCE_test_loss: 0.540825 Total_KLD_test_loss: 0.005283 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 35 total_train_loss: 0.661429 Total_test_loss: 0.616277 Total_BCE_test_loss: 0.541748 Total_KLD_test_loss: 0.005299 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 36 total_train_loss: 0.659413 Total_test_loss: 0.615869 Total_BCE_test_loss: 0.541304 Total_KLD_test_loss: 0.005328 Total_CEP_test_loss: 0.069236\n",
      "====> Epoch: 37 total_train_loss: 0.660850 Total_test_loss: 0.615628 Total_BCE_test_loss: 0.541121 Total_KLD_test_loss: 0.005263 Total_CEP_test_loss: 0.069245\n",
      "====> Epoch: 38 total_train_loss: 0.662572 Total_test_loss: 0.616260 Total_BCE_test_loss: 0.541684 Total_KLD_test_loss: 0.005304 Total_CEP_test_loss: 0.069272\n",
      "====> Epoch: 39 total_train_loss: 0.663750 Total_test_loss: 0.616295 Total_BCE_test_loss: 0.541810 Total_KLD_test_loss: 0.005255 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 40 total_train_loss: 0.658632 Total_test_loss: 0.614924 Total_BCE_test_loss: 0.540368 Total_KLD_test_loss: 0.005315 Total_CEP_test_loss: 0.069240\n",
      "====> Epoch: 41 total_train_loss: 0.658458 Total_test_loss: 0.616004 Total_BCE_test_loss: 0.541473 Total_KLD_test_loss: 0.005293 Total_CEP_test_loss: 0.069238\n",
      "====> Epoch: 42 total_train_loss: 0.664316 Total_test_loss: 0.616275 Total_BCE_test_loss: 0.541760 Total_KLD_test_loss: 0.005271 Total_CEP_test_loss: 0.069243\n",
      "====> Epoch: 43 total_train_loss: 0.660883 Total_test_loss: 0.615402 Total_BCE_test_loss: 0.540894 Total_KLD_test_loss: 0.005283 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 44 total_train_loss: 0.660690 Total_test_loss: 0.615623 Total_BCE_test_loss: 0.541112 Total_KLD_test_loss: 0.005275 Total_CEP_test_loss: 0.069236\n",
      "====> Epoch: 45 total_train_loss: 0.660325 Total_test_loss: 0.615497 Total_BCE_test_loss: 0.541010 Total_KLD_test_loss: 0.005266 Total_CEP_test_loss: 0.069221\n",
      "====> Epoch: 46 total_train_loss: 0.661975 Total_test_loss: 0.616393 Total_BCE_test_loss: 0.541821 Total_KLD_test_loss: 0.005315 Total_CEP_test_loss: 0.069257\n",
      "====> Epoch: 47 total_train_loss: 0.663267 Total_test_loss: 0.615754 Total_BCE_test_loss: 0.541251 Total_KLD_test_loss: 0.005278 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 48 total_train_loss: 0.656526 Total_test_loss: 0.616634 Total_BCE_test_loss: 0.542094 Total_KLD_test_loss: 0.005308 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 49 total_train_loss: 0.659352 Total_test_loss: 0.616240 Total_BCE_test_loss: 0.541766 Total_KLD_test_loss: 0.005221 Total_CEP_test_loss: 0.069253\n",
      "====> Epoch: 50 total_train_loss: 0.662083 Total_test_loss: 0.616375 Total_BCE_test_loss: 0.541903 Total_KLD_test_loss: 0.005228 Total_CEP_test_loss: 0.069244\n",
      "5e-06\n",
      "====> Epoch: 1 total_train_loss: 0.659997 Total_test_loss: 0.616663 Total_BCE_test_loss: 0.542172 Total_KLD_test_loss: 0.005236 Total_CEP_test_loss: 0.069255\n",
      "====> Epoch: 2 total_train_loss: 0.659061 Total_test_loss: 0.616640 Total_BCE_test_loss: 0.542163 Total_KLD_test_loss: 0.005245 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 3 total_train_loss: 0.659207 Total_test_loss: 0.616560 Total_BCE_test_loss: 0.542095 Total_KLD_test_loss: 0.005243 Total_CEP_test_loss: 0.069221\n",
      "====> Epoch: 4 total_train_loss: 0.661296 Total_test_loss: 0.615512 Total_BCE_test_loss: 0.540963 Total_KLD_test_loss: 0.005317 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 5 total_train_loss: 0.658738 Total_test_loss: 0.616136 Total_BCE_test_loss: 0.541588 Total_KLD_test_loss: 0.005295 Total_CEP_test_loss: 0.069253\n",
      "====> Epoch: 6 total_train_loss: 0.660323 Total_test_loss: 0.616279 Total_BCE_test_loss: 0.541788 Total_KLD_test_loss: 0.005267 Total_CEP_test_loss: 0.069224\n",
      "====> Epoch: 7 total_train_loss: 0.656294 Total_test_loss: 0.616933 Total_BCE_test_loss: 0.542489 Total_KLD_test_loss: 0.005251 Total_CEP_test_loss: 0.069193\n",
      "====> Epoch: 8 total_train_loss: 0.657132 Total_test_loss: 0.616327 Total_BCE_test_loss: 0.541825 Total_KLD_test_loss: 0.005235 Total_CEP_test_loss: 0.069267\n",
      "====> Epoch: 9 total_train_loss: 0.659237 Total_test_loss: 0.616455 Total_BCE_test_loss: 0.541999 Total_KLD_test_loss: 0.005254 Total_CEP_test_loss: 0.069202\n",
      "====> Epoch: 10 total_train_loss: 0.662972 Total_test_loss: 0.615974 Total_BCE_test_loss: 0.541504 Total_KLD_test_loss: 0.005252 Total_CEP_test_loss: 0.069219\n",
      "====> Epoch: 11 total_train_loss: 0.657642 Total_test_loss: 0.615837 Total_BCE_test_loss: 0.541305 Total_KLD_test_loss: 0.005300 Total_CEP_test_loss: 0.069231\n",
      "====> Epoch: 12 total_train_loss: 0.660128 Total_test_loss: 0.614208 Total_BCE_test_loss: 0.539655 Total_KLD_test_loss: 0.005332 Total_CEP_test_loss: 0.069221\n",
      "====> Epoch: 13 total_train_loss: 0.663962 Total_test_loss: 0.615923 Total_BCE_test_loss: 0.541354 Total_KLD_test_loss: 0.005326 Total_CEP_test_loss: 0.069244\n",
      "====> Epoch: 14 total_train_loss: 0.661321 Total_test_loss: 0.616897 Total_BCE_test_loss: 0.542359 Total_KLD_test_loss: 0.005304 Total_CEP_test_loss: 0.069235\n",
      "====> Epoch: 15 total_train_loss: 0.659272 Total_test_loss: 0.615589 Total_BCE_test_loss: 0.541065 Total_KLD_test_loss: 0.005298 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 16 total_train_loss: 0.662009 Total_test_loss: 0.615830 Total_BCE_test_loss: 0.541313 Total_KLD_test_loss: 0.005289 Total_CEP_test_loss: 0.069227\n",
      "====> Epoch: 17 total_train_loss: 0.657101 Total_test_loss: 0.614591 Total_BCE_test_loss: 0.540106 Total_KLD_test_loss: 0.005247 Total_CEP_test_loss: 0.069238\n",
      "====> Epoch: 18 total_train_loss: 0.658778 Total_test_loss: 0.616678 Total_BCE_test_loss: 0.542220 Total_KLD_test_loss: 0.005248 Total_CEP_test_loss: 0.069210\n",
      "====> Epoch: 19 total_train_loss: 0.657400 Total_test_loss: 0.614604 Total_BCE_test_loss: 0.540169 Total_KLD_test_loss: 0.005225 Total_CEP_test_loss: 0.069210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 20 total_train_loss: 0.663980 Total_test_loss: 0.616629 Total_BCE_test_loss: 0.542146 Total_KLD_test_loss: 0.005253 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 21 total_train_loss: 0.658068 Total_test_loss: 0.616440 Total_BCE_test_loss: 0.541946 Total_KLD_test_loss: 0.005243 Total_CEP_test_loss: 0.069251\n",
      "====> Epoch: 22 total_train_loss: 0.660671 Total_test_loss: 0.616794 Total_BCE_test_loss: 0.542281 Total_KLD_test_loss: 0.005251 Total_CEP_test_loss: 0.069262\n",
      "====> Epoch: 23 total_train_loss: 0.661646 Total_test_loss: 0.615606 Total_BCE_test_loss: 0.541079 Total_KLD_test_loss: 0.005328 Total_CEP_test_loss: 0.069199\n",
      "====> Epoch: 24 total_train_loss: 0.659047 Total_test_loss: 0.616470 Total_BCE_test_loss: 0.541933 Total_KLD_test_loss: 0.005302 Total_CEP_test_loss: 0.069236\n",
      "====> Epoch: 25 total_train_loss: 0.658802 Total_test_loss: 0.617046 Total_BCE_test_loss: 0.542522 Total_KLD_test_loss: 0.005312 Total_CEP_test_loss: 0.069212\n",
      "====> Epoch: 26 total_train_loss: 0.656420 Total_test_loss: 0.617462 Total_BCE_test_loss: 0.542941 Total_KLD_test_loss: 0.005303 Total_CEP_test_loss: 0.069218\n",
      "====> Epoch: 27 total_train_loss: 0.661616 Total_test_loss: 0.615001 Total_BCE_test_loss: 0.540500 Total_KLD_test_loss: 0.005275 Total_CEP_test_loss: 0.069226\n",
      "====> Epoch: 28 total_train_loss: 0.660935 Total_test_loss: 0.617190 Total_BCE_test_loss: 0.542679 Total_KLD_test_loss: 0.005252 Total_CEP_test_loss: 0.069259\n",
      "====> Epoch: 29 total_train_loss: 0.665797 Total_test_loss: 0.614915 Total_BCE_test_loss: 0.540409 Total_KLD_test_loss: 0.005278 Total_CEP_test_loss: 0.069228\n",
      "====> Epoch: 30 total_train_loss: 0.656551 Total_test_loss: 0.615813 Total_BCE_test_loss: 0.541361 Total_KLD_test_loss: 0.005221 Total_CEP_test_loss: 0.069231\n",
      "====> Epoch: 31 total_train_loss: 0.660244 Total_test_loss: 0.615907 Total_BCE_test_loss: 0.541444 Total_KLD_test_loss: 0.005250 Total_CEP_test_loss: 0.069213\n",
      "====> Epoch: 32 total_train_loss: 0.656272 Total_test_loss: 0.617003 Total_BCE_test_loss: 0.542524 Total_KLD_test_loss: 0.005256 Total_CEP_test_loss: 0.069223\n",
      "====> Epoch: 33 total_train_loss: 0.657916 Total_test_loss: 0.615400 Total_BCE_test_loss: 0.540911 Total_KLD_test_loss: 0.005264 Total_CEP_test_loss: 0.069224\n",
      "====> Epoch: 34 total_train_loss: 0.657539 Total_test_loss: 0.615522 Total_BCE_test_loss: 0.540969 Total_KLD_test_loss: 0.005316 Total_CEP_test_loss: 0.069237\n",
      "====> Epoch: 35 total_train_loss: 0.662260 Total_test_loss: 0.616125 Total_BCE_test_loss: 0.541529 Total_KLD_test_loss: 0.005353 Total_CEP_test_loss: 0.069244\n",
      "====> Epoch: 36 total_train_loss: 0.657776 Total_test_loss: 0.616088 Total_BCE_test_loss: 0.541550 Total_KLD_test_loss: 0.005308 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 37 total_train_loss: 0.664838 Total_test_loss: 0.616112 Total_BCE_test_loss: 0.541542 Total_KLD_test_loss: 0.005321 Total_CEP_test_loss: 0.069249\n",
      "====> Epoch: 38 total_train_loss: 0.658676 Total_test_loss: 0.616203 Total_BCE_test_loss: 0.541696 Total_KLD_test_loss: 0.005293 Total_CEP_test_loss: 0.069214\n",
      "====> Epoch: 39 total_train_loss: 0.660116 Total_test_loss: 0.615366 Total_BCE_test_loss: 0.540826 Total_KLD_test_loss: 0.005275 Total_CEP_test_loss: 0.069265\n",
      "====> Epoch: 40 total_train_loss: 0.660104 Total_test_loss: 0.615575 Total_BCE_test_loss: 0.541101 Total_KLD_test_loss: 0.005264 Total_CEP_test_loss: 0.069209\n",
      "====> Epoch: 41 total_train_loss: 0.660756 Total_test_loss: 0.615120 Total_BCE_test_loss: 0.540641 Total_KLD_test_loss: 0.005256 Total_CEP_test_loss: 0.069223\n",
      "====> Epoch: 42 total_train_loss: 0.658776 Total_test_loss: 0.614910 Total_BCE_test_loss: 0.540365 Total_KLD_test_loss: 0.005322 Total_CEP_test_loss: 0.069223\n",
      "====> Epoch: 43 total_train_loss: 0.663289 Total_test_loss: 0.616598 Total_BCE_test_loss: 0.542106 Total_KLD_test_loss: 0.005254 Total_CEP_test_loss: 0.069238\n",
      "====> Epoch: 44 total_train_loss: 0.661167 Total_test_loss: 0.616493 Total_BCE_test_loss: 0.541942 Total_KLD_test_loss: 0.005300 Total_CEP_test_loss: 0.069251\n",
      "====> Epoch: 45 total_train_loss: 0.660112 Total_test_loss: 0.616213 Total_BCE_test_loss: 0.541728 Total_KLD_test_loss: 0.005253 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 46 total_train_loss: 0.657845 Total_test_loss: 0.617184 Total_BCE_test_loss: 0.542657 Total_KLD_test_loss: 0.005273 Total_CEP_test_loss: 0.069253\n",
      "====> Epoch: 47 total_train_loss: 0.668517 Total_test_loss: 0.616181 Total_BCE_test_loss: 0.541699 Total_KLD_test_loss: 0.005251 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 48 total_train_loss: 0.658639 Total_test_loss: 0.616245 Total_BCE_test_loss: 0.541754 Total_KLD_test_loss: 0.005277 Total_CEP_test_loss: 0.069213\n",
      "====> Epoch: 49 total_train_loss: 0.665168 Total_test_loss: 0.616952 Total_BCE_test_loss: 0.542429 Total_KLD_test_loss: 0.005291 Total_CEP_test_loss: 0.069231\n",
      "====> Epoch: 50 total_train_loss: 0.659591 Total_test_loss: 0.616358 Total_BCE_test_loss: 0.541773 Total_KLD_test_loss: 0.005331 Total_CEP_test_loss: 0.069255\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "if model_tobe_trained:\n",
    "    lr=1e-2\n",
    "    print(lr)\n",
    "    obj1.model_training(epochs=100,learning_rate=lr)\n",
    "\n",
    "    lr=1e-3\n",
    "    print(lr)\n",
    "    #obj.model_training(epochs=70,learning_rate=lr)\n",
    "\n",
    "    lr=1e-3\n",
    "    print(lr)\n",
    "    #obj.model_training(epochs=200,learning_rate=lr)\n",
    "\n",
    "    obj1.model_save(address=save_address+\".pt\")\n",
    "    obj1.save_residuals(address=save_address+'_residuals.pkl')\n",
    "    lr=1e-3\n",
    "    print(lr)\n",
    "    #obj.model_training(epochs=70,learning_rate=lr)\n",
    "\n",
    "    lr=5e-4\n",
    "    print(lr)\n",
    "    obj1.model_training(epochs=50,learning_rate=lr)\n",
    "\n",
    "    obj1.model_save(address=save_address+\".pt\")\n",
    "    obj1.save_residuals(address=save_address+'_residuals.pkl')\n",
    "\n",
    "    lr=1e-5\n",
    "    print(lr)\n",
    "    obj1.model_training(epochs=50,learning_rate=lr)\n",
    "\n",
    "    lr=5e-6\n",
    "    print(lr)\n",
    "    obj1.model_training(epochs=50,learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5tsLzrBNa7E"
   },
   "source": [
    "# Save The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42YFEvnqbE9U",
    "outputId": "555826a8-f613-4331-b6a5-1acc5a1b82a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running the neural network\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "print(\"running the neural network\")\n",
    "#run(obj1,save_address)\n",
    "obj1.model_save(address=save_address+\".pt\")\n",
    "obj1.save_residuals(address=save_address+'_residuals.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUnPPyZ6NfDr"
   },
   "source": [
    "# Visualize Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "DStavVSXYRs5",
    "outputId": "047b7d45-2f98-4854-9ea2-17f3781d9842"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj1.plot_residuals(init_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkjkH6AjN5pq"
   },
   "source": [
    "# Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DBW6HgBINu9v"
   },
   "outputs": [],
   "source": [
    "from ci_vae import ivae\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "#import umap\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqNZPHbPOkoh",
    "outputId": "35686f32-9d60-4ae3-b7b6-a634658bb1b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the code\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the code\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "##############################################################   \n",
    "##############################################################\n",
    "model_init=True\n",
    "model_tobe_trained=False\n",
    "\n",
    "model_init=True\n",
    "model_file_address='./bb.pt'\n",
    "save_address1=\"./\"\n",
    "\n",
    "df_XY=pd.read_csv('df_XY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oDqQbsnOO6d"
   },
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fHFjOqpnigK_"
   },
   "outputs": [],
   "source": [
    "obj2 = ivae.IVAE(df_XY = df_XY,\n",
    "               reconst_coef = reconst_coef,\n",
    "               latent_size = 10,\n",
    "               kl_coef = kl_coef,\n",
    "               classifier_coef = classifier_coef,\n",
    "               test_ratio = 1)\n",
    "\n",
    "obj2.model_initialiaze()\n",
    "\n",
    "obj2.model_load(address=\"bb.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOUIzmGTOTyG"
   },
   "source": [
    "## Print the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-H3bybRp484",
    "outputId": "fce40859-ea30-4f75-b4b5-08284301f7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0155,  0.1019, -0.0324, -0.0207,  0.3712],\n",
      "        [ 0.0554,  0.3167,  0.2738, -0.2131, -0.2541],\n",
      "        [ 0.1391, -0.0379, -0.0697,  0.5671,  0.1832],\n",
      "        [-0.2832,  0.3884,  0.3305,  0.2895,  0.4208],\n",
      "        [-0.1114, -0.3216,  0.1055, -0.0972,  0.1871],\n",
      "        [ 0.3036,  0.4402,  0.0748,  0.1447, -0.2154],\n",
      "        [ 0.1178, -0.3803,  0.0624, -0.0521, -0.2992],\n",
      "        [ 0.2434, -0.4074,  0.1455, -0.3698,  0.0199],\n",
      "        [ 0.3827,  0.0347, -0.2962,  0.4424,  0.0400],\n",
      "        [ 0.1899,  0.1763,  0.0239,  0.4662,  0.1351],\n",
      "        [ 0.4213,  0.2268, -0.1542, -0.0675,  0.2199],\n",
      "        [-0.2024, -0.0701, -0.2209,  0.4568, -0.2427],\n",
      "        [ 0.1540, -0.1161, -0.3095,  0.0918, -0.4462],\n",
      "        [-0.1807, -0.2961, -0.2772,  0.2066,  0.1174],\n",
      "        [ 0.2022, -0.0343,  0.0716,  0.1548,  0.5143],\n",
      "        [ 0.3442,  0.2070,  0.3629,  0.5374, -0.1946],\n",
      "        [-0.1881,  0.0641, -0.2297, -0.0685,  0.5897],\n",
      "        [ 0.5352, -0.0050,  0.0885, -0.2583, -0.3173],\n",
      "        [ 0.0530, -0.0497,  0.0760,  0.5312, -0.1796],\n",
      "        [-0.0591,  0.1600,  0.0611, -0.3157, -0.3448]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2816, -0.0186,  0.2597, -0.2727, -0.1088, -0.1950, -0.3469, -0.3531,\n",
      "        -0.3192, -0.0917, -0.3755,  0.6025, -0.0025, -0.4570,  0.1146, -0.0109,\n",
      "        -0.3960, -0.0136,  0.4632,  0.1000], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.1302, 0.9715, 0.9786, 1.0821, 1.0228, 0.9675, 0.9422, 0.8208, 1.0972,\n",
      "        0.9364, 0.8570, 1.0347, 0.9329, 0.9163, 0.9582, 0.9935, 0.9301, 1.0126,\n",
      "        1.2244, 0.8500], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0915,  0.0152,  0.0213, -0.0585,  0.0997,  0.0403, -0.0314,  0.0078,\n",
      "        -0.1168, -0.0121,  0.0315, -0.1310, -0.0053, -0.0159,  0.0205, -0.1002,\n",
      "         0.0751, -0.0129, -0.1441,  0.0828], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.1800e-01,  2.5634e-01, -2.7929e-01,  8.9378e-02, -2.4961e-01,\n",
      "         -2.2543e-02, -1.8421e-02, -7.8935e-02, -6.4405e-02, -1.3560e-01,\n",
      "          1.7112e-01, -2.4618e-01,  6.2663e-02, -1.2372e-01, -2.7293e-02,\n",
      "          1.1416e-01,  1.3533e-01, -1.0942e-01, -6.5420e-02, -4.8328e-03],\n",
      "        [-1.2646e-01, -4.5470e-02,  2.0870e-01, -1.1347e-01, -3.1871e-01,\n",
      "         -2.7805e-02, -2.1058e-01, -3.6435e-02, -1.2529e-01, -1.2382e-02,\n",
      "          6.1102e-02,  1.3463e-01, -8.7477e-02, -1.2892e-01, -2.1824e-01,\n",
      "          1.9779e-01, -1.3773e-01,  9.7883e-02,  1.3351e-02,  9.2128e-02],\n",
      "        [-6.6010e-03, -1.0998e-01, -8.7294e-02, -7.6609e-02,  2.3630e-01,\n",
      "          8.8574e-02, -3.8749e-02,  1.0726e-01, -1.4614e-01, -1.8138e-01,\n",
      "         -9.1715e-02, -2.4760e-01, -9.1377e-02,  8.2385e-02, -1.1823e-01,\n",
      "         -4.1939e-01, -5.0617e-02, -2.0506e-02, -3.8050e-01,  1.5278e-01],\n",
      "        [-1.4023e-01,  1.4122e-01,  6.5937e-02,  7.4930e-02,  1.9119e-01,\n",
      "          2.1927e-01,  5.3760e-02, -9.4672e-02,  1.3734e-01, -1.7930e-01,\n",
      "          1.2861e-01, -1.3507e-01,  1.7314e-02, -1.5607e-01, -3.6349e-02,\n",
      "         -3.3389e-02, -2.0093e-01,  3.5001e-01,  9.9333e-03, -6.8244e-02],\n",
      "        [ 7.9910e-02,  3.1830e-02, -3.6869e-01, -2.2421e-01,  7.4071e-02,\n",
      "          4.1423e-02,  2.6843e-02, -1.1099e-01, -1.5181e-01, -2.0426e-02,\n",
      "         -1.7296e-02,  3.2512e-02,  7.9284e-02,  7.9310e-02, -1.7021e-01,\n",
      "         -3.0840e-02, -1.1661e-01,  1.4305e-01, -3.0391e-01,  2.5343e-01],\n",
      "        [ 8.2428e-02,  1.5662e-01,  7.1750e-02,  3.6488e-02, -1.4498e-01,\n",
      "         -4.7345e-02, -2.2267e-01, -2.6833e-02, -4.7425e-02, -8.6586e-02,\n",
      "          1.6175e-01, -2.1003e-01,  9.4746e-02, -9.2541e-02, -1.2254e-01,\n",
      "          7.6414e-02,  1.4377e-01,  4.0435e-02, -1.3729e-01,  1.5406e-01],\n",
      "        [-3.0778e-01,  8.9221e-02,  1.1281e-02, -1.0732e-01, -1.7579e-01,\n",
      "          2.4948e-01,  2.1209e-01,  1.8857e-01, -2.6031e-01, -3.5583e-02,\n",
      "         -1.1928e-02, -2.0545e-01,  7.8533e-02, -1.1032e-01, -2.3174e-01,\n",
      "         -2.0336e-01,  1.0711e-01,  1.7342e-01, -1.7675e-01,  6.0704e-02],\n",
      "        [ 1.5614e-01, -5.2512e-02,  3.9626e-02, -2.2220e-01,  7.5068e-02,\n",
      "         -1.4536e-01, -4.9525e-02,  4.9383e-02, -6.3429e-02, -1.7890e-02,\n",
      "          2.8790e-01,  4.7930e-02, -8.5057e-02, -9.1706e-03, -4.8099e-02,\n",
      "         -1.0553e-01,  1.2081e-01, -1.4948e-01, -3.4650e-01, -4.6700e-02],\n",
      "        [-7.8067e-02,  9.0493e-02, -2.8682e-02,  3.7240e-02, -4.0330e-02,\n",
      "          2.4614e-01, -8.4196e-02,  1.7247e-02,  1.0955e-01, -9.7636e-02,\n",
      "          1.3283e-02,  3.7340e-01,  3.2823e-01, -1.4112e-01, -2.0058e-01,\n",
      "         -1.2995e-01, -2.9656e-01,  7.7769e-02,  1.0433e-01, -6.2469e-02],\n",
      "        [-2.0103e-01, -1.0326e-01,  2.1593e-02,  7.0922e-02,  1.6926e-01,\n",
      "         -1.3272e-01, -8.9048e-02,  1.0135e-01,  2.3730e-01, -2.3129e-02,\n",
      "          8.9826e-02, -5.5395e-02,  6.6185e-02,  2.0557e-01,  9.3830e-03,\n",
      "          1.0842e-01,  8.3770e-02, -1.0429e-01,  2.9916e-01, -2.0575e-01],\n",
      "        [ 1.4628e-01, -1.3297e-01,  2.1820e-01,  3.2697e-01, -1.0184e-02,\n",
      "          2.2590e-01, -1.5968e-01,  4.5789e-02, -2.6145e-01,  8.4616e-02,\n",
      "         -2.0907e-02,  1.8352e-01, -1.2461e-01, -9.2702e-02,  1.4708e-01,\n",
      "          9.1060e-02, -2.1387e-01,  1.2575e-01,  1.0775e-01,  5.9853e-02],\n",
      "        [ 2.5560e-01, -2.3420e-01, -1.4268e-01,  1.5091e-01,  1.9527e-01,\n",
      "         -8.9783e-02,  4.2643e-03,  2.2659e-01, -2.5908e-01,  8.5796e-02,\n",
      "          1.1268e-01, -3.7885e-02,  1.6074e-01,  6.3745e-02,  9.0735e-02,\n",
      "          5.8188e-02,  2.1964e-01,  4.3899e-02,  7.3032e-03, -8.3805e-02],\n",
      "        [-4.0295e-02, -6.6551e-02, -6.9935e-02,  3.0861e-01, -1.3469e-01,\n",
      "          4.3221e-02,  3.4974e-02, -2.5769e-02, -3.7137e-02,  1.9478e-01,\n",
      "         -1.9069e-01, -1.5045e-01, -2.4368e-01,  2.7898e-02,  8.3413e-02,\n",
      "          1.2042e-01,  1.8449e-02, -2.5139e-01, -1.9984e-02,  6.6824e-02],\n",
      "        [ 2.9752e-01,  1.6124e-01, -3.6484e-03, -1.4867e-01, -1.1864e-01,\n",
      "         -1.0004e-01, -1.1463e-01, -1.5306e-01,  1.1043e-01,  1.8530e-01,\n",
      "          1.0042e-03, -1.7838e-01, -1.0302e-01,  1.4542e-01,  2.4267e-02,\n",
      "         -9.6440e-03,  1.9493e-01, -1.4945e-01,  2.6560e-02,  7.6765e-02],\n",
      "        [ 1.3401e-01,  2.9045e-02, -2.1614e-02,  1.3928e-01, -1.4638e-01,\n",
      "          1.0963e-01,  1.9475e-01,  1.6227e-01,  2.3961e-01,  4.7414e-02,\n",
      "          4.5762e-02, -1.0702e-01,  9.5452e-02,  3.9815e-02, -2.4182e-01,\n",
      "          1.6427e-01, -1.5745e-01,  1.0202e-01,  3.0697e-01, -8.8496e-02],\n",
      "        [ 1.4651e-01, -1.9178e-01, -2.9358e-02,  1.9242e-01,  2.8491e-01,\n",
      "          8.5384e-03, -1.6568e-01,  2.2483e-01,  2.7861e-02, -7.1017e-02,\n",
      "          1.6148e-01,  6.1612e-02, -2.6480e-01,  5.7856e-03,  7.2016e-02,\n",
      "          8.8313e-02, -8.4413e-02,  2.0652e-01,  1.3288e-01,  4.5687e-03],\n",
      "        [-2.3967e-01,  2.0434e-01,  2.9345e-02, -2.1771e-01,  1.7932e-01,\n",
      "          2.0241e-01, -1.2737e-02,  8.0698e-02,  6.8060e-02, -3.4032e-02,\n",
      "          7.4597e-02,  5.5581e-02, -2.5330e-01, -8.0403e-02, -9.9955e-02,\n",
      "         -8.8708e-03, -1.7342e-01,  1.3743e-01,  1.2782e-04,  8.4250e-02],\n",
      "        [-4.8304e-02, -1.5954e-01,  2.5851e-01,  2.7953e-02,  1.2628e-01,\n",
      "         -5.2860e-03,  1.0512e-02, -1.3380e-01,  2.0242e-01,  2.5417e-01,\n",
      "          3.7490e-02,  3.9135e-02, -1.1820e-01,  4.0181e-02,  1.6928e-01,\n",
      "          1.0138e-01, -1.4948e-01, -1.2727e-01,  1.0900e-01, -2.3922e-01],\n",
      "        [ 1.9512e-01, -4.6740e-02, -2.3410e-01, -6.8614e-02, -2.0454e-03,\n",
      "         -3.3222e-02, -6.8015e-02,  9.5279e-02,  7.2648e-02,  9.1339e-03,\n",
      "         -3.3661e-02, -3.3481e-01, -3.0209e-01, -1.5028e-01,  1.0214e-01,\n",
      "         -5.5705e-02,  1.1852e-01,  6.4274e-02, -2.3203e-01, -1.6210e-01],\n",
      "        [ 6.0176e-02, -2.4843e-01,  1.2904e-01,  9.0527e-02,  6.5988e-02,\n",
      "          6.6443e-02, -1.3708e-01, -1.6354e-01,  2.4362e-01,  1.2412e-01,\n",
      "          1.2846e-01, -1.3293e-01, -5.7873e-02, -1.8149e-01,  1.2570e-01,\n",
      "         -1.8497e-02, -1.3442e-01,  2.0372e-01, -8.3921e-02, -2.3966e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2804,  0.0013, -0.0024, -0.1034, -0.0794,  0.4900, -0.0079,  0.0534,\n",
      "        -0.0327, -0.1787,  0.2270,  0.2134, -0.0760,  0.0388,  0.0553, -0.0744,\n",
      "         0.1710,  0.1437,  0.0021, -0.0686], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9661, 0.9684, 1.0118, 0.8600, 0.9446, 1.0578, 0.9590, 1.0588, 1.1153,\n",
      "        0.9835, 1.0067, 0.8719, 0.9948, 0.9327, 1.0372, 0.9622, 0.9158, 1.0432,\n",
      "        1.1505, 0.9048], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0265,  0.0357,  0.1588, -0.0531, -0.0699,  0.0073,  0.0615,  0.1182,\n",
      "         0.0660,  0.0191, -0.0616, -0.0890, -0.0176, -0.0751, -0.0157, -0.0108,\n",
      "         0.0154,  0.0629,  0.0647,  0.0591], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.3781e-01,  1.6708e-01, -1.4241e-01,  9.4008e-02, -1.7652e-01,\n",
      "         -3.2905e-01, -1.5053e-01, -9.2133e-02, -1.1173e-02, -9.5055e-05,\n",
      "          5.9172e-02, -2.4853e-01, -2.2075e-01, -1.5792e-01,  8.5932e-02,\n",
      "         -8.2331e-02,  3.9220e-02, -1.9737e-01, -2.7665e-01, -3.7118e-02],\n",
      "        [ 8.2747e-02,  1.3071e-01,  7.2450e-02,  2.7542e-01,  2.4374e-01,\n",
      "          1.1852e-01,  2.0982e-01,  7.3589e-02,  1.9347e-01, -1.3934e-01,\n",
      "         -3.5756e-02, -7.1305e-02,  5.1228e-02,  6.1645e-02,  2.1582e-02,\n",
      "         -6.9421e-02,  2.1554e-01, -1.9477e-01, -8.7254e-02, -2.2437e-01],\n",
      "        [-1.5339e-01, -1.1436e-01,  6.7126e-02,  1.2476e-01,  8.5539e-02,\n",
      "          5.8328e-02, -2.1224e-01,  1.8489e-01,  2.1576e-01, -2.5917e-02,\n",
      "         -2.9466e-02,  1.1604e-01, -1.4691e-02,  2.9517e-02,  1.6981e-01,\n",
      "          2.1431e-01,  1.1617e-01,  2.3459e-01, -4.7480e-02,  1.6679e-01],\n",
      "        [ 1.6035e-01, -2.0545e-01,  8.4684e-02, -6.8570e-02,  1.4153e-01,\n",
      "          1.0800e-01,  1.6098e-01,  2.5165e-01,  1.3468e-01, -2.3127e-01,\n",
      "         -1.2006e-01, -1.7856e-02,  1.5232e-01,  3.4117e-02, -2.8635e-01,\n",
      "         -6.0928e-02, -1.1950e-02,  1.3076e-01,  3.0217e-01,  1.5669e-01],\n",
      "        [-8.4380e-02,  2.1034e-02,  1.9932e-01, -2.3964e-01,  1.8134e-01,\n",
      "         -5.5571e-02, -3.1568e-02,  4.4438e-02, -9.2751e-02, -7.1735e-03,\n",
      "         -8.1771e-02, -4.8370e-02,  2.1449e-03,  1.5240e-03, -2.0554e-01,\n",
      "         -1.8210e-01, -8.2446e-02, -2.8992e-01,  3.9462e-02,  6.5770e-02],\n",
      "        [ 2.8180e-01,  2.2096e-03, -9.3488e-02,  1.0072e-01,  2.1937e-01,\n",
      "          9.5684e-02,  1.3267e-01,  1.1145e-01, -4.2467e-02,  8.1602e-02,\n",
      "          1.2560e-01,  4.2864e-02, -1.0882e-01,  2.6053e-02, -3.8290e-02,\n",
      "          1.9852e-02, -9.4653e-03, -9.6457e-02,  2.7357e-01, -2.2866e-01],\n",
      "        [ 1.3124e-01, -1.6798e-01, -2.1373e-01, -1.8569e-01, -2.0913e-01,\n",
      "          1.3438e-01, -2.7842e-01, -3.3609e-02, -4.3707e-02, -1.6894e-01,\n",
      "          9.6185e-02,  4.1933e-02, -4.0137e-02,  2.6097e-01,  1.8573e-01,\n",
      "          8.1929e-02,  1.5120e-01,  4.2515e-02,  3.9307e-03,  1.9947e-01],\n",
      "        [-3.9725e-02,  2.6746e-04, -2.3981e-01, -2.6622e-01, -1.6477e-01,\n",
      "         -1.6129e-01, -4.0114e-02,  8.9366e-02,  8.3841e-02, -2.5356e-01,\n",
      "          1.6610e-01, -1.4076e-01,  2.3928e-01, -3.6422e-02, -5.2907e-03,\n",
      "         -2.0444e-01, -2.0300e-01,  1.4111e-01,  4.4434e-02,  1.2064e-01],\n",
      "        [ 1.3564e-01, -5.2850e-02, -1.3045e-01, -3.4023e-02, -2.1029e-03,\n",
      "         -1.2207e-01, -1.3784e-01,  1.9861e-01,  1.4365e-01,  1.3776e-01,\n",
      "         -3.9291e-01, -2.8933e-02, -1.0041e-01,  2.6715e-01, -2.2524e-01,\n",
      "          6.6002e-02, -2.4623e-01,  1.5158e-01,  1.4810e-01,  1.1898e-02],\n",
      "        [-3.1276e-01,  1.7558e-01,  2.7613e-01, -1.4408e-01,  1.4756e-01,\n",
      "         -2.1173e-01,  1.8367e-01,  1.2815e-01,  4.6774e-02,  9.9248e-02,\n",
      "         -2.2405e-01,  7.7722e-02, -5.8354e-02, -8.1110e-02,  4.9931e-02,\n",
      "          4.8301e-02, -5.8747e-03, -4.0213e-02,  9.5225e-02, -1.4288e-01],\n",
      "        [ 1.1230e-02,  9.8307e-02, -2.1908e-01,  4.6079e-02, -2.7316e-01,\n",
      "         -2.4460e-01, -2.8335e-01,  3.9093e-02, -1.2389e-01,  2.7137e-02,\n",
      "          1.4707e-01, -1.3589e-01,  7.4320e-02, -1.0678e-01, -1.3748e-01,\n",
      "          6.9693e-02, -8.7574e-02,  2.5471e-02, -2.1118e-01,  1.4822e-01],\n",
      "        [ 1.2856e-01,  1.5230e-01, -2.2305e-02, -4.4957e-02, -8.8986e-02,\n",
      "         -5.3315e-02, -1.5234e-01, -1.0832e-01,  6.6460e-02,  1.9873e-01,\n",
      "          5.9792e-02,  1.3861e-01,  7.9277e-02,  8.6963e-03,  8.5522e-02,\n",
      "         -7.9714e-02, -6.3803e-02,  3.9059e-01, -8.5792e-02, -7.2026e-02],\n",
      "        [ 9.0055e-02, -4.2058e-02, -1.5198e-01, -7.3835e-02, -1.4106e-01,\n",
      "         -1.5742e-01, -9.3493e-02, -3.9559e-01,  2.4978e-01,  6.1404e-02,\n",
      "         -1.3598e-01, -8.8430e-02, -1.0755e-01,  1.5623e-01,  1.0648e-01,\n",
      "          6.6587e-02,  1.0439e-01,  1.4853e-01, -2.0723e-01, -6.4854e-02],\n",
      "        [-1.3596e-01,  4.4012e-02, -9.8447e-02, -1.9673e-03, -3.1196e-02,\n",
      "          2.6127e-03,  5.1687e-02, -6.4637e-02,  1.1504e-01,  9.4517e-02,\n",
      "         -7.9621e-02,  3.1399e-02, -2.5504e-01, -7.4883e-02,  1.6201e-01,\n",
      "         -1.5474e-01,  8.6953e-03, -1.6196e-01, -1.6160e-01, -3.0427e-02],\n",
      "        [ 4.0623e-02,  2.1063e-01, -2.1752e-01,  1.5890e-01,  3.2890e-02,\n",
      "          6.9493e-02,  1.7350e-01, -2.5041e-01, -5.6279e-02, -7.7862e-02,\n",
      "         -1.0606e-01, -8.5269e-02,  1.9807e-01, -5.8775e-02,  2.8156e-02,\n",
      "          1.6614e-02,  1.7369e-01, -1.4011e-01, -2.3432e-01, -1.6194e-01],\n",
      "        [-1.9272e-01, -1.8770e-02, -9.9342e-02,  1.6148e-01,  2.5847e-01,\n",
      "         -2.2823e-01,  1.6350e-01, -9.3343e-02,  3.8660e-02,  1.8547e-01,\n",
      "          1.9482e-01, -1.6799e-03,  2.0424e-01,  1.3057e-01,  2.7606e-02,\n",
      "          4.0445e-02, -1.7752e-01, -1.9576e-02, -1.7767e-01, -8.1054e-03],\n",
      "        [ 8.3349e-02, -5.1039e-02,  1.2288e-01,  8.6990e-02, -2.0792e-01,\n",
      "          9.1808e-02, -7.6146e-02,  1.3859e-01,  2.8545e-02,  3.7184e-02,\n",
      "          1.0114e-01,  1.2987e-01,  2.4553e-01,  6.3681e-02, -5.6987e-02,\n",
      "          1.7122e-01, -2.0166e-01, -1.2064e-01,  2.5264e-01,  1.0645e-01],\n",
      "        [ 4.5352e-03, -1.4393e-04,  2.1738e-01, -1.8625e-02,  1.9320e-01,\n",
      "          8.4833e-02,  1.7748e-01, -3.4219e-02,  2.2375e-01,  8.4586e-02,\n",
      "         -2.1157e-02, -3.8617e-02, -4.4893e-02, -2.1642e-01,  9.4511e-02,\n",
      "          1.7662e-01, -1.3145e-01, -1.7970e-01,  3.2355e-01,  5.6260e-02],\n",
      "        [-2.4032e-01, -1.3030e-01, -1.6406e-01,  5.8686e-02, -1.6085e-01,\n",
      "          1.1536e-02,  8.9377e-02, -4.6444e-02,  1.4083e-01,  2.8332e-01,\n",
      "          1.7624e-01, -1.1697e-01, -2.2953e-01,  3.6916e-02,  7.7359e-02,\n",
      "          1.9810e-01,  1.6206e-01,  1.6248e-01, -1.9073e-01,  1.0984e-01],\n",
      "        [ 1.9719e-03, -1.8947e-01, -8.7307e-02,  5.0425e-02, -4.5160e-02,\n",
      "          5.0270e-02, -2.8248e-02, -5.0633e-02,  3.4570e-01, -3.1397e-02,\n",
      "         -2.1976e-01, -2.1192e-01, -1.8266e-01, -9.5669e-02, -7.6294e-02,\n",
      "         -7.6877e-02, -1.5107e-01,  4.0403e-02, -1.3581e-02,  1.7394e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0830,  0.3136, -0.2065, -0.1391, -0.1289,  0.1172, -0.1143,  0.2477,\n",
      "         0.1382,  0.2763, -0.1399,  0.0099, -0.0694, -0.2068, -0.1244, -0.2575,\n",
      "         0.1624, -0.1221, -0.0541,  0.1430], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8384, 1.1380, 0.8836, 0.9830, 0.9086, 1.0326, 0.9472, 1.1041, 1.0266,\n",
      "        1.0037, 0.9707, 1.0864, 1.0461, 1.0472, 1.0227, 0.8399, 1.1162, 0.8409,\n",
      "        0.9304, 0.9991], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0601, -0.0197,  0.0374,  0.1563,  0.1936, -0.0794, -0.0025,  0.0498,\n",
      "        -0.0325,  0.0113,  0.0987, -0.1145,  0.0991,  0.1195,  0.0819,  0.0530,\n",
      "         0.0478, -0.1223, -0.0419,  0.0941], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2446,  0.2185, -0.1075, -0.1509, -0.1301,  0.0226, -0.0457, -0.1160,\n",
      "          0.0613, -0.0141, -0.0550,  0.1727,  0.1088,  0.2753, -0.0943, -0.1456,\n",
      "         -0.1557,  0.1193, -0.0435,  0.0207],\n",
      "        [-0.0613, -0.3002,  0.0911, -0.1017, -0.0747, -0.1046,  0.0476,  0.1244,\n",
      "         -0.2796, -0.1345,  0.1544,  0.2110,  0.1538, -0.2055,  0.0343,  0.1393,\n",
      "          0.0492, -0.2106,  0.1670, -0.2198],\n",
      "        [ 0.0869, -0.0100,  0.0736,  0.2861, -0.1564,  0.2738,  0.1545, -0.1298,\n",
      "         -0.0850, -0.2959,  0.0201, -0.2340, -0.1447, -0.1259, -0.1058, -0.1106,\n",
      "          0.0793, -0.0075, -0.1167, -0.1716],\n",
      "        [ 0.0314, -0.2267, -0.2801,  0.0934,  0.2398,  0.0916,  0.1851, -0.0323,\n",
      "          0.0942, -0.0825,  0.0556, -0.1734, -0.0325, -0.1257, -0.1795, -0.1395,\n",
      "          0.0891, -0.1871, -0.2480,  0.1674],\n",
      "        [-0.0949,  0.1927, -0.1177,  0.1188, -0.1783,  0.2657,  0.1579, -0.1348,\n",
      "          0.0251,  0.1389, -0.2224,  0.0289,  0.1885, -0.1776, -0.0566,  0.0255,\n",
      "          0.0487,  0.2061, -0.1738, -0.0834],\n",
      "        [ 0.0298,  0.2088,  0.1277,  0.1581,  0.0524,  0.1203, -0.2766, -0.2586,\n",
      "         -0.0692, -0.1124, -0.2192, -0.0927,  0.0527, -0.0720,  0.1577,  0.1420,\n",
      "          0.0272,  0.0018, -0.0627,  0.1141],\n",
      "        [ 0.2202,  0.2207, -0.0637,  0.2279,  0.1394,  0.1479, -0.0039, -0.2356,\n",
      "         -0.1632, -0.0210, -0.1335, -0.3186, -0.0310,  0.1833,  0.1862,  0.0223,\n",
      "         -0.1145,  0.0416,  0.1304, -0.2947],\n",
      "        [-0.0465,  0.1163, -0.0765,  0.1904,  0.0942, -0.0872,  0.0800,  0.0760,\n",
      "         -0.2368,  0.1237,  0.0228,  0.0679, -0.0550,  0.0061, -0.0862,  0.0697,\n",
      "         -0.1456,  0.0208, -0.1140, -0.1766],\n",
      "        [-0.1499, -0.0479,  0.0944,  0.0174, -0.1882, -0.0736, -0.0614, -0.2758,\n",
      "          0.1305,  0.0603,  0.0219,  0.1706,  0.0091, -0.2151, -0.0020, -0.2218,\n",
      "          0.2121,  0.0024, -0.0788, -0.0025],\n",
      "        [-0.1631, -0.1957,  0.1715, -0.2317,  0.0060, -0.1674, -0.0106,  0.1127,\n",
      "          0.0831, -0.1315, -0.0406,  0.1628,  0.2084,  0.0425,  0.3232,  0.1391,\n",
      "          0.0575, -0.0958,  0.2168,  0.2506],\n",
      "        [-0.1937,  0.2619,  0.0373, -0.0828,  0.1834, -0.0053, -0.0777, -0.0903,\n",
      "         -0.2400, -0.0907, -0.0239, -0.2217,  0.1491,  0.1456,  0.1799,  0.0072,\n",
      "         -0.2339, -0.1396, -0.1150,  0.1465],\n",
      "        [ 0.0068, -0.0312,  0.1756,  0.1482,  0.0196,  0.0465, -0.1146,  0.1591,\n",
      "          0.0287,  0.1581,  0.0070,  0.2459,  0.0891, -0.0597, -0.0754, -0.1605,\n",
      "         -0.1070, -0.0992,  0.2819,  0.0046],\n",
      "        [ 0.0410, -0.1474, -0.1796, -0.0386, -0.1329, -0.1302, -0.1179,  0.0442,\n",
      "          0.0653,  0.0508,  0.2174,  0.0758,  0.0955, -0.0166, -0.1259,  0.2562,\n",
      "         -0.2890, -0.1943,  0.1489, -0.1635],\n",
      "        [-0.1267, -0.2440,  0.1579,  0.0305,  0.1370,  0.0754, -0.0841, -0.1751,\n",
      "          0.2278, -0.0045, -0.2010,  0.0439,  0.1220,  0.0719, -0.2378,  0.0386,\n",
      "          0.1057,  0.2299, -0.0223, -0.0735],\n",
      "        [ 0.1461, -0.1082, -0.1929,  0.0060,  0.0837, -0.0095,  0.0752,  0.1290,\n",
      "          0.1468, -0.0083,  0.1584, -0.1287,  0.2580,  0.2540, -0.1071,  0.0116,\n",
      "         -0.1578, -0.0387, -0.0350,  0.1453],\n",
      "        [-0.1550, -0.2024,  0.1529,  0.1631, -0.0544,  0.0998, -0.1433, -0.1722,\n",
      "         -0.1213,  0.0954,  0.1959, -0.0796, -0.0724, -0.2474, -0.1300,  0.1774,\n",
      "          0.2189, -0.1134,  0.1596,  0.0386],\n",
      "        [-0.0299, -0.1411, -0.1365,  0.1854,  0.1999, -0.2163, -0.2714,  0.0977,\n",
      "         -0.0961,  0.1495,  0.0680, -0.1474,  0.0192,  0.1866, -0.1174,  0.1001,\n",
      "         -0.0738, -0.1333, -0.1696,  0.1767],\n",
      "        [-0.0609, -0.2421,  0.1666,  0.1478, -0.0332, -0.1817,  0.0728,  0.2992,\n",
      "         -0.0749, -0.1476, -0.0625, -0.1664, -0.1706, -0.0043,  0.0530, -0.0097,\n",
      "          0.3270, -0.0701, -0.0603, -0.0786],\n",
      "        [ 0.2186, -0.1725,  0.0692,  0.0637, -0.0385, -0.1624, -0.1865,  0.0009,\n",
      "          0.1874,  0.1240,  0.0518,  0.1193,  0.2287,  0.1933,  0.1022,  0.2012,\n",
      "         -0.0631,  0.0009,  0.1592,  0.1836],\n",
      "        [ 0.1878, -0.0046,  0.0976,  0.0196, -0.0125, -0.0214,  0.1634,  0.2944,\n",
      "          0.0021, -0.0836,  0.0938,  0.1922,  0.2109,  0.1608,  0.1242,  0.0198,\n",
      "          0.1183, -0.1148, -0.1646,  0.0537]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2924, -0.0024, -0.0962, -0.0239,  0.0397,  0.2816,  0.0853,  0.0482,\n",
      "        -0.2242,  0.0276, -0.0586, -0.2367, -0.2020,  0.2047,  0.2239, -0.1414,\n",
      "         0.0719,  0.2715,  0.2289, -0.0184], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9762, 1.1122, 0.9781, 0.9700, 0.9369, 1.1965, 1.0673, 0.9342, 0.9425,\n",
      "        1.0045, 1.0380, 0.8744, 1.0351, 0.8880, 0.9841, 0.9675, 0.9707, 1.0987,\n",
      "        0.9584, 0.9648], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0639,  0.0418, -0.0178,  0.0899,  0.0846, -0.0799, -0.1147,  0.0405,\n",
      "         0.1610, -0.0222,  0.0125, -0.0164,  0.0080,  0.2292, -0.0970,  0.0049,\n",
      "         0.0098,  0.0759, -0.0320,  0.0479], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-2.3293e-01, -2.7893e-01,  7.0187e-02, -1.4392e-01,  5.2464e-03,\n",
      "          5.9517e-02,  2.4325e-03,  2.2467e-01, -7.7698e-02, -1.0120e-01,\n",
      "          1.9316e-01,  1.8437e-03, -2.1445e-01, -1.2309e-01, -1.8401e-01,\n",
      "         -8.4199e-02, -7.9149e-02, -2.3905e-01,  2.1545e-02,  1.4866e-01],\n",
      "        [-8.6353e-02, -4.9552e-02,  3.9649e-01,  2.6243e-01, -8.6548e-02,\n",
      "          2.4299e-02,  9.5417e-02, -1.4704e-01,  1.0351e-01, -5.6119e-02,\n",
      "         -1.3964e-01, -1.7350e-02, -1.2174e-01,  1.3199e-01, -2.8641e-01,\n",
      "          1.8617e-01,  5.4912e-02,  9.1652e-02,  8.5652e-02, -2.0437e-01],\n",
      "        [-1.4820e-01, -2.6386e-02,  1.6707e-01,  1.2135e-01,  2.6870e-01,\n",
      "         -2.7359e-02,  1.9520e-01, -1.2481e-01, -1.6316e-01, -2.8508e-01,\n",
      "          6.0942e-02, -1.1585e-01,  5.0208e-02,  3.1085e-01, -1.3755e-01,\n",
      "         -5.5046e-02,  1.7456e-02, -1.9541e-02, -1.0490e-01,  4.9935e-02],\n",
      "        [ 1.6013e-01,  1.5402e-01, -1.0813e-02, -2.0747e-01,  1.0916e-01,\n",
      "         -2.1673e-01, -1.8859e-01,  8.1915e-02, -5.3874e-02,  2.2819e-01,\n",
      "          1.5146e-01,  2.8464e-01, -4.6736e-02,  7.7410e-02, -1.2621e-01,\n",
      "         -5.2669e-02,  2.2079e-02, -1.5060e-01,  2.6068e-01, -1.5873e-02],\n",
      "        [ 1.2231e-01,  2.4875e-01, -1.1373e-01, -3.5457e-02, -1.2205e-01,\n",
      "         -1.5043e-01, -2.2012e-01,  1.4938e-01,  6.8053e-02,  1.6617e-01,\n",
      "         -3.2950e-01, -1.4388e-01,  2.8247e-02, -2.1097e-02,  3.3486e-02,\n",
      "          1.3204e-01, -1.1954e-01, -9.5207e-02, -3.9893e-04,  4.1108e-02],\n",
      "        [ 1.7604e-01, -2.3088e-01,  5.9206e-02, -3.5991e-02, -1.8430e-01,\n",
      "         -7.8976e-02,  1.7230e-01, -2.0476e-01, -9.7681e-02, -4.1152e-02,\n",
      "          2.4402e-01, -1.0766e-01, -8.0656e-02, -2.8098e-01, -6.9589e-02,\n",
      "         -2.5028e-01,  3.2151e-02, -1.7220e-01,  1.1961e-01,  9.0879e-02],\n",
      "        [ 9.0378e-02, -2.1373e-01,  2.3705e-01,  1.5369e-01,  1.8005e-01,\n",
      "         -3.8069e-02, -2.6104e-01, -2.1161e-01,  2.1185e-01,  2.4898e-01,\n",
      "         -9.1715e-02, -2.8257e-03, -3.7006e-02,  3.3643e-02,  2.3542e-01,\n",
      "         -1.8443e-04,  2.0076e-01,  7.7828e-02, -4.2073e-02,  1.3408e-01],\n",
      "        [-3.6301e-02, -1.0449e-01,  1.5927e-01,  2.3938e-01,  1.7129e-01,\n",
      "          1.0774e-01,  3.8080e-02,  8.5144e-02,  4.3779e-02, -1.0709e-01,\n",
      "          9.2324e-02, -3.3395e-02,  2.3353e-02,  4.4814e-02, -2.2885e-01,\n",
      "          7.2778e-02, -9.2170e-02,  3.2204e-02, -2.3231e-01, -2.1161e-01],\n",
      "        [ 1.9090e-01,  6.6758e-02, -4.8514e-02,  1.2632e-01,  5.4803e-02,\n",
      "          1.7707e-02, -7.9331e-02,  6.0470e-02,  1.0730e-01,  6.0303e-02,\n",
      "         -2.9351e-01, -2.4528e-02,  2.7840e-01, -1.1399e-01,  9.3974e-04,\n",
      "         -1.6975e-01, -9.3648e-02, -1.0489e-01,  3.0626e-01,  1.6950e-01],\n",
      "        [-2.3107e-03,  7.0850e-02,  6.1697e-02, -3.2929e-01, -1.8982e-01,\n",
      "          1.3705e-01,  1.1235e-01, -1.0838e-01,  1.4032e-01,  8.8084e-02,\n",
      "          2.1574e-01,  7.7698e-02,  1.3687e-01, -1.7966e-01, -2.5816e-01,\n",
      "          1.9705e-01,  4.0699e-02,  3.6003e-02, -1.2390e-01,  1.2312e-01],\n",
      "        [-2.8060e-02, -1.6677e-01,  2.0603e-01,  1.2536e-01,  3.2354e-01,\n",
      "          1.9913e-01, -5.0656e-02, -1.0906e-01,  2.2970e-01, -1.7891e-01,\n",
      "          5.8867e-02, -1.8747e-01,  2.6981e-02, -1.0892e-01,  1.2391e-01,\n",
      "          1.8451e-01, -7.9179e-02, -5.9593e-02,  4.7787e-02,  1.3047e-01],\n",
      "        [ 1.0964e-01, -1.6697e-01, -8.4794e-02, -4.8991e-02,  2.1999e-01,\n",
      "          7.4730e-02,  6.7670e-02,  2.2580e-03, -5.2708e-02,  4.4470e-02,\n",
      "          2.1136e-01,  1.9478e-01, -1.0314e-01, -1.3908e-01, -1.7901e-02,\n",
      "         -1.0269e-01, -2.2389e-01, -1.1355e-01, -1.3022e-01, -2.3731e-02],\n",
      "        [ 7.2730e-02,  1.8001e-01,  7.0974e-03, -1.2442e-03, -2.4155e-01,\n",
      "         -2.7288e-01, -3.5280e-02,  2.2850e-01, -1.8562e-02,  2.0015e-02,\n",
      "          3.3946e-02,  8.4110e-02,  1.1809e-01, -2.5786e-02,  1.1307e-01,\n",
      "          8.0331e-02, -5.0769e-02, -2.6734e-02,  5.8602e-02,  1.7878e-01],\n",
      "        [-1.3414e-01, -1.9917e-01, -5.9204e-02,  1.6951e-01,  1.6754e-01,\n",
      "         -1.9159e-01,  1.2793e-02,  2.4542e-01,  1.6437e-01, -1.6290e-01,\n",
      "          2.0735e-03, -1.6111e-01, -1.8793e-01,  2.2905e-01, -6.3229e-02,\n",
      "          1.4009e-01, -2.4910e-02,  9.5825e-02, -1.7991e-01, -2.4811e-01],\n",
      "        [-1.3743e-01,  3.0248e-01, -7.0448e-02,  1.3242e-01,  1.5915e-01,\n",
      "         -3.2679e-01, -1.0358e-01, -2.3293e-02, -1.2137e-01,  2.6620e-02,\n",
      "         -7.5977e-03, -7.3073e-02, -6.1700e-02,  4.4090e-02, -1.9034e-01,\n",
      "         -7.7400e-02, -3.0162e-02,  2.1793e-01, -2.2749e-01,  2.2822e-01],\n",
      "        [ 1.5107e-01,  3.6370e-02,  3.4519e-02,  4.6014e-02, -1.4308e-01,\n",
      "          3.1136e-01,  1.8503e-01, -1.4552e-01, -8.7479e-02,  7.6868e-02,\n",
      "          2.4821e-02, -1.7356e-01, -1.4626e-01, -1.4387e-01, -2.6465e-01,\n",
      "         -1.0149e-01, -1.7878e-01, -6.2409e-02, -6.3022e-03, -2.3537e-01],\n",
      "        [-4.5051e-02, -8.3602e-02, -3.4324e-01, -3.8398e-02, -1.2378e-01,\n",
      "         -2.5511e-02, -1.9671e-01,  4.5790e-02,  1.7584e-01, -2.7409e-01,\n",
      "          5.3121e-02,  4.8320e-02,  1.3525e-01,  3.7856e-02, -1.6790e-01,\n",
      "         -2.1197e-01,  3.0618e-01, -2.3317e-02, -1.4788e-02,  8.9874e-03],\n",
      "        [-7.3742e-02,  2.4345e-01,  2.6797e-01,  7.5044e-02, -3.7823e-03,\n",
      "          2.4203e-02, -7.1942e-03,  1.3057e-01, -1.8033e-01, -1.6346e-02,\n",
      "         -1.3446e-01, -2.9683e-02, -1.5447e-01,  3.6124e-02,  1.9314e-02,\n",
      "         -7.5925e-02,  9.5272e-02,  3.6831e-01, -1.7151e-02,  2.0993e-01],\n",
      "        [-1.3730e-01,  2.5904e-01,  3.9967e-01, -2.3377e-01, -2.4440e-02,\n",
      "         -3.6448e-02, -1.3760e-01,  1.5201e-01, -1.3922e-03,  8.3007e-02,\n",
      "          8.6725e-02,  5.8549e-02,  2.6639e-01, -2.9940e-02,  3.7325e-02,\n",
      "         -1.9807e-01, -1.1512e-01, -9.7820e-03,  1.5088e-03,  4.4615e-02],\n",
      "        [ 8.5849e-02,  1.1278e-01,  1.1458e-01,  8.8608e-02, -2.9939e-02,\n",
      "         -1.9846e-01, -2.4210e-01, -4.8374e-02,  9.5854e-02,  2.7638e-02,\n",
      "         -1.9037e-01,  1.3073e-02,  2.6249e-02, -1.5037e-01, -1.0672e-01,\n",
      "         -3.5145e-03, -2.5255e-01,  1.3343e-01, -2.2951e-01, -1.1152e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0117, -0.0675,  0.0900, -0.0972, -0.1662, -0.1152,  0.0452,  0.3950,\n",
      "         0.0444, -0.1238,  0.1282, -0.1930,  0.0569,  0.1839, -0.1237,  0.1572,\n",
      "         0.1163, -0.1772,  0.1483,  0.1693], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0237, 1.0325, 0.8752, 1.0688, 0.9024, 1.0325, 0.9612, 1.0190, 1.0104,\n",
      "        0.9764, 0.9207, 1.1515, 0.8924, 1.0791, 0.9773, 1.0629, 0.9280, 0.9287,\n",
      "        0.8716, 0.9687], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0818, -0.0229,  0.1205, -0.1411, -0.0435, -0.1330, -0.1539,  0.0143,\n",
      "        -0.2121, -0.0966,  0.0933, -0.0418,  0.0751, -0.0368,  0.0931, -0.1524,\n",
      "         0.0874, -0.0605,  0.1303,  0.0413], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 2.3319e-02,  2.8945e-02, -1.6476e-01, -1.7672e-01,  1.8395e-01,\n",
      "          2.2408e-01, -1.0562e-01,  7.3609e-02,  2.4828e-02,  1.5023e-01,\n",
      "          6.1472e-02,  8.9820e-03,  3.6429e-02, -5.2505e-02,  1.9018e-01,\n",
      "         -5.2231e-02, -7.8936e-02,  3.1092e-01,  3.2111e-02,  4.2772e-03],\n",
      "        [ 1.5156e-02,  1.2190e-02,  2.2000e-01, -1.7891e-01, -1.5905e-01,\n",
      "          7.4888e-02, -1.1978e-01,  1.4470e-01, -3.5512e-01,  5.3676e-02,\n",
      "          4.4679e-02, -2.2464e-01, -8.3939e-03,  5.1694e-02, -1.4283e-01,\n",
      "         -1.6676e-01,  1.6602e-01, -1.7892e-01, -7.5945e-02, -1.7845e-01],\n",
      "        [-9.5841e-02, -1.5124e-01,  1.4412e-01, -2.8576e-01,  8.2854e-02,\n",
      "         -5.3570e-02, -2.7811e-01, -2.0131e-01, -4.3689e-02, -2.1223e-02,\n",
      "          7.0147e-02,  8.6826e-02, -5.9271e-02,  3.5794e-04,  1.1052e-01,\n",
      "          1.2144e-01, -1.3767e-01,  1.0380e-01,  1.7033e-01,  4.4124e-02],\n",
      "        [-2.3983e-01,  8.9774e-02,  1.1793e-01,  7.3992e-02,  3.8481e-02,\n",
      "          1.9967e-01,  1.8597e-01,  7.2759e-02, -3.8152e-02,  4.2367e-03,\n",
      "          5.2830e-02,  1.1370e-01, -1.2061e-01, -5.7736e-02,  1.9210e-01,\n",
      "          1.5854e-01, -2.4811e-01, -1.2018e-01,  1.1347e-01, -1.9640e-01],\n",
      "        [ 3.8141e-02,  2.0364e-01, -1.4699e-01,  1.2132e-01,  7.5198e-02,\n",
      "         -3.1111e-01, -1.5087e-01, -2.8839e-01, -6.9881e-02,  2.3402e-01,\n",
      "         -3.0210e-01, -8.7666e-02, -3.0477e-02, -2.1603e-01,  2.3949e-01,\n",
      "         -1.7050e-01,  5.4902e-02,  2.1433e-01, -1.1358e-01,  1.8699e-01],\n",
      "        [-1.0718e-01, -1.4651e-01,  2.7515e-01, -1.1596e-01,  2.3259e-01,\n",
      "         -1.7723e-01, -9.8772e-02,  6.7946e-02,  3.5432e-02,  7.5557e-02,\n",
      "          1.3250e-01,  8.7592e-02,  2.0202e-02,  1.1602e-02, -1.4662e-01,\n",
      "         -1.3488e-01,  6.7113e-02, -2.3137e-01,  2.5600e-01, -6.3760e-02],\n",
      "        [-8.7979e-02, -1.9994e-01,  1.0253e-01, -2.0348e-01, -2.4038e-02,\n",
      "          9.9241e-02,  7.6657e-02, -7.8946e-02,  2.6101e-01,  2.2877e-02,\n",
      "         -7.9914e-02, -2.0010e-01,  3.0138e-01, -1.7246e-01,  5.9572e-02,\n",
      "         -6.7752e-02,  1.9677e-01,  1.4996e-01,  2.2928e-01,  1.0209e-01],\n",
      "        [ 1.9479e-01, -1.5655e-01, -1.7031e-01, -5.3402e-02, -8.9790e-02,\n",
      "          2.5195e-01, -2.8302e-01,  2.5434e-02, -1.0384e-01,  1.8828e-02,\n",
      "         -1.1706e-01,  2.2058e-01, -1.0144e-01,  1.1370e-01, -2.6598e-01,\n",
      "          2.4088e-01,  1.7600e-01, -1.3144e-01, -2.0731e-02, -6.1788e-02],\n",
      "        [-1.4781e-01, -1.8836e-01, -1.5215e-01,  2.6615e-01, -7.6294e-02,\n",
      "         -1.6718e-01, -4.5094e-02, -1.0104e-01, -9.6464e-03, -2.1697e-01,\n",
      "         -7.1979e-02,  5.3175e-02,  1.0959e-01, -1.7527e-01,  9.5263e-02,\n",
      "         -1.7256e-01, -9.5615e-03,  2.0755e-02, -5.1964e-03,  4.0375e-02],\n",
      "        [-4.8663e-02,  3.1388e-01, -5.3480e-03,  2.2874e-02, -1.3848e-01,\n",
      "          1.7462e-01, -1.8988e-03,  2.6201e-01, -1.3522e-01, -2.8010e-02,\n",
      "         -3.3403e-02, -1.6173e-01, -1.2331e-01,  1.7433e-01,  8.4395e-02,\n",
      "          2.4824e-02, -2.0575e-01,  1.0510e-01,  5.6916e-02,  2.1194e-01],\n",
      "        [-1.8618e-01, -7.7859e-02, -1.8492e-01, -6.4889e-02,  8.9421e-02,\n",
      "         -2.8177e-01, -2.4108e-02, -1.2017e-02, -6.5085e-02, -8.3113e-02,\n",
      "         -2.8161e-02, -2.8528e-01,  1.8875e-02,  6.3957e-02,  2.1701e-01,\n",
      "         -1.1175e-01,  5.8169e-02,  7.3510e-02,  5.0347e-02,  3.0770e-01],\n",
      "        [ 3.2159e-01, -6.6117e-02, -3.0633e-02, -2.8581e-02, -9.7050e-02,\n",
      "         -1.0765e-01, -7.5537e-02,  9.0995e-02, -1.7715e-02,  2.1874e-01,\n",
      "         -1.4242e-01,  1.5737e-01, -2.5243e-01, -7.8770e-02,  4.2064e-02,\n",
      "          2.8079e-01, -5.6814e-03, -2.6568e-02, -1.4420e-03,  8.0561e-02],\n",
      "        [-1.3510e-02, -8.2357e-02, -1.1313e-01,  2.2025e-01, -1.4543e-01,\n",
      "          9.8123e-02, -3.3865e-02, -1.3914e-01,  3.0050e-01, -2.0286e-01,\n",
      "          2.0447e-01, -2.5620e-01, -3.7690e-02,  1.3620e-02, -1.0209e-01,\n",
      "         -1.5628e-03, -5.9960e-02, -4.4416e-02,  1.3712e-01, -1.8029e-01],\n",
      "        [ 1.4083e-01, -2.7256e-02,  1.8960e-01,  1.5902e-01, -1.3380e-01,\n",
      "         -3.0674e-01,  2.2284e-01,  1.0164e-01, -2.3850e-01, -2.5709e-01,\n",
      "          3.5113e-02,  9.1600e-03,  7.6527e-02,  2.3608e-01,  1.0031e-02,\n",
      "          1.4269e-01, -1.6631e-01,  1.7356e-01,  9.4279e-02, -1.6722e-01],\n",
      "        [-1.6975e-02,  1.7849e-01,  6.2090e-02, -5.9435e-02, -2.3653e-01,\n",
      "          2.4162e-02, -6.9050e-02,  2.8220e-01,  1.6200e-02,  7.2849e-02,\n",
      "          2.1369e-01,  1.3460e-01, -9.3483e-02,  8.7750e-02, -7.0985e-02,\n",
      "         -1.3398e-01,  8.8506e-02,  2.0244e-01,  9.4577e-02,  1.9502e-01],\n",
      "        [-2.1565e-01,  1.9031e-01,  4.9995e-02, -3.0062e-01, -1.4976e-01,\n",
      "         -4.1713e-01, -2.4391e-01, -6.6488e-02,  1.8500e-02, -1.4656e-01,\n",
      "          6.1714e-02,  3.7754e-03,  3.5908e-02, -2.3511e-01,  2.6854e-01,\n",
      "         -5.5352e-02,  3.5283e-06, -1.3972e-01, -2.1754e-02,  8.9651e-02],\n",
      "        [ 3.9790e-02,  2.8113e-02, -2.5934e-01,  1.5053e-01,  7.1794e-02,\n",
      "         -1.8153e-01, -8.2538e-02, -6.1120e-02,  1.5150e-01, -5.6678e-03,\n",
      "         -2.9374e-01,  9.7950e-03,  2.1262e-01, -2.7771e-01,  1.3853e-01,\n",
      "         -1.0976e-01, -1.0208e-01,  8.0351e-02,  1.4188e-01, -2.7040e-02],\n",
      "        [ 2.1274e-01, -1.7454e-02, -1.1332e-01,  5.8416e-02, -9.0832e-02,\n",
      "          7.3872e-02, -5.0100e-02,  2.6658e-01, -1.6937e-01, -8.8976e-02,\n",
      "          5.2580e-02,  2.0581e-01, -1.2284e-01,  1.6124e-01, -3.7004e-02,\n",
      "          2.4990e-01, -8.1164e-02, -8.9411e-02,  1.2080e-02, -1.3864e-02],\n",
      "        [-3.6704e-02, -2.6661e-01, -1.0784e-01,  1.1061e-01, -9.1355e-02,\n",
      "          1.4928e-01, -1.1464e-01, -2.4277e-01, -1.0479e-01,  1.0206e-01,\n",
      "         -6.9357e-02, -7.8862e-02,  1.6036e-01, -2.9333e-01,  6.5554e-02,\n",
      "          1.9157e-02, -1.1045e-01, -1.0694e-01,  1.2363e-01,  9.1610e-02],\n",
      "        [-1.8688e-01, -5.4166e-02,  1.0344e-01, -3.3564e-01, -4.0177e-02,\n",
      "          1.2158e-01,  1.1150e-01,  7.7426e-02, -2.1023e-01,  8.7603e-02,\n",
      "          4.5594e-03, -2.2706e-01,  1.3941e-01,  1.4168e-01,  1.3765e-01,\n",
      "         -2.8516e-01,  1.6614e-01, -8.5749e-02,  1.2944e-01,  1.5788e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0147,  0.0055,  0.4778,  0.2394,  0.0185,  0.3508, -0.1449, -0.0926,\n",
      "         0.1296, -0.0534,  0.2543,  0.0413,  0.1407,  0.1651,  0.3011,  0.1000,\n",
      "        -0.0110, -0.0010,  0.1729,  0.1249], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9426, 0.9488, 0.9027, 1.0070, 1.0154, 1.0139, 0.8981, 0.9447, 0.9614,\n",
      "        1.0050, 1.0878, 0.9834, 0.9153, 1.0822, 1.1505, 0.8891, 1.0885, 0.9458,\n",
      "        0.9912, 0.9770], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0836, -0.2354,  0.0677, -0.1039,  0.0240, -0.0851,  0.0091, -0.0305,\n",
      "         0.0415,  0.0040, -0.0839,  0.0226, -0.0493, -0.0451, -0.0631,  0.0228,\n",
      "        -0.0174, -0.0330,  0.0646,  0.0293], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0158, -0.3534,  0.0284, -0.0298, -0.0016,  0.0847, -0.0858, -0.1236,\n",
      "          0.1067, -0.0022,  0.2472, -0.1782,  0.1617,  0.0839, -0.1272, -0.0745,\n",
      "          0.0480, -0.1579,  0.1077, -0.0383],\n",
      "        [ 0.2601, -0.2010, -0.0439, -0.1202,  0.2174,  0.2629, -0.0914, -0.1707,\n",
      "          0.1135, -0.1141, -0.0127, -0.0188, -0.1435, -0.1155, -0.1240, -0.0239,\n",
      "          0.3464, -0.1166,  0.0819, -0.0910],\n",
      "        [-0.1135,  0.2280,  0.1392,  0.1187, -0.2096, -0.0678, -0.0767, -0.1118,\n",
      "         -0.0387,  0.1595, -0.0475, -0.0623, -0.0206,  0.2837, -0.0460,  0.2047,\n",
      "         -0.0111, -0.1471, -0.0329,  0.2930],\n",
      "        [-0.0397,  0.2130,  0.0226, -0.2555, -0.0936, -0.0220,  0.0019,  0.2323,\n",
      "         -0.1006, -0.0542, -0.0496,  0.0351, -0.2792, -0.0827, -0.1020,  0.0762,\n",
      "         -0.2142,  0.0407,  0.0411,  0.0317],\n",
      "        [-0.1801,  0.0281, -0.0590,  0.1515,  0.1676,  0.0176, -0.1277, -0.0305,\n",
      "          0.2604, -0.0208, -0.0901, -0.2291,  0.0448, -0.2890, -0.2307,  0.2088,\n",
      "         -0.1576, -0.1427,  0.1797, -0.0230],\n",
      "        [ 0.1928, -0.2202,  0.0102,  0.1380,  0.1314, -0.1772, -0.1816, -0.2865,\n",
      "         -0.0240,  0.1659,  0.2258, -0.0921, -0.0770,  0.0453, -0.0276, -0.1217,\n",
      "         -0.1012, -0.2382, -0.2197,  0.1953],\n",
      "        [-0.0617,  0.0193,  0.0771,  0.1162, -0.2017,  0.1453,  0.1614, -0.0646,\n",
      "          0.0087, -0.2086, -0.2390,  0.1727, -0.1327,  0.0392,  0.1542,  0.2530,\n",
      "         -0.2639,  0.1302, -0.1325, -0.2297],\n",
      "        [ 0.1884,  0.0646, -0.2070,  0.0638,  0.0611,  0.0878,  0.1204, -0.2019,\n",
      "          0.1584,  0.0179, -0.1542, -0.1638,  0.0913, -0.0479, -0.0330, -0.2172,\n",
      "          0.2606, -0.0223,  0.0840, -0.1516],\n",
      "        [-0.1430, -0.0765, -0.1325, -0.0181,  0.0872, -0.1590, -0.2145,  0.0706,\n",
      "         -0.1726, -0.2378, -0.2390, -0.0476, -0.2104, -0.1855, -0.1905, -0.1232,\n",
      "         -0.1737, -0.1526,  0.2220,  0.1537],\n",
      "        [ 0.2271,  0.0148,  0.1785,  0.2336,  0.0888,  0.1179, -0.1948,  0.0356,\n",
      "         -0.1994, -0.0152,  0.0289,  0.0126,  0.1151, -0.3592, -0.1383, -0.1979,\n",
      "         -0.0007, -0.0327,  0.3077, -0.1399],\n",
      "        [-0.0954,  0.2023, -0.2011,  0.0423, -0.0167,  0.2396, -0.0039,  0.0448,\n",
      "          0.1064,  0.1560, -0.1803, -0.1146,  0.0644,  0.0934,  0.2832,  0.0791,\n",
      "          0.2226,  0.0817,  0.0296,  0.0779],\n",
      "        [ 0.0318, -0.1466, -0.2436, -0.1376, -0.1487, -0.2263,  0.0475,  0.0345,\n",
      "          0.1477,  0.0858, -0.2817, -0.2376,  0.2244,  0.0128, -0.1989,  0.0357,\n",
      "          0.0846, -0.1726,  0.0340,  0.0411],\n",
      "        [-0.0018, -0.1295,  0.0348,  0.1792,  0.2828, -0.1708,  0.0269, -0.1345,\n",
      "         -0.0740, -0.0616,  0.0395,  0.0042, -0.1043,  0.1648,  0.1312, -0.2152,\n",
      "          0.1420, -0.1557,  0.1552, -0.1243],\n",
      "        [ 0.0224,  0.0738,  0.1290, -0.0872, -0.0661,  0.2446,  0.1604, -0.1909,\n",
      "          0.0940, -0.1982,  0.0709, -0.1379, -0.0221, -0.1560, -0.0466, -0.0736,\n",
      "          0.0504, -0.2086,  0.3173, -0.0083],\n",
      "        [-0.0082, -0.0241, -0.2047, -0.0913, -0.1290, -0.0474, -0.0453, -0.1809,\n",
      "         -0.1948,  0.2003, -0.1522, -0.1138, -0.1859,  0.1840,  0.2282,  0.1120,\n",
      "         -0.0079, -0.1353, -0.0452,  0.0547],\n",
      "        [ 0.2422, -0.1075,  0.1308, -0.1505,  0.2183,  0.0757,  0.0257, -0.0262,\n",
      "         -0.0917,  0.0579, -0.0549, -0.1087, -0.3155, -0.1123,  0.1670,  0.1419,\n",
      "          0.1026, -0.2058,  0.1349,  0.2363],\n",
      "        [ 0.2418, -0.0844,  0.2349,  0.1571,  0.0665, -0.3135, -0.1819,  0.1899,\n",
      "          0.1140,  0.0944, -0.0094,  0.1560,  0.0167, -0.2875,  0.1431,  0.1354,\n",
      "         -0.2062,  0.0491, -0.0184, -0.2002],\n",
      "        [ 0.0961,  0.0195,  0.1630,  0.1870, -0.0203,  0.1109,  0.0442,  0.1492,\n",
      "         -0.1186,  0.0259, -0.2483,  0.0589, -0.0652,  0.0016,  0.0930, -0.1474,\n",
      "         -0.2700,  0.0347, -0.0754, -0.1067],\n",
      "        [ 0.0582, -0.0548, -0.0596,  0.2117, -0.1176, -0.0405, -0.0887,  0.1207,\n",
      "          0.0704,  0.1739, -0.0638,  0.2222, -0.1027,  0.0522, -0.1569,  0.0427,\n",
      "          0.1627,  0.1725,  0.0669, -0.2915],\n",
      "        [ 0.1224, -0.2464,  0.0723, -0.2541,  0.1983, -0.0045,  0.2371, -0.1306,\n",
      "          0.1038, -0.0240,  0.1371,  0.2045, -0.0282, -0.1196, -0.0578,  0.1487,\n",
      "         -0.0130, -0.0500, -0.1155, -0.0582]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2910, -0.1185,  0.0873, -0.1019,  0.1870, -0.1137, -0.1845,  0.0792,\n",
      "         0.0598, -0.0842,  0.0354, -0.0246, -0.0137,  0.0092, -0.1314,  0.3122,\n",
      "         0.1371,  0.2720,  0.1712, -0.0036], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0535, 1.0814, 0.8860, 0.9245, 0.9857, 1.0841, 1.0099, 1.0047, 0.9747,\n",
      "        0.9777, 0.8582, 0.9572, 0.9518, 1.0613, 1.0433, 0.9938, 1.0179, 1.0104,\n",
      "        0.8876, 0.9973], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0175,  0.0951,  0.0034,  0.0744,  0.0842, -0.0197, -0.0062,  0.0418,\n",
      "         0.0601,  0.0392, -0.1161,  0.1652,  0.0046,  0.2100,  0.0567,  0.0296,\n",
      "         0.1321,  0.0368,  0.0558,  0.0782], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1705, -0.1736,  0.0922, -0.0065,  0.1629, -0.0901,  0.0181,  0.2091,\n",
      "         -0.0777, -0.1209, -0.0150,  0.1720,  0.1401,  0.3785,  0.0666,  0.1686,\n",
      "          0.1267, -0.0573, -0.2547,  0.0928],\n",
      "        [ 0.1315, -0.1341, -0.1508, -0.2153, -0.0225,  0.0052, -0.0012, -0.0362,\n",
      "          0.2474,  0.3352,  0.0089, -0.0141,  0.2567, -0.0267, -0.2449,  0.0242,\n",
      "         -0.0643,  0.1793,  0.0489, -0.1863],\n",
      "        [-0.1855,  0.0822,  0.1756, -0.0174, -0.1752,  0.0390, -0.0337,  0.0745,\n",
      "          0.0154, -0.1834,  0.1474, -0.2410,  0.1071, -0.1530,  0.3113, -0.1196,\n",
      "         -0.0299,  0.2657,  0.1307, -0.0187],\n",
      "        [ 0.0394, -0.0125, -0.1020,  0.1313, -0.1586, -0.2268, -0.2719, -0.1526,\n",
      "          0.0498,  0.3364, -0.2215, -0.0338,  0.1200,  0.0591, -0.2211, -0.0299,\n",
      "          0.0994,  0.0367,  0.1423,  0.0643],\n",
      "        [-0.1201,  0.2490,  0.0711,  0.0005,  0.0622,  0.2496, -0.2148, -0.1333,\n",
      "         -0.0062,  0.2266, -0.1450,  0.0908,  0.0860, -0.0567,  0.0615,  0.2266,\n",
      "          0.1075, -0.1673, -0.0904,  0.0696],\n",
      "        [-0.1092, -0.1978, -0.1254, -0.1378, -0.0992, -0.0574,  0.2795, -0.0671,\n",
      "         -0.1211,  0.2055,  0.0470, -0.1262, -0.1087,  0.0623, -0.0969,  0.0276,\n",
      "          0.0557,  0.2040,  0.1836, -0.0793],\n",
      "        [-0.2618, -0.1134, -0.0039, -0.0576, -0.2910, -0.2465, -0.0832,  0.1110,\n",
      "         -0.1629, -0.0675, -0.1432,  0.0877, -0.1351, -0.3416, -0.0916, -0.0317,\n",
      "          0.0965,  0.2508, -0.0078, -0.0007],\n",
      "        [ 0.1114,  0.3188, -0.1583, -0.1743,  0.1939, -0.0924, -0.1010,  0.2333,\n",
      "          0.1111, -0.0474, -0.1093, -0.0569,  0.0253,  0.2209, -0.1668, -0.0339,\n",
      "         -0.0615, -0.1776,  0.1374, -0.1204],\n",
      "        [ 0.0856,  0.2177,  0.1341, -0.0736,  0.2117, -0.1999,  0.0586,  0.2094,\n",
      "         -0.0149, -0.1567, -0.0512,  0.0703, -0.0490, -0.0187, -0.1696,  0.1750,\n",
      "         -0.1847,  0.1053,  0.1514,  0.2200],\n",
      "        [ 0.1308,  0.2852,  0.0230,  0.0031, -0.0763,  0.0891,  0.0899,  0.1700,\n",
      "          0.1645, -0.1744, -0.0186, -0.1306,  0.0535,  0.3148, -0.1471,  0.1948,\n",
      "         -0.2135, -0.1098,  0.1648,  0.1459],\n",
      "        [ 0.1298, -0.0540,  0.0256, -0.2249, -0.3203,  0.2334, -0.2726, -0.0930,\n",
      "         -0.2058, -0.0262,  0.0744,  0.0872,  0.2028, -0.1855,  0.0679,  0.1708,\n",
      "          0.0797, -0.1731, -0.1049,  0.1219],\n",
      "        [-0.0409, -0.2666, -0.1514,  0.0261,  0.2179, -0.2113,  0.1035, -0.0920,\n",
      "          0.2671,  0.2246, -0.0504,  0.0889, -0.2000, -0.0660, -0.2097, -0.2881,\n",
      "          0.1945,  0.1151,  0.0815, -0.1718],\n",
      "        [-0.0010,  0.0382, -0.0347, -0.0726,  0.1002, -0.1385, -0.3132,  0.2976,\n",
      "          0.0410,  0.1801,  0.0700,  0.3023,  0.0659,  0.0865, -0.0324, -0.1664,\n",
      "         -0.1221, -0.1800,  0.1492, -0.0993],\n",
      "        [ 0.1232,  0.1517, -0.2791, -0.0652, -0.1508, -0.1077, -0.0887,  0.2983,\n",
      "         -0.2513,  0.1708, -0.0289,  0.0579,  0.0156, -0.0946, -0.0101, -0.1105,\n",
      "         -0.3446, -0.1402, -0.2213, -0.2313],\n",
      "        [-0.0401,  0.1851,  0.2504, -0.1298, -0.1472,  0.1737, -0.0022,  0.0746,\n",
      "         -0.0817, -0.0006,  0.0953,  0.0045,  0.1304,  0.1449,  0.1183,  0.2920,\n",
      "          0.0467,  0.0428, -0.0307,  0.0534],\n",
      "        [-0.1750, -0.0993,  0.2027,  0.0862, -0.1203, -0.0380,  0.0437, -0.1240,\n",
      "          0.0605, -0.0904, -0.1776,  0.2432, -0.0445,  0.0024,  0.1817,  0.0287,\n",
      "         -0.2787,  0.0936, -0.1982, -0.2503],\n",
      "        [ 0.0785,  0.1446, -0.0299, -0.1555, -0.0857, -0.0186, -0.1158,  0.2923,\n",
      "         -0.0295,  0.0359,  0.1142,  0.2782,  0.0748,  0.3106, -0.2125, -0.0495,\n",
      "         -0.1962,  0.0267,  0.1414, -0.0052],\n",
      "        [-0.4101, -0.1673,  0.0536, -0.0727,  0.1188, -0.0359,  0.3502,  0.0886,\n",
      "         -0.0751,  0.1503,  0.1903, -0.2065,  0.0569,  0.0748,  0.1287, -0.2437,\n",
      "         -0.0612, -0.0162,  0.2228,  0.0450],\n",
      "        [-0.0447, -0.1485, -0.1412,  0.2493, -0.0197, -0.0656, -0.0804,  0.2076,\n",
      "          0.1111, -0.1489,  0.0501,  0.2991,  0.2675,  0.0471, -0.0731, -0.2582,\n",
      "          0.2531, -0.0055,  0.1253, -0.4005],\n",
      "        [ 0.1618,  0.0642, -0.2588,  0.0751,  0.1996,  0.0337, -0.2780,  0.2300,\n",
      "         -0.0960,  0.1995, -0.0269,  0.1653,  0.1654,  0.1588, -0.2664, -0.0793,\n",
      "         -0.0670, -0.0695, -0.0924,  0.1990]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.3789e-01, -1.3480e-01,  3.9548e-02,  5.6483e-02,  4.5738e-01,\n",
      "         1.6675e-01, -1.0306e-01,  2.5387e-01, -5.9936e-02,  9.8027e-02,\n",
      "        -1.7852e-01,  2.5714e-04,  4.1620e-02, -2.6667e-01,  1.4385e-01,\n",
      "         2.6149e-01, -6.2264e-02, -2.6780e-01, -2.4299e-02,  3.4478e-01],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9689, 1.0512, 0.9189, 0.9051, 1.0330, 1.0240, 0.8473, 0.8842, 0.8634,\n",
      "        0.9973, 1.0965, 1.0715, 0.9965, 0.8172, 1.0960, 0.8397, 0.8670, 1.0713,\n",
      "        1.0725, 0.9466], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1194,  0.0304,  0.0629,  0.0059,  0.1080, -0.0612, -0.0947,  0.1245,\n",
      "        -0.0811, -0.0615,  0.3258, -0.1404, -0.1159,  0.0268,  0.1991, -0.2367,\n",
      "         0.0961, -0.1682, -0.1720,  0.2590], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0778,  0.0101, -0.0867,  0.1327,  0.2459, -0.2864, -0.0880,  0.1601,\n",
      "         -0.0760, -0.0634,  0.2644, -0.3196, -0.0196,  0.1115, -0.0252, -0.3211,\n",
      "          0.1821, -0.2708, -0.2028,  0.1122],\n",
      "        [ 0.0461, -0.0930,  0.0805, -0.1149,  0.1066, -0.0946, -0.0976, -0.0776,\n",
      "         -0.0926, -0.0060,  0.2110, -0.2016, -0.1513, -0.1080,  0.2008,  0.0198,\n",
      "         -0.0950,  0.0179, -0.1405,  0.0673],\n",
      "        [ 0.1253,  0.3425, -0.1409,  0.2283,  0.0633,  0.1443,  0.0240, -0.0827,\n",
      "          0.1348, -0.2205, -0.2973,  0.3184, -0.0611, -0.1269, -0.2677, -0.1733,\n",
      "         -0.0832,  0.0341,  0.0148, -0.1386],\n",
      "        [-0.0906, -0.0578,  0.0031, -0.0074, -0.1879,  0.1056,  0.1909, -0.1063,\n",
      "          0.0926,  0.0455, -0.1554,  0.0282, -0.2817,  0.0446, -0.1549,  0.0787,\n",
      "         -0.0828,  0.1405,  0.0252, -0.1321],\n",
      "        [-0.2322,  0.0607, -0.1526,  0.1833, -0.0878,  0.1010,  0.1374,  0.0833,\n",
      "         -0.2220,  0.0353, -0.2408,  0.1514, -0.0878, -0.2476, -0.2067, -0.0814,\n",
      "          0.0412,  0.0298, -0.0230, -0.1603],\n",
      "        [-0.0059,  0.1927,  0.0418,  0.0611,  0.0677,  0.1300,  0.0734,  0.1689,\n",
      "          0.2260,  0.2429, -0.1221, -0.2528,  0.1433, -0.0387,  0.0965, -0.1470,\n",
      "         -0.0773, -0.1641,  0.0077,  0.2542],\n",
      "        [ 0.1271,  0.2031, -0.0522,  0.1251,  0.0474, -0.1469,  0.0345,  0.1352,\n",
      "          0.1029,  0.3133,  0.0470, -0.0510, -0.0376,  0.0640,  0.0430,  0.0595,\n",
      "          0.1673, -0.1120,  0.2205,  0.2272],\n",
      "        [ 0.1947,  0.0549, -0.1868,  0.1148,  0.2340,  0.0625, -0.2033,  0.1461,\n",
      "         -0.0159,  0.1224,  0.0370, -0.0676, -0.0820,  0.0922,  0.3309,  0.0516,\n",
      "          0.0468, -0.0929, -0.2850, -0.0882],\n",
      "        [-0.1326, -0.0997,  0.1864, -0.1016, -0.1361,  0.2606,  0.0507, -0.1825,\n",
      "         -0.1133, -0.1177,  0.1150, -0.1121,  0.0598,  0.0556, -0.0017, -0.0567,\n",
      "         -0.1737,  0.1419, -0.1044, -0.2778],\n",
      "        [ 0.2060, -0.1294, -0.1105, -0.2257, -0.0655, -0.1054, -0.2703, -0.0188,\n",
      "         -0.1058, -0.0733, -0.0691,  0.0674,  0.1984,  0.2288, -0.0934, -0.0208,\n",
      "          0.1908,  0.0320,  0.1796, -0.0407]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2518,  0.4440, -0.1413,  0.1093,  0.0924,  0.2303,  0.1214,  0.0622,\n",
      "         0.0300,  0.2206], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.3396, 1.6977, 1.4574, 1.1381, 1.2057, 1.3772, 1.0831, 1.0720, 1.4260,\n",
      "        1.2277], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3049, -0.0540, -0.3513, -0.7187,  0.1209, -0.5171, -0.3488,  0.3653,\n",
      "         0.4570,  0.0792], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 3.6906e-01,  5.2815e-01, -3.7441e-01, -3.5960e-02, -2.2622e-01,\n",
      "         -4.6319e-02, -1.9684e-02,  2.5153e-01, -1.5326e-01,  4.9159e-02],\n",
      "        [ 3.9832e-01, -2.6054e-01,  1.8292e-01, -2.8223e-01, -4.4696e-01,\n",
      "          3.2225e-01,  1.5256e-01, -2.9133e-02, -3.6290e-01,  1.6031e-01],\n",
      "        [-2.8424e-01,  9.9616e-01, -6.7489e-01,  4.1794e-02,  1.4589e-02,\n",
      "         -2.3492e-01, -4.6321e-01,  1.9851e-01,  6.2871e-01, -5.0199e-01],\n",
      "        [ 1.6345e-01,  6.3014e-01, -6.0223e-01,  3.5309e-03, -6.5539e-01,\n",
      "         -2.6007e-01,  1.6265e-01,  2.1390e-01,  2.1561e-01, -3.5797e-01],\n",
      "        [-1.5850e-01,  1.5999e-01, -6.8085e-02,  1.1152e-01,  1.3464e-01,\n",
      "          1.7868e-01,  1.2231e-01, -3.2822e-02, -3.2656e-01,  1.2752e-01],\n",
      "        [-3.2644e-01,  4.4247e-01, -1.3416e-01,  8.5574e-03, -9.7802e-02,\n",
      "         -2.3020e-01, -1.8827e-01, -1.9676e-01,  5.3954e-01, -3.1282e-01],\n",
      "        [ 4.6261e-01, -7.1421e-02, -1.3515e-01, -1.1161e-01, -4.0905e-02,\n",
      "          9.6937e-02,  2.4494e-01,  4.9065e-01, -1.3312e-01, -2.5614e-01],\n",
      "        [-7.1276e-01, -4.1913e-01,  5.0950e-01,  5.6178e-01,  2.3805e-01,\n",
      "         -4.9356e-01, -2.7381e-01, -3.4070e-01,  5.3806e-01, -9.1471e-02],\n",
      "        [ 2.5207e-01,  4.2691e-01, -1.4797e-02, -2.2418e-01, -3.1024e-01,\n",
      "          7.0875e-02, -1.3806e-01,  1.4813e-01, -1.5125e-05, -1.8722e-01],\n",
      "        [-3.4366e-01,  1.5853e-02, -3.7061e-01,  1.2013e-01, -3.7639e-01,\n",
      "         -5.0912e-01, -2.3185e-01, -3.8602e-01, -2.6657e-01,  1.9119e-01],\n",
      "        [ 9.0739e-02,  4.4454e-02,  1.1434e-02,  6.5383e-02, -8.3216e-02,\n",
      "          2.8137e-01, -4.9407e-02, -1.8902e-01, -2.1300e-01, -9.5597e-02],\n",
      "        [-1.5537e-01,  1.3582e-01,  1.8032e-01,  2.6816e-01,  1.8783e-01,\n",
      "          1.6728e-02,  3.1345e-01,  7.9779e-02, -1.4588e-01, -1.8146e-01],\n",
      "        [-1.4626e-01, -7.8121e-02,  2.2116e-01,  4.5764e-01, -9.8125e-03,\n",
      "          4.0338e-01, -1.8532e-02,  1.6941e-01, -1.9453e-01,  1.0676e-01],\n",
      "        [-1.1901e-01,  2.3479e-01,  4.7261e-02,  2.6470e-01,  2.2667e-01,\n",
      "          4.0047e-01,  1.9528e-01, -8.6303e-02, -1.0658e-01,  1.7714e-01],\n",
      "        [-4.5435e-02,  1.6774e-01,  4.1748e-02,  1.4279e-01,  5.2135e-02,\n",
      "          8.7666e-02, -3.0480e-02,  2.1789e-01,  8.0341e-02, -2.1126e-01],\n",
      "        [-1.3861e-01,  2.5928e-01,  3.7972e-01,  3.5897e-01, -2.4121e-01,\n",
      "          5.0213e-01,  1.0050e-01, -1.4787e-01, -7.3280e-04,  2.5222e-01],\n",
      "        [-1.7177e-01,  1.9024e-01,  3.7137e-02,  4.7490e-01, -3.8340e-02,\n",
      "          1.9346e-01, -1.4752e-01, -1.1700e-01, -7.0695e-03, -1.5444e-01],\n",
      "        [-1.6612e-01,  2.1030e-01,  3.1733e-01,  3.3624e-01, -2.9663e-01,\n",
      "          2.5949e-01,  4.2103e-01, -3.3829e-01, -4.2311e-01, -1.8937e-01],\n",
      "        [-7.7754e-02, -2.2211e-01,  5.8231e-02,  3.4991e-01,  1.4774e-01,\n",
      "          3.0349e-01,  7.9672e-04, -2.0626e-01,  1.9469e-01, -2.2910e-01],\n",
      "        [-3.4911e-01, -7.5457e-03,  2.9373e-01, -5.0491e-02, -7.6359e-02,\n",
      "          2.3029e-01,  4.8047e-02, -1.0024e-01,  5.1614e-02, -2.6808e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0315, -0.4098,  0.0849,  0.0793,  0.1804,  0.0540,  0.1780, -0.0668,\n",
      "         0.2424, -0.3245, -0.4848, -0.0374, -1.0130, -0.7376, -0.5008, -0.3390,\n",
      "        -0.4488, -0.8759, -0.2251, -0.5137], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1635, -0.2066, -0.1414, -0.1928, -0.0516,  0.0167, -0.1328,  0.2408,\n",
      "         -0.0597, -0.2241],\n",
      "        [ 0.0572,  0.1082, -0.2471,  0.0931,  0.1064, -0.0818,  0.2701, -0.4324,\n",
      "          0.1088, -0.2528],\n",
      "        [-0.0894,  0.0230,  0.1576,  0.0079,  0.1468,  0.3798,  0.0915,  0.1063,\n",
      "         -0.1975,  0.0994],\n",
      "        [-0.3271, -0.1173, -0.0345, -0.1401,  0.1053, -0.0268,  0.2009,  0.3749,\n",
      "          0.2176,  0.0187],\n",
      "        [-0.2265,  0.2931, -0.3334, -0.4073, -0.0703, -0.1147,  0.1582,  0.2670,\n",
      "         -0.1268, -0.0563],\n",
      "        [ 0.0409, -0.1636,  0.2900,  0.0758, -0.2136, -0.0109, -0.0910,  0.2341,\n",
      "         -0.0091, -0.0622],\n",
      "        [ 0.0162, -0.0628,  0.3073,  0.2470,  0.0448,  0.2358,  0.0104, -0.0970,\n",
      "          0.2412, -0.0204],\n",
      "        [ 0.1210,  0.0502,  0.2847,  0.0886, -0.0789, -0.1322,  0.1952, -0.2088,\n",
      "          0.1645, -0.2031],\n",
      "        [-0.1802,  0.2445,  0.2059,  0.0376,  0.1064,  0.0571, -0.1957,  0.3596,\n",
      "         -0.0166, -0.1325],\n",
      "        [ 0.1191, -0.1932, -0.0026, -0.1941, -0.0559,  0.2137,  0.0808,  0.3923,\n",
      "         -0.1244,  0.1058]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0845,  0.0853,  0.2002,  0.2436, -0.1642,  0.0828,  0.3466, -0.1122,\n",
      "        -0.2214, -0.0161], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0412, 1.1153, 0.9761, 1.0035, 0.9569, 0.9681, 0.9760, 0.9685, 0.9268,\n",
      "        0.9490], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0631, -0.0667,  0.0783,  0.0563,  0.1361, -0.0237,  0.0587,  0.0669,\n",
      "        -0.0483, -0.0879], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0796, -0.1254,  0.0531, -0.0590, -0.2809,  0.2350,  0.1760,  0.1021,\n",
      "         -0.1789, -0.2579],\n",
      "        [ 0.0625,  0.2693,  0.2861,  0.2901,  0.3046,  0.0350, -0.2600, -0.1007,\n",
      "         -0.1732,  0.2377],\n",
      "        [-0.1286,  0.3128, -0.1951, -0.3708, -0.2480,  0.2113, -0.1352,  0.0481,\n",
      "         -0.0731, -0.2644],\n",
      "        [-0.2282,  0.3875, -0.0514, -0.0393,  0.2218, -0.0894, -0.0304,  0.0270,\n",
      "         -0.2815, -0.1770],\n",
      "        [-0.0756, -0.1506,  0.0913,  0.0384, -0.3407, -0.1698,  0.2207,  0.2463,\n",
      "         -0.1916, -0.0868],\n",
      "        [ 0.2956,  0.0038, -0.1109,  0.0852,  0.2717,  0.0588,  0.2261, -0.2219,\n",
      "          0.1101,  0.2795],\n",
      "        [-0.2083, -0.1234,  0.0286,  0.2271, -0.0798,  0.0679,  0.2952, -0.0026,\n",
      "         -0.0972, -0.0019],\n",
      "        [ 0.0466, -0.3017,  0.4256, -0.2002,  0.0521,  0.1321,  0.0302,  0.1134,\n",
      "         -0.0089,  0.2822],\n",
      "        [ 0.1427,  0.3987,  0.0564, -0.2313, -0.2223,  0.3080,  0.3162,  0.0643,\n",
      "          0.1178,  0.0340],\n",
      "        [-0.1920, -0.1655,  0.1060, -0.1711,  0.2435,  0.2220, -0.0716, -0.3618,\n",
      "          0.0806, -0.3330],\n",
      "        [-0.2396, -0.0324, -0.2567,  0.1287,  0.1870, -0.3847,  0.0433,  0.2182,\n",
      "         -0.2605, -0.1081],\n",
      "        [-0.0616, -0.1714,  0.0828, -0.3621,  0.2770,  0.0930,  0.1727,  0.1470,\n",
      "          0.0065, -0.0232],\n",
      "        [ 0.1902,  0.0164,  0.0424,  0.2932,  0.1349,  0.0451,  0.1405,  0.2094,\n",
      "          0.2403,  0.1331],\n",
      "        [ 0.0547,  0.1110, -0.0489, -0.1352,  0.3296, -0.1630, -0.3708,  0.0552,\n",
      "         -0.1228,  0.0742],\n",
      "        [ 0.1521, -0.2540,  0.0043,  0.2994, -0.1131,  0.1184, -0.2469,  0.1739,\n",
      "          0.1812,  0.1864],\n",
      "        [-0.1481,  0.4034,  0.1955, -0.1253,  0.0409,  0.0641,  0.0923,  0.0872,\n",
      "         -0.0477, -0.2976],\n",
      "        [-0.2298, -0.1918,  0.0146, -0.0513,  0.1115, -0.2338,  0.2850,  0.3281,\n",
      "          0.1689,  0.0651],\n",
      "        [ 0.2704, -0.2739, -0.2581,  0.2387,  0.3233, -0.0467,  0.1993,  0.0652,\n",
      "          0.0274, -0.1171],\n",
      "        [ 0.0878, -0.0365, -0.1985, -0.3698, -0.0300, -0.0666,  0.1991, -0.1788,\n",
      "         -0.3455,  0.0099],\n",
      "        [ 0.1617, -0.0574,  0.1214,  0.0730,  0.0214, -0.2742, -0.3833, -0.4569,\n",
      "         -0.1675, -0.1979]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2324, -0.0278,  0.2198,  0.3340,  0.3165,  0.2706,  0.0992,  0.1350,\n",
      "        -0.1191,  0.1874,  0.0629, -0.2358, -0.3851,  0.0700, -0.2209,  0.4290,\n",
      "         0.0419, -0.1077,  0.1264,  0.1507], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.1027, 0.8863, 1.0342, 1.0740, 1.1760, 0.9737, 0.8588, 0.9607, 1.0097,\n",
      "        0.9269, 0.9240, 0.9212, 0.9717, 1.0117, 0.9877, 1.0828, 0.8595, 0.9197,\n",
      "        0.8517, 1.0139], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0823, -0.0834, -0.0109, -0.1861, -0.0786,  0.0595,  0.0455, -0.0278,\n",
      "         0.0647,  0.0672, -0.0224,  0.0057,  0.0546,  0.0684,  0.0270,  0.0431,\n",
      "         0.0208,  0.0735, -0.0756, -0.0558], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0654, -0.0665, -0.1183, -0.1683, -0.0760,  0.2439,  0.0018,  0.1308,\n",
      "          0.1513,  0.1185, -0.2397,  0.0159,  0.1872, -0.0955,  0.2012, -0.0090,\n",
      "          0.0564,  0.0519, -0.2102, -0.1963],\n",
      "        [ 0.0548, -0.1275,  0.2339,  0.2175,  0.2215,  0.0391, -0.1606,  0.1065,\n",
      "          0.2308, -0.0973,  0.0526, -0.1053, -0.0917,  0.2258, -0.1949,  0.2053,\n",
      "          0.0889, -0.0611, -0.0876, -0.0645],\n",
      "        [-0.0524, -0.0096,  0.3003,  0.1416,  0.0940,  0.0422, -0.2011, -0.2375,\n",
      "         -0.1081,  0.1555,  0.2209, -0.0854,  0.0609,  0.1765, -0.1497,  0.0211,\n",
      "          0.0674, -0.1786,  0.2274, -0.0487],\n",
      "        [ 0.0576,  0.0541, -0.1737,  0.1227, -0.1207,  0.1740, -0.1521,  0.0640,\n",
      "         -0.2532, -0.0202,  0.0761,  0.0966, -0.0105,  0.2662,  0.0576, -0.2719,\n",
      "          0.1957,  0.2784,  0.1601,  0.1893],\n",
      "        [-0.1423,  0.0990, -0.1507, -0.1184, -0.2756, -0.0376, -0.1845,  0.1796,\n",
      "         -0.2217, -0.0473, -0.0069,  0.1910, -0.1310, -0.0196,  0.1289, -0.1889,\n",
      "         -0.0938, -0.0508, -0.1388,  0.1594],\n",
      "        [ 0.0431,  0.1635,  0.1424,  0.2736, -0.0672, -0.0069, -0.1589, -0.1584,\n",
      "         -0.1124, -0.1831, -0.1460, -0.0020,  0.0258,  0.2727, -0.0610,  0.1273,\n",
      "         -0.0030,  0.0696,  0.0426, -0.1095],\n",
      "        [-0.2444,  0.1616, -0.0670,  0.2227, -0.1683,  0.1132, -0.0568, -0.0337,\n",
      "          0.0111,  0.2132, -0.0476,  0.0818,  0.0269,  0.1075, -0.0100,  0.0964,\n",
      "          0.1677,  0.1599, -0.1134,  0.0468],\n",
      "        [-0.1315, -0.0508,  0.0888,  0.2826, -0.1218, -0.1717,  0.0046, -0.0103,\n",
      "          0.0862, -0.0137,  0.1913, -0.1040, -0.2408,  0.1800,  0.0298,  0.1040,\n",
      "          0.1802, -0.1227, -0.0427,  0.0723],\n",
      "        [ 0.1364, -0.0940, -0.0085, -0.1303,  0.0303,  0.0754, -0.1109, -0.0501,\n",
      "          0.1347, -0.1808,  0.1742,  0.0204,  0.0856, -0.1145, -0.1480, -0.0527,\n",
      "          0.0918,  0.2667, -0.1778, -0.2854],\n",
      "        [-0.0007,  0.0423,  0.0989,  0.0157,  0.2380, -0.1599,  0.0179, -0.1142,\n",
      "          0.1148, -0.1387,  0.1373,  0.1950, -0.1065, -0.0687, -0.1683,  0.1822,\n",
      "          0.2706, -0.0361,  0.0582, -0.0643],\n",
      "        [-0.2406,  0.0022,  0.1557,  0.1033, -0.3632, -0.1352,  0.0963, -0.2602,\n",
      "         -0.0369, -0.0381,  0.1238,  0.1769,  0.0225,  0.1383,  0.0039, -0.0030,\n",
      "         -0.1355, -0.0405,  0.0286,  0.2237],\n",
      "        [-0.0581, -0.0978, -0.0443,  0.0171, -0.1980,  0.1062,  0.1320, -0.2323,\n",
      "         -0.1178,  0.0530,  0.1087, -0.2610, -0.0809,  0.0305, -0.1865, -0.2667,\n",
      "          0.0411,  0.1103, -0.0624,  0.2857],\n",
      "        [-0.1114,  0.0470, -0.1069, -0.0298, -0.0652,  0.1445, -0.1257, -0.2377,\n",
      "          0.1594, -0.0847, -0.1997, -0.1726,  0.2245, -0.0537,  0.0245, -0.0839,\n",
      "         -0.1336, -0.0425,  0.1282,  0.1182],\n",
      "        [ 0.2529, -0.2482, -0.0212, -0.2027,  0.2275, -0.1798,  0.0861, -0.0265,\n",
      "          0.1792, -0.0884,  0.0469,  0.1212,  0.0208, -0.0316,  0.1149,  0.1208,\n",
      "          0.2246,  0.1711, -0.1497, -0.1372],\n",
      "        [ 0.0666,  0.0720,  0.0687, -0.1783, -0.1215,  0.2123, -0.2291, -0.0679,\n",
      "         -0.0290,  0.0130, -0.0048,  0.0231, -0.0087,  0.2099,  0.1784, -0.2872,\n",
      "         -0.1215,  0.0378, -0.0932,  0.1918],\n",
      "        [-0.2902, -0.0710,  0.1757,  0.1684, -0.1603, -0.0457, -0.0660, -0.0573,\n",
      "         -0.1883, -0.0627,  0.1611,  0.1472,  0.0697,  0.2974, -0.0955,  0.2067,\n",
      "          0.0105, -0.0755,  0.0599, -0.0608],\n",
      "        [-0.0897, -0.0325,  0.0042, -0.2208,  0.0413,  0.1405,  0.1661,  0.0075,\n",
      "         -0.2088,  0.0326, -0.1045, -0.1300,  0.1327,  0.0990,  0.1784, -0.2501,\n",
      "         -0.0185,  0.1182,  0.0410,  0.0191],\n",
      "        [ 0.2758,  0.0668,  0.1414, -0.2522,  0.1426,  0.0844,  0.2280, -0.1194,\n",
      "          0.1356,  0.1649, -0.2224,  0.1188, -0.2424,  0.0516, -0.0109, -0.1476,\n",
      "          0.1089,  0.1821, -0.0258, -0.1066],\n",
      "        [-0.2257,  0.0681,  0.1333,  0.0343, -0.1962,  0.1096,  0.1164,  0.1519,\n",
      "          0.1408, -0.1061, -0.0137,  0.2216, -0.0428, -0.1200,  0.0417,  0.0592,\n",
      "         -0.0637, -0.0842, -0.0602, -0.0995],\n",
      "        [-0.1535,  0.1700, -0.2327, -0.0044,  0.1478,  0.1358, -0.0480, -0.0780,\n",
      "         -0.1768,  0.0412,  0.1339,  0.0614,  0.2357,  0.0651,  0.2660, -0.0150,\n",
      "         -0.0661,  0.1714, -0.1507, -0.1295]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1969,  0.2470,  0.1770, -0.0601, -0.1099,  0.0044, -0.1643, -0.0016,\n",
      "        -0.0904,  0.2851,  0.0455,  0.3000,  0.1111, -0.0893,  0.0503,  0.0016,\n",
      "         0.2310,  0.0921,  0.2051,  0.1572], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0705, 1.0157, 0.9061, 1.0291, 0.8748, 0.8890, 0.9780, 0.9190, 0.9350,\n",
      "        1.1032, 0.8413, 0.9927, 0.9878, 1.0241, 1.0749, 0.9105, 1.0585, 1.0239,\n",
      "        0.9600, 1.0857], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0287, -0.1574,  0.1371, -0.1286,  0.1254, -0.0530,  0.0532,  0.0102,\n",
      "        -0.0032, -0.1353, -0.0859, -0.0662, -0.0781, -0.2187,  0.0155, -0.0308,\n",
      "        -0.0131,  0.0690,  0.0822, -0.0199], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.3277e-01,  1.9317e-01, -1.6594e-01,  1.2735e-01, -1.2757e-01,\n",
      "          4.2886e-02, -1.2715e-01,  2.3276e-01,  2.1474e-01,  3.0631e-01,\n",
      "          9.5768e-02, -1.8677e-03,  1.9400e-01,  1.8913e-01, -4.4112e-02,\n",
      "         -1.6343e-02,  1.3307e-02,  9.6446e-02,  2.8280e-01, -6.3147e-03],\n",
      "        [ 3.2677e-01, -1.1513e-01,  1.3870e-02,  1.7685e-01, -1.6189e-01,\n",
      "         -1.0552e-01,  5.1940e-04,  4.0781e-02,  2.8891e-02,  1.1355e-01,\n",
      "         -6.8114e-02,  9.2164e-02, -6.0067e-02,  2.1067e-01, -3.6968e-03,\n",
      "          1.2619e-01, -2.4096e-01,  1.9346e-01,  2.5030e-01,  1.8633e-02],\n",
      "        [ 1.4274e-01,  2.9544e-01,  5.3794e-02, -2.6398e-02,  1.3827e-01,\n",
      "          7.0709e-02,  1.0507e-01,  9.3745e-02, -6.7769e-02,  1.4117e-01,\n",
      "         -2.3481e-01, -3.0218e-01, -1.6487e-01, -6.6732e-02, -4.0549e-02,\n",
      "         -6.3570e-02, -2.0313e-01,  2.3915e-02,  9.9908e-02, -5.7077e-02],\n",
      "        [ 1.8316e-02,  9.7475e-02,  7.5443e-02,  2.0184e-01,  2.6576e-01,\n",
      "          3.0018e-02, -1.8843e-01, -6.0524e-02, -1.0926e-02,  3.4269e-02,\n",
      "         -1.1542e-01,  1.9366e-01,  1.2832e-01, -1.4547e-01,  2.4340e-01,\n",
      "         -2.5318e-01,  9.0521e-02,  1.5428e-01, -1.2989e-01,  1.1800e-01],\n",
      "        [ 4.1369e-02,  8.6196e-02,  1.5752e-01, -9.4169e-02, -8.7175e-02,\n",
      "         -1.8300e-01,  4.4987e-03, -1.4796e-01,  5.1199e-03,  2.4676e-01,\n",
      "         -4.2673e-02, -2.0484e-01, -1.2510e-01,  2.5170e-02, -2.1726e-01,\n",
      "         -4.3647e-02, -2.4389e-01,  1.1227e-01, -1.2222e-01, -2.3157e-01],\n",
      "        [ 1.0435e-01,  2.5772e-02,  2.9669e-02,  1.5720e-01,  8.4153e-04,\n",
      "         -4.3860e-02,  3.0699e-01,  1.1382e-01, -4.0936e-02, -7.5189e-02,\n",
      "          1.9650e-01, -1.0319e-02, -4.4353e-02, -2.0976e-02, -2.9656e-01,\n",
      "          5.2621e-02, -2.0267e-01, -4.1330e-02, -2.4752e-02,  1.8286e-01],\n",
      "        [ 1.1864e-01, -7.7568e-02, -1.4933e-01,  1.0145e-01,  2.1899e-01,\n",
      "         -3.9041e-02,  1.1976e-01, -1.4640e-02, -2.3171e-02, -1.6427e-01,\n",
      "         -1.0479e-02,  9.8690e-02,  1.0995e-01, -4.5108e-04,  1.7564e-01,\n",
      "         -4.1214e-02,  2.0822e-01,  7.7515e-02,  3.0759e-02,  3.3647e-02],\n",
      "        [ 2.7585e-01, -2.1251e-01, -1.9689e-02,  5.3283e-02,  9.3005e-02,\n",
      "         -1.4710e-01,  2.9318e-02,  5.5067e-02,  4.1352e-02, -1.7611e-01,\n",
      "         -8.6779e-02, -7.4041e-02, -2.3738e-01, -2.4832e-02, -2.2358e-01,\n",
      "         -4.8605e-02,  1.1616e-01,  1.6661e-01,  1.9719e-01,  5.3737e-02],\n",
      "        [-1.7522e-01,  9.9407e-02,  9.8282e-02, -1.0388e-01, -4.4148e-02,\n",
      "          3.0791e-01,  1.5560e-01,  1.6972e-01,  1.8437e-01, -6.1834e-02,\n",
      "          3.6082e-02, -6.3368e-02,  6.7509e-02, -4.5455e-02,  5.7951e-04,\n",
      "          2.8520e-01, -3.1673e-01, -1.0890e-01,  3.5664e-03, -1.3431e-01],\n",
      "        [-1.9384e-02, -1.4140e-01, -3.4457e-02,  1.9819e-01, -5.3862e-02,\n",
      "         -1.6778e-01,  1.6559e-01, -1.2417e-01,  1.0837e-01,  3.1310e-04,\n",
      "         -1.5002e-01,  1.2676e-01,  7.5327e-02, -3.5570e-03, -1.5786e-01,\n",
      "         -2.6603e-02,  1.2122e-01, -2.2442e-01,  3.3416e-01,  1.9284e-01],\n",
      "        [-8.0875e-02, -4.5806e-03, -8.2700e-02, -7.6678e-02,  9.5011e-02,\n",
      "         -6.2805e-02, -8.1694e-02, -2.1161e-01, -2.3126e-01, -1.4607e-02,\n",
      "         -1.2744e-01,  1.3377e-02,  1.2689e-01, -1.4900e-01, -5.0783e-02,\n",
      "         -2.8483e-01,  1.0456e-01, -2.6994e-01,  5.6413e-02,  5.3889e-02],\n",
      "        [-1.3043e-02, -1.9594e-01,  2.3508e-02,  1.6998e-01,  7.1206e-02,\n",
      "         -2.6552e-01,  1.7963e-01,  1.0559e-02,  1.2130e-01, -1.1995e-01,\n",
      "          9.1195e-02,  2.4979e-01,  6.5242e-02, -8.7488e-02,  1.2596e-01,\n",
      "          1.7039e-01,  5.1459e-02, -1.6389e-02, -1.0746e-01,  9.4436e-02],\n",
      "        [ 2.4241e-01, -1.0526e-01,  6.4473e-02,  4.3542e-03,  5.3496e-02,\n",
      "         -1.1977e-02, -6.4738e-02, -1.7879e-01, -3.2837e-02, -2.5169e-01,\n",
      "         -3.0641e-02, -5.6460e-02, -2.6405e-02, -2.6490e-01,  1.7872e-01,\n",
      "          2.5836e-02,  6.4253e-02, -1.0130e-01,  1.9581e-02,  2.5177e-01],\n",
      "        [ 1.5255e-01, -2.0514e-01, -1.2716e-01,  3.3190e-01,  1.6103e-01,\n",
      "          2.9306e-01,  1.8746e-01, -1.3743e-01,  2.7995e-03,  1.1223e-01,\n",
      "         -1.8253e-01,  1.4980e-01,  2.1810e-01,  1.9546e-01,  7.8478e-02,\n",
      "          9.7258e-03,  1.4616e-01, -4.9163e-02,  1.0875e-01, -5.8196e-04],\n",
      "        [-2.0548e-01,  1.3695e-01,  2.8172e-01, -1.6320e-01, -6.7859e-02,\n",
      "          7.3277e-02, -1.7414e-01,  1.5620e-01, -1.9608e-01,  4.1707e-02,\n",
      "          2.6154e-02, -3.7782e-03, -1.3441e-01, -1.5427e-01, -4.2178e-02,\n",
      "          1.5037e-01, -2.2877e-02, -3.7209e-02,  1.2360e-01,  1.5469e-01],\n",
      "        [ 2.2629e-02, -1.3185e-01,  6.5093e-02,  4.0394e-01, -1.9529e-01,\n",
      "          1.2042e-02,  1.8137e-01,  2.5999e-02, -2.8162e-01,  1.2702e-01,\n",
      "          3.2075e-02,  1.8567e-01, -6.2551e-02,  2.2377e-02, -1.4041e-01,\n",
      "         -9.4531e-02, -1.3277e-01,  5.6926e-02, -1.4696e-01,  2.6302e-01],\n",
      "        [ 2.1425e-01, -4.9692e-02, -2.8654e-01, -3.5813e-01, -6.0556e-03,\n",
      "         -2.0984e-02,  1.2248e-01, -7.6038e-02,  6.3214e-03, -1.9703e-01,\n",
      "          4.5773e-02, -2.2727e-02,  1.4700e-01,  1.0360e-01,  3.0192e-02,\n",
      "         -1.9962e-01, -6.8731e-02,  5.5488e-02,  6.1534e-02,  4.4338e-02],\n",
      "        [-2.1251e-01, -1.4900e-01, -6.5569e-02,  4.6979e-02, -6.1326e-02,\n",
      "          9.0826e-02,  1.8671e-02, -4.6768e-02, -1.1981e-01,  2.8438e-01,\n",
      "         -1.7690e-01,  1.2620e-01, -1.6687e-01,  1.2550e-01, -1.8238e-01,\n",
      "         -5.8222e-02, -1.8241e-01,  2.4088e-01,  1.3667e-02, -2.0766e-01],\n",
      "        [-1.4836e-01, -2.3080e-01,  1.3641e-01, -1.1728e-01,  1.2589e-01,\n",
      "         -1.7716e-02, -2.5231e-02,  1.4030e-01, -2.6920e-01, -3.1335e-01,\n",
      "          5.5784e-02,  7.3579e-02, -9.1735e-02, -1.4001e-01, -6.5779e-02,\n",
      "         -1.2599e-01,  3.0299e-04, -1.7682e-01, -8.4215e-02, -2.7923e-01],\n",
      "        [ 2.0421e-01, -5.2768e-02, -8.9144e-02,  2.2004e-01, -9.5051e-02,\n",
      "         -6.2054e-02, -4.9881e-02,  5.6692e-02, -1.8548e-01, -1.4141e-02,\n",
      "          1.4919e-01, -1.8916e-01, -2.1614e-02,  1.9502e-01,  1.6908e-01,\n",
      "          1.0545e-01,  2.2524e-01, -8.5564e-02, -1.5724e-02,  2.3630e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0531, -0.1696, -0.0473,  0.0863,  0.0361, -0.0582, -0.1713,  0.0827,\n",
      "         0.0658, -0.1878,  0.0569,  0.2081,  0.1972,  0.1962,  0.0228,  0.0676,\n",
      "         0.0662,  0.2134,  0.0360, -0.1001], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0796, 0.8598, 0.7795, 0.9668, 1.0240, 0.9036, 1.0007, 1.0091, 1.1797,\n",
      "        0.9396, 0.8691, 1.0909, 1.0654, 1.0204, 0.9788, 0.8653, 0.9524, 0.9635,\n",
      "        0.8582, 0.8069], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0634,  0.0369,  0.0755,  0.0270, -0.0431,  0.0386, -0.0153, -0.0561,\n",
      "         0.0860,  0.0117,  0.0083,  0.0425,  0.0704, -0.0880,  0.0763, -0.0367,\n",
      "         0.0300,  0.0590, -0.2532,  0.0982], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1867, -0.1152, -0.0101, -0.0066,  0.0860,  0.0155,  0.0446, -0.1348,\n",
      "          0.2775,  0.0326,  0.0330, -0.0267, -0.3091, -0.0893,  0.0362, -0.0532,\n",
      "         -0.0398, -0.0040, -0.1632, -0.0613],\n",
      "        [-0.1135, -0.1902, -0.0877,  0.0420, -0.3240,  0.0654,  0.0299,  0.1899,\n",
      "         -0.1862,  0.1393,  0.2514, -0.0055,  0.1036,  0.0007, -0.1273, -0.2092,\n",
      "          0.1221,  0.0575,  0.0018,  0.1698],\n",
      "        [ 0.1451, -0.0063,  0.2041, -0.0590, -0.2509,  0.0181, -0.0110,  0.0135,\n",
      "         -0.0172,  0.2312, -0.0084,  0.2942,  0.0976,  0.0513,  0.1252,  0.1357,\n",
      "         -0.1246, -0.1470, -0.0031, -0.0965],\n",
      "        [-0.1905, -0.0559,  0.1925,  0.0791, -0.0769, -0.3042,  0.0160, -0.0083,\n",
      "         -0.0623,  0.0409, -0.1174, -0.1112,  0.2633,  0.1005, -0.1525,  0.0704,\n",
      "          0.2228,  0.0161,  0.0023,  0.2631],\n",
      "        [ 0.0234, -0.0483,  0.1543,  0.0706, -0.0629,  0.1269,  0.1555,  0.0495,\n",
      "          0.0182,  0.2667, -0.0774,  0.2360,  0.0783,  0.2748, -0.2521, -0.0355,\n",
      "          0.0876, -0.1125,  0.0439,  0.1551],\n",
      "        [-0.1101, -0.2112,  0.0420,  0.1446, -0.1766, -0.0385,  0.0754, -0.2990,\n",
      "         -0.2957,  0.0514,  0.1802,  0.0536,  0.0159, -0.0792, -0.3116,  0.0850,\n",
      "         -0.1429, -0.1697, -0.1256,  0.0619],\n",
      "        [ 0.3119,  0.0498,  0.2198,  0.2026,  0.2584,  0.0209, -0.1541,  0.0839,\n",
      "         -0.0826, -0.1330, -0.0823,  0.1550,  0.0692,  0.1640,  0.1950,  0.1181,\n",
      "          0.0550,  0.1397,  0.0292,  0.0052],\n",
      "        [ 0.1937, -0.0632,  0.1061, -0.2885, -0.1737,  0.1874, -0.1226,  0.0305,\n",
      "          0.2066,  0.0402, -0.1415, -0.2195, -0.0554,  0.0345,  0.1061,  0.1887,\n",
      "         -0.1119, -0.0327,  0.1159, -0.1371],\n",
      "        [ 0.0225,  0.2673,  0.1019, -0.0417, -0.1435, -0.0970, -0.1538,  0.0722,\n",
      "         -0.1776,  0.0687, -0.1318, -0.1130, -0.0513,  0.0669, -0.3001,  0.1452,\n",
      "          0.0904,  0.2463, -0.0842, -0.0759],\n",
      "        [ 0.2888, -0.0843,  0.0333,  0.3136,  0.0963, -0.1446,  0.2158, -0.0965,\n",
      "         -0.0129, -0.0142, -0.1545, -0.0989,  0.0054,  0.0968, -0.2102,  0.0533,\n",
      "         -0.2379, -0.1085, -0.1640, -0.0218],\n",
      "        [-0.0178, -0.0571,  0.1357, -0.0658, -0.1526,  0.2932,  0.0830, -0.1449,\n",
      "          0.2673, -0.1642, -0.1138,  0.0625, -0.1081, -0.0047,  0.0983,  0.1239,\n",
      "         -0.2339, -0.1898,  0.1453,  0.1582],\n",
      "        [ 0.0920,  0.1753,  0.0341,  0.1818,  0.0969,  0.0209,  0.2003, -0.0403,\n",
      "         -0.0918,  0.1667, -0.0202,  0.3100,  0.2610,  0.1245,  0.0761,  0.2811,\n",
      "          0.2024, -0.2382,  0.0713, -0.0425],\n",
      "        [ 0.2233,  0.0814,  0.1405, -0.1140, -0.1148,  0.0574,  0.0875, -0.2260,\n",
      "          0.1081, -0.1103, -0.0953, -0.1869, -0.2892, -0.1636,  0.1539, -0.1535,\n",
      "         -0.1084,  0.0931, -0.2217,  0.1722],\n",
      "        [ 0.1712, -0.0086,  0.1974, -0.1587, -0.0374,  0.1453, -0.1248, -0.2378,\n",
      "          0.1127, -0.1086,  0.0195, -0.2312,  0.0287, -0.1405,  0.1556, -0.1395,\n",
      "         -0.0685, -0.1736,  0.0210, -0.1212],\n",
      "        [ 0.0491, -0.0654, -0.1516,  0.1125,  0.0077,  0.2103,  0.2037,  0.1097,\n",
      "         -0.1802,  0.2354,  0.0190, -0.0009,  0.2825, -0.0538, -0.0954,  0.0217,\n",
      "         -0.1499, -0.0825, -0.3073,  0.2323],\n",
      "        [ 0.0563,  0.0833,  0.2141, -0.1047, -0.0109, -0.1334,  0.1471,  0.1787,\n",
      "         -0.2998,  0.0940,  0.0643, -0.2881,  0.0991, -0.2009, -0.1959, -0.0211,\n",
      "          0.0834, -0.1240, -0.0281, -0.0866],\n",
      "        [-0.0756, -0.1248, -0.2103, -0.1259, -0.1649,  0.1217,  0.0521, -0.1782,\n",
      "          0.0674, -0.0665,  0.0147,  0.2687, -0.0190, -0.0920, -0.0254,  0.2344,\n",
      "          0.0900, -0.1019,  0.3054, -0.0102],\n",
      "        [ 0.0980,  0.2895, -0.1067, -0.1918, -0.0078, -0.0790,  0.0775,  0.0310,\n",
      "          0.1346,  0.0669,  0.1419, -0.0351, -0.0045,  0.0877, -0.1381, -0.0559,\n",
      "          0.2644, -0.1700, -0.2303, -0.0523],\n",
      "        [ 0.1481,  0.1381,  0.1232, -0.0834,  0.2226, -0.0328, -0.2872, -0.1580,\n",
      "         -0.0964,  0.0239,  0.1083, -0.2012, -0.0006, -0.1134, -0.0327,  0.0601,\n",
      "         -0.0143,  0.1867,  0.1110, -0.1192],\n",
      "        [ 0.0011,  0.1059,  0.0738, -0.1433,  0.2279, -0.0307, -0.3084, -0.0373,\n",
      "         -0.0521, -0.2114, -0.1991, -0.1962, -0.0603,  0.0009,  0.0859, -0.0780,\n",
      "          0.1371,  0.3565,  0.1040, -0.0287]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1934,  0.0577,  0.2242,  0.2665,  0.0294,  0.0681,  0.1537,  0.0540,\n",
      "         0.1429,  0.1053,  0.0777, -0.0602, -0.0065,  0.0807, -0.0886, -0.0795,\n",
      "         0.2838,  0.1705,  0.3006, -0.0311], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8890, 1.0333, 0.9476, 0.8883, 1.0780, 0.8200, 0.9318, 1.0332, 0.9161,\n",
      "        0.9923, 0.9389, 1.0170, 1.0142, 0.9890, 0.9836, 0.8352, 0.9259, 0.8900,\n",
      "        1.0017, 0.8298], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1682,  0.0242,  0.0074,  0.0393, -0.0341,  0.0455,  0.0891,  0.0775,\n",
      "         0.0228,  0.0822, -0.1541, -0.0615, -0.0074, -0.1201,  0.1733,  0.0055,\n",
      "         0.0575,  0.2571, -0.0244,  0.1995], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0047, -0.2482, -0.0276, -0.1965,  0.1369,  0.0128,  0.0444,  0.2684,\n",
      "         -0.1578, -0.1847,  0.3093,  0.0992, -0.0188, -0.0324, -0.1044,  0.0613,\n",
      "          0.0960,  0.0556, -0.1129, -0.3169],\n",
      "        [ 0.1607, -0.0099,  0.1717,  0.0474, -0.1534, -0.2413,  0.0810,  0.1401,\n",
      "         -0.1395,  0.0513,  0.1633, -0.0770,  0.0812,  0.2394, -0.2593, -0.2162,\n",
      "         -0.0100, -0.0708, -0.0133,  0.0324],\n",
      "        [-0.0586,  0.4062, -0.0741,  0.0822,  0.1816, -0.1485, -0.1258,  0.0224,\n",
      "         -0.1124, -0.0094, -0.1878, -0.0297, -0.1773, -0.1701,  0.1013,  0.1333,\n",
      "         -0.0481,  0.1847, -0.1249,  0.1130],\n",
      "        [ 0.2123,  0.0581,  0.3242,  0.1876,  0.3557,  0.0019,  0.1496, -0.0148,\n",
      "          0.1037, -0.0126, -0.0125,  0.1611,  0.0535,  0.0481,  0.2722,  0.1457,\n",
      "          0.0444, -0.1744,  0.2367, -0.1085],\n",
      "        [-0.0961,  0.2918,  0.0235,  0.0088, -0.0937,  0.2744, -0.0755,  0.0151,\n",
      "          0.1052,  0.0937, -0.1344,  0.2000, -0.0853,  0.0419,  0.2977, -0.0219,\n",
      "          0.0832,  0.0321, -0.2384, -0.0752],\n",
      "        [-0.1289,  0.1608, -0.1071,  0.1601,  0.1007,  0.1819, -0.1159, -0.1958,\n",
      "         -0.0079, -0.0713, -0.2508, -0.0829, -0.3007, -0.0147,  0.2029, -0.0099,\n",
      "          0.0681,  0.1463, -0.0989, -0.0912],\n",
      "        [-0.1118,  0.1613,  0.0054, -0.1271,  0.3428,  0.0408,  0.2781,  0.0091,\n",
      "         -0.0527,  0.0159,  0.1122,  0.2800, -0.1848,  0.0684,  0.0214,  0.0900,\n",
      "          0.0139,  0.1236,  0.1392, -0.1104],\n",
      "        [ 0.0395, -0.0891,  0.0384,  0.0279,  0.1617,  0.2020,  0.3098,  0.0797,\n",
      "          0.1210,  0.1146,  0.1979, -0.0127, -0.0093,  0.2335,  0.1770, -0.0960,\n",
      "         -0.2543, -0.0586,  0.1833,  0.0334],\n",
      "        [-0.0761, -0.1838,  0.2489,  0.0975,  0.2279,  0.2551, -0.0762, -0.0540,\n",
      "          0.0874,  0.0941,  0.0438, -0.0455, -0.2257, -0.0447,  0.1007, -0.1914,\n",
      "          0.1489, -0.0667, -0.1598,  0.0805],\n",
      "        [ 0.0656,  0.0649,  0.2086,  0.0443,  0.1156, -0.1909,  0.0599,  0.1289,\n",
      "          0.0492, -0.1696, -0.0393,  0.1120,  0.1633,  0.0599,  0.0675,  0.0917,\n",
      "         -0.2395,  0.1583, -0.1935, -0.0721],\n",
      "        [-0.1274, -0.0635,  0.1126, -0.2423, -0.1170, -0.0278, -0.1828,  0.0883,\n",
      "         -0.0830, -0.2703,  0.0884, -0.0468, -0.0875,  0.0914, -0.0251,  0.0210,\n",
      "          0.1903, -0.0675, -0.0744,  0.0605],\n",
      "        [-0.2251,  0.1267,  0.0608, -0.1161,  0.2903, -0.1357,  0.1084, -0.1733,\n",
      "         -0.2030,  0.2631,  0.0493,  0.1186, -0.0358, -0.1892,  0.1767, -0.1219,\n",
      "         -0.1128, -0.0746, -0.1333, -0.1725],\n",
      "        [ 0.1156,  0.0235,  0.1129,  0.0011,  0.2479, -0.0941, -0.1130, -0.0187,\n",
      "          0.1603,  0.0313,  0.1133,  0.1256,  0.2269,  0.2117, -0.0632, -0.1144,\n",
      "         -0.0381, -0.0968, -0.1578, -0.0977],\n",
      "        [ 0.1554, -0.0598, -0.0336,  0.2053,  0.0085, -0.1192,  0.1388, -0.2754,\n",
      "          0.2030,  0.1431,  0.0718, -0.1173, -0.0745, -0.2053,  0.0564,  0.2052,\n",
      "         -0.2680,  0.0044, -0.1702,  0.1249],\n",
      "        [-0.3535, -0.0069,  0.1141, -0.0499, -0.1069, -0.1247,  0.1742, -0.0963,\n",
      "          0.1286, -0.1398, -0.0005,  0.1955, -0.0285, -0.1639, -0.0028,  0.2163,\n",
      "         -0.0166,  0.1778, -0.0206, -0.0591],\n",
      "        [ 0.0592, -0.1228,  0.0860,  0.1559,  0.1488,  0.1825,  0.0931, -0.0560,\n",
      "         -0.0911,  0.1247, -0.0494, -0.1104, -0.0912, -0.1688,  0.1145, -0.2485,\n",
      "          0.0258,  0.2073, -0.1860, -0.1585],\n",
      "        [ 0.0450, -0.0681, -0.0144, -0.1996, -0.3124, -0.0717,  0.1919, -0.0302,\n",
      "         -0.0124,  0.0406, -0.0913, -0.2267,  0.0682,  0.1191, -0.2511,  0.0285,\n",
      "         -0.1505,  0.1524,  0.1745,  0.1555],\n",
      "        [-0.1809, -0.0984,  0.1959, -0.1267, -0.0184,  0.1509,  0.1193, -0.1753,\n",
      "          0.0655, -0.0612, -0.1040,  0.1765, -0.1968, -0.2262,  0.0055, -0.1195,\n",
      "          0.2005, -0.0372,  0.2095,  0.1574],\n",
      "        [ 0.1714, -0.0543, -0.1322, -0.0123, -0.0796,  0.0734,  0.0909,  0.2358,\n",
      "         -0.0998,  0.3108, -0.0943, -0.2157,  0.2908, -0.0070, -0.1166, -0.1182,\n",
      "         -0.1431, -0.1167,  0.1961, -0.0320],\n",
      "        [-0.1548, -0.1305, -0.1616, -0.0825, -0.2457, -0.2110,  0.0749,  0.1384,\n",
      "          0.1681, -0.0038, -0.1935, -0.1252,  0.0464, -0.1039,  0.0546,  0.1455,\n",
      "         -0.0359,  0.2686,  0.1823,  0.0582]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1221,  0.1237,  0.1853, -0.0534,  0.2301,  0.2443,  0.0875,  0.0868,\n",
      "         0.1056,  0.0854,  0.5108,  0.0109, -0.0322,  0.0591,  0.1918,  0.0982,\n",
      "         0.5662,  0.2459, -0.0106,  0.2227], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9680, 1.0349, 1.0826, 0.8969, 1.1416, 0.9988, 0.8274, 0.9520, 0.9741,\n",
      "        0.9856, 0.9116, 0.9465, 0.9742, 0.9021, 0.8809, 1.0238, 1.1160, 0.8888,\n",
      "        0.8969, 0.9353], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1621,  0.0822, -0.0812, -0.1598,  0.0190, -0.0328,  0.1310,  0.0173,\n",
      "         0.0207, -0.0681, -0.0756, -0.1053, -0.0119, -0.0048,  0.1172, -0.0096,\n",
      "        -0.0101,  0.0337, -0.1112,  0.0244], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 2.0136e-02,  2.4822e-01, -1.1195e-01,  1.0212e-01, -7.4306e-02,\n",
      "         -6.7405e-02,  5.5422e-02, -5.5123e-02, -3.4945e-01, -5.4920e-02,\n",
      "          1.0813e-01,  9.4507e-02,  2.0608e-01, -1.2773e-01, -4.4885e-02,\n",
      "         -1.0062e-01,  2.4555e-01, -1.4413e-01,  1.7079e-01,  1.4895e-01],\n",
      "        [ 1.6721e-01, -2.4303e-02, -7.6853e-02,  2.2723e-03, -1.5213e-01,\n",
      "         -5.1449e-02,  1.8445e-01, -7.9235e-03,  1.0683e-01, -3.3791e-03,\n",
      "          1.6697e-01,  1.8884e-01,  1.8041e-01, -2.0798e-01,  1.4875e-01,\n",
      "          5.5621e-02, -2.1431e-01,  1.4639e-01,  2.2265e-02, -3.6670e-01],\n",
      "        [-1.5819e-01, -1.2444e-01,  2.3752e-01, -1.5669e-01,  1.4019e-01,\n",
      "          1.9205e-01, -4.3322e-02, -1.6982e-01,  1.0038e-01,  2.3527e-01,\n",
      "         -8.1641e-02, -1.2484e-01,  5.3647e-02,  6.8728e-03,  2.3454e-01,\n",
      "          1.8807e-02, -2.2831e-01, -1.5923e-01, -7.3451e-02,  1.1252e-01],\n",
      "        [-3.7711e-03,  1.7904e-01, -3.1616e-02,  2.3740e-01,  6.6330e-02,\n",
      "          1.3762e-01,  2.8989e-01, -2.1349e-02,  1.7551e-01,  2.6718e-01,\n",
      "         -1.9372e-01,  1.9791e-01, -1.4541e-01, -7.5399e-02,  1.3504e-01,\n",
      "          7.0689e-02, -1.7710e-01,  4.9714e-02,  6.5659e-02, -9.5196e-02],\n",
      "        [ 1.1071e-01,  9.2062e-02, -2.4569e-01,  2.9510e-01,  2.1457e-01,\n",
      "         -2.2428e-01,  1.1378e-01,  1.2620e-01,  5.0558e-02, -4.3808e-02,\n",
      "         -4.8692e-02, -1.1680e-01, -2.5670e-01,  8.1455e-02,  6.6593e-02,\n",
      "          2.2496e-01,  1.0414e-01,  2.5134e-01, -7.7382e-02, -9.7155e-02],\n",
      "        [-1.4351e-01,  1.8988e-01, -7.9564e-02, -1.9554e-02, -1.9161e-01,\n",
      "         -2.0327e-01, -1.0047e-01,  1.1320e-01, -1.2801e-01, -4.4511e-02,\n",
      "          5.0843e-02, -1.7523e-02,  6.1504e-02,  5.7087e-02, -1.5193e-01,\n",
      "         -8.9194e-02,  2.4230e-01,  1.7483e-01,  1.7133e-01,  2.9568e-01],\n",
      "        [ 2.3086e-01,  2.9574e-01, -1.3894e-01, -1.9782e-01, -3.8770e-02,\n",
      "         -3.3427e-01, -9.7133e-02, -5.0740e-02, -2.2729e-01, -1.2164e-01,\n",
      "          2.9575e-02, -2.7947e-01,  8.9885e-02, -5.9071e-02, -3.8480e-03,\n",
      "          1.0058e-02, -1.4489e-01,  7.8682e-04, -1.8078e-01, -5.3050e-02],\n",
      "        [-5.5052e-02,  5.2458e-03, -1.7439e-01, -1.3935e-01, -1.8676e-01,\n",
      "         -1.2740e-01, -2.5072e-02,  2.3499e-02, -1.0710e-01, -1.4573e-01,\n",
      "         -2.6004e-01, -6.2782e-02, -1.2070e-01,  7.9882e-02, -1.0769e-01,\n",
      "         -7.8988e-02,  1.4344e-01,  1.4318e-01,  1.6680e-01,  2.0746e-01],\n",
      "        [-2.1497e-01, -2.2103e-01, -1.7781e-02,  7.9279e-02,  1.2542e-01,\n",
      "          1.4887e-01,  3.2964e-02,  1.8216e-01,  7.6241e-02, -1.4166e-01,\n",
      "         -1.4917e-01,  1.2926e-01,  9.7015e-02,  2.4682e-01,  2.5270e-01,\n",
      "          2.7000e-01, -1.7787e-01,  2.6330e-02,  1.4206e-01, -1.4587e-02],\n",
      "        [ 1.3367e-01,  3.8620e-02,  1.8946e-01,  7.3725e-02,  2.1161e-01,\n",
      "         -2.7461e-02,  3.5938e-02, -4.9005e-02,  1.1638e-01,  2.1315e-01,\n",
      "         -1.9957e-02,  2.3200e-01, -1.2937e-01,  9.3779e-02, -1.6216e-01,\n",
      "          2.6927e-01, -2.9607e-01,  1.2271e-01, -5.2722e-04, -1.1709e-01],\n",
      "        [ 2.1291e-01,  1.3371e-01, -2.7091e-01,  4.2800e-02, -2.2481e-01,\n",
      "         -7.2091e-02,  3.7288e-02,  1.2043e-01, -3.9056e-02,  5.6425e-02,\n",
      "          6.4178e-02, -1.8008e-01, -7.0527e-02, -6.4464e-02, -1.7262e-02,\n",
      "         -8.0045e-02,  1.4072e-01, -2.7870e-01,  1.3419e-01, -1.2511e-01],\n",
      "        [-1.0201e-01, -2.4464e-01, -1.5050e-01,  1.1691e-01, -1.1088e-01,\n",
      "         -2.4984e-01,  8.5264e-02, -8.6231e-02, -1.7705e-01, -1.3760e-01,\n",
      "         -9.4680e-02, -6.7223e-02, -1.8245e-01,  6.4679e-02,  2.1153e-01,\n",
      "         -1.9419e-01,  2.5817e-01,  1.4870e-01, -1.7183e-01,  3.1236e-01],\n",
      "        [ 2.7351e-01,  8.9407e-02, -2.0210e-01, -1.3728e-01, -8.0309e-02,\n",
      "         -1.8588e-04, -4.8220e-02, -4.9002e-02, -1.0363e-01, -1.3359e-01,\n",
      "          1.5841e-01, -2.3062e-01, -1.2265e-01, -1.5884e-01, -6.5483e-02,\n",
      "          4.3324e-02, -1.1809e-01,  6.8266e-02, -2.4976e-01,  5.0757e-02],\n",
      "        [ 2.3166e-01,  8.1490e-02,  1.5007e-02, -9.0055e-02, -8.6825e-02,\n",
      "         -1.4461e-01, -1.0924e-01,  3.7271e-02, -1.7410e-01,  2.5343e-01,\n",
      "          7.2141e-03, -1.5919e-01,  2.6022e-01, -6.5838e-02, -8.9762e-02,\n",
      "         -2.1244e-01, -2.7189e-02, -1.5027e-01,  5.1467e-02, -1.1328e-01],\n",
      "        [ 3.4471e-02, -1.8848e-01, -2.4148e-02, -1.2722e-01, -3.4416e-01,\n",
      "         -1.1958e-01,  1.1220e-01, -1.6095e-01, -5.8636e-02,  2.2762e-01,\n",
      "         -1.0965e-01, -1.0716e-01, -8.0930e-02,  3.0792e-01,  2.3106e-01,\n",
      "          3.9462e-02, -1.0657e-02, -1.5325e-01, -1.0289e-01,  2.5039e-01],\n",
      "        [-5.5342e-02,  5.0433e-02, -2.8996e-01, -1.3038e-01, -1.8793e-01,\n",
      "         -1.9461e-01,  1.5040e-01,  2.4880e-01,  6.1589e-02,  9.5750e-02,\n",
      "         -3.5316e-01, -8.3355e-02, -1.4909e-01, -1.4670e-01, -3.5052e-02,\n",
      "         -1.3758e-01,  2.5761e-01, -1.2610e-01,  1.6098e-01, -1.5589e-02],\n",
      "        [-3.8634e-02,  1.0725e-01,  2.8326e-01, -7.9110e-02,  1.3320e-01,\n",
      "          2.6161e-01,  1.3679e-01, -2.0464e-01,  1.9427e-02,  1.7905e-01,\n",
      "         -1.6956e-02, -1.4015e-01,  1.1198e-01, -1.4017e-01,  2.6786e-02,\n",
      "          2.4000e-01, -1.8953e-01, -4.5439e-02, -1.8190e-01, -2.2993e-01],\n",
      "        [-9.1669e-02, -1.6533e-01, -4.5564e-02, -7.8665e-02,  1.5108e-01,\n",
      "         -7.6566e-02, -7.2695e-02,  3.6786e-03,  1.7030e-01, -2.7853e-01,\n",
      "         -5.4701e-02,  3.0237e-01,  7.9721e-02,  1.6283e-02, -1.9285e-02,\n",
      "          2.2959e-01, -2.3129e-01,  1.4439e-02,  8.6599e-02,  5.8635e-03],\n",
      "        [-1.8389e-01, -1.7561e-01,  1.8092e-01, -9.8558e-02,  2.9130e-01,\n",
      "          5.5981e-02, -4.6035e-02,  9.3299e-02, -2.7677e-01, -1.8613e-02,\n",
      "         -8.9464e-02, -9.5846e-02, -2.6208e-01, -1.3499e-02,  1.7096e-01,\n",
      "         -3.3259e-02, -1.3010e-01, -1.3136e-01, -2.4909e-01,  6.4846e-02],\n",
      "        [ 2.5525e-01, -7.8474e-02, -2.3928e-01, -2.2630e-01,  7.8921e-02,\n",
      "          1.1123e-01,  1.0723e-01, -2.9017e-01,  1.9875e-01, -2.2770e-01,\n",
      "          2.6346e-01, -2.2210e-02, -2.5161e-02, -2.0789e-01, -2.7156e-02,\n",
      "         -1.7657e-01, -2.5237e-03, -3.7143e-02, -6.2102e-02, -4.7267e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0424, -0.0509,  0.2609,  0.0610,  0.2862,  0.2112,  0.1503,  0.0460,\n",
      "        -0.0166,  0.0669,  0.1932, -0.1504,  0.4587,  0.0373,  0.0406,  0.0950,\n",
      "        -0.2078, -0.0599, -0.0037,  0.0969], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0096, 0.9057, 0.9515, 1.0009, 0.8686, 0.9697, 1.0027, 0.9613, 0.8702,\n",
      "        0.8643, 0.9590, 0.9110, 0.9532, 1.0846, 0.9413, 1.1009, 0.9575, 0.9890,\n",
      "        0.8625, 1.0401], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0855, -0.0175,  0.1004,  0.1053, -0.0143, -0.0513, -0.1162,  0.0070,\n",
      "         0.0426, -0.0076,  0.0734,  0.0548, -0.0980, -0.0836,  0.0080,  0.0818,\n",
      "        -0.1087, -0.1130,  0.0838,  0.0219], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2041,  0.0495, -0.1018,  0.3266,  0.0538, -0.2811, -0.3228, -0.0828,\n",
      "          0.0963,  0.2154,  0.1714, -0.0785, -0.1497, -0.1999, -0.0108, -0.2592,\n",
      "         -0.0543, -0.0569,  0.2113, -0.0464],\n",
      "        [ 0.0304, -0.0504,  0.2154, -0.1705, -0.1712, -0.0804,  0.0384,  0.0575,\n",
      "          0.0801,  0.1530, -0.2195, -0.0817, -0.2265,  0.0395, -0.1447, -0.2299,\n",
      "          0.3040, -0.0644, -0.0439, -0.1276],\n",
      "        [ 0.2259,  0.0179, -0.0900, -0.0661, -0.1371,  0.0297,  0.0372, -0.0478,\n",
      "          0.0589, -0.1466, -0.0811, -0.1696,  0.0045,  0.3178, -0.0570,  0.1222,\n",
      "          0.0010,  0.1142, -0.0832,  0.0628],\n",
      "        [ 0.0236,  0.0757, -0.0712, -0.1601,  0.3265,  0.1944,  0.1728,  0.2375,\n",
      "         -0.0227, -0.1256, -0.0374,  0.1044,  0.1331, -0.0452,  0.2489,  0.2039,\n",
      "         -0.0947, -0.0832,  0.1387, -0.2499],\n",
      "        [ 0.0212,  0.0011, -0.2286, -0.0234,  0.2163,  0.1763, -0.1323,  0.2499,\n",
      "         -0.0501,  0.0100,  0.1552,  0.0414,  0.0252, -0.0109,  0.0716,  0.2065,\n",
      "         -0.1176, -0.1895,  0.0950, -0.2206],\n",
      "        [ 0.1553, -0.1605,  0.0523,  0.1272,  0.0782, -0.0507,  0.1196,  0.0231,\n",
      "         -0.0834, -0.2682,  0.3468, -0.0484,  0.0600,  0.2334, -0.0012,  0.0481,\n",
      "         -0.1003, -0.0013, -0.2064, -0.0234],\n",
      "        [ 0.0485, -0.1769,  0.1109, -0.1958, -0.1314, -0.1585, -0.1181,  0.0891,\n",
      "         -0.0156, -0.1969, -0.0358,  0.2744, -0.1481, -0.1046,  0.1623,  0.0275,\n",
      "         -0.1395, -0.3035,  0.1451,  0.0754],\n",
      "        [-0.1397,  0.0176, -0.0435, -0.2124,  0.0463,  0.0474,  0.3969,  0.0613,\n",
      "         -0.1432,  0.0840,  0.2538, -0.1346,  0.2022,  0.0680, -0.0017,  0.0361,\n",
      "         -0.1678, -0.1271, -0.0615,  0.0961],\n",
      "        [ 0.0078,  0.1254, -0.0546, -0.1199, -0.0760,  0.1181, -0.0171,  0.0082,\n",
      "          0.0483,  0.0457,  0.0943, -0.1796, -0.2122,  0.2130, -0.1883,  0.2441,\n",
      "         -0.2427, -0.0450, -0.2085, -0.0809],\n",
      "        [ 0.0988, -0.0011, -0.3308,  0.1531, -0.0631, -0.2194,  0.0292,  0.0765,\n",
      "         -0.3347, -0.1129,  0.0746,  0.1016,  0.0169,  0.0775, -0.1564, -0.0849,\n",
      "         -0.0952, -0.3357, -0.2080,  0.0478],\n",
      "        [ 0.2494,  0.1148, -0.1612,  0.0905, -0.1084,  0.1913, -0.1208, -0.0195,\n",
      "          0.0229, -0.1466,  0.0553, -0.3147, -0.0057,  0.2466,  0.0616, -0.0577,\n",
      "         -0.1852, -0.0660,  0.0568, -0.0384],\n",
      "        [-0.2915,  0.2407,  0.0653, -0.0756,  0.0164, -0.2976, -0.1657, -0.1847,\n",
      "          0.0964,  0.1108, -0.1648, -0.1972, -0.0251, -0.2795, -0.0876, -0.2796,\n",
      "         -0.0034, -0.0076,  0.1018,  0.1687],\n",
      "        [ 0.1680,  0.0238,  0.1327,  0.1634, -0.1174, -0.0219, -0.1991, -0.2851,\n",
      "          0.0221,  0.2307, -0.0224, -0.1035,  0.1455, -0.0749,  0.1639, -0.0298,\n",
      "          0.2177, -0.0728,  0.1024,  0.0218],\n",
      "        [ 0.3176, -0.2745, -0.0072,  0.1140, -0.1182,  0.1967,  0.0208,  0.0603,\n",
      "         -0.1545, -0.0459,  0.0518,  0.0452, -0.0020,  0.2636, -0.0726,  0.2137,\n",
      "         -0.1497, -0.1507, -0.1850, -0.2134],\n",
      "        [ 0.0433, -0.1753,  0.0950,  0.2745, -0.0878,  0.1307, -0.0202,  0.1678,\n",
      "         -0.0352, -0.1247,  0.0392, -0.0324, -0.2794, -0.1234,  0.1431,  0.2110,\n",
      "          0.2001, -0.2280, -0.0210, -0.1944],\n",
      "        [ 0.0573,  0.0990, -0.1333, -0.1692, -0.0370,  0.0733,  0.2152, -0.1429,\n",
      "         -0.0329,  0.0299,  0.1738, -0.1492,  0.1540,  0.2792, -0.1170,  0.0410,\n",
      "         -0.1884, -0.1797, -0.2844,  0.0834],\n",
      "        [-0.1009,  0.1481,  0.1680, -0.2118, -0.0081, -0.1814,  0.2243, -0.3364,\n",
      "         -0.0347, -0.0630,  0.0724, -0.1403,  0.2678, -0.0264, -0.1982, -0.3262,\n",
      "         -0.1232,  0.0919,  0.0202,  0.2110],\n",
      "        [-0.0785, -0.0447,  0.2353,  0.0306, -0.0877,  0.0123, -0.2301,  0.0199,\n",
      "          0.0078,  0.1216, -0.1353,  0.1976, -0.3827, -0.1542,  0.2708,  0.0439,\n",
      "         -0.0085,  0.0921,  0.1556, -0.3297],\n",
      "        [-0.1238, -0.1406,  0.0743,  0.3401,  0.1494, -0.1515, -0.2974, -0.1848,\n",
      "          0.1127, -0.0159, -0.0492, -0.0731, -0.1603, -0.2261, -0.2480,  0.1724,\n",
      "          0.1750,  0.1530,  0.1120,  0.0515],\n",
      "        [-0.1739,  0.2093,  0.0937,  0.1131,  0.1487, -0.1956,  0.0854, -0.1347,\n",
      "          0.2708,  0.1696,  0.0923,  0.0477, -0.0518, -0.0568, -0.1302, -0.0012,\n",
      "         -0.1397,  0.2294, -0.2252,  0.1393]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1565,  0.1118, -0.1404, -0.1557,  0.1873,  0.0309,  0.3380,  0.1996,\n",
      "         0.0787,  0.2662,  0.0332,  0.3877,  0.1096,  0.0063,  0.2470,  0.0916,\n",
      "        -0.0505,  0.0746, -0.0666,  0.0007], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8296, 0.9164, 0.9807, 0.8008, 1.0911, 0.8457, 1.1047, 0.8807, 1.0527,\n",
      "        0.9753, 0.8838, 1.0096, 0.8365, 0.9410, 1.0033, 0.9823, 0.9071, 1.1255,\n",
      "        0.8703, 1.1882], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0161, -0.2240, -0.1321,  0.0922,  0.1502, -0.0734, -0.2406, -0.0290,\n",
      "        -0.1408, -0.1340,  0.0546, -0.1453,  0.0814, -0.0600, -0.0271, -0.0365,\n",
      "         0.1021, -0.0682, -0.2181, -0.1294], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 4.9528e-02, -2.1607e-01, -2.3236e-01,  1.2857e-01,  8.5621e-02,\n",
      "         -2.3931e-01,  1.7532e-01, -1.6168e-02, -2.7014e-01, -3.4164e-02,\n",
      "         -3.0882e-02,  3.7979e-02, -1.5127e-02, -3.9759e-02, -8.0086e-02,\n",
      "         -2.7878e-01,  5.1603e-02,  7.3681e-03, -2.4632e-01, -1.9159e-01],\n",
      "        [-2.6511e-02,  1.3487e-01, -5.5876e-02, -2.7731e-01, -1.8163e-01,\n",
      "         -2.6746e-01,  1.2896e-01, -4.7933e-02, -2.1954e-01,  2.6128e-02,\n",
      "          7.6292e-03,  1.5635e-01,  5.7017e-03, -2.5462e-01,  2.3670e-03,\n",
      "         -2.2742e-01,  1.7427e-01,  3.7561e-02,  6.4122e-02, -3.1920e-01],\n",
      "        [-1.8156e-03, -4.3618e-02,  1.9013e-01, -1.5373e-02, -2.2658e-01,\n",
      "          8.4296e-03, -1.4312e-01,  7.1502e-02,  1.1979e-01, -3.1709e-01,\n",
      "         -2.3329e-01,  7.7220e-02, -8.7147e-02, -2.5683e-01,  5.8873e-03,\n",
      "         -1.5024e-01, -1.7261e-01,  2.1509e-01,  4.3752e-02,  2.8842e-01],\n",
      "        [-1.2801e-01,  1.2236e-01,  7.3352e-02,  1.6154e-02, -7.6888e-02,\n",
      "          8.8523e-02, -1.8837e-01,  3.1981e-01, -1.0937e-02,  1.1320e-01,\n",
      "          1.3361e-01,  3.2794e-03,  1.5545e-01, -1.4698e-02, -1.5240e-01,\n",
      "          3.3878e-01,  3.6009e-01, -1.0067e-02, -1.1134e-01,  1.6729e-01],\n",
      "        [ 9.0734e-03, -4.1732e-02,  1.9079e-01,  8.1191e-02, -5.4548e-02,\n",
      "         -1.0705e-02, -2.6002e-01,  1.9696e-02,  1.9739e-01, -8.3851e-04,\n",
      "          6.7262e-02, -3.2168e-01,  3.6591e-02,  2.4915e-01, -7.6633e-02,\n",
      "         -5.2442e-02,  2.0736e-02, -4.4509e-02,  4.4638e-02, -1.6995e-01],\n",
      "        [-1.8218e-01, -3.5523e-01, -9.0290e-02, -1.2212e-02, -1.0454e-01,\n",
      "          3.4947e-03, -3.3117e-02,  8.8890e-02, -2.0172e-01,  7.4485e-02,\n",
      "          1.2430e-01, -1.2994e-02,  3.4018e-02, -1.4981e-01, -2.6155e-01,\n",
      "          1.9855e-03,  2.2099e-01, -2.9545e-01, -1.3412e-01,  1.9339e-01],\n",
      "        [ 1.5340e-01,  8.5980e-02, -1.7298e-01, -1.2622e-01, -4.9125e-02,\n",
      "         -2.7513e-01, -3.6584e-01, -2.5716e-01, -1.1431e-01, -2.2621e-01,\n",
      "         -1.6923e-01,  1.9622e-01,  1.9048e-02,  7.8401e-02,  1.4329e-01,\n",
      "         -8.2481e-02,  1.3895e-01, -1.0124e-01,  1.7452e-01, -3.3852e-02],\n",
      "        [ 4.4736e-03, -1.0093e-02, -1.2476e-01,  2.9510e-02, -3.1260e-01,\n",
      "         -1.6588e-01, -3.5687e-01,  4.4157e-02, -3.7483e-02, -7.1206e-03,\n",
      "         -2.2760e-01,  2.9906e-01, -6.5802e-02, -3.4087e-01, -6.5720e-02,\n",
      "          7.4978e-02,  1.9411e-01, -1.3120e-03, -1.0406e-01,  2.9069e-01],\n",
      "        [-3.2056e-02, -3.6584e-01, -8.5182e-02, -1.4909e-01,  3.4240e-01,\n",
      "          1.6768e-01,  1.8867e-02,  1.2350e-01,  1.1737e-01,  1.4439e-01,\n",
      "         -1.3026e-01, -2.3160e-01,  6.6431e-02, -2.6091e-02,  1.8838e-01,\n",
      "          8.4065e-02, -3.8720e-03,  1.3850e-01,  1.4364e-02,  7.8190e-02],\n",
      "        [ 1.3725e-01,  1.6012e-01, -2.7942e-01, -2.4057e-01, -3.7169e-02,\n",
      "          1.4565e-02,  9.4352e-03,  5.9935e-02, -1.0041e-02, -2.9224e-01,\n",
      "         -1.8867e-01,  9.6489e-02,  2.0140e-01, -2.4993e-01,  2.2591e-02,\n",
      "         -9.4330e-02, -2.0086e-01, -9.8800e-02, -1.1103e-02, -1.2911e-01],\n",
      "        [-1.2028e-01,  3.5747e-02,  3.7553e-02,  1.3035e-01,  2.6291e-01,\n",
      "         -5.7747e-02, -1.0358e-02,  4.3110e-03,  2.1319e-01,  5.8528e-03,\n",
      "          1.5678e-01, -2.0820e-01, -1.0799e-01, -1.8899e-02, -2.9159e-03,\n",
      "          1.5768e-01, -2.8216e-01, -2.2083e-01, -1.3616e-01, -2.8012e-01],\n",
      "        [-7.3005e-03, -7.0471e-02, -1.5189e-02, -3.7265e-02,  1.6907e-01,\n",
      "         -1.8448e-01,  9.7639e-02, -2.5061e-02, -3.0755e-01, -1.0696e-01,\n",
      "          9.7004e-02,  8.8990e-03,  1.4898e-01, -1.5542e-01,  8.8594e-02,\n",
      "         -1.8149e-01, -1.6560e-01,  4.3198e-01,  4.1515e-02,  2.1207e-02],\n",
      "        [-3.1502e-01, -1.1836e-01, -7.8601e-02, -2.4651e-02,  1.9954e-01,\n",
      "          6.1651e-02, -1.0432e-01, -3.6693e-02,  1.6029e-02,  1.3836e-02,\n",
      "          8.2749e-02, -2.1922e-01, -1.6836e-01,  1.8155e-01,  2.3524e-01,\n",
      "          5.1654e-02, -1.6835e-02, -6.5158e-02, -7.3616e-02, -1.3580e-01],\n",
      "        [-4.4116e-02, -3.0070e-02,  4.5686e-02,  2.7784e-01,  5.0120e-02,\n",
      "          1.3430e-01, -4.1936e-02, -8.2075e-02,  1.1931e-01,  6.9971e-02,\n",
      "          9.6414e-02, -8.9630e-03,  1.7381e-01,  2.5472e-01,  3.8357e-01,\n",
      "         -1.8692e-01, -1.2319e-01,  1.5801e-01,  7.8062e-02,  1.1051e-01],\n",
      "        [-1.5613e-01,  1.2275e-01, -6.0861e-02,  7.0283e-02, -7.0552e-02,\n",
      "         -6.8884e-02,  1.1071e-01, -2.2072e-01, -1.5426e-01, -3.3737e-01,\n",
      "          6.3744e-02, -1.1524e-01, -2.0980e-01, -1.5021e-01,  5.5468e-02,\n",
      "         -5.5105e-02, -1.8691e-01,  4.2158e-02, -3.1852e-01, -3.2898e-01],\n",
      "        [ 2.0598e-01,  8.1482e-02, -1.0182e-01,  4.7889e-02, -2.3732e-01,\n",
      "         -1.4588e-01, -7.5836e-02, -1.7613e-01, -2.4490e-01,  2.2944e-02,\n",
      "          1.7205e-01,  2.0754e-01,  1.9549e-01, -7.8991e-02,  9.7280e-02,\n",
      "         -1.2512e-01,  2.9358e-04,  2.7728e-01,  1.3406e-01,  6.4532e-02],\n",
      "        [-2.1460e-01, -6.0700e-02,  1.0978e-01, -8.2788e-02, -2.8411e-01,\n",
      "         -9.9285e-03, -1.7178e-01,  1.4524e-01,  1.5370e-01,  1.3587e-01,\n",
      "          1.2260e-01, -3.6669e-03, -2.1764e-02, -1.7420e-01, -1.3250e-01,\n",
      "          2.5147e-01, -2.4029e-02,  5.5144e-02, -1.1430e-01,  7.3165e-02],\n",
      "        [ 2.3998e-01, -7.4550e-02, -2.9971e-01,  4.5101e-02,  1.9884e-01,\n",
      "         -1.6656e-01,  7.4736e-02, -1.5830e-01,  2.2382e-02,  7.5420e-02,\n",
      "         -5.9175e-02, -1.3453e-01,  2.9262e-01,  1.1514e-01,  3.2333e-01,\n",
      "         -2.5067e-01,  6.7101e-02,  1.1366e-01,  4.6776e-02, -3.3781e-02],\n",
      "        [-8.6783e-03, -1.3963e-01,  1.9822e-02, -2.7912e-01, -2.0867e-02,\n",
      "          6.4677e-02, -3.2994e-01, -2.0974e-01, -2.4248e-01,  7.2003e-02,\n",
      "         -1.1936e-01, -2.5473e-01, -8.0765e-02,  4.0560e-02, -2.2462e-01,\n",
      "         -2.4548e-02,  7.3771e-02, -2.6062e-01, -1.2071e-01, -1.4036e-01],\n",
      "        [-7.3966e-02, -4.0309e-01,  1.6363e-01,  8.6833e-02, -1.9420e-01,\n",
      "          1.9340e-01, -1.9107e-01,  2.1098e-01,  7.0438e-02,  8.2295e-02,\n",
      "          1.0819e-01, -2.2319e-02,  1.6259e-01, -1.3210e-01, -1.5318e-01,\n",
      "          2.3067e-01,  4.6901e-02, -1.2799e-01, -9.1764e-02, -2.6119e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0742,  0.1147, -0.1209, -0.0787,  0.2573,  0.2847, -0.0040,  0.1609,\n",
      "         0.1309,  0.4142,  0.1551,  0.1636,  0.3267,  0.3576,  0.2921, -0.1802,\n",
      "         0.0692,  0.0730,  0.3678,  0.0713], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8232, 0.8153, 0.7258, 0.7349, 0.7796, 0.8259, 0.7333, 0.7956, 0.6687,\n",
      "        0.7585, 0.7937, 0.7418, 0.8089, 0.6710, 0.8619, 0.7463, 0.8020, 0.7028,\n",
      "        0.8183, 0.7730], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0387,  0.0673, -0.1261, -0.1430, -0.0323, -0.0720, -0.0101,  0.1012,\n",
      "        -0.1340, -0.0484,  0.0757,  0.0744,  0.0927,  0.1502, -0.1035, -0.0508,\n",
      "        -0.1167, -0.1177,  0.0993,  0.0993], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0943, -0.0926,  0.1237,  0.1077,  0.0089,  0.0217,  0.0213,  0.0067,\n",
      "          0.0208,  0.0390,  0.0126,  0.0980,  0.0180, -0.0462, -0.0295,  0.1220,\n",
      "          0.0869,  0.1108, -0.0571,  0.0394],\n",
      "        [-0.0459,  0.0024,  0.0298, -0.0100,  0.0337, -0.0880,  0.0620,  0.0758,\n",
      "          0.0357, -0.0158,  0.0737,  0.0683,  0.0854,  0.1340, -0.0235,  0.0821,\n",
      "         -0.0247,  0.1333, -0.1002,  0.0308],\n",
      "        [-0.1496,  0.0121,  0.0141, -0.0580,  0.0621, -0.1148,  0.0755, -0.0930,\n",
      "         -0.0113,  0.0377,  0.0762,  0.0217,  0.0888, -0.0226, -0.0542,  0.0505,\n",
      "         -0.0366, -0.0362, -0.0927, -0.0321],\n",
      "        [-0.0920, -0.1758,  0.0574,  0.0627,  0.1184,  0.0896, -0.0444,  0.0621,\n",
      "          0.0211, -0.1277,  0.0993, -0.0894,  0.1057,  0.0399, -0.1646, -0.0163,\n",
      "          0.1088, -0.0488,  0.0857,  0.1193],\n",
      "        [ 0.1742, -0.0768, -0.0662, -0.0172,  0.0254, -0.0655, -0.1866, -0.1952,\n",
      "          0.0548, -0.1158,  0.0897,  0.0459,  0.1151,  0.0700,  0.1725, -0.1027,\n",
      "         -0.0664,  0.0685, -0.0249, -0.0088]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0190,  0.0122, -0.0405, -0.0308,  0.0080], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0090, -0.0039, -0.0006, -0.0032,  0.0036, -0.0026, -0.0033, -0.0069,\n",
      "          0.0009,  0.0034],\n",
      "        [-0.0029, -0.0042, -0.0003,  0.0070, -0.0039, -0.0049, -0.0090, -0.0010,\n",
      "          0.0026, -0.0012]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0038, -0.0110], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in obj2.model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi3yqTDIOoui"
   },
   "source": [
    "# Make Prediction of All Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHcer1BPikHd",
    "outputId": "f72b5c62-5fd7-438d-818f-47f5dddaf3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "test data generated\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    obj2.model.eval()\n",
    "\n",
    "    #obj1.load_residuals(address='bb_residuals.pkl')\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    obj2.generate_test_results()\n",
    "    print(\"test data generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaKllEltPf16"
   },
   "source": [
    "# Comprehensive Checking of The Prediction Values vs. True Values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BK8l95VcvpJt",
    "outputId": "470c82e6-2b9a-4903-eaa1-732e46bd84c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7641,  0.4002,  0.9787,  2.2409,  1.8676],\n",
      "        [-0.9773,  0.9501, -0.1514, -0.1032,  0.4106],\n",
      "        [ 0.1440,  1.4543,  0.7610,  0.1217,  0.4439],\n",
      "        ...,\n",
      "        [-1.9519,  2.4412, -0.0173,  0.9123,  1.2397],\n",
      "        [-0.5734,  0.4249, -0.2713, -0.6836, -1.5374],\n",
      "        [-0.1014,  0.7467,  0.9292,  0.2294,  0.4144]])\n"
     ]
    }
   ],
   "source": [
    "print(obj2.x_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9ZitDT26ZXW",
    "outputId": "de963c21-10fd-4515-b6b5-b9a06eb3bd46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1172,  0.9667,  0.7347,  1.6802,  0.9620],\n",
      "        [-0.3261, -0.0919, -0.0794,  0.0088,  0.7322],\n",
      "        [-0.1200,  0.5585,  0.4476,  0.4416,  0.8562],\n",
      "        ...,\n",
      "        [-0.0878,  0.6471,  0.5311,  0.5500,  0.8537],\n",
      "        [-0.1267, -0.0641,  0.0474, -0.4015, -0.8813],\n",
      "        [-0.1524,  0.4272,  0.4688,  0.6176,  0.6871]])\n"
     ]
    }
   ],
   "source": [
    "print(obj2.x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ENQ8rtRHInw",
    "outputId": "959af6be-4ab0-4150-e843-b0d2297efc30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5409)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs(obj2.x_pred - obj2.x_last)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJJfodLhQmrD",
    "outputId": "1bc5cb45-60ba-4bc1-c812-fd51c64c41ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6468,  0.5665, -0.2440, -0.5607, -0.9055],\n",
       "        [ 0.6512, -1.0420,  0.0719,  0.1120,  0.3216],\n",
       "        [-0.2640, -0.8958, -0.3134,  0.3199,  0.4123],\n",
       "        ...,\n",
       "        [ 1.8641, -1.7941,  0.5484, -0.3623, -0.3860],\n",
       "        [ 0.4467, -0.4890,  0.3186,  0.2821,  0.6561],\n",
       "        [-0.0510, -0.3195, -0.4604,  0.3882,  0.2727]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(obj2.x_pred-obj2.x_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3q3XVFEvsEQ",
    "outputId": "4add0237-b89d-4803-983f-2d35cad6599d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(obj2.y_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Opj3sBJX6cQH",
    "outputId": "daedae9e-1edb-4243-efa3-e54976aaee6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0387, -0.0629],\n",
      "        [-0.0068, -0.0040],\n",
      "        [-0.0172, -0.0073],\n",
      "        ...,\n",
      "        [-0.0260,  0.0054],\n",
      "        [ 0.0305, -0.0008],\n",
      "        [-0.0305, -0.0363]])\n"
     ]
    }
   ],
   "source": [
    "print(obj2.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "N-n9_o8nQxBa",
    "outputId": "08c51321-bbdc-4302-8c5d-c97c8700b590"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>Y</th>\n",
       "      <th>YY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>2.240893</td>\n",
       "      <td>1.867558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.977278</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144044</td>\n",
       "      <td>1.454274</td>\n",
       "      <td>0.761038</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.443863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333674</td>\n",
       "      <td>1.494079</td>\n",
       "      <td>-0.205158</td>\n",
       "      <td>0.313068</td>\n",
       "      <td>-0.854096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.552990</td>\n",
       "      <td>0.653619</td>\n",
       "      <td>0.864436</td>\n",
       "      <td>-0.742165</td>\n",
       "      <td>2.269755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.711489</td>\n",
       "      <td>-1.820816</td>\n",
       "      <td>0.163495</td>\n",
       "      <td>-0.813117</td>\n",
       "      <td>-0.605355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.327524</td>\n",
       "      <td>-0.644172</td>\n",
       "      <td>1.908883</td>\n",
       "      <td>-0.563545</td>\n",
       "      <td>1.082473</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.951911</td>\n",
       "      <td>2.441216</td>\n",
       "      <td>-0.017285</td>\n",
       "      <td>0.912282</td>\n",
       "      <td>1.239658</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.573367</td>\n",
       "      <td>0.424889</td>\n",
       "      <td>-0.271260</td>\n",
       "      <td>-0.683568</td>\n",
       "      <td>-1.537438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.101374</td>\n",
       "      <td>0.746666</td>\n",
       "      <td>0.929182</td>\n",
       "      <td>0.229418</td>\n",
       "      <td>0.414406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C         D         E  Y  YY\n",
       "0    1.764052  0.400157  0.978738  2.240893  1.867558  1   1\n",
       "1   -0.977278  0.950088 -0.151357 -0.103219  0.410599  0   0\n",
       "2    0.144044  1.454274  0.761038  0.121675  0.443863  0   0\n",
       "3    0.333674  1.494079 -0.205158  0.313068 -0.854096  1   0\n",
       "4   -2.552990  0.653619  0.864436 -0.742165  2.269755  0   1\n",
       "..        ...       ...       ...       ...       ... ..  ..\n",
       "995  1.711489 -1.820816  0.163495 -0.813117 -0.605355  0   0\n",
       "996 -1.327524 -0.644172  1.908883 -0.563545  1.082473  1   0\n",
       "997 -1.951911  2.441216 -0.017285  0.912282  1.239658  1   1\n",
       "998 -0.573367  0.424889 -0.271260 -0.683568 -1.537438  1   1\n",
       "999 -0.101374  0.746666  0.929182  0.229418  0.414406  0   1\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2Yzu9Eiis50",
    "outputId": "d909e107-e05b-41a0-f075-c48541287153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 5])\n",
      "tensor([[ 1.7641,  0.4002,  0.9787,  2.2409,  1.8676],\n",
      "        [-0.9773,  0.9501, -0.1514, -0.1032,  0.4106],\n",
      "        [ 0.1440,  1.4543,  0.7610,  0.1217,  0.4439],\n",
      "        ...,\n",
      "        [-1.9519,  2.4412, -0.0173,  0.9123,  1.2397],\n",
      "        [-0.5734,  0.4249, -0.2713, -0.6836, -1.5374],\n",
      "        [-0.1014,  0.7467,  0.9292,  0.2294,  0.4144]])\n",
      "(1000, 5)\n",
      "Full_data_reconstructed...\n",
      "========df_reconstructed========\n",
      "            A         B         C         D         E\n",
      "0    0.351372  0.865062  0.624223  1.941547  0.782118\n",
      "1   -0.382521 -0.169283 -0.168879 -0.227918  0.735888\n",
      "2   -0.143557  0.513098  0.392422  0.376914  0.876138\n",
      "3    0.254413  0.097964  0.114112  0.045557 -1.162482\n",
      "4   -0.144946  0.545727 -0.224350 -0.687987  1.690156\n",
      "..        ...       ...       ...       ...       ...\n",
      "995 -0.029707  0.172607  0.231951 -1.074538 -0.322066\n",
      "996 -0.377260 -0.136964 -0.176268 -0.431910  0.793489\n",
      "997 -0.093372  0.669241  0.574006  0.667202  0.842162\n",
      "998  0.121768  0.182474  0.295279 -0.473983 -0.977691\n",
      "999 -0.158259  0.445661  0.386211  0.413622  0.805763\n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "========df_reconstructed_decoder========\n",
      "            A         B         C         D         E\n",
      "0    0.351372  0.865062  0.624223  1.941547  0.782118\n",
      "1   -0.382521 -0.169283 -0.168879 -0.227918  0.735888\n",
      "2   -0.143557  0.513098  0.392422  0.376914  0.876138\n",
      "3    0.254413  0.097964  0.114112  0.045557 -1.162482\n",
      "4   -0.144946  0.545727 -0.224350 -0.687987  1.690156\n",
      "..        ...       ...       ...       ...       ...\n",
      "995 -0.029707  0.172607  0.231951 -1.074538 -0.322066\n",
      "996 -0.377260 -0.136964 -0.176268 -0.431910  0.793489\n",
      "997 -0.093372  0.669241  0.574006  0.667202  0.842162\n",
      "998  0.121768  0.182474  0.295279 -0.473983 -0.977691\n",
      "999 -0.158259  0.445661  0.386211  0.413622  0.805763\n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "========df_Original========\n",
      "            A         B         C         D         E  Y  YY\n",
      "0    1.764052  0.400157  0.978738  2.240893  1.867558  1   1\n",
      "1   -0.977278  0.950088 -0.151357 -0.103219  0.410599  0   0\n",
      "2    0.144044  1.454274  0.761038  0.121675  0.443863  0   0\n",
      "3    0.333674  1.494079 -0.205158  0.313068 -0.854096  1   0\n",
      "4   -2.552990  0.653619  0.864436 -0.742165  2.269755  0   1\n",
      "..        ...       ...       ...       ...       ... ..  ..\n",
      "995  1.711489 -1.820816  0.163495 -0.813117 -0.605355  0   0\n",
      "996 -1.327524 -0.644172  1.908883 -0.563545  1.082473  1   0\n",
      "997 -1.951911  2.441216 -0.017285  0.912282  1.239658  1   1\n",
      "998 -0.573367  0.424889 -0.271260 -0.683568 -1.537438  1   1\n",
      "999 -0.101374  0.746666  0.929182  0.229418  0.414406  0   1\n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    obj2.model.eval()\n",
    "    for x, y in obj2.testloader:\n",
    "      x = x.to(device)\n",
    "      print(x.size())\n",
    "      print(x)\n",
    "      # forward\n",
    "      x_hat,y_hat, mu, logvar,z = obj2.model(x)\n",
    "    \n",
    "    df_reconstructed = pd.DataFrame(x_hat.cpu().detach().numpy(), columns=obj1.df_XY.drop(columns=['Y']).columns)\n",
    "    print(df_reconstructed.shape)\n",
    "    df_latent=pd.DataFrame(z.cpu().detach().numpy())\n",
    "    \n",
    "    obj2.model.eval()\n",
    "    \n",
    "    df_reconstructed_decoder=pd.DataFrame(obj2.model.decoder(z).cpu().detach().numpy(), columns=obj1.df_XY.drop(columns=['Y']).columns)\n",
    "\n",
    "    df_reconstructed.to_csv('df_reconstructed.csv')\n",
    "    df_latent.to_csv('df_latent.csv')\n",
    "    df_reconstructed_decoder.to_csv('df_reconstructed_decoder.csv')\n",
    "    print(\"Full_data_reconstructed...\")\n",
    "    \n",
    "    print(\"========df_reconstructed========\")\n",
    "    print(df_reconstructed)\n",
    "    print(\"========df_reconstructed_decoder========\")\n",
    "    print(df_reconstructed_decoder)\n",
    "    print(\"========df_Original========\")\n",
    "    print(df_XY)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CciNZOW_Rc0n"
   },
   "source": [
    "# Checking Linear Separability of Data on Lower Dimensioanl Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHqfONTOlqSr",
    "outputId": "6a2fa0ee-b52d-49dd-f55a-f6cdae3ee20e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression analysis\n",
      "0.538\n"
     ]
    }
   ],
   "source": [
    "print(\"regression analysis\")\n",
    "obj2.regression_analysis(obj2.zs,df_XY['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBQlR5KERlL-"
   },
   "source": [
    "# Visualize Data on Lower Dimensional Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SXZtQfoj93-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate tsne_umap_pca\n"
     ]
    }
   ],
   "source": [
    "print(\"calculate tsne_umap_pca\")\n",
    "tsne_mat,umap_mat,pca_mat,Y=obj2.calculate_lower_dimensions(obj2.zs,obj2.y_last,N=100)\n",
    "obj2.plot_lower_dimension(tsne_mat,Y,projection='3d',save_str='tsne3d.pdf')\n",
    "obj2.plot_lower_dimension(tsne_mat,Y,projection='2d',save_str='tsne2d.pdf')\n",
    "obj2.plot_lower_dimension(umap_mat,Y,projection='3d',save_str='umap3d.pdf')\n",
    "obj2.plot_lower_dimension(umap_mat,Y,projection='2d',save_str='umap2d.pdf')\n",
    "obj2.plot_lower_dimension(pca_mat,Y,projection='3d',save_str='pca3d.pdf')\n",
    "obj2.plot_lower_dimension(pca_mat,Y,projection='2d',save_str='pca2d.pdf')\n",
    "\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76ULT6UtRxU6"
   },
   "source": [
    "# Perform Interpolation across all groups (Y) and all features from YY=0 to YY=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dXtgbd1iJ0s",
    "outputId": "4710be7c-960f-4184-bdb5-931a5699dd5a"
   },
   "outputs": [],
   "source": [
    "ff = obj2.traversal_all_groups(traversal_step=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyAzr8KSAgH"
   },
   "source": [
    "# See the interpolation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWzpnwK0g-8g"
   },
   "outputs": [],
   "source": [
    "with open('results_dict.pkl', 'rb') as f:\n",
    "    ff = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "p23aMsKEknL4",
    "outputId": "29141142-bd3d-4f66-c936-9479312bcba9"
   },
   "outputs": [],
   "source": [
    "ff['med']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hMMGIGAslEoz",
    "outputId": "52e9d86d-dcb8-46c1-dfbf-1866da50861b"
   },
   "outputs": [],
   "source": [
    "ff['mean']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "T7sydB3ISVvE",
    "outputId": "36818219-d221-43b4-aa92-fb45eb31fb7a"
   },
   "outputs": [],
   "source": [
    "plt.plot(ff['med']['1']['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "qHpnnAoxoy_r",
    "outputId": "cc5504d0-001b-4b5d-afc1-d01f408db930"
   },
   "outputs": [],
   "source": [
    "plt.plot(ff['mean']['1']['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "kR4GHdxyqCxn",
    "outputId": "f9387ed5-758f-41db-bd4a-9043c31ccb4a"
   },
   "outputs": [],
   "source": [
    "plt.plot(ff['med']['0']['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "l92UJyGZSMYB",
    "outputId": "5632470a-2575-41d5-9877-1335947b8d45"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ff['mean']['0']['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCHBvdSESFRV"
   },
   "source": [
    "# Generate Synthetic Data for a Given Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZ_3NAgi2-6L",
    "outputId": "a11c8fd5-41de-40d3-dee2-91580cb322a9"
   },
   "outputs": [],
   "source": [
    "bb = obj2.synthetic_single_group(group_id=0,nr_of_synthetic=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E330szfA6BD7",
    "outputId": "a8687ace-e5b6-46d2-904d-e854e532d0d8"
   },
   "outputs": [],
   "source": [
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey_yS1WZ3Os2",
    "outputId": "dbeb2f28-2746-4a69-beeb-a934f19eb8a1"
   },
   "outputs": [],
   "source": [
    "bb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
