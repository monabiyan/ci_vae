{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhV9PPiQKgSg"
   },
   "source": [
    "# Generate Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9HIiKcw_PCm5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "#Generate 5 random numbers between 10 and 30\n",
    "np.random.seed(0)\n",
    "n_samples=1000\n",
    "n_features = 5\n",
    "df_XY=pd.DataFrame(data = np.random.normal(0,1, size=(n_samples, n_features)), columns = ['A','B','C','D','E'])\n",
    "df_XY['Y']=list(np.random.randint(2, size=n_samples))\n",
    "df_XY['YY']=list(np.random.randint(2, size=n_samples))\n",
    "df_XY\n",
    "\n",
    "##############################################################   \n",
    "df_XY.shape\n",
    "df_XY.head()\n",
    "df_XY.to_csv('df_XY.csv',index=False)\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "31zCNsOv0BoE",
    "outputId": "b7af009e-8ad8-463e-805d-07a8d5e7e082"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>Y</th>\n",
       "      <th>YY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>2.240893</td>\n",
       "      <td>1.867558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.977278</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144044</td>\n",
       "      <td>1.454274</td>\n",
       "      <td>0.761038</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.443863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333674</td>\n",
       "      <td>1.494079</td>\n",
       "      <td>-0.205158</td>\n",
       "      <td>0.313068</td>\n",
       "      <td>-0.854096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.552990</td>\n",
       "      <td>0.653619</td>\n",
       "      <td>0.864436</td>\n",
       "      <td>-0.742165</td>\n",
       "      <td>2.269755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.711489</td>\n",
       "      <td>-1.820816</td>\n",
       "      <td>0.163495</td>\n",
       "      <td>-0.813117</td>\n",
       "      <td>-0.605355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.327524</td>\n",
       "      <td>-0.644172</td>\n",
       "      <td>1.908883</td>\n",
       "      <td>-0.563545</td>\n",
       "      <td>1.082473</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.951911</td>\n",
       "      <td>2.441216</td>\n",
       "      <td>-0.017285</td>\n",
       "      <td>0.912282</td>\n",
       "      <td>1.239658</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.573367</td>\n",
       "      <td>0.424889</td>\n",
       "      <td>-0.271260</td>\n",
       "      <td>-0.683568</td>\n",
       "      <td>-1.537438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.101374</td>\n",
       "      <td>0.746666</td>\n",
       "      <td>0.929182</td>\n",
       "      <td>0.229418</td>\n",
       "      <td>0.414406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C         D         E  Y  YY\n",
       "0    1.764052  0.400157  0.978738  2.240893  1.867558  1   1\n",
       "1   -0.977278  0.950088 -0.151357 -0.103219  0.410599  0   0\n",
       "2    0.144044  1.454274  0.761038  0.121675  0.443863  0   0\n",
       "3    0.333674  1.494079 -0.205158  0.313068 -0.854096  1   0\n",
       "4   -2.552990  0.653619  0.864436 -0.742165  2.269755  0   1\n",
       "..        ...       ...       ...       ...       ... ..  ..\n",
       "995  1.711489 -1.820816  0.163495 -0.813117 -0.605355  0   0\n",
       "996 -1.327524 -0.644172  1.908883 -0.563545  1.082473  1   0\n",
       "997 -1.951911  2.441216 -0.017285  0.912282  1.239658  1   1\n",
       "998 -0.573367  0.424889 -0.271260 -0.683568 -1.537438  1   1\n",
       "999 -0.101374  0.746666  0.929182  0.229418  0.414406  0   1\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y77NKQyeKwIj"
   },
   "source": [
    "# Download CI-VAE, other necessary packages and Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cAuVLcUNETr7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: residuals.pdf: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -rf ci_vae\n",
    "! rm bb.pt\n",
    "! rm bb_residuals.pkl\n",
    "! rm df_reconstructed.csv\n",
    "! rm df_reconstructed_decoder.csv\n",
    "! rm residuals.pdf\n",
    "! rm results_dict.pkl\n",
    "! rm df_latent.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "18S0saDPLp0X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ci_vae'...\n",
      "remote: Enumerating objects: 359, done.\u001b[K\n",
      "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
      "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
      "remote: Total 359 (delta 55), reused 87 (delta 28), pack-reused 245\u001b[K\n",
      "Receiving objects: 100% (359/359), 47.52 MiB | 14.47 MiB/s, done.\n",
      "Resolving deltas: 100% (211/211), done.\n",
      "Requirement already satisfied: umap-learn in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (0.5.3)\n",
      "Requirement already satisfied: numba>=0.49 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (0.51.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (1.19.2)\n",
      "Requirement already satisfied: tqdm in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (4.50.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (0.5.8)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from umap-learn) (1.5.2)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
      "Requirement already satisfied: setuptools in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from numba>=0.49->umap-learn) (50.3.1.post20201107)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from pynndescent>=0.5->umap-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mohsennabian/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22->umap-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/monabiyan/ci_vae.git\n",
    "! pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kzwk1I17VAQx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ci_vae import ivae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPVcV9thL8SP"
   },
   "source": [
    "# Set Necessary Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KAVb-irtbIpc"
   },
   "outputs": [],
   "source": [
    "model_init=True\n",
    "model_tobe_trained=True\n",
    "save_address=\"bb\"\n",
    "\n",
    "kl_coef = 0.0001\n",
    "reconst_coef = 1\n",
    "classifier_coef = 0.1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRIfHjpSMKF5"
   },
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ll0w2DunMJei"
   },
   "outputs": [],
   "source": [
    "obj1 = ivae.IVAE(df_XY = df_XY,\n",
    "               latent_size = 10,\n",
    "               reconst_coef = reconst_coef,\n",
    "               kl_coef = kl_coef,\n",
    "               classifier_coef = classifier_coef,\n",
    "               test_ratio = 1)\n",
    "\n",
    "if model_init:\n",
    "    obj1.model_initialiaze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT-AB_8-M-tD"
   },
   "source": [
    "## See The Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJXlsM8Uk2Ry",
    "outputId": "129babee-fc0e-48c5-9262-08404a9b89c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVAE_ARCH(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.05, inplace=False)\n",
      "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.05, inplace=False)\n",
      "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.05, inplace=False)\n",
      "    (12): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (15): Dropout(p=0.05, inplace=False)\n",
      "    (16): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (19): Dropout(p=0.05, inplace=False)\n",
      "    (20): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (21): ReLU()\n",
      "    (22): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (23): Dropout(p=0.05, inplace=False)\n",
      "    (24): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (25): ReLU()\n",
      "    (26): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (27): Dropout(p=0.05, inplace=False)\n",
      "    (28): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (29): ReLU()\n",
      "    (30): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (31): Dropout(p=0.05, inplace=False)\n",
      "    (32): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (33): ReLU()\n",
      "    (34): BatchNorm1d(10, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (35): Dropout(p=0.05, inplace=False)\n",
      "    (36): Linear(in_features=10, out_features=20, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.05, inplace=False)\n",
      "    (4): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.05, inplace=False)\n",
      "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.05, inplace=False)\n",
      "    (12): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (15): Dropout(p=0.05, inplace=False)\n",
      "    (16): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (19): Dropout(p=0.05, inplace=False)\n",
      "    (20): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (21): ReLU()\n",
      "    (22): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (23): Dropout(p=0.05, inplace=False)\n",
      "    (24): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (25): ReLU()\n",
      "    (26): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (27): Dropout(p=0.05, inplace=False)\n",
      "    (28): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (29): ReLU()\n",
      "    (30): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (31): Dropout(p=0.05, inplace=False)\n",
      "    (32): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (33): ReLU()\n",
      "    (34): BatchNorm1d(20, eps=1e-05, momentum=0.2, affine=True, track_running_stats=True)\n",
      "    (35): Dropout(p=0.05, inplace=False)\n",
      "    (36): Linear(in_features=20, out_features=5, bias=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "    (1): Dropout(p=0.8, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(obj1.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSj9WT_mNHNl"
   },
   "source": [
    "## See the Initialized Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUFyVcu4ldFH",
    "outputId": "5a470060-626d-4602-dcf4-78d601febd3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0747, -0.4014,  0.3841, -0.4040, -0.2730],\n",
      "        [ 0.0152,  0.2909,  0.0636,  0.3650, -0.1679],\n",
      "        [-0.0572, -0.3146,  0.1278,  0.4166,  0.1843],\n",
      "        [-0.0581,  0.0611, -0.2101, -0.0264,  0.0574],\n",
      "        [ 0.2054, -0.3049,  0.1189, -0.0844,  0.1019],\n",
      "        [-0.0242, -0.0359, -0.4122,  0.3340,  0.0313],\n",
      "        [ 0.2736,  0.4144, -0.0199,  0.4242,  0.3415],\n",
      "        [ 0.0230, -0.0945,  0.0876,  0.3803,  0.1955],\n",
      "        [ 0.1780, -0.0242,  0.3783,  0.0307, -0.2490],\n",
      "        [ 0.4335,  0.1754,  0.3635, -0.1546, -0.1531],\n",
      "        [-0.2522, -0.3066,  0.0109, -0.0216, -0.1530],\n",
      "        [-0.1127,  0.1609, -0.2668, -0.3952, -0.2981],\n",
      "        [-0.4291, -0.1409, -0.2690,  0.4390, -0.2103],\n",
      "        [ 0.3971,  0.0332, -0.1817,  0.0430,  0.3265],\n",
      "        [ 0.0222,  0.2415, -0.0886,  0.3953,  0.4071],\n",
      "        [ 0.1544,  0.1162, -0.3165, -0.2653, -0.1039],\n",
      "        [-0.1088,  0.4356,  0.4429, -0.4162, -0.1157],\n",
      "        [ 0.4063, -0.3566,  0.1302,  0.1427,  0.2995],\n",
      "        [ 0.1612,  0.1249, -0.2349,  0.3882,  0.1403],\n",
      "        [ 0.0758, -0.0227,  0.2188, -0.0765,  0.1026]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0085,  0.0449, -0.1042, -0.1842,  0.2330,  0.2866,  0.2722,  0.1502,\n",
      "        -0.0961, -0.1857, -0.0710,  0.1630,  0.3994, -0.2511, -0.2015, -0.2439,\n",
      "         0.2262,  0.3488, -0.3234,  0.3625], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0258, -0.0499, -0.0544,  0.0327,  0.2084,  0.1391,  0.0159, -0.0210,\n",
      "          0.1608, -0.0607, -0.1364, -0.1352, -0.0934,  0.2155, -0.0699,  0.1489,\n",
      "          0.1403, -0.1803,  0.1325, -0.0196],\n",
      "        [ 0.0887, -0.0038, -0.1031, -0.1964, -0.0941,  0.1594,  0.1752, -0.0931,\n",
      "          0.0297, -0.1330,  0.0113,  0.0905,  0.1516, -0.0457, -0.0021,  0.0101,\n",
      "         -0.0428,  0.1314,  0.0564, -0.1620],\n",
      "        [ 0.1203,  0.1766,  0.0517,  0.2054,  0.1106, -0.0829, -0.0109,  0.1284,\n",
      "          0.1828,  0.1062,  0.1517, -0.1238, -0.1020,  0.0821, -0.1280, -0.1539,\n",
      "         -0.1393,  0.1022,  0.1036, -0.1293],\n",
      "        [-0.0122,  0.0324, -0.1238, -0.0749, -0.1317, -0.1356,  0.1259, -0.1829,\n",
      "         -0.0787, -0.0637, -0.0695,  0.2152, -0.0098, -0.1594,  0.1875, -0.0305,\n",
      "          0.1404,  0.0027, -0.0367, -0.1169],\n",
      "        [-0.1898,  0.0693,  0.1645, -0.0504,  0.1784,  0.1728, -0.0432,  0.2178,\n",
      "         -0.0768,  0.1743, -0.0738, -0.1820,  0.0574, -0.0729, -0.1896,  0.0343,\n",
      "         -0.0548,  0.1419, -0.1215, -0.1764],\n",
      "        [-0.1978,  0.1839, -0.1006, -0.0678, -0.1599, -0.1262,  0.1312, -0.0185,\n",
      "          0.1058,  0.1734,  0.0421,  0.0719,  0.1615,  0.1410,  0.2229,  0.1141,\n",
      "         -0.1647,  0.1043, -0.1887,  0.1283],\n",
      "        [ 0.1529, -0.1542, -0.2040,  0.0688, -0.1507, -0.1133,  0.1581, -0.0846,\n",
      "          0.2044, -0.1479,  0.0736,  0.0939, -0.0210, -0.0611, -0.0143, -0.0493,\n",
      "          0.1123,  0.1015,  0.0217, -0.1900],\n",
      "        [-0.1851,  0.1215, -0.0456,  0.2019, -0.1114, -0.1113, -0.0579,  0.1442,\n",
      "          0.2152, -0.1234,  0.1946, -0.2197, -0.0152,  0.0187, -0.1567, -0.0876,\n",
      "          0.2201,  0.0905, -0.0080, -0.0557],\n",
      "        [-0.2005, -0.1315,  0.1391, -0.0928,  0.1379, -0.0130, -0.0801, -0.1055,\n",
      "          0.1059,  0.0036,  0.0501, -0.1183, -0.1231,  0.1547, -0.0636,  0.1165,\n",
      "          0.1647, -0.1369, -0.0911,  0.2170],\n",
      "        [-0.2141, -0.2040, -0.1323,  0.0255,  0.0580,  0.2208,  0.1846,  0.0423,\n",
      "          0.1409,  0.1206, -0.2219, -0.1750,  0.0588,  0.0116, -0.2036,  0.0863,\n",
      "          0.1897,  0.1073,  0.1506, -0.1812],\n",
      "        [ 0.1071, -0.1777, -0.0889, -0.1831, -0.1163, -0.1284,  0.0025, -0.0099,\n",
      "          0.1917, -0.1707, -0.2103, -0.0737, -0.0908,  0.1877, -0.1065, -0.0490,\n",
      "         -0.2197, -0.2095, -0.0632, -0.1861],\n",
      "        [-0.1791, -0.1662,  0.2005, -0.1635,  0.0796, -0.1282,  0.1209,  0.1814,\n",
      "          0.1194,  0.0983,  0.0143, -0.1514, -0.0611,  0.1002, -0.1421, -0.0131,\n",
      "          0.1045,  0.0281, -0.0036,  0.2062],\n",
      "        [-0.1732,  0.2169, -0.1013, -0.0233, -0.0686, -0.0560,  0.0856,  0.2120,\n",
      "         -0.1949, -0.0897, -0.1087, -0.2023,  0.2173,  0.1138, -0.2100, -0.0130,\n",
      "          0.0151, -0.0133,  0.0865, -0.1848],\n",
      "        [-0.0137,  0.1476,  0.1290, -0.1773,  0.0072,  0.1130,  0.1058,  0.0250,\n",
      "          0.2235, -0.1931,  0.1472, -0.1761,  0.0769, -0.0680, -0.1050, -0.0156,\n",
      "          0.1672, -0.0625,  0.0220,  0.1042],\n",
      "        [ 0.1768, -0.0366,  0.0405,  0.0503, -0.0606,  0.2177,  0.1291, -0.0307,\n",
      "          0.2145,  0.1554,  0.0889, -0.1729, -0.1917,  0.1871,  0.0588,  0.0132,\n",
      "         -0.2004, -0.1798, -0.2098,  0.0383],\n",
      "        [ 0.1779,  0.1747,  0.1495,  0.1524,  0.1951, -0.0866, -0.0867, -0.0192,\n",
      "         -0.1266,  0.2027, -0.1969,  0.0792, -0.1719,  0.0278,  0.0125, -0.0106,\n",
      "          0.0606,  0.1668, -0.1037,  0.0146],\n",
      "        [-0.0098,  0.0956,  0.0208,  0.0886,  0.0182, -0.1268,  0.0813,  0.1624,\n",
      "         -0.0759, -0.2173,  0.1977,  0.0348, -0.0996, -0.1939,  0.0235,  0.0978,\n",
      "         -0.1513, -0.1764,  0.1379,  0.0650],\n",
      "        [ 0.1457, -0.0252,  0.1938, -0.0545,  0.0828,  0.1267, -0.0694,  0.1439,\n",
      "          0.0459,  0.2036,  0.0739, -0.1584,  0.1880, -0.0993,  0.1654, -0.0140,\n",
      "          0.0236,  0.0630, -0.1544, -0.1950],\n",
      "        [-0.0034, -0.1640,  0.1093, -0.0289, -0.0998,  0.0951, -0.1518,  0.2181,\n",
      "          0.0761,  0.1246,  0.0087, -0.1321, -0.1856,  0.0420,  0.1284,  0.0221,\n",
      "          0.1313, -0.1377, -0.0370,  0.2087],\n",
      "        [ 0.0719, -0.1774, -0.1062, -0.0746, -0.0317, -0.0579, -0.0008,  0.1969,\n",
      "         -0.1983, -0.2144,  0.1375,  0.0725, -0.0755, -0.0656, -0.1413, -0.1884,\n",
      "         -0.2112, -0.1042,  0.2031,  0.0574]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0379,  0.1232,  0.0557,  0.0205, -0.1386,  0.1693,  0.0134,  0.1523,\n",
      "        -0.0470,  0.0319,  0.0729,  0.1761, -0.1091,  0.0350,  0.0925,  0.0981,\n",
      "        -0.1616,  0.1307, -0.0626,  0.1301], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0795,  0.0793, -0.0962,  0.0818, -0.2217, -0.0601,  0.0818,  0.0922,\n",
      "         -0.2100,  0.2201,  0.1923, -0.2044, -0.0281, -0.1355, -0.1783,  0.0757,\n",
      "          0.1141,  0.1952,  0.0699,  0.1721],\n",
      "        [-0.1724,  0.1783, -0.0543,  0.0560,  0.1484, -0.0297,  0.1081, -0.0040,\n",
      "          0.1168, -0.1817,  0.0350, -0.0131, -0.1560, -0.0378, -0.1650, -0.0917,\n",
      "         -0.0233,  0.1194,  0.1862, -0.0904],\n",
      "        [-0.1405, -0.0752, -0.1039, -0.0004, -0.1603,  0.0796, -0.0281, -0.0224,\n",
      "          0.0123,  0.0108,  0.0589,  0.0647,  0.1556,  0.0754,  0.0236,  0.0472,\n",
      "          0.0658, -0.2025,  0.1482, -0.1997],\n",
      "        [ 0.0236,  0.2065,  0.0492,  0.0465, -0.0932,  0.2228,  0.1396, -0.1770,\n",
      "          0.0648,  0.1395,  0.0656, -0.2120, -0.1601,  0.1934,  0.1448,  0.0468,\n",
      "         -0.1193,  0.0700, -0.0494, -0.1544],\n",
      "        [-0.0529, -0.1415,  0.1639, -0.0726,  0.2092, -0.1473, -0.0385,  0.2175,\n",
      "          0.0014, -0.0634,  0.2000, -0.0426, -0.0497, -0.0700, -0.0832,  0.0512,\n",
      "          0.0623,  0.0676, -0.1363, -0.0269],\n",
      "        [-0.0172, -0.2216, -0.1392, -0.1600,  0.1192, -0.1195, -0.0771,  0.1160,\n",
      "          0.1198, -0.0644, -0.1536, -0.1440,  0.1458,  0.0118, -0.0392, -0.0753,\n",
      "          0.1296, -0.0864, -0.0516,  0.0211],\n",
      "        [-0.1451, -0.1165,  0.1572,  0.0579,  0.1383,  0.0508, -0.0856, -0.0045,\n",
      "          0.1740,  0.0468, -0.1168,  0.0467,  0.2067, -0.0612, -0.0140,  0.1491,\n",
      "         -0.2092, -0.2061, -0.0184,  0.1717],\n",
      "        [-0.1096, -0.1532, -0.1290,  0.1970, -0.1791,  0.0698,  0.0603,  0.2072,\n",
      "         -0.0323, -0.2142, -0.0350,  0.0271, -0.1745, -0.0895,  0.1659, -0.0008,\n",
      "         -0.0071, -0.0840, -0.1248, -0.1883],\n",
      "        [ 0.0883, -0.1546,  0.0475,  0.0145,  0.1734,  0.0201, -0.0424, -0.1012,\n",
      "          0.2004, -0.2011,  0.0780, -0.0440, -0.0833,  0.0019,  0.0926,  0.1900,\n",
      "         -0.2085,  0.0256, -0.1864,  0.1399],\n",
      "        [-0.0768,  0.2218, -0.1917,  0.1372, -0.1816, -0.1714,  0.0847, -0.0066,\n",
      "         -0.1265, -0.1571, -0.0696,  0.1138,  0.2141, -0.0251,  0.1432, -0.2074,\n",
      "          0.1922,  0.0061,  0.0222,  0.0111],\n",
      "        [-0.0330, -0.1464,  0.0202, -0.0765,  0.0635, -0.0916,  0.0248, -0.1057,\n",
      "          0.1177,  0.1302, -0.1605, -0.1159, -0.0012, -0.0074,  0.0270,  0.0108,\n",
      "         -0.2021, -0.1147, -0.1873,  0.1711],\n",
      "        [ 0.0448, -0.0289, -0.0764, -0.1417, -0.0768,  0.0460, -0.1950,  0.1575,\n",
      "          0.0965, -0.0362,  0.1852, -0.0896, -0.1308,  0.1501, -0.0832,  0.0658,\n",
      "         -0.1931,  0.0668,  0.1221,  0.1950],\n",
      "        [ 0.1679, -0.1160,  0.0833,  0.1686,  0.0897,  0.1078,  0.0632, -0.0319,\n",
      "         -0.1929,  0.2204,  0.0942, -0.0779, -0.0587, -0.0897,  0.2203,  0.0198,\n",
      "          0.0947, -0.1909,  0.2118,  0.0097],\n",
      "        [ 0.1635, -0.0302,  0.1334, -0.1585,  0.0632, -0.1543,  0.2046,  0.0676,\n",
      "         -0.0864,  0.1326,  0.1214, -0.0151,  0.0251, -0.0021, -0.0340, -0.1342,\n",
      "          0.0355,  0.1981,  0.1758,  0.0098],\n",
      "        [ 0.0770, -0.2148,  0.0726, -0.2137, -0.0837, -0.1401,  0.0961,  0.1861,\n",
      "         -0.1255,  0.1329, -0.0713, -0.0617,  0.1708, -0.1978,  0.2196,  0.0257,\n",
      "         -0.1182, -0.1767,  0.0601, -0.0602],\n",
      "        [-0.1215, -0.0259, -0.2044, -0.1107, -0.1383,  0.0172,  0.1882, -0.2074,\n",
      "         -0.0741, -0.1981,  0.0975,  0.0511,  0.0563,  0.0644, -0.1333,  0.0813,\n",
      "         -0.1945, -0.1042,  0.2079,  0.2225],\n",
      "        [ 0.0603,  0.0227, -0.0758, -0.0888, -0.1701,  0.0224,  0.0871, -0.1559,\n",
      "         -0.0460, -0.0156,  0.0079, -0.0803, -0.1608, -0.0670, -0.0770,  0.0800,\n",
      "          0.1342,  0.2101, -0.1181, -0.1545],\n",
      "        [-0.0564, -0.2127,  0.0154, -0.1962,  0.1383,  0.0116,  0.0508, -0.2022,\n",
      "         -0.1140,  0.1529, -0.0258, -0.0684, -0.1915, -0.0245,  0.1760,  0.1074,\n",
      "          0.1028,  0.1756, -0.1276, -0.1552],\n",
      "        [-0.0696, -0.2131, -0.0939,  0.1507, -0.1309,  0.1684,  0.1317,  0.0029,\n",
      "         -0.0860,  0.0926, -0.2032, -0.1263,  0.1679,  0.1832,  0.2110, -0.0379,\n",
      "          0.0358, -0.1671, -0.1269,  0.1021],\n",
      "        [-0.1006,  0.1526, -0.0593,  0.0092, -0.1633,  0.1226, -0.2229, -0.0526,\n",
      "          0.1423,  0.1228,  0.1091, -0.2230, -0.1742, -0.0725, -0.1195,  0.1160,\n",
      "         -0.0496, -0.2153,  0.1586, -0.0123]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1654, -0.0301, -0.1839,  0.1711, -0.1435, -0.1913, -0.0314,  0.1110,\n",
      "         0.1381, -0.1153,  0.1490,  0.0970, -0.0030,  0.1560, -0.2044, -0.0184,\n",
      "         0.0015, -0.1323, -0.1201,  0.0273], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1837, -0.0566, -0.1995, -0.0090, -0.1484, -0.0490, -0.2080, -0.1319,\n",
      "          0.1327, -0.1666,  0.0506,  0.0177,  0.1878, -0.1574, -0.0379,  0.1681,\n",
      "          0.0842, -0.0933, -0.1420,  0.1356],\n",
      "        [ 0.1601, -0.0395, -0.1584,  0.0307,  0.0953, -0.1962,  0.0796, -0.1252,\n",
      "          0.1132,  0.1833,  0.0935,  0.2040,  0.1579,  0.0211,  0.0588, -0.0889,\n",
      "          0.2218,  0.1331,  0.2173, -0.1393],\n",
      "        [-0.0272, -0.1818,  0.0188, -0.0296, -0.1405,  0.0695, -0.0119,  0.0737,\n",
      "          0.1846,  0.0531,  0.0883, -0.0697,  0.1986,  0.1546,  0.2224,  0.0386,\n",
      "          0.0987,  0.1601,  0.1432,  0.0737],\n",
      "        [-0.2063, -0.0309,  0.2185,  0.1986, -0.0038, -0.0432, -0.1036,  0.0258,\n",
      "         -0.1210, -0.0360,  0.1968,  0.0110,  0.1881,  0.0331,  0.1453, -0.2012,\n",
      "          0.1941, -0.1466, -0.1919,  0.0227],\n",
      "        [-0.1366, -0.0754,  0.0784,  0.1186, -0.1965,  0.1510, -0.0780,  0.2079,\n",
      "          0.1294, -0.0977, -0.0144, -0.0302,  0.1153,  0.1978,  0.0925, -0.0272,\n",
      "         -0.1391, -0.0734,  0.1077,  0.0048],\n",
      "        [ 0.2014, -0.1447, -0.0722,  0.0046,  0.2046,  0.2034,  0.0102, -0.1791,\n",
      "          0.0508,  0.0790, -0.0109, -0.0267,  0.2176,  0.0488,  0.1986,  0.0785,\n",
      "          0.2052, -0.0243,  0.1381,  0.1418],\n",
      "        [-0.1784,  0.0744, -0.2063, -0.0764, -0.0068,  0.1530, -0.0207, -0.0163,\n",
      "         -0.1226,  0.1038,  0.1256,  0.1661,  0.0061,  0.0289, -0.2073,  0.1304,\n",
      "         -0.2017,  0.0495,  0.1163,  0.0459],\n",
      "        [-0.0755, -0.1447,  0.0673, -0.0661, -0.0534,  0.1447,  0.2019,  0.0279,\n",
      "         -0.0797,  0.1628, -0.1365,  0.1957, -0.0806,  0.0332, -0.1390,  0.1509,\n",
      "          0.0112, -0.2129,  0.0130,  0.1122],\n",
      "        [ 0.0833, -0.0288, -0.1692, -0.1499,  0.1848, -0.1510, -0.1347, -0.2162,\n",
      "         -0.2047, -0.0500,  0.1933,  0.0737,  0.0110, -0.1009,  0.0091,  0.2185,\n",
      "         -0.0333, -0.0289,  0.0919,  0.2208],\n",
      "        [ 0.1936,  0.1672,  0.0844, -0.0182,  0.1436, -0.0610,  0.1132, -0.0354,\n",
      "          0.0807,  0.1207,  0.0802,  0.2093,  0.0749,  0.1997,  0.0417, -0.0623,\n",
      "         -0.0355, -0.0702,  0.1472,  0.1319],\n",
      "        [ 0.1111,  0.0985, -0.0480, -0.0142, -0.1936, -0.0024,  0.1028,  0.0656,\n",
      "         -0.0046,  0.1187, -0.0059, -0.0286, -0.0190, -0.0035, -0.1655, -0.2189,\n",
      "         -0.0759,  0.0239, -0.2030, -0.1262],\n",
      "        [-0.0033,  0.0341,  0.0124,  0.1862,  0.0561, -0.1393, -0.0515,  0.1807,\n",
      "         -0.1424,  0.1273,  0.2078,  0.0932,  0.2109,  0.2113,  0.0629, -0.1655,\n",
      "          0.1122, -0.1774, -0.0637,  0.1635],\n",
      "        [-0.0042,  0.1000, -0.1738, -0.0556,  0.1267, -0.2023, -0.1045,  0.1825,\n",
      "         -0.0942,  0.0784,  0.0756,  0.0043,  0.0493, -0.1277, -0.1171, -0.0065,\n",
      "          0.1314, -0.0825,  0.0799, -0.1455],\n",
      "        [ 0.1898, -0.1229,  0.1547, -0.1039, -0.0019,  0.1434, -0.1620, -0.1854,\n",
      "         -0.0559, -0.0646,  0.0907,  0.0998, -0.0909, -0.1693,  0.0505,  0.1685,\n",
      "         -0.0381,  0.0538,  0.2082,  0.0877],\n",
      "        [ 0.0085,  0.1171, -0.2152, -0.0507,  0.0290,  0.1277,  0.1773, -0.0340,\n",
      "         -0.1823, -0.0447, -0.1764, -0.0937,  0.1980, -0.1670,  0.0191,  0.2085,\n",
      "         -0.1992, -0.0558,  0.0964,  0.1187],\n",
      "        [-0.0789, -0.0072, -0.0093,  0.1327,  0.1404,  0.0834,  0.0155,  0.1194,\n",
      "          0.0636, -0.0325, -0.0594, -0.0617,  0.0787, -0.0746,  0.1339,  0.0233,\n",
      "          0.1915, -0.1286, -0.0138,  0.2057],\n",
      "        [ 0.1977,  0.0982, -0.0710, -0.1873,  0.0675, -0.1565,  0.0948,  0.1632,\n",
      "         -0.2034,  0.0950,  0.1398, -0.0511,  0.0255, -0.1363, -0.0794,  0.2076,\n",
      "         -0.0543,  0.1752, -0.0660, -0.0208],\n",
      "        [-0.0338, -0.2038, -0.1801, -0.1831,  0.1503, -0.1879, -0.1437, -0.2163,\n",
      "         -0.1896, -0.0726, -0.1342,  0.0797,  0.2196,  0.0728, -0.1774,  0.1560,\n",
      "          0.2004, -0.1077, -0.1900, -0.0128],\n",
      "        [ 0.1791, -0.1353, -0.0542,  0.1323, -0.0318, -0.2206,  0.1054,  0.0989,\n",
      "         -0.0648, -0.1173,  0.0678,  0.1521, -0.2138, -0.2178,  0.1501,  0.0566,\n",
      "         -0.1153,  0.0884,  0.0246,  0.2124],\n",
      "        [ 0.0115, -0.1472,  0.0536,  0.1537, -0.0677,  0.1077, -0.0183, -0.1134,\n",
      "         -0.0062,  0.1282, -0.0199,  0.0942, -0.2084,  0.0290,  0.1455, -0.1735,\n",
      "         -0.0796, -0.0166, -0.1769,  0.2205]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1305, -0.0544, -0.1010, -0.0447,  0.2234, -0.0791,  0.1680,  0.0056,\n",
      "        -0.2010, -0.0734, -0.1290,  0.0599,  0.0361,  0.2211,  0.0928, -0.0482,\n",
      "        -0.0225, -0.1073,  0.1184,  0.0499], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 2.1705e-01, -4.3750e-05, -2.0362e-01, -4.3494e-02,  1.1689e-01,\n",
      "         -6.8513e-02,  8.9576e-02, -1.5209e-01, -1.4613e-03, -1.8960e-01,\n",
      "          7.4770e-02,  7.6742e-02, -3.6364e-02, -9.9378e-02,  6.1183e-02,\n",
      "          8.1958e-02, -1.3815e-01,  1.3967e-01,  1.7134e-02, -8.9153e-03],\n",
      "        [ 4.6115e-02,  1.3283e-01,  1.0207e-01, -1.0713e-01,  1.1253e-01,\n",
      "         -3.1316e-02, -8.6499e-02,  1.2689e-01, -8.4362e-02,  1.1582e-01,\n",
      "          1.6712e-01, -1.0122e-01,  1.3355e-01,  1.5574e-01,  5.8373e-02,\n",
      "         -1.2044e-01, -2.9470e-02, -9.8618e-02,  1.9269e-01, -1.4471e-01],\n",
      "        [-3.2494e-02,  2.9822e-02,  1.3190e-01, -2.0400e-01, -6.0776e-02,\n",
      "         -1.5137e-01, -1.8870e-01, -7.3064e-02,  4.8757e-03,  8.0599e-02,\n",
      "         -2.1844e-01,  6.4008e-02,  8.2386e-02, -3.9617e-02,  1.9262e-01,\n",
      "          1.3436e-01,  2.0325e-01,  5.2630e-02, -1.4520e-01, -2.1995e-01],\n",
      "        [-8.3017e-02, -1.1033e-01,  1.0741e-01,  1.4732e-01, -9.9663e-02,\n",
      "          1.2226e-01,  1.1121e-01,  8.3036e-02,  1.3085e-01, -2.5873e-02,\n",
      "          1.4478e-01,  1.4549e-01,  1.1686e-01, -2.2111e-02, -2.9071e-03,\n",
      "          2.2523e-02, -1.0720e-01,  2.0343e-01, -1.5333e-01, -1.4407e-01],\n",
      "        [ 1.9805e-01,  6.3062e-02, -5.1744e-02,  1.9756e-01,  4.3402e-02,\n",
      "         -1.3963e-01,  1.6151e-01,  9.7816e-02,  1.6702e-01,  8.7876e-02,\n",
      "         -6.9510e-02,  1.0724e-01, -3.8839e-02, -2.0022e-01,  1.4033e-01,\n",
      "          8.3638e-02, -9.7031e-02, -6.5716e-02, -3.2135e-02,  8.9064e-02],\n",
      "        [ 7.1612e-02,  1.6972e-01, -6.2797e-02,  3.5514e-02, -4.9182e-02,\n",
      "          6.2312e-02, -9.6066e-03,  1.2601e-01, -3.8734e-02, -1.4667e-01,\n",
      "          2.1357e-01, -1.0885e-01, -1.3549e-01, -1.5368e-01, -1.1946e-01,\n",
      "          1.4485e-01, -8.1065e-03,  1.9155e-01, -4.8535e-02,  1.6684e-01],\n",
      "        [ 1.0080e-01, -1.0556e-01, -8.9166e-02, -1.4708e-01, -1.0130e-01,\n",
      "          3.9233e-02,  1.3249e-01,  1.3226e-01,  1.5529e-01,  4.5653e-02,\n",
      "          1.5887e-01, -8.5514e-02, -1.5081e-02,  5.8329e-02, -1.7499e-01,\n",
      "          1.9820e-01, -1.6329e-01, -1.9083e-01, -1.5614e-01,  8.7394e-02],\n",
      "        [ 2.1246e-01,  7.4799e-02, -8.6156e-02,  1.8644e-01,  1.1975e-01,\n",
      "         -1.5606e-02,  1.2579e-01, -3.4123e-03,  1.4799e-01,  5.8890e-03,\n",
      "          3.9474e-02,  3.2652e-03,  1.3538e-02,  1.4808e-01,  1.8737e-01,\n",
      "         -2.6392e-02,  6.7159e-02, -1.1892e-02, -2.1041e-01, -7.4220e-02],\n",
      "        [-5.4391e-02,  1.9877e-01, -1.1873e-01,  9.2471e-02, -8.1863e-02,\n",
      "         -2.1943e-02, -3.6143e-02,  5.8232e-02, -1.8834e-01,  8.6846e-02,\n",
      "         -1.9376e-02,  1.0589e-01, -6.5776e-02, -1.3855e-01, -1.0163e-01,\n",
      "         -1.7410e-01, -2.1150e-01, -1.1145e-01,  1.8899e-01,  2.0798e-01],\n",
      "        [ 8.4277e-02, -2.0744e-01,  1.0012e-02, -7.5747e-03, -2.0547e-01,\n",
      "          9.7020e-02,  1.0829e-01,  2.1933e-01,  4.1425e-02, -1.1705e-01,\n",
      "          5.6680e-02,  1.5901e-01,  1.9531e-01,  6.1029e-02,  2.6712e-02,\n",
      "          9.8195e-02, -1.0644e-01, -1.3765e-01,  8.1755e-03, -2.0953e-01],\n",
      "        [ 8.5770e-02,  2.0011e-01, -2.1719e-01,  2.0935e-01,  7.5468e-03,\n",
      "         -2.1647e-01,  1.7569e-01,  3.9933e-02,  1.9189e-01, -1.6159e-01,\n",
      "          1.9354e-01, -8.7069e-03, -1.2669e-02,  1.8902e-01,  1.8549e-01,\n",
      "          9.4641e-02, -1.5309e-02, -1.3537e-01, -7.6215e-02, -6.5146e-02],\n",
      "        [-2.8211e-02, -2.0628e-01,  6.1363e-02, -2.1211e-01, -1.3559e-01,\n",
      "         -1.5843e-01,  1.8481e-01, -5.4900e-02, -1.5208e-01, -1.9239e-01,\n",
      "         -1.1238e-01, -1.7604e-01,  1.5600e-01,  7.7937e-02, -1.8813e-01,\n",
      "          3.6197e-02,  1.1533e-01, -3.4350e-02, -5.2049e-02,  1.8490e-01],\n",
      "        [-2.0816e-01, -1.5053e-01,  1.1707e-02, -1.9990e-01, -1.6992e-01,\n",
      "         -9.2682e-02,  1.5882e-01,  4.3906e-02,  1.3362e-01,  1.6132e-01,\n",
      "          1.9473e-01,  1.6000e-01,  5.9877e-02, -8.8552e-02, -2.6946e-02,\n",
      "          1.9255e-01,  2.2272e-01,  1.1817e-01, -6.4439e-02, -2.0640e-01],\n",
      "        [ 1.1719e-01, -9.8887e-02, -9.1238e-03, -1.6235e-01, -2.0970e-01,\n",
      "         -1.1681e-01,  8.0133e-02,  9.7768e-02, -9.7731e-02, -1.2257e-01,\n",
      "         -1.0894e-01,  1.4584e-02, -1.1338e-01,  1.3421e-01,  2.1819e-02,\n",
      "          1.8604e-01,  1.7647e-01,  5.0519e-02,  1.0678e-01, -5.4580e-02],\n",
      "        [-1.7581e-01, -1.5982e-01, -8.3306e-02, -2.2107e-01,  1.1249e-02,\n",
      "          1.6393e-02, -5.1351e-02, -1.4357e-01,  6.5293e-02, -9.1492e-02,\n",
      "         -1.3284e-01, -1.9938e-01,  7.4907e-02,  4.3750e-02, -1.5911e-01,\n",
      "          2.0025e-01, -2.6694e-02, -1.5426e-01, -1.9383e-01,  2.0846e-02],\n",
      "        [ 2.1568e-01, -1.1025e-01, -8.5896e-02,  4.7224e-02, -1.8956e-01,\n",
      "          1.4407e-01,  9.7288e-02, -1.4084e-01,  6.7403e-02, -1.0540e-01,\n",
      "         -8.7326e-02,  1.8149e-01, -1.1140e-01, -5.6518e-02, -1.8192e-01,\n",
      "          8.8045e-02,  2.0577e-01, -5.3914e-03, -2.2118e-01,  3.9178e-02],\n",
      "        [ 1.3721e-01,  1.2105e-01,  8.6720e-02,  1.3293e-01, -1.0312e-01,\n",
      "         -1.6232e-01, -1.7805e-01, -9.5724e-02, -1.4115e-01, -2.9943e-02,\n",
      "         -1.2883e-01, -1.8653e-02,  1.1273e-01, -1.7269e-01,  1.8508e-01,\n",
      "         -1.7875e-01,  1.9699e-01, -1.8300e-01, -4.1162e-02, -1.8613e-01],\n",
      "        [-1.1589e-01, -8.0372e-02,  5.4828e-02,  5.7103e-02,  8.9126e-02,\n",
      "         -1.4010e-01, -8.0396e-02,  3.6565e-02,  3.8606e-02, -4.1897e-02,\n",
      "          2.0709e-01,  2.1699e-01, -1.6177e-01,  1.2945e-01,  4.4596e-02,\n",
      "         -2.1076e-01, -3.8882e-02, -1.3798e-01, -1.5533e-02, -1.5433e-01],\n",
      "        [ 1.1154e-01,  1.1933e-02, -8.1792e-02,  6.5531e-02,  8.0054e-03,\n",
      "          2.3483e-02, -3.2292e-02, -1.9317e-02, -1.9811e-01, -1.1309e-01,\n",
      "         -1.4945e-01,  2.1550e-01,  4.3065e-02, -2.2211e-01, -1.5707e-01,\n",
      "          2.2075e-01, -1.6554e-02, -2.0668e-01, -2.1076e-01,  7.0078e-02],\n",
      "        [-3.7958e-02,  1.6823e-03,  1.3619e-02, -6.0301e-02,  2.2051e-01,\n",
      "         -2.6573e-02,  1.1397e-01,  1.3294e-02,  1.6730e-02,  6.6348e-02,\n",
      "          1.3035e-01,  8.3913e-02,  5.9365e-02,  5.6902e-02,  1.3114e-01,\n",
      "         -1.6674e-01, -1.0854e-01, -1.8137e-01, -1.1698e-01,  1.2716e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0057, -0.0598,  0.1123,  0.1977, -0.0756,  0.0539,  0.1229,  0.1798,\n",
      "        -0.2182,  0.0711,  0.1906,  0.1750, -0.0811, -0.0786,  0.0871,  0.0980,\n",
      "         0.1403, -0.1817, -0.2045,  0.0898], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0646, -0.0721, -0.1548,  0.1526,  0.1233,  0.0537,  0.1552, -0.2159,\n",
      "         -0.1527,  0.1459,  0.1912, -0.0381,  0.1696, -0.0361,  0.0246, -0.1063,\n",
      "         -0.1307,  0.0519,  0.0332,  0.0013],\n",
      "        [ 0.0910,  0.1442, -0.0456,  0.1123,  0.1884,  0.1150, -0.0966,  0.0028,\n",
      "         -0.1002, -0.1616, -0.0696,  0.1174,  0.0369, -0.1004,  0.0499, -0.0845,\n",
      "          0.1658,  0.1685, -0.1923,  0.1718],\n",
      "        [ 0.2077, -0.1028,  0.1017,  0.1424, -0.0537, -0.1470, -0.0363, -0.1935,\n",
      "         -0.1202, -0.1186,  0.1232,  0.1877, -0.1053,  0.0764,  0.1360,  0.1027,\n",
      "          0.1343, -0.0609,  0.2012, -0.0866],\n",
      "        [ 0.0772, -0.2026,  0.1256, -0.0598,  0.1699, -0.0426,  0.1195, -0.0207,\n",
      "         -0.1389, -0.1713,  0.0948,  0.1682, -0.1822, -0.1693,  0.1704,  0.1331,\n",
      "          0.1279,  0.0526, -0.1256, -0.0023],\n",
      "        [-0.2180,  0.2121,  0.0136, -0.1398, -0.0084,  0.1068, -0.2121, -0.0422,\n",
      "          0.1077, -0.0327, -0.1727, -0.1964, -0.0386,  0.0387,  0.0445,  0.0083,\n",
      "         -0.1416, -0.1683, -0.1369, -0.0600],\n",
      "        [ 0.1621,  0.1318, -0.2184, -0.2059, -0.0307, -0.1528, -0.1474,  0.0023,\n",
      "          0.1949,  0.0038,  0.1190, -0.0024,  0.0779, -0.2168, -0.2083, -0.2200,\n",
      "          0.2092, -0.1831,  0.1567, -0.0321],\n",
      "        [-0.1989, -0.1149,  0.1582,  0.1627, -0.2218,  0.0419, -0.0040,  0.1647,\n",
      "          0.1007, -0.1302,  0.0355,  0.0415,  0.0897,  0.0116, -0.1325,  0.0280,\n",
      "          0.0209, -0.0165, -0.0487, -0.1255],\n",
      "        [ 0.1800,  0.0189,  0.1910, -0.1280,  0.1943, -0.1428,  0.1649, -0.1013,\n",
      "          0.0987,  0.2188, -0.2230,  0.1678,  0.0236, -0.1307,  0.0551,  0.1458,\n",
      "         -0.0245, -0.0921, -0.2209,  0.1735],\n",
      "        [-0.0153, -0.0764, -0.1721,  0.2123, -0.1723, -0.1695,  0.1341,  0.0824,\n",
      "         -0.1525, -0.0578,  0.1101,  0.2141, -0.0052,  0.1862,  0.1932,  0.0768,\n",
      "          0.0787, -0.1732,  0.0617, -0.0343],\n",
      "        [ 0.1745,  0.0037,  0.0552, -0.0365, -0.0015, -0.0115, -0.1204, -0.0883,\n",
      "         -0.1856,  0.1277, -0.1447, -0.0782, -0.1402, -0.0902, -0.1117,  0.1823,\n",
      "          0.0519, -0.0899,  0.0509, -0.1358],\n",
      "        [ 0.1139, -0.0864, -0.1654, -0.0688, -0.2228, -0.1910,  0.2025, -0.2045,\n",
      "         -0.0917,  0.1849,  0.0666,  0.0115, -0.0935, -0.2055,  0.0541,  0.0675,\n",
      "         -0.2001,  0.0262,  0.1070, -0.0780],\n",
      "        [ 0.0400, -0.0265,  0.1378,  0.0095, -0.0337, -0.0658,  0.1472, -0.0590,\n",
      "         -0.2186,  0.0921, -0.1103, -0.1681,  0.1516,  0.0371, -0.1471, -0.1000,\n",
      "         -0.0938, -0.0648,  0.0725, -0.1000],\n",
      "        [ 0.0877, -0.0749,  0.1283, -0.1689, -0.0317,  0.0917, -0.2071, -0.0055,\n",
      "         -0.1421, -0.1377,  0.1169, -0.1307,  0.2215, -0.0348, -0.2203,  0.1030,\n",
      "          0.0175, -0.1375,  0.2208, -0.1953],\n",
      "        [ 0.0805,  0.1312, -0.0663, -0.1993, -0.1296,  0.1949,  0.0232, -0.0587,\n",
      "          0.1254,  0.1315,  0.0420, -0.1001, -0.1265, -0.0719, -0.0800,  0.2013,\n",
      "          0.0797, -0.1370,  0.1943, -0.1662],\n",
      "        [-0.1174,  0.1307,  0.1813,  0.1359,  0.1758,  0.1200,  0.1798,  0.0960,\n",
      "         -0.1971,  0.1928, -0.2231,  0.2078,  0.1799, -0.1504, -0.1164, -0.1835,\n",
      "          0.0552,  0.1580, -0.0618, -0.1324],\n",
      "        [-0.1053, -0.0751, -0.0245,  0.0852, -0.1554,  0.1100, -0.1968,  0.1980,\n",
      "          0.1980, -0.1584,  0.1051,  0.0319,  0.0328, -0.2041,  0.0747,  0.1838,\n",
      "         -0.0203,  0.1112,  0.1120, -0.0680],\n",
      "        [ 0.0702, -0.2185,  0.1682,  0.1625,  0.0591, -0.0813, -0.0630,  0.1700,\n",
      "         -0.0817, -0.0230, -0.1451,  0.0355,  0.1855,  0.1250, -0.0705, -0.1508,\n",
      "          0.1889,  0.0936, -0.0004,  0.0851],\n",
      "        [ 0.0493, -0.0002, -0.1561, -0.1366,  0.1566,  0.1013,  0.0824,  0.1832,\n",
      "         -0.1808, -0.1944,  0.1619, -0.1559, -0.0898, -0.1304,  0.0532, -0.0224,\n",
      "         -0.1919, -0.0117, -0.0443,  0.2072],\n",
      "        [ 0.0129,  0.1221,  0.1389,  0.1463, -0.0611,  0.0838, -0.1627, -0.0025,\n",
      "          0.0005, -0.0035,  0.0546,  0.1079,  0.1475, -0.0616, -0.0836, -0.1992,\n",
      "         -0.0912,  0.0548, -0.0157, -0.0833],\n",
      "        [ 0.1825, -0.1297, -0.1686, -0.0063,  0.0591,  0.1940,  0.1679,  0.0195,\n",
      "         -0.0156,  0.1234,  0.1840,  0.0823, -0.0955,  0.0803, -0.0233, -0.0439,\n",
      "         -0.1283,  0.1776, -0.1612,  0.0752]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1120, -0.0004,  0.1206,  0.1016, -0.1442,  0.0261,  0.0199, -0.1540,\n",
      "        -0.1543, -0.0809,  0.0125,  0.0081, -0.1433,  0.0992,  0.1761,  0.0831,\n",
      "        -0.1840,  0.2152, -0.0241, -0.0669], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0566,  0.2005,  0.1757,  0.1780, -0.2224, -0.0136,  0.0196,  0.0987,\n",
      "          0.0950, -0.1371, -0.1947, -0.0996, -0.1695,  0.0391,  0.0058, -0.1750,\n",
      "          0.0323, -0.1508, -0.0363, -0.1898],\n",
      "        [ 0.0733,  0.1803,  0.1950,  0.0671, -0.0294,  0.1234,  0.1013, -0.0253,\n",
      "          0.2179, -0.0757,  0.0842,  0.0333, -0.0292, -0.1274, -0.1712,  0.1479,\n",
      "         -0.1466,  0.0127,  0.2125, -0.0910],\n",
      "        [ 0.1224, -0.1201, -0.0243,  0.2173,  0.1529, -0.1220, -0.1401,  0.0251,\n",
      "         -0.0424, -0.2167,  0.2131, -0.1293,  0.1346,  0.0361,  0.1775,  0.1300,\n",
      "         -0.0423,  0.1122, -0.2099, -0.1102],\n",
      "        [ 0.0527, -0.1130, -0.1604,  0.0797, -0.1450, -0.2075,  0.1315,  0.1668,\n",
      "          0.1215,  0.0674, -0.0697,  0.1209, -0.1960,  0.0823,  0.1416, -0.1859,\n",
      "         -0.0443,  0.0164,  0.0673, -0.0519],\n",
      "        [-0.0979, -0.0122, -0.0200, -0.1235,  0.2226, -0.0357,  0.0142,  0.1504,\n",
      "         -0.0784,  0.1071, -0.1086,  0.0986,  0.0812, -0.1529, -0.1673, -0.0587,\n",
      "          0.1742,  0.0952,  0.1539,  0.1337],\n",
      "        [ 0.1601, -0.1525,  0.0980, -0.1379,  0.1821,  0.0157,  0.0728,  0.0489,\n",
      "         -0.0359,  0.1932, -0.1517,  0.2037,  0.1368,  0.1554,  0.0531,  0.0693,\n",
      "         -0.1533,  0.0169, -0.0389, -0.2142],\n",
      "        [ 0.1292,  0.0252,  0.1202,  0.1380,  0.2070,  0.2145, -0.1543, -0.1337,\n",
      "          0.1743,  0.1049,  0.0895,  0.0365, -0.0520, -0.0686, -0.1039,  0.0505,\n",
      "          0.1796,  0.0940,  0.1909, -0.1226],\n",
      "        [-0.0910, -0.0335,  0.2227, -0.2091,  0.1592,  0.0662,  0.0303, -0.0470,\n",
      "          0.1180,  0.0548, -0.1587, -0.1574, -0.2029,  0.1150, -0.0818, -0.0927,\n",
      "         -0.1650, -0.1197, -0.2185,  0.0716],\n",
      "        [-0.1542, -0.2069, -0.1868,  0.0128,  0.0499,  0.1807, -0.0077, -0.1355,\n",
      "         -0.0243, -0.0903, -0.0881,  0.0895, -0.2024, -0.2082,  0.0381, -0.0951,\n",
      "          0.2076,  0.0792,  0.2232,  0.1020],\n",
      "        [-0.2050, -0.2187, -0.1194,  0.1927, -0.1772, -0.1607, -0.0597, -0.0928,\n",
      "         -0.0907, -0.1638, -0.0119, -0.2120,  0.0211,  0.0192,  0.2125,  0.0816,\n",
      "         -0.1423, -0.0815,  0.1867, -0.0822],\n",
      "        [ 0.1791,  0.1011,  0.1161, -0.0819,  0.2201, -0.1041,  0.1362,  0.0446,\n",
      "          0.1949, -0.0959, -0.1176,  0.1158, -0.1159,  0.0850, -0.0971,  0.0103,\n",
      "         -0.1585,  0.1639,  0.1487,  0.1011],\n",
      "        [-0.0014,  0.1410, -0.1032,  0.0263,  0.1870, -0.1101,  0.1428, -0.1452,\n",
      "         -0.1693,  0.2127,  0.2198,  0.1098, -0.0285,  0.1304,  0.1057,  0.0876,\n",
      "          0.0159,  0.1686,  0.1514, -0.0037],\n",
      "        [-0.1126, -0.0339,  0.0067, -0.0147,  0.1063, -0.0153, -0.0971, -0.1987,\n",
      "         -0.1319,  0.1026,  0.1282, -0.1937, -0.1784,  0.0315, -0.0082,  0.0879,\n",
      "          0.0501,  0.0597, -0.1491,  0.0761],\n",
      "        [ 0.0932, -0.1280, -0.1911,  0.1508,  0.0499, -0.1041,  0.1569, -0.0602,\n",
      "         -0.0909, -0.1333,  0.1650, -0.0869, -0.1439,  0.1153,  0.1684, -0.0888,\n",
      "         -0.0798, -0.0045,  0.2017, -0.1930],\n",
      "        [-0.2182, -0.1983, -0.0514, -0.0851,  0.0385,  0.0248,  0.0708,  0.0241,\n",
      "         -0.0362, -0.1121, -0.0513, -0.2114,  0.0597,  0.0029, -0.0473,  0.0999,\n",
      "          0.0559, -0.1581, -0.0777,  0.1846],\n",
      "        [ 0.0687, -0.1411,  0.0039, -0.1233, -0.0621, -0.0750, -0.1373, -0.0570,\n",
      "          0.1948, -0.1609, -0.0474,  0.1636, -0.1671,  0.1010,  0.0352,  0.1208,\n",
      "         -0.1121,  0.0653, -0.1250, -0.0196],\n",
      "        [ 0.1527, -0.0973, -0.1610,  0.1559, -0.0379, -0.2174,  0.0691, -0.1558,\n",
      "         -0.2019, -0.0654, -0.2009, -0.1589,  0.0835, -0.2208, -0.0556,  0.2138,\n",
      "         -0.0632,  0.0462,  0.1458,  0.1560],\n",
      "        [-0.1262, -0.0924, -0.1597, -0.1469,  0.1593,  0.0387,  0.0881,  0.0900,\n",
      "         -0.2216, -0.0888,  0.0919,  0.0834, -0.0376, -0.0528, -0.1928,  0.1305,\n",
      "         -0.0888,  0.0966, -0.2016,  0.1897],\n",
      "        [ 0.1492,  0.0502,  0.1498, -0.1271, -0.1480, -0.2215,  0.2189, -0.0390,\n",
      "          0.0711, -0.1643, -0.0293, -0.1212,  0.0158,  0.1279,  0.0310,  0.1393,\n",
      "         -0.1849, -0.1255, -0.0797,  0.1268],\n",
      "        [ 0.1899, -0.0599,  0.2206,  0.2035,  0.2200,  0.1951,  0.0810,  0.1325,\n",
      "          0.1464,  0.1099,  0.1860, -0.2225,  0.0796, -0.0856,  0.0237, -0.0208,\n",
      "         -0.1482, -0.0355, -0.0431, -0.0586]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1183, -0.1249,  0.1847,  0.0470,  0.2064,  0.0450, -0.2178, -0.0207,\n",
      "         0.1932,  0.1763,  0.0698,  0.1041, -0.0084,  0.0744, -0.2181,  0.0446,\n",
      "        -0.1945, -0.1087, -0.0801,  0.1027], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1617, -0.1369,  0.1044, -0.1459, -0.1927, -0.1213,  0.1974,  0.2117,\n",
      "         -0.0901, -0.0617,  0.1201, -0.1257, -0.1873,  0.1800, -0.0380, -0.1554,\n",
      "         -0.1029, -0.0391,  0.0103, -0.1247],\n",
      "        [-0.2231, -0.0888, -0.0961, -0.0229,  0.1687,  0.0203, -0.0004,  0.0012,\n",
      "          0.0157, -0.0923,  0.1179,  0.1529, -0.2035,  0.1352,  0.0673, -0.1028,\n",
      "          0.1469,  0.0021,  0.2160, -0.1134],\n",
      "        [ 0.0193,  0.1663,  0.0157, -0.0730,  0.0973, -0.1720,  0.0297, -0.0460,\n",
      "          0.0928,  0.1787, -0.0469, -0.0251, -0.1595,  0.0622, -0.0637,  0.0906,\n",
      "          0.0308,  0.1896,  0.1798, -0.1122],\n",
      "        [-0.0481, -0.0715,  0.2136, -0.0694, -0.0383, -0.2012,  0.2138, -0.0986,\n",
      "          0.1291, -0.1882, -0.0944, -0.1001,  0.1555,  0.2186,  0.1495, -0.0556,\n",
      "          0.0691,  0.1333,  0.1176, -0.1164],\n",
      "        [-0.2128,  0.0308,  0.1738, -0.1781, -0.1242, -0.2088, -0.0351,  0.1126,\n",
      "         -0.0692,  0.1158,  0.0283,  0.1727, -0.0201, -0.2043,  0.2123,  0.0185,\n",
      "         -0.0997, -0.1087, -0.1164,  0.1268],\n",
      "        [-0.0755, -0.0616, -0.2198, -0.0840, -0.1731, -0.2074,  0.0698,  0.1188,\n",
      "          0.0275, -0.1275, -0.1528,  0.0111, -0.1834,  0.0700, -0.2098,  0.0257,\n",
      "         -0.0313, -0.1129, -0.1916,  0.1098],\n",
      "        [-0.1953,  0.1909, -0.1346,  0.1102, -0.0435, -0.2111,  0.0438, -0.0358,\n",
      "         -0.0382,  0.0343,  0.1592,  0.1419, -0.1202, -0.1873, -0.1072,  0.0073,\n",
      "          0.0414, -0.0594,  0.1145, -0.0013],\n",
      "        [-0.1319,  0.0151, -0.1649,  0.0789,  0.1663,  0.0883, -0.0746,  0.0624,\n",
      "         -0.0231, -0.1013, -0.2151,  0.2052,  0.2020, -0.2214, -0.1692,  0.1110,\n",
      "          0.1804, -0.0650, -0.0526, -0.0866],\n",
      "        [-0.0032,  0.0717, -0.0493, -0.1889,  0.1889,  0.1619,  0.1787,  0.1020,\n",
      "         -0.1268, -0.0200, -0.0022, -0.0117,  0.0446,  0.0730, -0.2030, -0.0587,\n",
      "          0.0156,  0.1628,  0.1242, -0.0799],\n",
      "        [ 0.1167,  0.1594, -0.1285, -0.1211,  0.0089, -0.1081,  0.0216,  0.0400,\n",
      "          0.1549,  0.1753,  0.1287,  0.2115, -0.0754,  0.0742, -0.2041, -0.0791,\n",
      "          0.1000, -0.0446,  0.1477,  0.0550],\n",
      "        [-0.0630, -0.1437, -0.0925,  0.0213, -0.0140, -0.1444, -0.1407, -0.1058,\n",
      "         -0.2234,  0.0090,  0.0987,  0.1847,  0.2068, -0.1913,  0.1973,  0.2182,\n",
      "          0.1073, -0.2027, -0.0376,  0.1435],\n",
      "        [ 0.0460, -0.2145,  0.1808,  0.1944,  0.0155,  0.0693,  0.0893,  0.0637,\n",
      "          0.0456,  0.1798, -0.0381,  0.1749, -0.0940, -0.0484,  0.0272,  0.1226,\n",
      "          0.2158, -0.0325,  0.2187, -0.1655],\n",
      "        [-0.2149, -0.1710,  0.1678, -0.1601,  0.1428,  0.1224,  0.2222,  0.0730,\n",
      "          0.1859,  0.1471, -0.1680,  0.2167,  0.0703, -0.2113,  0.1319, -0.0437,\n",
      "         -0.0011,  0.0171, -0.0207, -0.1300],\n",
      "        [-0.1769,  0.0759, -0.2094,  0.0854, -0.0511,  0.0860, -0.1108,  0.2082,\n",
      "         -0.2125,  0.2070, -0.0452,  0.2219, -0.1240,  0.0501,  0.1254, -0.2050,\n",
      "          0.0623,  0.0228,  0.0191,  0.1252],\n",
      "        [-0.1858,  0.0344, -0.1513, -0.0417, -0.0489, -0.0406, -0.1300,  0.0331,\n",
      "          0.0040,  0.0158,  0.0513, -0.1666, -0.0917, -0.1031, -0.1876, -0.0904,\n",
      "         -0.1059,  0.1428,  0.2121, -0.0143],\n",
      "        [ 0.1870,  0.1485,  0.0191,  0.1701, -0.1989, -0.2028, -0.0259, -0.1138,\n",
      "         -0.1009,  0.1086,  0.0447,  0.1773, -0.1748,  0.0067, -0.0062,  0.0697,\n",
      "          0.2020,  0.2160,  0.2149,  0.0121],\n",
      "        [ 0.1353, -0.1411, -0.1634, -0.1349, -0.1698, -0.0914,  0.2123,  0.1739,\n",
      "          0.0323, -0.0241, -0.1434,  0.0411,  0.1014, -0.1047, -0.2071,  0.1144,\n",
      "          0.1117, -0.0545, -0.2037, -0.0509],\n",
      "        [ 0.1169,  0.0661, -0.0676,  0.1032,  0.0876,  0.2115, -0.0127,  0.0885,\n",
      "         -0.1423, -0.1883, -0.1205, -0.2157,  0.0517,  0.0749, -0.0656, -0.1308,\n",
      "          0.0075,  0.0764,  0.1274, -0.0178],\n",
      "        [-0.1998,  0.1718, -0.1562, -0.0219,  0.1289, -0.1728,  0.1516,  0.1754,\n",
      "         -0.1173,  0.0143,  0.0703, -0.0804,  0.1823,  0.0775,  0.0232, -0.0910,\n",
      "         -0.0156, -0.1625, -0.0764, -0.1206],\n",
      "        [-0.1784, -0.1374, -0.1063,  0.1783,  0.0777,  0.0444,  0.0326,  0.1308,\n",
      "          0.1995,  0.0020, -0.0363,  0.1564, -0.2139, -0.1048,  0.1149,  0.1286,\n",
      "          0.1850,  0.1636, -0.1331, -0.1301]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1240, -0.0093, -0.1869,  0.1325,  0.0653,  0.0934,  0.0770,  0.1029,\n",
      "         0.0417,  0.0706,  0.1452,  0.0367,  0.0041,  0.1666, -0.0850, -0.0896,\n",
      "        -0.2016, -0.1257,  0.1394, -0.1532], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1189, -0.0248,  0.1910,  0.0688, -0.2089, -0.1570,  0.1495, -0.1941,\n",
      "         -0.1664, -0.2209,  0.1707,  0.2089,  0.0560,  0.0792,  0.0679, -0.2175,\n",
      "          0.2141, -0.1945,  0.0457,  0.2090],\n",
      "        [ 0.1317,  0.0024, -0.0216,  0.0767,  0.0557, -0.2128, -0.1299, -0.0093,\n",
      "         -0.0247, -0.1161,  0.0074, -0.2000,  0.0501, -0.1839,  0.2104,  0.0391,\n",
      "         -0.0927,  0.1672, -0.1003,  0.1167],\n",
      "        [-0.1983,  0.1939,  0.1957,  0.1176,  0.0361, -0.1450,  0.1361, -0.0442,\n",
      "          0.0588, -0.1665, -0.1090, -0.1395,  0.0670, -0.1453,  0.2224,  0.0311,\n",
      "          0.1771, -0.0659, -0.1272, -0.1532],\n",
      "        [-0.2168, -0.2110, -0.0621,  0.1917,  0.1478,  0.0250, -0.0168, -0.1943,\n",
      "          0.1956, -0.1213,  0.1231, -0.0596, -0.1354, -0.1164,  0.2193,  0.0765,\n",
      "         -0.2228, -0.0516, -0.1299,  0.0465],\n",
      "        [ 0.1217,  0.1988, -0.1598, -0.0996, -0.0755,  0.2180,  0.0287,  0.0807,\n",
      "         -0.0242,  0.0712, -0.1804, -0.0619, -0.1832, -0.0226,  0.0705,  0.0331,\n",
      "         -0.0462,  0.0770,  0.0625, -0.1984],\n",
      "        [ 0.1358,  0.1320,  0.1988,  0.0573,  0.0388, -0.1926,  0.1559,  0.0209,\n",
      "         -0.0666,  0.1878,  0.1826, -0.2183,  0.0464, -0.0850,  0.2129, -0.2133,\n",
      "         -0.2197, -0.0901, -0.1372,  0.2080],\n",
      "        [-0.0813, -0.0756, -0.1372,  0.0662, -0.1207,  0.2145,  0.1673, -0.1689,\n",
      "         -0.0055, -0.0159,  0.2235, -0.1657, -0.1411,  0.0562, -0.0895,  0.1942,\n",
      "         -0.1532,  0.0009, -0.1540, -0.0291],\n",
      "        [ 0.1076, -0.1428, -0.0965,  0.1941, -0.1765,  0.1148, -0.0790,  0.1118,\n",
      "         -0.1200, -0.0107, -0.1505,  0.0954, -0.1923, -0.0958,  0.1703, -0.0523,\n",
      "          0.0107, -0.0573,  0.0379, -0.0148],\n",
      "        [ 0.0028, -0.0825, -0.2172, -0.0680, -0.2139, -0.0566,  0.2156,  0.1749,\n",
      "         -0.0873,  0.1199,  0.1404, -0.0683, -0.1899, -0.0916, -0.1536,  0.0645,\n",
      "          0.0983, -0.0554,  0.1441,  0.1549],\n",
      "        [ 0.1174, -0.0063, -0.1649,  0.0809, -0.0323, -0.0468,  0.0899,  0.0536,\n",
      "          0.1409, -0.2157,  0.0897,  0.1520, -0.0136,  0.0954,  0.1701, -0.1703,\n",
      "          0.0569,  0.2035, -0.0273, -0.0831]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0925,  0.0789,  0.0740, -0.1863,  0.1684,  0.0564, -0.1642, -0.0364,\n",
      "         0.0940, -0.0068], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-2.3303e-01, -1.0504e-01,  2.3415e-01, -1.2545e-01, -5.8529e-02,\n",
      "          4.8956e-02, -5.0496e-02,  2.4670e-01,  1.7252e-01,  6.3334e-02],\n",
      "        [-9.1946e-02,  2.7015e-01,  2.0282e-01,  1.2316e-01,  2.2286e-01,\n",
      "          7.3165e-03,  1.0087e-01, -2.1977e-01,  1.5425e-02, -2.3202e-01],\n",
      "        [-2.0974e-01,  3.1536e-01, -2.6399e-01,  1.7396e-02, -7.3562e-02,\n",
      "          1.8599e-01, -4.7203e-02, -2.7834e-01,  1.3393e-01,  5.1878e-02],\n",
      "        [-3.0059e-01, -2.2787e-04,  8.4423e-02,  2.5373e-01, -1.4981e-01,\n",
      "          1.3182e-01, -2.4056e-01, -1.0118e-01,  1.0584e-01, -2.5296e-01],\n",
      "        [ 2.5052e-01, -5.2539e-02, -2.1223e-01, -1.4110e-01, -3.0636e-01,\n",
      "         -2.3927e-01,  1.3664e-01,  4.1039e-02, -1.9802e-01, -1.6166e-01],\n",
      "        [ 2.1342e-01,  2.1734e-01,  2.8483e-01,  2.1529e-01, -1.3197e-01,\n",
      "          2.5576e-01, -1.0115e-01, -1.8775e-02, -3.0254e-01, -2.4488e-01],\n",
      "        [-1.5760e-01, -1.4407e-01, -1.5252e-01,  1.2256e-01, -4.0981e-03,\n",
      "         -4.4744e-02,  6.9500e-02,  9.6124e-02, -2.0318e-01, -1.4160e-01],\n",
      "        [ 6.4325e-02,  1.6015e-01, -1.6232e-01,  1.6340e-01, -2.6335e-01,\n",
      "          2.7486e-01, -2.6861e-01,  2.6659e-01, -3.0972e-01,  1.6203e-01],\n",
      "        [-3.0477e-02, -1.7579e-01, -1.1003e-02, -9.0675e-02,  1.3849e-01,\n",
      "          9.5393e-02,  3.0766e-01, -4.9881e-02, -1.4509e-01,  2.3502e-01],\n",
      "        [ 2.9075e-01, -1.6221e-01, -9.5864e-02,  2.9390e-01, -5.7426e-02,\n",
      "         -2.4179e-01, -9.1937e-02,  5.9804e-02,  2.8473e-02, -1.8886e-01],\n",
      "        [ 1.5249e-01,  2.3897e-01, -2.5073e-01, -1.9611e-01,  1.2811e-01,\n",
      "         -3.3453e-02,  1.2982e-01,  3.4756e-02, -1.1168e-01,  3.0653e-01],\n",
      "        [ 1.2234e-01,  1.0676e-01,  9.9984e-02, -2.5689e-01, -6.1342e-02,\n",
      "         -1.0649e-01, -1.0447e-01, -1.8146e-01, -3.0735e-01,  2.4099e-01],\n",
      "        [-2.6283e-01,  6.3605e-02,  6.8558e-02,  2.3902e-01,  2.7378e-01,\n",
      "          9.8451e-02, -2.1954e-01, -1.6407e-01, -1.3123e-01,  2.4324e-01],\n",
      "        [-7.2305e-03, -2.4157e-01,  5.8889e-04, -2.2759e-03, -6.8241e-02,\n",
      "          1.7647e-01, -2.2272e-01,  1.9271e-02,  2.8330e-01,  1.7602e-01],\n",
      "        [-5.3117e-02, -4.1031e-03,  2.1707e-01,  9.6394e-02, -1.3640e-01,\n",
      "         -6.3354e-02, -2.9608e-01, -1.3973e-01,  1.4172e-01, -2.2256e-01],\n",
      "        [-2.7946e-01, -9.9653e-02, -1.5351e-02,  2.0736e-01,  2.9313e-03,\n",
      "         -1.8329e-01, -3.6258e-02, -3.2959e-02,  2.4243e-01,  1.2576e-01],\n",
      "        [ 6.9220e-02, -1.8670e-01,  5.3978e-02, -1.5060e-01, -4.6999e-02,\n",
      "          2.6249e-01, -1.2691e-01, -2.5967e-01,  2.6998e-01,  5.6529e-02],\n",
      "        [-8.0287e-02,  6.0135e-02, -4.5656e-02, -1.2401e-01,  2.8329e-01,\n",
      "         -5.4355e-02,  2.6564e-01, -1.6856e-01, -1.8448e-01,  9.8570e-02],\n",
      "        [-1.5664e-01,  2.8430e-01,  2.1785e-01,  1.6496e-01,  2.5566e-01,\n",
      "          7.0857e-03,  1.5090e-01,  2.2146e-01, -1.7688e-01,  6.2860e-02],\n",
      "        [-3.0756e-01,  7.6838e-02, -1.8602e-01, -1.2961e-01,  3.6468e-02,\n",
      "          2.0812e-01,  2.5153e-01,  1.9447e-01, -2.6644e-01, -6.3670e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0327, -0.0539, -0.2957, -0.2985,  0.2558,  0.2096, -0.1527,  0.1419,\n",
      "         0.2769,  0.3054, -0.1337,  0.0805,  0.1323,  0.1017, -0.1549,  0.2871,\n",
      "         0.0409,  0.1889,  0.0967, -0.2675], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1525,  0.1841, -0.2726, -0.1080,  0.0515,  0.0493, -0.3142, -0.2477,\n",
      "          0.2744,  0.0062],\n",
      "        [-0.2673,  0.1300, -0.2097,  0.2123, -0.2030, -0.2373, -0.2787, -0.1887,\n",
      "          0.1159, -0.1731],\n",
      "        [-0.0708, -0.1537, -0.0758,  0.0204,  0.2949,  0.2007,  0.2863, -0.1194,\n",
      "         -0.3017,  0.0235],\n",
      "        [-0.0087,  0.1303, -0.1009,  0.2784, -0.0934, -0.2651,  0.1238,  0.2270,\n",
      "         -0.0162,  0.2379],\n",
      "        [ 0.1996,  0.1703,  0.0173,  0.1613,  0.2445, -0.2103,  0.2767,  0.0103,\n",
      "          0.2062, -0.1768],\n",
      "        [ 0.1247,  0.0119, -0.3119,  0.1181,  0.0112, -0.1463, -0.1149, -0.0516,\n",
      "         -0.3137,  0.1897],\n",
      "        [ 0.1930, -0.0730,  0.1127, -0.1804, -0.0563, -0.1926,  0.0904,  0.1510,\n",
      "         -0.2101,  0.2700],\n",
      "        [-0.2285,  0.2155,  0.0537, -0.0281, -0.1973, -0.2899, -0.0123,  0.2939,\n",
      "         -0.1185, -0.1523],\n",
      "        [-0.1902,  0.2888,  0.2280,  0.2239, -0.0101,  0.1815, -0.0514,  0.1385,\n",
      "         -0.0252,  0.0885],\n",
      "        [ 0.0594, -0.1896, -0.0158, -0.2207, -0.3144,  0.0654,  0.1582, -0.3060,\n",
      "         -0.2553, -0.1838]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1815,  0.2583,  0.1088,  0.1394, -0.1567, -0.0304, -0.0980,  0.2541,\n",
      "         0.1815, -0.0290], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-2.4807e-01, -1.7050e-01,  3.5457e-02,  1.0805e-01,  1.4145e-02,\n",
      "          3.0039e-01, -3.0449e-01,  2.7702e-01,  1.2393e-02, -7.4869e-03],\n",
      "        [-3.5071e-02, -2.2856e-01, -2.9876e-01,  8.2246e-02, -6.5734e-02,\n",
      "         -1.3115e-01,  1.4805e-01,  1.9064e-01, -1.5337e-01,  1.9614e-01],\n",
      "        [ 1.7894e-01,  2.2268e-01,  2.7097e-01,  1.2119e-01, -1.8728e-01,\n",
      "          2.0339e-01, -2.1981e-01,  1.8747e-01, -3.1330e-01, -1.4596e-01],\n",
      "        [ 1.6509e-01, -2.3302e-01,  2.5229e-01, -7.4552e-03, -2.0285e-01,\n",
      "         -2.1672e-01,  2.6687e-01,  2.0933e-01, -1.3369e-02,  6.2087e-02],\n",
      "        [ 1.1684e-01, -1.0669e-01, -2.8123e-01, -9.3966e-02,  2.7845e-01,\n",
      "          2.1068e-01,  4.1871e-02, -1.4260e-01, -1.3427e-01, -1.8340e-01],\n",
      "        [-7.3080e-02,  2.0526e-01,  1.6939e-01, -1.7680e-02, -2.1925e-01,\n",
      "         -5.7260e-02,  2.4612e-01, -2.7773e-01,  4.8296e-03,  1.5317e-01],\n",
      "        [ 2.8516e-02, -1.6285e-01,  2.6482e-02, -1.2818e-01,  3.4688e-02,\n",
      "         -1.1348e-01, -3.0324e-01, -2.6707e-01,  1.4160e-01,  2.5079e-01],\n",
      "        [-2.8995e-02, -2.9008e-01,  1.4890e-01,  2.2522e-01,  3.4134e-02,\n",
      "          1.5902e-01,  2.8241e-01, -9.7752e-06, -3.1613e-01, -5.6610e-02],\n",
      "        [-1.9663e-01, -4.3336e-02,  2.8494e-01,  2.5364e-01,  2.8066e-01,\n",
      "         -1.1042e-01, -1.7759e-01, -1.4660e-01, -2.8627e-01,  2.3049e-01],\n",
      "        [-6.0857e-02,  7.3119e-02, -6.0422e-02, -2.1777e-02,  3.2504e-02,\n",
      "         -2.1048e-01, -2.6760e-01,  1.1279e-01, -3.8682e-03, -2.1742e-01],\n",
      "        [ 2.7922e-01, -2.5655e-02,  1.1768e-01, -1.1369e-02,  2.7274e-01,\n",
      "         -1.8564e-01,  1.0161e-01, -8.0454e-02,  2.3796e-01,  1.7956e-01],\n",
      "        [-2.5137e-01, -1.9190e-01, -2.2779e-01,  2.4148e-01, -1.1445e-01,\n",
      "         -2.2080e-01, -2.0495e-01, -3.6913e-02, -2.9012e-01,  7.6880e-02],\n",
      "        [ 1.9473e-01, -3.0707e-01,  7.0295e-02, -2.5063e-01, -2.4678e-01,\n",
      "          2.3860e-01,  2.6106e-01, -1.0071e-01, -6.3003e-02,  2.1992e-01],\n",
      "        [ 1.7288e-01,  8.2811e-02, -1.7335e-01,  2.6889e-01, -2.3860e-01,\n",
      "          2.1470e-01,  2.3460e-01, -1.6423e-01, -2.9132e-01, -2.6706e-01],\n",
      "        [ 2.0351e-02,  2.1771e-01, -2.9134e-01,  1.1373e-01,  1.6888e-01,\n",
      "          2.9057e-01,  1.2107e-01,  1.5427e-02,  2.5781e-01,  1.9748e-01],\n",
      "        [ 3.1857e-02,  1.4709e-01, -6.4350e-02, -1.7084e-01,  2.2433e-01,\n",
      "          1.4082e-01, -1.4402e-02,  1.9037e-01,  2.3784e-01, -5.4863e-02],\n",
      "        [ 5.2453e-02, -2.9235e-01, -1.2145e-02,  7.3265e-02, -1.5352e-02,\n",
      "         -2.9010e-01, -2.4503e-01,  5.6428e-02,  2.4489e-01, -1.4566e-01],\n",
      "        [-2.3881e-02, -1.6073e-01,  1.2259e-01,  1.7989e-01,  1.3933e-01,\n",
      "          3.1150e-01,  7.0751e-02, -5.6953e-02,  9.2370e-03, -2.6399e-01],\n",
      "        [ 3.9268e-03, -2.9114e-01,  1.7768e-01,  1.8262e-01, -1.0829e-01,\n",
      "         -2.0643e-01, -2.5455e-01,  9.1239e-02, -1.2446e-01, -2.1183e-01],\n",
      "        [-1.8643e-01, -2.4219e-01,  4.4025e-02, -2.3947e-01,  1.9970e-01,\n",
      "         -3.0194e-01, -5.0959e-02, -2.2829e-01,  8.1070e-02, -2.6042e-03]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2409,  0.2258, -0.1826, -0.1825, -0.2436,  0.2645, -0.1102, -0.1402,\n",
      "        -0.2789,  0.2635,  0.0939,  0.1380,  0.2472, -0.0193, -0.2137, -0.2882,\n",
      "         0.2103, -0.1004, -0.2882,  0.3013], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.0565e-01, -1.4356e-01, -9.5824e-02,  2.0583e-01,  2.2210e-01,\n",
      "          7.6625e-02, -1.6421e-01, -1.6042e-01, -2.5698e-02,  1.5857e-01,\n",
      "          1.1357e-01, -1.9626e-02, -9.1526e-02,  3.6672e-02,  1.9164e-01,\n",
      "         -5.9460e-02, -2.1587e-01, -9.8010e-02, -3.1305e-02,  1.1410e-01],\n",
      "        [ 8.2210e-02,  2.3108e-02, -2.0934e-01,  4.6293e-02,  1.8010e-04,\n",
      "         -7.4111e-02,  1.1167e-01, -9.8196e-02,  8.0805e-02,  4.4098e-02,\n",
      "         -2.1008e-01, -5.0569e-02,  2.1234e-01, -1.0847e-01, -8.0029e-02,\n",
      "          1.8425e-01,  1.6303e-01, -1.4832e-01, -6.4279e-02, -1.1790e-01],\n",
      "        [-1.5654e-01, -1.3660e-01,  1.0728e-01,  7.6192e-02,  1.2796e-01,\n",
      "          3.9866e-02,  1.9561e-01, -2.4404e-03, -1.0277e-01, -3.9713e-03,\n",
      "         -9.4516e-02,  1.4897e-01, -2.0908e-01,  1.6568e-01,  1.3918e-02,\n",
      "         -1.9019e-02, -8.0539e-02, -2.5664e-02, -1.2546e-01, -2.8371e-02],\n",
      "        [-1.9684e-01,  2.0649e-01, -2.1810e-02,  2.0322e-02,  1.1152e-01,\n",
      "          1.1536e-01, -1.7718e-01, -1.5801e-01, -2.1188e-01,  1.5340e-01,\n",
      "          2.1586e-01,  1.3839e-01,  1.4857e-01,  8.1448e-02,  8.6059e-03,\n",
      "          7.7252e-02, -1.8307e-02, -1.0556e-01,  1.6602e-01,  2.5077e-03],\n",
      "        [-7.5823e-02,  1.6083e-01,  1.8779e-01, -1.4202e-01,  2.0873e-01,\n",
      "          1.1587e-01,  2.0518e-01,  1.7509e-01,  2.1402e-02,  2.1066e-01,\n",
      "         -5.7711e-02,  8.5657e-03, -1.9480e-01,  1.7324e-01,  1.7153e-01,\n",
      "         -4.2277e-02, -2.0119e-03, -1.8166e-01,  2.0972e-01, -1.6811e-02],\n",
      "        [ 9.8396e-03, -1.5812e-01,  1.4324e-01,  1.0425e-01, -1.2487e-01,\n",
      "         -1.7546e-01, -1.7664e-01, -1.4044e-01,  1.5199e-01,  1.7826e-02,\n",
      "         -2.0833e-01,  2.0879e-01,  6.1815e-02,  2.1863e-01,  6.9340e-02,\n",
      "         -7.0157e-02, -1.1786e-01,  5.2999e-02, -2.1589e-01,  2.0420e-01],\n",
      "        [ 1.4688e-01,  1.4315e-01, -2.0936e-01,  6.4312e-02,  2.1877e-01,\n",
      "          5.0455e-02,  1.9806e-01,  1.8757e-01,  2.0541e-01, -5.1020e-02,\n",
      "         -1.1005e-01,  1.1113e-01,  1.0733e-01,  7.6333e-02, -2.8946e-02,\n",
      "         -3.2163e-02,  1.5164e-01, -6.2794e-02, -7.3826e-02, -7.4685e-02],\n",
      "        [ 1.6631e-01, -1.9165e-01, -1.4531e-01,  7.1336e-02, -3.9859e-02,\n",
      "          2.1496e-01, -1.0297e-01, -1.4086e-01, -1.3132e-01, -6.7781e-02,\n",
      "         -1.7713e-01,  1.3292e-01,  1.8102e-01,  1.2802e-01,  5.5051e-02,\n",
      "         -1.5719e-01,  1.0492e-01, -2.0718e-01,  7.3584e-02,  1.9829e-01],\n",
      "        [ 5.8246e-03, -8.9397e-02, -7.7026e-02,  2.7380e-02, -6.8070e-02,\n",
      "         -4.9391e-02,  1.0547e-01,  8.3464e-02,  1.0179e-01,  1.4122e-01,\n",
      "          1.6448e-01,  1.5629e-01,  9.4726e-02,  9.1456e-02, -2.5438e-02,\n",
      "         -1.0107e-01, -2.2064e-01, -5.1968e-02, -1.7818e-01, -4.3997e-02],\n",
      "        [ 1.1234e-01,  2.2431e-02,  1.2961e-01, -5.1350e-02,  2.1191e-01,\n",
      "          1.8246e-01, -1.6483e-01, -2.7571e-02, -2.0329e-01, -2.0603e-01,\n",
      "         -1.1798e-01, -1.0498e-01, -1.0357e-01,  1.3749e-01,  1.9885e-01,\n",
      "         -2.0375e-01,  1.0279e-01,  1.7525e-01, -1.1114e-01, -7.8997e-02],\n",
      "        [-1.8150e-01,  1.7924e-01,  5.4554e-02, -1.3325e-01,  8.0861e-02,\n",
      "         -1.1831e-01, -2.2206e-01, -9.0125e-02, -2.5219e-02, -1.2264e-01,\n",
      "         -3.1249e-02,  6.4559e-02,  1.7215e-01,  1.4033e-01, -1.6370e-01,\n",
      "         -1.5255e-01,  7.5517e-02,  1.7203e-01,  2.1601e-01, -2.0773e-01],\n",
      "        [-2.0710e-02, -6.9112e-02, -3.0801e-02,  2.0017e-01, -8.4947e-02,\n",
      "          1.2376e-03, -1.1383e-01,  1.9612e-02, -1.0805e-01, -2.9731e-02,\n",
      "          2.1805e-01, -1.3153e-01,  2.0836e-01,  1.6446e-01,  1.9570e-01,\n",
      "         -1.3396e-01,  1.1728e-01, -9.5316e-02,  1.6648e-01, -1.0095e-02],\n",
      "        [-6.7020e-02, -1.7903e-01,  2.2893e-02, -2.2258e-03,  9.7182e-02,\n",
      "          1.9171e-01, -1.4631e-01,  1.9434e-01,  1.3101e-01,  1.7363e-01,\n",
      "         -1.7956e-01, -2.1423e-01,  4.3243e-02,  1.4766e-02, -1.0652e-01,\n",
      "         -1.1608e-01, -2.1310e-01, -1.9839e-01,  9.9012e-02,  9.1709e-02],\n",
      "        [-1.2551e-01,  1.8687e-01,  3.0726e-02, -2.0976e-01, -9.9270e-02,\n",
      "         -7.1524e-02, -1.4713e-01, -1.6350e-01,  1.6665e-01, -1.2499e-02,\n",
      "         -1.9573e-02, -2.0158e-01,  1.3044e-01, -8.5696e-02, -1.5769e-01,\n",
      "         -2.9393e-02,  2.1286e-01, -2.7599e-02, -1.3156e-01, -1.5821e-02],\n",
      "        [-2.1891e-01, -1.2309e-01, -6.7142e-02,  2.9845e-02,  4.0866e-02,\n",
      "         -1.2168e-01,  6.3500e-02, -4.8071e-02,  1.9145e-01,  1.2858e-01,\n",
      "         -7.4762e-02, -1.3164e-01, -1.4912e-02,  5.5978e-02, -1.8750e-01,\n",
      "         -2.0362e-01, -8.5750e-02, -2.0562e-01,  1.2022e-01,  9.9319e-02],\n",
      "        [-1.4253e-01,  2.2406e-02, -1.3709e-01,  1.7911e-01, -1.9608e-01,\n",
      "          1.4143e-01, -3.4945e-02,  1.3740e-01, -2.3891e-02,  1.3158e-01,\n",
      "          2.1284e-01,  1.3769e-03, -4.8873e-02, -1.9537e-01, -1.4964e-01,\n",
      "          7.6518e-03, -1.7628e-01, -1.1463e-01, -2.0162e-01, -1.8348e-01],\n",
      "        [ 1.8237e-01,  1.5736e-01, -1.1114e-01, -2.1238e-01, -4.4854e-02,\n",
      "         -1.1487e-01, -4.1392e-02,  4.5414e-02, -1.9564e-01,  1.6127e-01,\n",
      "          8.6685e-02, -1.4725e-01,  2.1994e-01,  4.8537e-02,  2.2125e-01,\n",
      "         -1.5630e-01, -1.7324e-01, -1.7596e-01, -2.2087e-01,  2.0284e-01],\n",
      "        [ 1.8155e-01, -1.0593e-01,  1.7053e-01,  6.3793e-04, -5.8949e-02,\n",
      "          1.2466e-01, -1.6024e-01,  1.2125e-01, -4.3612e-02, -1.8672e-01,\n",
      "         -1.7836e-01,  1.8941e-01,  1.3118e-01, -1.8129e-01,  1.2796e-01,\n",
      "         -9.5061e-02, -5.3257e-02,  1.2417e-01,  8.1443e-02, -1.5755e-01],\n",
      "        [-6.4867e-02, -1.3019e-01, -8.1144e-02,  2.0207e-01, -1.5614e-01,\n",
      "          1.2333e-01, -1.1529e-01,  2.2428e-02,  9.9465e-02, -1.7153e-01,\n",
      "          1.9133e-01, -1.9368e-01, -1.7180e-02, -4.8974e-02, -1.9915e-01,\n",
      "         -6.4188e-03, -2.0217e-01,  6.1173e-02,  1.1144e-01,  1.4417e-01],\n",
      "        [ 2.1464e-01,  1.7030e-01,  1.1019e-01,  1.3449e-01,  1.8987e-01,\n",
      "          2.1272e-01, -1.5171e-02,  1.3452e-01,  4.5818e-02,  2.9238e-02,\n",
      "         -6.5120e-02,  9.5388e-02,  1.3847e-01,  1.1369e-01, -1.6541e-01,\n",
      "         -2.2311e-01, -1.6106e-01, -1.4515e-01, -1.0022e-01, -1.1490e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1948, -0.0041, -0.1408,  0.0745, -0.1011,  0.0499, -0.1295, -0.1360,\n",
      "         0.1932, -0.0926, -0.0512,  0.0807, -0.1581, -0.0522, -0.1024, -0.1473,\n",
      "        -0.0756, -0.0934,  0.1592,  0.1379], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1367, -0.1379,  0.0663, -0.0074,  0.1158, -0.0084,  0.0421,  0.2234,\n",
      "          0.0900, -0.1838,  0.0583,  0.0008,  0.1549,  0.0825,  0.1989, -0.1879,\n",
      "          0.1259,  0.0910,  0.0150,  0.0181],\n",
      "        [ 0.0956, -0.1325,  0.1189,  0.0615,  0.0631, -0.0418,  0.0110, -0.0529,\n",
      "         -0.2013,  0.2111,  0.0763,  0.0156,  0.1147,  0.2206, -0.1664,  0.1542,\n",
      "          0.2116,  0.0937,  0.0178, -0.0882],\n",
      "        [ 0.0142, -0.2131,  0.0791, -0.1153, -0.1470,  0.2110, -0.0976, -0.1101,\n",
      "         -0.0447, -0.1190,  0.1926,  0.1250,  0.0245,  0.0274, -0.0794,  0.2167,\n",
      "          0.1133,  0.1579,  0.1971, -0.0750],\n",
      "        [-0.0383,  0.2228,  0.0157, -0.1820,  0.0786,  0.1752,  0.1825,  0.0206,\n",
      "          0.1419, -0.0870,  0.0295,  0.2010, -0.0598,  0.1926,  0.2009,  0.0950,\n",
      "         -0.0180, -0.1831, -0.2207, -0.1065],\n",
      "        [ 0.1707, -0.1036, -0.1955,  0.0343,  0.1843,  0.0249, -0.0142, -0.0725,\n",
      "         -0.1281,  0.0212, -0.1392,  0.1401,  0.1030,  0.1029, -0.2174, -0.1053,\n",
      "          0.0362, -0.1520,  0.2131, -0.0091],\n",
      "        [-0.1502, -0.1779,  0.1736,  0.2168, -0.1229, -0.1753, -0.1491, -0.1604,\n",
      "         -0.1414, -0.0164,  0.0422, -0.1028,  0.2083, -0.0512,  0.1372,  0.1898,\n",
      "          0.1557,  0.1514, -0.2162, -0.0407],\n",
      "        [-0.1777,  0.0884,  0.0410,  0.0776, -0.1835, -0.2125,  0.0587,  0.0912,\n",
      "          0.0066, -0.1399, -0.2211, -0.2031, -0.1690,  0.2204,  0.1909,  0.1033,\n",
      "          0.0415, -0.1294,  0.0451,  0.0504],\n",
      "        [-0.0956, -0.0783,  0.1237,  0.1748, -0.0501,  0.0146,  0.1287, -0.0268,\n",
      "         -0.0134, -0.0379, -0.0826, -0.1477, -0.0346,  0.1458, -0.0142, -0.0069,\n",
      "         -0.0382, -0.1401,  0.1539,  0.0521],\n",
      "        [ 0.2044, -0.0764, -0.1349, -0.0103, -0.1254, -0.1859,  0.0652, -0.1842,\n",
      "         -0.0934, -0.1354, -0.1982, -0.1697,  0.2037,  0.1988, -0.1606, -0.1230,\n",
      "          0.0750,  0.0193, -0.1853, -0.1844],\n",
      "        [ 0.1798,  0.2119, -0.0044, -0.0437, -0.0033, -0.0144,  0.1297, -0.0982,\n",
      "         -0.0992,  0.1670, -0.0726,  0.2079,  0.0164, -0.0956, -0.1422,  0.0352,\n",
      "          0.0994, -0.1708, -0.0943,  0.1551],\n",
      "        [ 0.1127,  0.1510,  0.0308,  0.0142, -0.1144, -0.1448,  0.0483, -0.0561,\n",
      "         -0.1726,  0.1747,  0.2177, -0.2041,  0.0706,  0.0318,  0.1349, -0.1777,\n",
      "          0.1285, -0.1631,  0.0129,  0.1648],\n",
      "        [ 0.1922, -0.0774,  0.0168, -0.1766,  0.0876,  0.0855,  0.0612, -0.1527,\n",
      "         -0.0803, -0.1665,  0.1095,  0.1136,  0.0083, -0.0134, -0.2235,  0.1465,\n",
      "         -0.1094, -0.0309,  0.1744, -0.0226],\n",
      "        [ 0.1844, -0.2024,  0.1532, -0.0092,  0.0680,  0.0846,  0.2024, -0.0938,\n",
      "         -0.1818, -0.1209, -0.2018, -0.1250,  0.1765, -0.0642, -0.1081, -0.0490,\n",
      "         -0.0232,  0.1853, -0.1996,  0.1236],\n",
      "        [-0.1558,  0.2013,  0.2209,  0.1967,  0.1609, -0.0726,  0.1122, -0.0395,\n",
      "         -0.1371, -0.0885, -0.1186,  0.0910,  0.2132, -0.1728,  0.1967, -0.1965,\n",
      "          0.0660,  0.0171, -0.1730, -0.0622],\n",
      "        [-0.1806,  0.0093, -0.2125, -0.2180, -0.0641,  0.0897,  0.1493, -0.0597,\n",
      "         -0.1007,  0.0898, -0.1800, -0.1966,  0.0026, -0.0500, -0.1342,  0.1990,\n",
      "          0.0817, -0.1343,  0.0108,  0.0340],\n",
      "        [ 0.0305,  0.0685,  0.1181,  0.1170, -0.0032, -0.2088, -0.0865,  0.1239,\n",
      "          0.1994, -0.0305,  0.1623, -0.1157,  0.1419,  0.2141,  0.2133,  0.0647,\n",
      "          0.0096,  0.1163, -0.2222, -0.1953],\n",
      "        [-0.0187,  0.1379, -0.0037, -0.0823, -0.1384, -0.2146,  0.2113, -0.0625,\n",
      "         -0.0250,  0.0593,  0.0602,  0.2127, -0.0060, -0.1356, -0.1648,  0.0243,\n",
      "          0.0811,  0.0390, -0.0541,  0.0111],\n",
      "        [ 0.1406, -0.0898, -0.1230,  0.0764,  0.2198,  0.0715,  0.0026,  0.1449,\n",
      "         -0.0039, -0.2129, -0.0785, -0.1720,  0.1946,  0.0690,  0.1003, -0.1178,\n",
      "         -0.0499, -0.1300, -0.2172, -0.1609],\n",
      "        [ 0.0051,  0.1658, -0.0499,  0.0126,  0.0399,  0.0933, -0.0576, -0.1852,\n",
      "          0.1902,  0.1002, -0.0960,  0.0576, -0.2022, -0.0631, -0.0691,  0.1386,\n",
      "          0.0530, -0.0588,  0.0956,  0.0982],\n",
      "        [-0.2202,  0.1707,  0.1459, -0.1308, -0.1653, -0.0845, -0.0248, -0.0905,\n",
      "         -0.1047,  0.0113, -0.2120,  0.1754,  0.0140,  0.0249,  0.1698,  0.0818,\n",
      "         -0.0260, -0.0885, -0.0376,  0.1281]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1332,  0.1083, -0.1921, -0.2073,  0.0948, -0.0592, -0.0438, -0.1012,\n",
      "         0.0631, -0.0682,  0.0251,  0.0098, -0.1024, -0.0170, -0.0117, -0.0047,\n",
      "        -0.0215,  0.2083, -0.0902, -0.0489], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-5.0413e-02, -1.5514e-01,  4.6098e-02, -1.3518e-01, -9.7669e-02,\n",
      "          5.6923e-02,  8.7605e-02,  1.3252e-01, -1.8703e-01,  9.7306e-02,\n",
      "         -6.3728e-03, -1.0975e-01, -1.9761e-01, -2.1327e-01,  7.5914e-02,\n",
      "         -9.2721e-04, -7.8047e-02, -2.1924e-02, -1.3420e-01,  5.1424e-03],\n",
      "        [ 2.1205e-01, -1.9826e-01, -7.3729e-02,  3.4491e-02, -8.9328e-03,\n",
      "         -8.3142e-02, -9.3663e-02,  6.7305e-02, -5.8133e-02,  1.2988e-01,\n",
      "          1.5302e-03, -1.2855e-01,  1.4099e-01, -9.6999e-03,  4.7300e-02,\n",
      "         -1.3973e-01,  1.4629e-02, -1.6778e-01,  3.4997e-02,  6.7652e-02],\n",
      "        [-1.6406e-01, -3.6441e-02,  1.4997e-01, -7.6691e-02,  2.0900e-02,\n",
      "          7.8557e-02, -8.7471e-02,  7.6726e-02,  1.1468e-01,  1.9966e-01,\n",
      "         -2.1368e-01,  4.4368e-04, -1.1524e-01,  1.9218e-01, -1.6836e-02,\n",
      "         -1.0532e-01, -1.8546e-01, -1.5770e-01,  9.2664e-02,  1.0634e-01],\n",
      "        [-2.1710e-01,  3.2981e-02, -1.9273e-01,  1.3851e-01,  2.1447e-01,\n",
      "         -5.4903e-02,  6.0183e-02, -1.5803e-01,  1.8873e-01,  1.3839e-01,\n",
      "          1.3270e-01, -2.2236e-01,  1.1393e-01, -1.3648e-02,  1.1055e-01,\n",
      "          8.2123e-02,  1.3704e-01,  1.0059e-01,  1.6095e-01,  1.8499e-01],\n",
      "        [-1.1347e-01, -6.8030e-02, -4.2378e-02,  3.1708e-02,  1.8006e-01,\n",
      "         -6.4253e-02, -1.9236e-01,  8.2660e-02,  1.3917e-01, -1.7464e-01,\n",
      "          1.6005e-01, -1.5733e-01,  1.2879e-01, -5.4483e-02,  9.8592e-02,\n",
      "         -6.6865e-02, -2.0318e-01,  8.1826e-02, -6.7588e-02,  4.6627e-02],\n",
      "        [-1.1475e-01,  7.9834e-02,  6.5252e-02, -1.1363e-01,  1.5895e-01,\n",
      "          7.3060e-02, -2.1153e-01, -8.4956e-02,  3.2555e-02,  9.5887e-02,\n",
      "         -1.9477e-01, -1.1143e-01,  2.1425e-01,  1.9141e-01, -1.1119e-01,\n",
      "          4.0125e-02,  4.0953e-02,  4.1152e-02,  2.1982e-01, -5.0572e-02],\n",
      "        [ 2.4929e-02,  1.9628e-01, -4.6847e-03,  1.6770e-01, -1.7672e-01,\n",
      "         -1.2444e-01,  2.0851e-01,  1.8129e-01, -7.8169e-02,  1.7197e-01,\n",
      "         -5.4084e-02, -1.4222e-01,  1.1877e-01,  1.2619e-01, -1.5950e-01,\n",
      "         -1.6281e-01, -1.5012e-01, -2.1135e-01,  3.8358e-02, -2.0549e-01],\n",
      "        [ 8.6758e-03,  6.4215e-02,  5.7604e-02,  1.1009e-02, -1.1084e-02,\n",
      "         -1.6875e-01, -1.8772e-01,  7.9146e-02, -1.1682e-01, -2.0189e-01,\n",
      "          2.0382e-01,  1.0641e-01, -4.7062e-02, -6.1101e-02, -1.7198e-01,\n",
      "          1.9583e-01, -6.3156e-02, -1.1066e-01, -2.4486e-02,  1.1114e-01],\n",
      "        [ 2.1411e-01, -1.0875e-01,  1.8978e-01,  2.7274e-02,  5.6185e-02,\n",
      "         -1.3190e-01, -7.0565e-02, -1.1802e-01, -1.8239e-01,  2.0611e-01,\n",
      "          5.3229e-02,  1.7841e-01,  3.5121e-02,  5.1102e-02,  7.4775e-02,\n",
      "          9.2947e-02, -2.7303e-02,  1.7042e-01, -2.1025e-01, -1.6162e-01],\n",
      "        [ 1.3048e-01, -2.1306e-01,  9.8370e-02, -4.2873e-02, -5.4112e-02,\n",
      "          1.5372e-01,  2.2221e-01, -2.2038e-01,  2.9560e-02, -2.0666e-01,\n",
      "          2.0378e-01, -3.3636e-02,  1.9938e-01,  9.3901e-02, -1.0504e-01,\n",
      "          1.8131e-01, -2.3670e-03,  6.0497e-02,  3.8241e-04, -1.9437e-01],\n",
      "        [ 1.1073e-01,  1.2496e-01, -2.0383e-01, -1.4983e-01,  1.9084e-01,\n",
      "          5.1520e-02,  1.4538e-01, -1.8299e-01,  7.9757e-02, -9.7369e-02,\n",
      "         -8.3833e-02, -1.1070e-01,  1.4345e-01,  1.0862e-02, -1.9439e-01,\n",
      "         -2.7288e-02,  1.2271e-01, -4.3058e-02, -1.3191e-01, -1.3744e-01],\n",
      "        [-6.6302e-02, -1.4546e-02,  1.9050e-02,  5.9735e-02,  3.8144e-02,\n",
      "         -1.3434e-01, -2.1657e-01, -1.1091e-01, -1.4981e-01, -2.8803e-02,\n",
      "         -1.4443e-01,  4.7424e-03, -9.2763e-02, -7.2980e-02,  1.2456e-01,\n",
      "         -9.1214e-02,  1.1771e-01, -1.0394e-01,  1.8500e-01,  1.7152e-01],\n",
      "        [ 1.3934e-01, -1.1827e-04, -1.7981e-01, -2.2069e-02, -5.3173e-02,\n",
      "          6.5162e-02, -1.6935e-01,  3.8167e-02,  2.6381e-03, -1.9086e-01,\n",
      "          1.6068e-01, -8.3347e-02,  1.3718e-01,  2.2174e-01, -1.6615e-01,\n",
      "         -1.5622e-01,  1.4059e-01,  6.9632e-02, -1.4774e-02, -1.1749e-01],\n",
      "        [-5.3827e-02,  1.4883e-01,  1.2063e-01, -7.9971e-02,  6.6178e-02,\n",
      "         -2.1431e-01, -1.5516e-01,  7.8908e-02, -4.4841e-02, -1.7239e-01,\n",
      "          1.2725e-01,  1.8232e-01,  1.0979e-01,  1.5969e-01, -1.4121e-01,\n",
      "          8.2408e-02,  8.3329e-02,  5.4962e-02, -3.6219e-02,  1.9696e-01],\n",
      "        [ 4.8452e-02, -1.4412e-02, -8.2602e-02, -2.0111e-02, -1.7704e-01,\n",
      "         -1.4719e-02,  2.8679e-02,  1.3600e-01, -8.5578e-02,  4.8090e-02,\n",
      "          1.7478e-01,  5.3768e-02,  7.6601e-03, -8.3519e-02, -4.8559e-02,\n",
      "         -4.8252e-02,  2.0484e-01, -2.1930e-01, -1.9959e-01,  1.9767e-01],\n",
      "        [ 1.0538e-01, -1.2999e-01,  1.3926e-01, -5.5628e-02, -1.9289e-01,\n",
      "          2.2161e-01, -2.1018e-01, -1.2951e-01,  1.8136e-01, -1.9672e-01,\n",
      "         -2.1893e-01, -1.7681e-02,  1.0243e-01,  6.3442e-02,  9.4227e-02,\n",
      "         -5.5804e-03, -2.1310e-01, -2.7123e-02, -1.4592e-01,  4.7022e-02],\n",
      "        [ 3.4999e-02, -1.5429e-01, -9.3316e-02, -7.0267e-02,  1.7306e-01,\n",
      "         -7.5216e-02, -2.0770e-01, -2.1747e-01, -1.7241e-01, -1.6017e-01,\n",
      "          8.0147e-02, -4.0352e-02, -9.3633e-02, -1.6746e-01,  1.0554e-01,\n",
      "         -6.0668e-02,  1.0831e-01,  1.0690e-01, -1.5878e-01, -5.6444e-02],\n",
      "        [-1.8618e-02, -1.4705e-01,  2.1153e-01, -1.4383e-01,  6.8983e-02,\n",
      "          4.8423e-02, -1.1550e-01,  8.2385e-02, -1.5133e-01,  1.2005e-01,\n",
      "          1.9394e-01, -4.1533e-03,  1.4041e-01,  1.9397e-01,  5.7082e-02,\n",
      "          8.1660e-03,  7.2122e-02,  1.0945e-01,  1.1059e-02,  1.6679e-01],\n",
      "        [-7.1139e-02, -2.2167e-01, -1.9492e-01,  5.8973e-02, -2.0408e-01,\n",
      "         -1.7554e-02,  4.0030e-02,  1.7250e-01,  4.1244e-02, -1.4383e-02,\n",
      "         -1.8021e-01, -1.4411e-01,  4.2088e-02,  2.2262e-02,  9.4331e-02,\n",
      "         -2.0881e-01, -2.5169e-02,  1.2504e-01, -1.4449e-01, -1.8337e-01],\n",
      "        [ 1.3757e-01,  2.1904e-01, -2.6149e-02,  1.0579e-02, -1.4612e-02,\n",
      "         -1.2611e-01, -2.7121e-02,  6.2047e-02, -2.0682e-01,  6.3480e-02,\n",
      "         -1.7329e-01, -1.0872e-01,  1.9076e-01,  6.6541e-03, -2.2212e-01,\n",
      "          1.5878e-01, -2.1526e-01,  2.2025e-01,  7.7635e-02, -1.7503e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0224, -0.1380,  0.0758, -0.0307, -0.0536,  0.0590,  0.2187,  0.0944,\n",
      "        -0.1287, -0.0168,  0.0036, -0.1340,  0.1380, -0.1648,  0.0702,  0.1302,\n",
      "         0.2215, -0.1748, -0.2162,  0.1346], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1932,  0.2031,  0.1301, -0.0996,  0.0896,  0.1849, -0.1595, -0.1104,\n",
      "          0.1124, -0.0544,  0.1641, -0.1019, -0.0326, -0.0246,  0.1320,  0.0425,\n",
      "         -0.0454, -0.0559, -0.1764,  0.0173],\n",
      "        [-0.1283,  0.0165, -0.1606,  0.0565, -0.0665, -0.0846, -0.1952,  0.1441,\n",
      "         -0.0716, -0.1023, -0.2149,  0.0125,  0.1548, -0.1227, -0.0146, -0.0234,\n",
      "          0.1738,  0.2145, -0.2019, -0.1871],\n",
      "        [-0.1827,  0.0037, -0.1408,  0.1407, -0.1278, -0.0453, -0.1638, -0.0032,\n",
      "          0.1398,  0.0135, -0.0686,  0.0811, -0.1897,  0.1276,  0.1817,  0.1230,\n",
      "         -0.1139,  0.2192,  0.0053,  0.1328],\n",
      "        [ 0.1292, -0.1262, -0.0272,  0.1160,  0.2234,  0.0036,  0.0487,  0.1179,\n",
      "          0.0021,  0.0771, -0.1381, -0.1786,  0.1150,  0.1636,  0.1158, -0.1526,\n",
      "         -0.1282,  0.1757, -0.0248,  0.1024],\n",
      "        [-0.1054,  0.1824, -0.1352, -0.1471, -0.2043,  0.1734,  0.2041, -0.0956,\n",
      "         -0.1401,  0.0441,  0.1170,  0.0916, -0.2120, -0.0903,  0.2168,  0.0439,\n",
      "          0.0345, -0.1942,  0.1091,  0.1368],\n",
      "        [ 0.0866,  0.0128, -0.0199,  0.1995,  0.1987,  0.1021,  0.0418,  0.0175,\n",
      "         -0.1941,  0.1903,  0.0315,  0.0842, -0.0641,  0.1187,  0.1062, -0.0363,\n",
      "          0.1978,  0.1104, -0.1995, -0.1027],\n",
      "        [ 0.0450, -0.0359,  0.1683,  0.1547,  0.1289,  0.1617, -0.2124, -0.0980,\n",
      "          0.0948, -0.0699,  0.1692,  0.0078, -0.2177, -0.1714, -0.0085,  0.1646,\n",
      "          0.1020, -0.0225,  0.1473, -0.1575],\n",
      "        [-0.1036,  0.0650, -0.0640, -0.1180,  0.2176, -0.1069, -0.1634, -0.0636,\n",
      "         -0.2218,  0.1123,  0.0894,  0.1851,  0.1481,  0.1180,  0.0782,  0.0535,\n",
      "         -0.0034, -0.0045, -0.0196, -0.0749],\n",
      "        [ 0.1879, -0.0176,  0.1334,  0.0647, -0.0666,  0.0324,  0.1023,  0.0441,\n",
      "          0.0481,  0.0082, -0.1034,  0.0740, -0.0904,  0.1180,  0.1889, -0.1981,\n",
      "          0.1919,  0.1217,  0.1075, -0.0570],\n",
      "        [ 0.1174,  0.1546, -0.1081,  0.0520, -0.1513, -0.0638, -0.1511,  0.1857,\n",
      "          0.0803,  0.0731, -0.2225,  0.0975, -0.0768,  0.0927,  0.1863,  0.2118,\n",
      "         -0.1117, -0.1049,  0.1495, -0.1006],\n",
      "        [ 0.0703,  0.0407, -0.1869, -0.1399,  0.0929, -0.1278, -0.0226, -0.2083,\n",
      "          0.1680, -0.1845, -0.0665, -0.0182,  0.2062,  0.1221,  0.0335,  0.1239,\n",
      "         -0.0652, -0.0613,  0.1473, -0.2057],\n",
      "        [ 0.0689, -0.1389,  0.1340, -0.2063,  0.0818, -0.1385,  0.1117,  0.1660,\n",
      "         -0.1772,  0.1515,  0.0117, -0.1958,  0.0643, -0.0811,  0.0376, -0.0314,\n",
      "          0.1180, -0.2179, -0.0344, -0.1684],\n",
      "        [ 0.1272, -0.1932,  0.1534,  0.0718, -0.1800,  0.1936, -0.1425, -0.1814,\n",
      "         -0.1211,  0.0546, -0.1059,  0.0455,  0.0471,  0.0711, -0.1788,  0.0727,\n",
      "         -0.1936,  0.0481,  0.1687,  0.0419],\n",
      "        [ 0.2168,  0.1262,  0.2109, -0.1595, -0.1416,  0.1491,  0.1623,  0.1807,\n",
      "         -0.0746, -0.1062,  0.0643, -0.0997,  0.0621, -0.2019, -0.1384, -0.1515,\n",
      "          0.0584,  0.0018, -0.0857, -0.1998],\n",
      "        [-0.0034,  0.1018, -0.0952,  0.1577, -0.1744, -0.0766,  0.0611, -0.2110,\n",
      "         -0.1034,  0.1851,  0.0828,  0.1124, -0.1055, -0.0542, -0.0275, -0.1518,\n",
      "          0.2185,  0.0382,  0.0366, -0.1475],\n",
      "        [-0.1579, -0.1715, -0.0279,  0.0021,  0.2112, -0.1000, -0.0411, -0.0663,\n",
      "         -0.2200, -0.1662, -0.1400,  0.1421,  0.0432,  0.2085,  0.0031,  0.1796,\n",
      "          0.1473, -0.0398, -0.2182, -0.1396],\n",
      "        [-0.1490, -0.0551,  0.0993,  0.1344,  0.0086, -0.0652,  0.2188, -0.1883,\n",
      "         -0.1837,  0.1871,  0.0572,  0.1610, -0.0991,  0.0545, -0.1650,  0.1926,\n",
      "          0.2223, -0.1764,  0.2169, -0.2133],\n",
      "        [-0.0100, -0.0308,  0.1239,  0.0226, -0.0139,  0.1901,  0.1424, -0.1188,\n",
      "         -0.0753, -0.0385, -0.0570, -0.1156, -0.0884, -0.1047,  0.1268, -0.1849,\n",
      "          0.0648, -0.2222,  0.1256,  0.1987],\n",
      "        [-0.0948, -0.1301, -0.0067,  0.0062, -0.1284,  0.1892, -0.1283, -0.1540,\n",
      "         -0.2208,  0.2168,  0.0577,  0.1865,  0.0348, -0.0044, -0.0400,  0.1535,\n",
      "         -0.0077,  0.2060,  0.0408,  0.1541],\n",
      "        [ 0.1540, -0.1971,  0.1237,  0.1470, -0.1146,  0.1695,  0.1503,  0.1133,\n",
      "          0.1165, -0.2188,  0.2180, -0.0623,  0.0277, -0.0960, -0.1337,  0.1943,\n",
      "         -0.1122,  0.2125, -0.2022, -0.2067]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0729, -0.1051,  0.0143,  0.1200, -0.0642, -0.1463, -0.1546,  0.0129,\n",
      "         0.1524, -0.1507, -0.1694, -0.0078,  0.1005, -0.0673, -0.0125,  0.1621,\n",
      "         0.0146, -0.0233, -0.1757,  0.0466], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0160,  0.1361,  0.0653,  0.0728, -0.0302,  0.2174, -0.0059,  0.2018,\n",
      "         -0.0572, -0.0488, -0.1234,  0.0707,  0.0758,  0.1907,  0.1534,  0.1238,\n",
      "          0.1410,  0.0882,  0.1367,  0.0620],\n",
      "        [-0.0656, -0.1605,  0.1136, -0.0925,  0.2160, -0.0593, -0.0506,  0.0076,\n",
      "         -0.2163, -0.0291,  0.0704,  0.0043, -0.0222,  0.1660, -0.2089, -0.0717,\n",
      "         -0.1302,  0.0165,  0.1279, -0.0873],\n",
      "        [ 0.0159, -0.0959, -0.1700, -0.0142, -0.0716, -0.1325, -0.0598, -0.1767,\n",
      "         -0.0237, -0.0841,  0.1832,  0.0045,  0.0571,  0.0328, -0.0487,  0.1641,\n",
      "         -0.1392,  0.0073, -0.0566,  0.0003],\n",
      "        [ 0.1750, -0.1293, -0.1813, -0.0483, -0.1050,  0.1992,  0.1068,  0.1543,\n",
      "          0.2054, -0.1970,  0.1860, -0.0480,  0.1302,  0.1118, -0.0119,  0.0012,\n",
      "         -0.0594, -0.0444,  0.0052, -0.1749],\n",
      "        [-0.0453, -0.1423, -0.0831,  0.1656,  0.0281, -0.2131,  0.0688, -0.0963,\n",
      "         -0.2021,  0.0243,  0.0391,  0.1305, -0.1712, -0.0955,  0.1577,  0.0476,\n",
      "          0.0202,  0.1929, -0.1026,  0.2032],\n",
      "        [-0.1152,  0.1498,  0.1000,  0.1407,  0.1562, -0.0296, -0.1609, -0.1604,\n",
      "         -0.0673,  0.1414,  0.1846, -0.1771,  0.0417,  0.0542,  0.0931,  0.0980,\n",
      "         -0.1293, -0.1411,  0.1418, -0.0915],\n",
      "        [-0.0022,  0.0363,  0.0113,  0.1890,  0.0598,  0.0295, -0.0666,  0.0460,\n",
      "         -0.1812,  0.1526, -0.1023,  0.1103, -0.1142,  0.0412, -0.0793, -0.0892,\n",
      "          0.1918, -0.1537,  0.0408, -0.0552],\n",
      "        [-0.1111, -0.1374,  0.0415, -0.0661, -0.1505, -0.1691,  0.0628,  0.1362,\n",
      "          0.0295,  0.0918,  0.1448, -0.2041,  0.1549,  0.0982,  0.1993, -0.1605,\n",
      "          0.1238,  0.1881,  0.1096, -0.2157],\n",
      "        [ 0.1370, -0.0603,  0.1949,  0.0506, -0.2185,  0.1215,  0.1099, -0.1684,\n",
      "          0.0548,  0.1375,  0.0773,  0.1943, -0.0675, -0.2082,  0.0226, -0.1568,\n",
      "          0.1709, -0.1668,  0.0319,  0.1068],\n",
      "        [-0.0557,  0.1365, -0.0024,  0.1864, -0.2210,  0.1172,  0.1735,  0.0353,\n",
      "          0.0608,  0.1195, -0.1036,  0.1114,  0.0272, -0.0053, -0.1286, -0.1951,\n",
      "         -0.1050,  0.1871,  0.1407,  0.1212],\n",
      "        [-0.0958,  0.0106, -0.1336, -0.0275,  0.0985,  0.1265,  0.0256, -0.0496,\n",
      "         -0.1148, -0.0305, -0.1104, -0.0423,  0.0828,  0.0058,  0.0543, -0.1454,\n",
      "          0.0829,  0.1426, -0.2029,  0.1543],\n",
      "        [ 0.0016,  0.1224,  0.1911, -0.0555,  0.1197,  0.0703,  0.0012, -0.0074,\n",
      "         -0.0270,  0.1967,  0.0203,  0.0014,  0.0827,  0.0623, -0.0837,  0.1026,\n",
      "         -0.1524, -0.0120,  0.0761, -0.1096],\n",
      "        [-0.0073, -0.1427, -0.2046,  0.0536,  0.2130,  0.1854, -0.1559,  0.0058,\n",
      "         -0.1695,  0.0399,  0.0212, -0.1085,  0.1728, -0.0096,  0.0267, -0.2173,\n",
      "          0.0225, -0.1622,  0.1773,  0.1849],\n",
      "        [ 0.1927,  0.2052, -0.1504, -0.0512, -0.0299, -0.0115, -0.1682, -0.2125,\n",
      "          0.0518, -0.0234, -0.2073,  0.0113,  0.2003,  0.0565,  0.1318, -0.1745,\n",
      "          0.1738,  0.2076, -0.1329, -0.0204],\n",
      "        [ 0.0604, -0.1470, -0.0745,  0.0027,  0.0283, -0.0903,  0.0740,  0.1614,\n",
      "          0.1995,  0.1246,  0.2097, -0.1853,  0.2005, -0.0637, -0.1444,  0.2103,\n",
      "         -0.1492,  0.1635, -0.1487, -0.1912],\n",
      "        [-0.2115, -0.0444,  0.0387, -0.0844,  0.1116, -0.1647,  0.0612,  0.0284,\n",
      "         -0.1848, -0.0397,  0.0884,  0.0380, -0.1142,  0.1604, -0.0182,  0.0036,\n",
      "          0.1236, -0.1663,  0.0249, -0.0216],\n",
      "        [ 0.1027,  0.2072, -0.0279, -0.1845, -0.0647,  0.0886,  0.1554,  0.0176,\n",
      "          0.0407,  0.0288, -0.0491,  0.1384,  0.1091,  0.1948, -0.2003, -0.1091,\n",
      "          0.0799,  0.0021,  0.1150, -0.2152],\n",
      "        [ 0.0268, -0.0440,  0.0908, -0.1131, -0.0658,  0.1501, -0.1907, -0.1405,\n",
      "         -0.1830, -0.1101,  0.2082,  0.1395,  0.1197, -0.0393,  0.1967, -0.1069,\n",
      "         -0.1632, -0.0066,  0.1901, -0.0758],\n",
      "        [ 0.0474, -0.0431, -0.0864, -0.0328,  0.1416, -0.2134, -0.1239, -0.0585,\n",
      "         -0.0005, -0.1380,  0.2047,  0.0364, -0.2182, -0.1865, -0.0695, -0.1530,\n",
      "          0.1304,  0.2079,  0.1250,  0.1469],\n",
      "        [-0.1153,  0.1004, -0.1694, -0.1941, -0.2120, -0.0752,  0.0122,  0.0544,\n",
      "         -0.2162,  0.1175, -0.1375, -0.1712,  0.0091, -0.1482,  0.0241, -0.1614,\n",
      "          0.0953, -0.1544, -0.0088,  0.1524]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1693,  0.0608, -0.1657, -0.0575,  0.1723,  0.0459, -0.0025, -0.2059,\n",
      "         0.0361,  0.1124,  0.1750,  0.1986, -0.0133,  0.1893,  0.0245, -0.1686,\n",
      "        -0.1247, -0.0084, -0.0983,  0.1385], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1897, -0.0389,  0.1614, -0.1778, -0.0742, -0.2079, -0.0709, -0.1375,\n",
      "          0.0880,  0.0773, -0.1336, -0.0132,  0.0650,  0.0823, -0.0899,  0.2213,\n",
      "          0.1649,  0.1093, -0.1508,  0.1530],\n",
      "        [ 0.0665,  0.1060, -0.2061,  0.0957, -0.1851,  0.0774,  0.1381,  0.0702,\n",
      "         -0.0255, -0.1678,  0.2037, -0.1756,  0.1784, -0.1421,  0.0038,  0.0393,\n",
      "         -0.0430,  0.0183, -0.2222, -0.1613],\n",
      "        [ 0.0282,  0.1760, -0.0376, -0.1040,  0.0281,  0.1199, -0.1445,  0.1994,\n",
      "          0.0399,  0.0491,  0.1124,  0.1031,  0.0302,  0.1296,  0.2126, -0.0477,\n",
      "          0.1529,  0.0063,  0.0628,  0.0953],\n",
      "        [ 0.0066, -0.1763,  0.0094, -0.1692,  0.0033,  0.0091,  0.1838,  0.0478,\n",
      "         -0.1972,  0.1286, -0.1919,  0.2233, -0.0793,  0.0124,  0.0642,  0.0456,\n",
      "          0.0894,  0.0576, -0.0338,  0.1202],\n",
      "        [-0.0164, -0.0920, -0.1743,  0.1321,  0.1259, -0.2126, -0.1541,  0.1474,\n",
      "         -0.0140,  0.0454,  0.1863, -0.2182, -0.1828,  0.0601, -0.0658, -0.0591,\n",
      "         -0.1290, -0.0020, -0.2098,  0.1883],\n",
      "        [ 0.1187,  0.0970, -0.1628,  0.1660,  0.1705, -0.0423, -0.0689,  0.1429,\n",
      "         -0.1546, -0.1093,  0.2007,  0.0301,  0.1143,  0.1133,  0.1714,  0.1257,\n",
      "         -0.0646,  0.1981,  0.1091,  0.0898],\n",
      "        [-0.1859,  0.0619, -0.2147,  0.1960, -0.0433,  0.1931, -0.1595, -0.0566,\n",
      "          0.1534,  0.1826, -0.2010, -0.1115,  0.0959, -0.0823,  0.0415,  0.0831,\n",
      "          0.0469, -0.0093,  0.1969, -0.2197],\n",
      "        [ 0.0763,  0.0135, -0.1106, -0.0830, -0.0165, -0.0487,  0.1722, -0.1630,\n",
      "         -0.1542,  0.2104,  0.1723,  0.0590,  0.2211,  0.2228, -0.0301, -0.0489,\n",
      "         -0.1222,  0.1147,  0.0794,  0.1110],\n",
      "        [ 0.2027, -0.1767, -0.0255, -0.1575,  0.0571,  0.0948,  0.0637, -0.1949,\n",
      "          0.0459, -0.0107, -0.0099,  0.0691, -0.2168, -0.2177, -0.0737, -0.2028,\n",
      "         -0.0981,  0.0458, -0.1873,  0.1585],\n",
      "        [ 0.0432,  0.0457,  0.1800,  0.1987,  0.0411, -0.1287,  0.1099, -0.2163,\n",
      "         -0.1817, -0.0303, -0.1256, -0.0777, -0.1895,  0.0132,  0.1222,  0.2179,\n",
      "          0.2036,  0.1105,  0.0726, -0.1643],\n",
      "        [ 0.0401,  0.0034, -0.0239,  0.1835,  0.1616, -0.2131, -0.1054, -0.0314,\n",
      "         -0.0539,  0.0658, -0.1797,  0.2170, -0.0611,  0.1551,  0.1146, -0.2109,\n",
      "          0.1211, -0.1846,  0.0414,  0.0707],\n",
      "        [ 0.0791, -0.0989, -0.0824, -0.2032, -0.1294, -0.0356, -0.1374,  0.1451,\n",
      "          0.0979,  0.2079,  0.1193,  0.2171, -0.2178, -0.0444, -0.0417, -0.0829,\n",
      "          0.2122,  0.1535, -0.0960,  0.1724],\n",
      "        [ 0.0508,  0.0883, -0.1634,  0.1653, -0.0584, -0.2051,  0.1088, -0.0417,\n",
      "          0.1799,  0.1203,  0.0402, -0.0363,  0.2205,  0.0777,  0.0835,  0.0094,\n",
      "          0.1983, -0.0830, -0.1537,  0.0809],\n",
      "        [-0.2127,  0.1014,  0.0797, -0.1587,  0.0109,  0.1520,  0.1721,  0.1484,\n",
      "         -0.1495, -0.0624,  0.1729,  0.1171,  0.2116, -0.1812, -0.0382,  0.0939,\n",
      "          0.2034,  0.1052, -0.1147, -0.1646],\n",
      "        [ 0.1592,  0.1293,  0.0591,  0.1884, -0.0029,  0.1251, -0.0714, -0.0393,\n",
      "         -0.1107, -0.1446, -0.1341,  0.1030, -0.1879,  0.0160, -0.0692, -0.0251,\n",
      "          0.0446,  0.0339, -0.0323, -0.0329],\n",
      "        [ 0.0883,  0.0684, -0.1228, -0.2212, -0.0629, -0.1134, -0.0757,  0.1794,\n",
      "          0.1270,  0.0579,  0.1725,  0.0085,  0.2171,  0.0594, -0.1617,  0.0793,\n",
      "         -0.2094, -0.1852, -0.1927, -0.1296],\n",
      "        [ 0.1907,  0.0115, -0.1830, -0.0201,  0.1228,  0.1262,  0.1055,  0.1601,\n",
      "         -0.1977,  0.0039,  0.0003, -0.0397, -0.0108, -0.0911,  0.1292,  0.1774,\n",
      "         -0.0953, -0.0759, -0.1802, -0.0896],\n",
      "        [-0.1690, -0.0301,  0.0241,  0.0234,  0.0565, -0.1985,  0.1028, -0.1037,\n",
      "          0.2079,  0.1024,  0.0715, -0.0283,  0.2124, -0.1456,  0.1392, -0.1030,\n",
      "         -0.0600, -0.1590,  0.0531,  0.1036],\n",
      "        [ 0.0328,  0.0184,  0.2173, -0.0811, -0.0147,  0.1062,  0.1363,  0.0806,\n",
      "          0.1600, -0.0414, -0.1334, -0.1669, -0.0601,  0.0871,  0.1655, -0.0831,\n",
      "          0.0649,  0.2196, -0.1813, -0.0772],\n",
      "        [-0.0179,  0.0012, -0.0965,  0.1144, -0.0876,  0.1874,  0.2029,  0.0509,\n",
      "         -0.0852, -0.0543, -0.0909,  0.1857,  0.2051, -0.1445, -0.1699, -0.0427,\n",
      "          0.0094,  0.1563,  0.0665,  0.0368]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.4673e-01,  9.3032e-02,  2.1385e-01, -1.1352e-01,  1.3569e-01,\n",
      "         9.0009e-02,  1.5443e-01, -2.0074e-01,  1.5217e-01,  1.3344e-01,\n",
      "        -1.9499e-01,  1.4146e-04,  2.1884e-01,  5.5420e-02,  2.2283e-01,\n",
      "        -1.5045e-01,  7.6016e-02,  2.0986e-01,  4.0497e-02, -1.9956e-01],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.3804e-01, -1.9656e-01,  2.1394e-01,  3.5141e-03,  8.4784e-02,\n",
      "         -6.0722e-03, -2.0362e-01,  7.1491e-02, -2.0827e-01, -2.0522e-01,\n",
      "         -8.0493e-02, -2.2336e-01,  1.4698e-01,  4.1999e-02, -1.9585e-01,\n",
      "          2.8948e-02,  1.7665e-02,  2.0323e-02,  8.7121e-02, -1.4319e-01],\n",
      "        [-8.3336e-02, -6.4858e-02,  1.6780e-01, -1.5560e-01,  7.5432e-02,\n",
      "          5.4933e-02, -9.4467e-02,  3.1882e-02, -1.5094e-01, -1.0746e-01,\n",
      "         -9.0126e-02,  1.2123e-01,  8.6776e-02,  5.2665e-02,  1.0542e-01,\n",
      "          1.7385e-01,  1.8799e-01, -1.4839e-01,  2.0157e-01, -1.9720e-01],\n",
      "        [ 1.5809e-01, -2.0641e-01, -9.0178e-02,  2.5268e-02, -1.1307e-01,\n",
      "          2.9937e-02, -5.5221e-02,  1.9820e-01,  9.5981e-02,  4.9070e-02,\n",
      "          1.5435e-01,  1.4670e-01,  3.1519e-02,  5.4787e-02, -7.0760e-02,\n",
      "         -2.0916e-01, -3.3742e-02, -1.1233e-01, -1.0034e-01,  1.4067e-01],\n",
      "        [ 1.0628e-01, -1.3259e-01, -1.2430e-01, -1.1941e-01, -2.0711e-01,\n",
      "          1.1188e-01,  2.5467e-02,  1.2552e-03,  1.6727e-01,  8.8419e-02,\n",
      "          1.8505e-01, -6.7201e-03,  1.0660e-01, -1.3615e-01,  3.2720e-02,\n",
      "         -9.3139e-02, -1.2328e-01,  1.6797e-01, -7.8284e-02, -9.3400e-02],\n",
      "        [-1.4634e-01,  1.5394e-02,  1.8818e-01,  9.7682e-02,  1.0176e-01,\n",
      "          3.0038e-02, -5.0775e-02,  2.1377e-01, -3.3979e-02, -1.1399e-01,\n",
      "         -1.0744e-01,  6.8300e-02,  1.5498e-01,  1.9153e-01, -2.1501e-01,\n",
      "          1.5397e-01,  7.2728e-02, -9.3230e-02, -7.4960e-02,  1.3856e-01],\n",
      "        [ 1.8909e-01,  1.3595e-01,  1.6933e-01,  1.8680e-02,  9.1702e-02,\n",
      "         -1.2120e-01,  1.6352e-01, -1.2530e-01,  2.2013e-01,  1.1639e-01,\n",
      "         -1.7583e-01, -3.9846e-02, -1.9106e-02, -1.9367e-02,  9.0322e-02,\n",
      "          1.9507e-01, -2.1292e-01,  9.8665e-03, -1.7705e-01,  6.2572e-02],\n",
      "        [-8.2629e-02,  3.7993e-02,  1.8741e-02, -2.1516e-01, -1.9409e-01,\n",
      "         -4.2965e-02, -1.0539e-01,  1.4258e-02, -1.9157e-01,  5.9628e-02,\n",
      "          1.9537e-01,  1.9459e-01,  1.1804e-01,  5.9392e-02, -2.0139e-01,\n",
      "          1.2431e-01,  1.8063e-01, -7.5986e-02,  6.3741e-02, -1.1261e-01],\n",
      "        [ 5.8766e-02, -1.6197e-01, -2.7227e-02,  2.2347e-01, -5.0384e-03,\n",
      "          1.3948e-01, -7.4935e-02,  1.6384e-02, -9.1748e-02,  2.0239e-01,\n",
      "         -2.6357e-02,  1.4320e-01,  1.8574e-01, -5.4269e-02,  7.9948e-02,\n",
      "          8.1929e-02, -2.1230e-01, -5.3399e-02,  1.9381e-01,  1.2189e-01],\n",
      "        [-1.3749e-01, -1.3020e-01,  2.0143e-01, -9.7049e-02,  5.3085e-02,\n",
      "          7.6951e-02, -3.1223e-02, -3.5480e-03, -1.8656e-01, -1.4845e-01,\n",
      "         -1.6931e-01, -1.3619e-01,  1.7046e-01, -1.4490e-01,  7.1723e-02,\n",
      "          1.1167e-01, -2.1883e-01, -1.8550e-01,  1.3898e-01, -1.6298e-01],\n",
      "        [ 1.7764e-01, -1.6544e-01,  1.1878e-01,  1.3225e-01,  4.7276e-03,\n",
      "          1.0421e-01,  1.7974e-01, -1.3845e-01,  3.3509e-02,  5.8453e-02,\n",
      "          1.9863e-01, -5.3952e-02,  9.8513e-02,  1.5970e-01,  1.9850e-01,\n",
      "         -1.8071e-02,  1.7576e-01,  1.7331e-01, -4.5763e-02, -2.3847e-02],\n",
      "        [ 9.5524e-02, -1.3551e-01,  4.3366e-02,  9.2928e-02,  1.8371e-01,\n",
      "         -1.4877e-01,  1.0461e-01, -1.4829e-01, -1.7830e-01, -2.1623e-01,\n",
      "          9.1615e-02,  8.5000e-03,  1.7832e-02, -1.6135e-01, -1.5955e-01,\n",
      "         -1.1249e-01,  6.5789e-02, -1.2491e-01, -1.3933e-01, -6.4350e-02],\n",
      "        [ 1.0281e-01,  1.7158e-01,  1.1922e-01, -1.4859e-01,  1.0011e-01,\n",
      "          1.0756e-01, -1.8525e-01, -1.4131e-01, -1.3105e-01, -1.0375e-01,\n",
      "         -1.1722e-01, -8.8458e-02,  2.0908e-01, -1.4750e-01,  3.9621e-02,\n",
      "          1.0329e-01, -2.0213e-01, -2.4536e-02, -7.0683e-02, -4.1641e-02],\n",
      "        [-1.2025e-01,  1.4691e-01, -1.5163e-01, -1.8224e-01, -1.9354e-01,\n",
      "          2.8881e-02, -1.2312e-01, -1.4654e-02, -1.7478e-01,  1.0773e-01,\n",
      "         -8.8593e-02,  1.3712e-01, -1.6597e-01,  1.3878e-01,  7.2496e-02,\n",
      "          1.0548e-02,  1.6996e-01, -1.8807e-01,  9.0028e-02,  3.2791e-02],\n",
      "        [-2.0849e-01, -1.9884e-02, -9.1562e-02, -1.2498e-01,  1.3234e-01,\n",
      "          4.8290e-02, -1.5230e-01,  8.5250e-02,  3.2403e-02, -8.7096e-02,\n",
      "         -1.3914e-01, -1.3388e-01, -5.0410e-02, -1.8697e-01, -1.2051e-01,\n",
      "         -7.9416e-03, -1.4297e-01, -6.9638e-02, -1.0598e-01, -2.2223e-02],\n",
      "        [ 1.9309e-01, -1.5030e-01, -1.9885e-01, -1.7850e-01,  1.4105e-01,\n",
      "          1.7057e-01, -6.5890e-02, -1.6784e-01,  6.4417e-02, -8.5600e-02,\n",
      "          2.2741e-02, -1.4811e-01, -2.1024e-01, -1.1784e-01, -9.9793e-02,\n",
      "         -7.9821e-02, -1.6165e-01,  7.5750e-02,  1.6745e-01,  2.1583e-01],\n",
      "        [-1.2287e-01, -1.9798e-01,  1.3093e-01, -7.7815e-02, -1.3970e-02,\n",
      "          1.5546e-01, -4.9397e-03, -1.9114e-01, -1.6595e-01,  8.4372e-02,\n",
      "          2.0629e-01,  1.9324e-01,  1.6357e-01,  2.3892e-02,  1.2848e-01,\n",
      "         -2.6209e-03,  5.5330e-02,  2.0013e-01,  7.5256e-02,  1.7666e-01],\n",
      "        [-1.5931e-01,  3.8050e-02,  9.3932e-02, -1.9647e-03, -1.6467e-01,\n",
      "          2.0086e-01,  1.2822e-02,  1.8635e-01,  1.7249e-01,  8.0585e-02,\n",
      "          6.8737e-02, -1.9160e-04, -1.6811e-01,  9.6275e-02, -1.5196e-02,\n",
      "         -8.3711e-02, -7.5815e-02, -8.0897e-02, -6.9133e-02, -3.0500e-02],\n",
      "        [ 7.7408e-02,  6.4475e-02, -3.3036e-02,  1.9165e-01,  2.1477e-01,\n",
      "          1.0161e-01,  1.1377e-01,  8.0861e-02, -5.8182e-02,  1.6777e-01,\n",
      "         -1.2479e-01, -7.6196e-02,  1.9046e-01,  1.4779e-01,  1.3734e-01,\n",
      "          1.6105e-01,  2.1916e-01,  1.4555e-01,  6.2805e-02,  1.3620e-01],\n",
      "        [ 1.2719e-02,  1.0459e-01,  9.2242e-02, -9.5387e-02,  2.1177e-01,\n",
      "         -7.5136e-02,  8.6148e-02,  2.2089e-01,  1.5720e-01, -1.2245e-02,\n",
      "          1.0870e-01,  5.0501e-02,  2.3096e-03, -1.2040e-01, -2.0657e-01,\n",
      "          3.4295e-02, -1.3215e-01, -3.6810e-02, -1.3001e-01,  6.0053e-02],\n",
      "        [ 1.3013e-01,  2.9992e-02,  5.9433e-02,  1.2428e-02,  1.8617e-01,\n",
      "         -1.7780e-01,  1.5794e-01,  1.6887e-01,  4.7626e-02, -1.5019e-01,\n",
      "         -2.0429e-02,  9.0132e-02, -1.5051e-01, -6.8489e-02,  1.5026e-01,\n",
      "          7.4534e-02, -1.2762e-01,  8.9281e-02, -1.6955e-01, -3.4628e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1267,  0.1868,  0.1184,  0.1880,  0.0519, -0.0926, -0.1878, -0.1015,\n",
      "         0.1832, -0.1159, -0.2084,  0.0662, -0.1230,  0.2027,  0.0196, -0.1410,\n",
      "         0.1429, -0.1540, -0.1426, -0.0530], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1091,  0.1249, -0.1758, -0.0867, -0.1984, -0.1938,  0.2170,  0.1245,\n",
      "         -0.0766, -0.2038,  0.0660,  0.1300, -0.0541,  0.1590,  0.1654, -0.1537,\n",
      "          0.1920,  0.0689,  0.1496,  0.1492],\n",
      "        [-0.1110, -0.2137, -0.1138, -0.1746, -0.2093, -0.0308, -0.0796,  0.0796,\n",
      "         -0.0831, -0.1893,  0.1598,  0.1358,  0.1807, -0.0900,  0.0649, -0.1450,\n",
      "          0.0234,  0.1754, -0.0431, -0.0889],\n",
      "        [-0.1340, -0.1318,  0.1003, -0.0378,  0.1669, -0.0329,  0.1269,  0.1122,\n",
      "         -0.0712,  0.0279, -0.0281, -0.0817, -0.1882,  0.0422, -0.0191,  0.1966,\n",
      "          0.1601,  0.1352,  0.0478,  0.0085],\n",
      "        [ 0.0245,  0.0778,  0.1820,  0.2043,  0.0272,  0.1909, -0.0835, -0.1838,\n",
      "          0.0397, -0.0234,  0.1738,  0.1777,  0.0076, -0.1641, -0.1686,  0.1272,\n",
      "         -0.1360,  0.1658,  0.0779, -0.0220],\n",
      "        [ 0.0764, -0.1829, -0.1693,  0.1721, -0.1295, -0.1211,  0.0921, -0.0021,\n",
      "          0.0018, -0.0408,  0.1844,  0.2120,  0.1316,  0.0070, -0.1139,  0.1708,\n",
      "          0.0101,  0.1490, -0.1235,  0.0296]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1919, -0.0462, -0.0664,  0.2046, -0.1843], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1125, -0.0415,  0.0902, -0.2539,  0.2646,  0.3139, -0.1084, -0.1892,\n",
      "         -0.1336,  0.0588],\n",
      "        [-0.2974, -0.0252,  0.1353,  0.3009, -0.1681, -0.0068,  0.1159, -0.0047,\n",
      "         -0.1056,  0.2720]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0995, 0.1578], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in obj1.model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59iLYeT-NRsG"
   },
   "source": [
    "# RUN for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ekz8oACnb3tA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "====> Epoch: 1 total_train_loss: 1.017181 Total_test_loss: 0.875592 Total_BCE_test_loss: 0.798675 Total_KLD_test_loss: 0.000051 Total_CEP_test_loss: 0.076866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohsennabian/Desktop/ci_vae/example/ci_vae/ivae.py:372: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(torch.reshape(y, (-1,)), dtype=torch.long)\n",
      "/Users/mohsennabian/Desktop/ci_vae/example/ci_vae/ivae.py:400: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(torch.reshape(y, (-1,)), dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 total_train_loss: 0.945560 Total_test_loss: 0.870121 Total_BCE_test_loss: 0.793847 Total_KLD_test_loss: 0.000045 Total_CEP_test_loss: 0.076229\n",
      "====> Epoch: 3 total_train_loss: 0.914561 Total_test_loss: 0.865661 Total_BCE_test_loss: 0.792392 Total_KLD_test_loss: 0.000044 Total_CEP_test_loss: 0.073225\n",
      "====> Epoch: 4 total_train_loss: 0.900481 Total_test_loss: 0.867067 Total_BCE_test_loss: 0.792484 Total_KLD_test_loss: 0.000047 Total_CEP_test_loss: 0.074535\n",
      "====> Epoch: 5 total_train_loss: 0.884053 Total_test_loss: 0.865572 Total_BCE_test_loss: 0.792121 Total_KLD_test_loss: 0.000064 Total_CEP_test_loss: 0.073387\n",
      "====> Epoch: 6 total_train_loss: 0.889137 Total_test_loss: 0.862568 Total_BCE_test_loss: 0.790794 Total_KLD_test_loss: 0.000104 Total_CEP_test_loss: 0.071669\n",
      "====> Epoch: 7 total_train_loss: 0.879185 Total_test_loss: 0.861602 Total_BCE_test_loss: 0.789488 Total_KLD_test_loss: 0.000171 Total_CEP_test_loss: 0.071943\n",
      "====> Epoch: 8 total_train_loss: 0.872060 Total_test_loss: 0.856596 Total_BCE_test_loss: 0.784498 Total_KLD_test_loss: 0.000262 Total_CEP_test_loss: 0.071836\n",
      "====> Epoch: 9 total_train_loss: 0.863994 Total_test_loss: 0.847609 Total_BCE_test_loss: 0.776133 Total_KLD_test_loss: 0.000397 Total_CEP_test_loss: 0.071080\n",
      "====> Epoch: 10 total_train_loss: 0.855162 Total_test_loss: 0.841607 Total_BCE_test_loss: 0.771265 Total_KLD_test_loss: 0.000533 Total_CEP_test_loss: 0.069809\n",
      "====> Epoch: 11 total_train_loss: 0.858249 Total_test_loss: 0.842288 Total_BCE_test_loss: 0.771864 Total_KLD_test_loss: 0.000664 Total_CEP_test_loss: 0.069760\n",
      "====> Epoch: 12 total_train_loss: 0.852423 Total_test_loss: 0.841954 Total_BCE_test_loss: 0.771375 Total_KLD_test_loss: 0.000749 Total_CEP_test_loss: 0.069831\n",
      "====> Epoch: 13 total_train_loss: 0.845374 Total_test_loss: 0.840016 Total_BCE_test_loss: 0.769576 Total_KLD_test_loss: 0.000829 Total_CEP_test_loss: 0.069611\n",
      "====> Epoch: 14 total_train_loss: 0.841779 Total_test_loss: 0.835095 Total_BCE_test_loss: 0.764882 Total_KLD_test_loss: 0.000917 Total_CEP_test_loss: 0.069296\n",
      "====> Epoch: 15 total_train_loss: 0.834884 Total_test_loss: 0.824891 Total_BCE_test_loss: 0.754328 Total_KLD_test_loss: 0.000993 Total_CEP_test_loss: 0.069570\n",
      "====> Epoch: 16 total_train_loss: 0.827760 Total_test_loss: 0.826640 Total_BCE_test_loss: 0.756047 Total_KLD_test_loss: 0.001118 Total_CEP_test_loss: 0.069476\n",
      "====> Epoch: 17 total_train_loss: 0.823880 Total_test_loss: 0.818819 Total_BCE_test_loss: 0.747948 Total_KLD_test_loss: 0.001239 Total_CEP_test_loss: 0.069632\n",
      "====> Epoch: 18 total_train_loss: 0.815049 Total_test_loss: 0.815427 Total_BCE_test_loss: 0.744818 Total_KLD_test_loss: 0.001370 Total_CEP_test_loss: 0.069240\n",
      "====> Epoch: 19 total_train_loss: 0.811248 Total_test_loss: 0.810352 Total_BCE_test_loss: 0.739475 Total_KLD_test_loss: 0.001472 Total_CEP_test_loss: 0.069404\n",
      "====> Epoch: 20 total_train_loss: 0.803644 Total_test_loss: 0.803881 Total_BCE_test_loss: 0.732835 Total_KLD_test_loss: 0.001614 Total_CEP_test_loss: 0.069432\n",
      "====> Epoch: 21 total_train_loss: 0.801901 Total_test_loss: 0.803693 Total_BCE_test_loss: 0.732695 Total_KLD_test_loss: 0.001718 Total_CEP_test_loss: 0.069279\n",
      "====> Epoch: 22 total_train_loss: 0.795980 Total_test_loss: 0.793247 Total_BCE_test_loss: 0.721849 Total_KLD_test_loss: 0.001848 Total_CEP_test_loss: 0.069551\n",
      "====> Epoch: 23 total_train_loss: 0.789076 Total_test_loss: 0.786375 Total_BCE_test_loss: 0.715036 Total_KLD_test_loss: 0.001946 Total_CEP_test_loss: 0.069393\n",
      "====> Epoch: 24 total_train_loss: 0.791875 Total_test_loss: 0.781219 Total_BCE_test_loss: 0.709841 Total_KLD_test_loss: 0.002017 Total_CEP_test_loss: 0.069361\n",
      "====> Epoch: 25 total_train_loss: 0.783037 Total_test_loss: 0.773829 Total_BCE_test_loss: 0.702334 Total_KLD_test_loss: 0.002106 Total_CEP_test_loss: 0.069389\n",
      "====> Epoch: 26 total_train_loss: 0.781967 Total_test_loss: 0.767145 Total_BCE_test_loss: 0.695650 Total_KLD_test_loss: 0.002132 Total_CEP_test_loss: 0.069363\n",
      "====> Epoch: 27 total_train_loss: 0.776843 Total_test_loss: 0.758867 Total_BCE_test_loss: 0.687314 Total_KLD_test_loss: 0.002112 Total_CEP_test_loss: 0.069441\n",
      "====> Epoch: 28 total_train_loss: 0.773759 Total_test_loss: 0.758654 Total_BCE_test_loss: 0.687086 Total_KLD_test_loss: 0.002155 Total_CEP_test_loss: 0.069413\n",
      "====> Epoch: 29 total_train_loss: 0.768003 Total_test_loss: 0.752969 Total_BCE_test_loss: 0.681334 Total_KLD_test_loss: 0.002224 Total_CEP_test_loss: 0.069411\n",
      "====> Epoch: 30 total_train_loss: 0.767298 Total_test_loss: 0.751681 Total_BCE_test_loss: 0.680165 Total_KLD_test_loss: 0.002339 Total_CEP_test_loss: 0.069176\n",
      "====> Epoch: 31 total_train_loss: 0.768066 Total_test_loss: 0.745639 Total_BCE_test_loss: 0.673743 Total_KLD_test_loss: 0.002510 Total_CEP_test_loss: 0.069386\n",
      "====> Epoch: 32 total_train_loss: 0.764000 Total_test_loss: 0.736403 Total_BCE_test_loss: 0.664223 Total_KLD_test_loss: 0.002655 Total_CEP_test_loss: 0.069525\n",
      "====> Epoch: 33 total_train_loss: 0.756711 Total_test_loss: 0.737277 Total_BCE_test_loss: 0.665053 Total_KLD_test_loss: 0.002776 Total_CEP_test_loss: 0.069448\n",
      "====> Epoch: 34 total_train_loss: 0.752322 Total_test_loss: 0.729863 Total_BCE_test_loss: 0.657734 Total_KLD_test_loss: 0.002815 Total_CEP_test_loss: 0.069314\n",
      "====> Epoch: 35 total_train_loss: 0.748971 Total_test_loss: 0.726932 Total_BCE_test_loss: 0.654633 Total_KLD_test_loss: 0.002891 Total_CEP_test_loss: 0.069407\n",
      "====> Epoch: 36 total_train_loss: 0.750845 Total_test_loss: 0.725181 Total_BCE_test_loss: 0.652800 Total_KLD_test_loss: 0.002980 Total_CEP_test_loss: 0.069401\n",
      "====> Epoch: 37 total_train_loss: 0.746960 Total_test_loss: 0.721174 Total_BCE_test_loss: 0.648667 Total_KLD_test_loss: 0.003074 Total_CEP_test_loss: 0.069433\n",
      "====> Epoch: 38 total_train_loss: 0.745497 Total_test_loss: 0.719366 Total_BCE_test_loss: 0.646757 Total_KLD_test_loss: 0.003123 Total_CEP_test_loss: 0.069486\n",
      "====> Epoch: 39 total_train_loss: 0.745105 Total_test_loss: 0.714981 Total_BCE_test_loss: 0.642408 Total_KLD_test_loss: 0.003204 Total_CEP_test_loss: 0.069369\n",
      "====> Epoch: 40 total_train_loss: 0.741669 Total_test_loss: 0.716067 Total_BCE_test_loss: 0.643277 Total_KLD_test_loss: 0.003291 Total_CEP_test_loss: 0.069499\n",
      "====> Epoch: 41 total_train_loss: 0.736196 Total_test_loss: 0.714624 Total_BCE_test_loss: 0.641841 Total_KLD_test_loss: 0.003342 Total_CEP_test_loss: 0.069441\n",
      "====> Epoch: 42 total_train_loss: 0.731768 Total_test_loss: 0.708298 Total_BCE_test_loss: 0.635599 Total_KLD_test_loss: 0.003384 Total_CEP_test_loss: 0.069315\n",
      "====> Epoch: 43 total_train_loss: 0.731964 Total_test_loss: 0.705880 Total_BCE_test_loss: 0.633153 Total_KLD_test_loss: 0.003393 Total_CEP_test_loss: 0.069334\n",
      "====> Epoch: 44 total_train_loss: 0.730221 Total_test_loss: 0.703806 Total_BCE_test_loss: 0.631003 Total_KLD_test_loss: 0.003449 Total_CEP_test_loss: 0.069354\n",
      "====> Epoch: 45 total_train_loss: 0.726050 Total_test_loss: 0.701945 Total_BCE_test_loss: 0.629135 Total_KLD_test_loss: 0.003479 Total_CEP_test_loss: 0.069331\n",
      "====> Epoch: 46 total_train_loss: 0.724268 Total_test_loss: 0.696338 Total_BCE_test_loss: 0.623411 Total_KLD_test_loss: 0.003593 Total_CEP_test_loss: 0.069335\n",
      "====> Epoch: 47 total_train_loss: 0.723569 Total_test_loss: 0.691710 Total_BCE_test_loss: 0.618763 Total_KLD_test_loss: 0.003667 Total_CEP_test_loss: 0.069280\n",
      "====> Epoch: 48 total_train_loss: 0.719234 Total_test_loss: 0.691087 Total_BCE_test_loss: 0.618096 Total_KLD_test_loss: 0.003694 Total_CEP_test_loss: 0.069297\n",
      "====> Epoch: 49 total_train_loss: 0.713537 Total_test_loss: 0.688997 Total_BCE_test_loss: 0.615960 Total_KLD_test_loss: 0.003785 Total_CEP_test_loss: 0.069253\n",
      "====> Epoch: 50 total_train_loss: 0.720016 Total_test_loss: 0.683012 Total_BCE_test_loss: 0.609883 Total_KLD_test_loss: 0.003881 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 51 total_train_loss: 0.715757 Total_test_loss: 0.683242 Total_BCE_test_loss: 0.610054 Total_KLD_test_loss: 0.003945 Total_CEP_test_loss: 0.069243\n",
      "====> Epoch: 52 total_train_loss: 0.711765 Total_test_loss: 0.678530 Total_BCE_test_loss: 0.605233 Total_KLD_test_loss: 0.004053 Total_CEP_test_loss: 0.069243\n",
      "====> Epoch: 53 total_train_loss: 0.710555 Total_test_loss: 0.679526 Total_BCE_test_loss: 0.606218 Total_KLD_test_loss: 0.004134 Total_CEP_test_loss: 0.069174\n",
      "====> Epoch: 54 total_train_loss: 0.711410 Total_test_loss: 0.674557 Total_BCE_test_loss: 0.601095 Total_KLD_test_loss: 0.004232 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 55 total_train_loss: 0.708709 Total_test_loss: 0.674950 Total_BCE_test_loss: 0.601205 Total_KLD_test_loss: 0.004341 Total_CEP_test_loss: 0.069404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 56 total_train_loss: 0.705025 Total_test_loss: 0.674251 Total_BCE_test_loss: 0.600495 Total_KLD_test_loss: 0.004413 Total_CEP_test_loss: 0.069343\n",
      "====> Epoch: 57 total_train_loss: 0.702544 Total_test_loss: 0.674352 Total_BCE_test_loss: 0.600349 Total_KLD_test_loss: 0.004526 Total_CEP_test_loss: 0.069476\n",
      "====> Epoch: 58 total_train_loss: 0.702546 Total_test_loss: 0.670263 Total_BCE_test_loss: 0.596083 Total_KLD_test_loss: 0.004640 Total_CEP_test_loss: 0.069540\n",
      "====> Epoch: 59 total_train_loss: 0.705836 Total_test_loss: 0.668055 Total_BCE_test_loss: 0.593981 Total_KLD_test_loss: 0.004743 Total_CEP_test_loss: 0.069331\n",
      "====> Epoch: 60 total_train_loss: 0.699513 Total_test_loss: 0.669548 Total_BCE_test_loss: 0.595480 Total_KLD_test_loss: 0.004813 Total_CEP_test_loss: 0.069255\n",
      "====> Epoch: 61 total_train_loss: 0.702216 Total_test_loss: 0.665810 Total_BCE_test_loss: 0.591922 Total_KLD_test_loss: 0.004853 Total_CEP_test_loss: 0.069036\n",
      "====> Epoch: 62 total_train_loss: 0.697989 Total_test_loss: 0.664150 Total_BCE_test_loss: 0.590111 Total_KLD_test_loss: 0.004881 Total_CEP_test_loss: 0.069159\n",
      "====> Epoch: 63 total_train_loss: 0.700028 Total_test_loss: 0.665414 Total_BCE_test_loss: 0.591152 Total_KLD_test_loss: 0.004960 Total_CEP_test_loss: 0.069302\n",
      "====> Epoch: 64 total_train_loss: 0.691835 Total_test_loss: 0.662058 Total_BCE_test_loss: 0.587692 Total_KLD_test_loss: 0.005020 Total_CEP_test_loss: 0.069346\n",
      "====> Epoch: 65 total_train_loss: 0.693881 Total_test_loss: 0.660483 Total_BCE_test_loss: 0.586027 Total_KLD_test_loss: 0.005124 Total_CEP_test_loss: 0.069332\n",
      "====> Epoch: 66 total_train_loss: 0.696466 Total_test_loss: 0.662977 Total_BCE_test_loss: 0.588397 Total_KLD_test_loss: 0.005197 Total_CEP_test_loss: 0.069383\n",
      "====> Epoch: 67 total_train_loss: 0.699455 Total_test_loss: 0.659396 Total_BCE_test_loss: 0.584698 Total_KLD_test_loss: 0.005287 Total_CEP_test_loss: 0.069410\n",
      "====> Epoch: 68 total_train_loss: 0.692894 Total_test_loss: 0.658714 Total_BCE_test_loss: 0.583854 Total_KLD_test_loss: 0.005394 Total_CEP_test_loss: 0.069466\n",
      "====> Epoch: 69 total_train_loss: 0.689900 Total_test_loss: 0.657064 Total_BCE_test_loss: 0.582129 Total_KLD_test_loss: 0.005450 Total_CEP_test_loss: 0.069484\n",
      "====> Epoch: 70 total_train_loss: 0.684705 Total_test_loss: 0.659442 Total_BCE_test_loss: 0.584575 Total_KLD_test_loss: 0.005498 Total_CEP_test_loss: 0.069370\n",
      "====> Epoch: 71 total_train_loss: 0.691687 Total_test_loss: 0.655674 Total_BCE_test_loss: 0.580915 Total_KLD_test_loss: 0.005437 Total_CEP_test_loss: 0.069322\n",
      "====> Epoch: 72 total_train_loss: 0.691644 Total_test_loss: 0.661971 Total_BCE_test_loss: 0.586966 Total_KLD_test_loss: 0.005434 Total_CEP_test_loss: 0.069571\n",
      "====> Epoch: 73 total_train_loss: 0.686523 Total_test_loss: 0.654536 Total_BCE_test_loss: 0.579551 Total_KLD_test_loss: 0.005628 Total_CEP_test_loss: 0.069356\n",
      "====> Epoch: 74 total_train_loss: 0.684746 Total_test_loss: 0.651438 Total_BCE_test_loss: 0.576422 Total_KLD_test_loss: 0.005666 Total_CEP_test_loss: 0.069350\n",
      "====> Epoch: 75 total_train_loss: 0.685409 Total_test_loss: 0.650919 Total_BCE_test_loss: 0.576010 Total_KLD_test_loss: 0.005783 Total_CEP_test_loss: 0.069126\n",
      "====> Epoch: 76 total_train_loss: 0.681697 Total_test_loss: 0.651771 Total_BCE_test_loss: 0.576629 Total_KLD_test_loss: 0.005869 Total_CEP_test_loss: 0.069272\n",
      "====> Epoch: 77 total_train_loss: 0.678951 Total_test_loss: 0.649002 Total_BCE_test_loss: 0.573716 Total_KLD_test_loss: 0.005837 Total_CEP_test_loss: 0.069449\n",
      "====> Epoch: 78 total_train_loss: 0.679343 Total_test_loss: 0.646230 Total_BCE_test_loss: 0.570966 Total_KLD_test_loss: 0.005880 Total_CEP_test_loss: 0.069384\n",
      "====> Epoch: 79 total_train_loss: 0.678356 Total_test_loss: 0.642090 Total_BCE_test_loss: 0.566709 Total_KLD_test_loss: 0.006040 Total_CEP_test_loss: 0.069341\n",
      "====> Epoch: 80 total_train_loss: 0.680934 Total_test_loss: 0.644298 Total_BCE_test_loss: 0.568859 Total_KLD_test_loss: 0.006135 Total_CEP_test_loss: 0.069305\n",
      "====> Epoch: 81 total_train_loss: 0.679081 Total_test_loss: 0.642286 Total_BCE_test_loss: 0.566880 Total_KLD_test_loss: 0.006062 Total_CEP_test_loss: 0.069345\n",
      "====> Epoch: 82 total_train_loss: 0.671342 Total_test_loss: 0.639498 Total_BCE_test_loss: 0.564232 Total_KLD_test_loss: 0.005891 Total_CEP_test_loss: 0.069375\n",
      "====> Epoch: 83 total_train_loss: 0.674583 Total_test_loss: 0.638934 Total_BCE_test_loss: 0.563771 Total_KLD_test_loss: 0.005845 Total_CEP_test_loss: 0.069319\n",
      "====> Epoch: 84 total_train_loss: 0.670733 Total_test_loss: 0.638406 Total_BCE_test_loss: 0.563191 Total_KLD_test_loss: 0.005861 Total_CEP_test_loss: 0.069354\n",
      "====> Epoch: 85 total_train_loss: 0.675916 Total_test_loss: 0.637372 Total_BCE_test_loss: 0.561912 Total_KLD_test_loss: 0.005940 Total_CEP_test_loss: 0.069520\n",
      "====> Epoch: 86 total_train_loss: 0.673014 Total_test_loss: 0.637135 Total_BCE_test_loss: 0.561361 Total_KLD_test_loss: 0.006112 Total_CEP_test_loss: 0.069661\n",
      "====> Epoch: 87 total_train_loss: 0.671470 Total_test_loss: 0.639443 Total_BCE_test_loss: 0.563589 Total_KLD_test_loss: 0.006261 Total_CEP_test_loss: 0.069593\n",
      "====> Epoch: 88 total_train_loss: 0.672745 Total_test_loss: 0.638943 Total_BCE_test_loss: 0.563084 Total_KLD_test_loss: 0.006429 Total_CEP_test_loss: 0.069430\n",
      "====> Epoch: 89 total_train_loss: 0.667593 Total_test_loss: 0.636720 Total_BCE_test_loss: 0.560915 Total_KLD_test_loss: 0.006466 Total_CEP_test_loss: 0.069339\n",
      "====> Epoch: 90 total_train_loss: 0.672835 Total_test_loss: 0.632068 Total_BCE_test_loss: 0.556209 Total_KLD_test_loss: 0.006504 Total_CEP_test_loss: 0.069355\n",
      "====> Epoch: 91 total_train_loss: 0.669500 Total_test_loss: 0.626962 Total_BCE_test_loss: 0.551393 Total_KLD_test_loss: 0.006325 Total_CEP_test_loss: 0.069243\n",
      "====> Epoch: 92 total_train_loss: 0.665772 Total_test_loss: 0.626968 Total_BCE_test_loss: 0.551005 Total_KLD_test_loss: 0.006271 Total_CEP_test_loss: 0.069692\n",
      "====> Epoch: 93 total_train_loss: 0.671592 Total_test_loss: 0.627422 Total_BCE_test_loss: 0.551940 Total_KLD_test_loss: 0.006146 Total_CEP_test_loss: 0.069337\n",
      "====> Epoch: 94 total_train_loss: 0.664356 Total_test_loss: 0.632247 Total_BCE_test_loss: 0.556671 Total_KLD_test_loss: 0.006130 Total_CEP_test_loss: 0.069446\n",
      "====> Epoch: 95 total_train_loss: 0.663033 Total_test_loss: 0.633557 Total_BCE_test_loss: 0.558021 Total_KLD_test_loss: 0.006231 Total_CEP_test_loss: 0.069305\n",
      "====> Epoch: 96 total_train_loss: 0.663334 Total_test_loss: 0.634112 Total_BCE_test_loss: 0.558456 Total_KLD_test_loss: 0.006308 Total_CEP_test_loss: 0.069348\n",
      "====> Epoch: 97 total_train_loss: 0.662564 Total_test_loss: 0.635265 Total_BCE_test_loss: 0.559407 Total_KLD_test_loss: 0.006343 Total_CEP_test_loss: 0.069515\n",
      "====> Epoch: 98 total_train_loss: 0.663093 Total_test_loss: 0.624025 Total_BCE_test_loss: 0.548025 Total_KLD_test_loss: 0.006511 Total_CEP_test_loss: 0.069489\n",
      "====> Epoch: 99 total_train_loss: 0.660978 Total_test_loss: 0.623601 Total_BCE_test_loss: 0.547898 Total_KLD_test_loss: 0.006471 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 100 total_train_loss: 0.661518 Total_test_loss: 0.620135 Total_BCE_test_loss: 0.544480 Total_KLD_test_loss: 0.006461 Total_CEP_test_loss: 0.069194\n",
      "0.001\n",
      "0.001\n",
      "0.001\n",
      "0.0005\n",
      "====> Epoch: 1 total_train_loss: 0.657549 Total_test_loss: 0.615843 Total_BCE_test_loss: 0.540288 Total_KLD_test_loss: 0.006369 Total_CEP_test_loss: 0.069186\n",
      "====> Epoch: 2 total_train_loss: 0.654160 Total_test_loss: 0.615546 Total_BCE_test_loss: 0.539893 Total_KLD_test_loss: 0.006411 Total_CEP_test_loss: 0.069241\n",
      "====> Epoch: 3 total_train_loss: 0.652007 Total_test_loss: 0.613951 Total_BCE_test_loss: 0.538296 Total_KLD_test_loss: 0.006408 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 4 total_train_loss: 0.653635 Total_test_loss: 0.612290 Total_BCE_test_loss: 0.536736 Total_KLD_test_loss: 0.006424 Total_CEP_test_loss: 0.069129\n",
      "====> Epoch: 5 total_train_loss: 0.653699 Total_test_loss: 0.612798 Total_BCE_test_loss: 0.537211 Total_KLD_test_loss: 0.006358 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 6 total_train_loss: 0.656923 Total_test_loss: 0.612260 Total_BCE_test_loss: 0.536640 Total_KLD_test_loss: 0.006391 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 7 total_train_loss: 0.653791 Total_test_loss: 0.612303 Total_BCE_test_loss: 0.536592 Total_KLD_test_loss: 0.006443 Total_CEP_test_loss: 0.069268\n",
      "====> Epoch: 8 total_train_loss: 0.654931 Total_test_loss: 0.609523 Total_BCE_test_loss: 0.533813 Total_KLD_test_loss: 0.006429 Total_CEP_test_loss: 0.069281\n",
      "====> Epoch: 9 total_train_loss: 0.653231 Total_test_loss: 0.610426 Total_BCE_test_loss: 0.534750 Total_KLD_test_loss: 0.006421 Total_CEP_test_loss: 0.069255\n",
      "====> Epoch: 10 total_train_loss: 0.654086 Total_test_loss: 0.610539 Total_BCE_test_loss: 0.534872 Total_KLD_test_loss: 0.006396 Total_CEP_test_loss: 0.069272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 11 total_train_loss: 0.650191 Total_test_loss: 0.610044 Total_BCE_test_loss: 0.534393 Total_KLD_test_loss: 0.006416 Total_CEP_test_loss: 0.069235\n",
      "====> Epoch: 12 total_train_loss: 0.653849 Total_test_loss: 0.609648 Total_BCE_test_loss: 0.534031 Total_KLD_test_loss: 0.006316 Total_CEP_test_loss: 0.069301\n",
      "====> Epoch: 13 total_train_loss: 0.649424 Total_test_loss: 0.609013 Total_BCE_test_loss: 0.533466 Total_KLD_test_loss: 0.006301 Total_CEP_test_loss: 0.069247\n",
      "====> Epoch: 14 total_train_loss: 0.651742 Total_test_loss: 0.608945 Total_BCE_test_loss: 0.533300 Total_KLD_test_loss: 0.006378 Total_CEP_test_loss: 0.069267\n",
      "====> Epoch: 15 total_train_loss: 0.653353 Total_test_loss: 0.606679 Total_BCE_test_loss: 0.530995 Total_KLD_test_loss: 0.006419 Total_CEP_test_loss: 0.069265\n",
      "====> Epoch: 16 total_train_loss: 0.650612 Total_test_loss: 0.608368 Total_BCE_test_loss: 0.532690 Total_KLD_test_loss: 0.006401 Total_CEP_test_loss: 0.069278\n",
      "====> Epoch: 17 total_train_loss: 0.654544 Total_test_loss: 0.608499 Total_BCE_test_loss: 0.532767 Total_KLD_test_loss: 0.006487 Total_CEP_test_loss: 0.069246\n",
      "====> Epoch: 18 total_train_loss: 0.652027 Total_test_loss: 0.607254 Total_BCE_test_loss: 0.531629 Total_KLD_test_loss: 0.006406 Total_CEP_test_loss: 0.069218\n",
      "====> Epoch: 19 total_train_loss: 0.653398 Total_test_loss: 0.607564 Total_BCE_test_loss: 0.531944 Total_KLD_test_loss: 0.006449 Total_CEP_test_loss: 0.069171\n",
      "====> Epoch: 20 total_train_loss: 0.651170 Total_test_loss: 0.607170 Total_BCE_test_loss: 0.531493 Total_KLD_test_loss: 0.006446 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 21 total_train_loss: 0.649842 Total_test_loss: 0.606516 Total_BCE_test_loss: 0.530870 Total_KLD_test_loss: 0.006437 Total_CEP_test_loss: 0.069209\n",
      "====> Epoch: 22 total_train_loss: 0.650677 Total_test_loss: 0.605899 Total_BCE_test_loss: 0.530082 Total_KLD_test_loss: 0.006450 Total_CEP_test_loss: 0.069367\n",
      "====> Epoch: 23 total_train_loss: 0.647130 Total_test_loss: 0.606641 Total_BCE_test_loss: 0.530993 Total_KLD_test_loss: 0.006424 Total_CEP_test_loss: 0.069224\n",
      "====> Epoch: 24 total_train_loss: 0.651406 Total_test_loss: 0.605925 Total_BCE_test_loss: 0.530226 Total_KLD_test_loss: 0.006474 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 25 total_train_loss: 0.643934 Total_test_loss: 0.605753 Total_BCE_test_loss: 0.530051 Total_KLD_test_loss: 0.006442 Total_CEP_test_loss: 0.069260\n",
      "====> Epoch: 26 total_train_loss: 0.651306 Total_test_loss: 0.604130 Total_BCE_test_loss: 0.528358 Total_KLD_test_loss: 0.006540 Total_CEP_test_loss: 0.069231\n",
      "====> Epoch: 27 total_train_loss: 0.647258 Total_test_loss: 0.603570 Total_BCE_test_loss: 0.527902 Total_KLD_test_loss: 0.006485 Total_CEP_test_loss: 0.069184\n",
      "====> Epoch: 28 total_train_loss: 0.647669 Total_test_loss: 0.603568 Total_BCE_test_loss: 0.527858 Total_KLD_test_loss: 0.006583 Total_CEP_test_loss: 0.069127\n",
      "====> Epoch: 29 total_train_loss: 0.650632 Total_test_loss: 0.603590 Total_BCE_test_loss: 0.527978 Total_KLD_test_loss: 0.006499 Total_CEP_test_loss: 0.069113\n",
      "====> Epoch: 30 total_train_loss: 0.645225 Total_test_loss: 0.603954 Total_BCE_test_loss: 0.528325 Total_KLD_test_loss: 0.006515 Total_CEP_test_loss: 0.069114\n",
      "====> Epoch: 31 total_train_loss: 0.649268 Total_test_loss: 0.603444 Total_BCE_test_loss: 0.527793 Total_KLD_test_loss: 0.006536 Total_CEP_test_loss: 0.069116\n",
      "====> Epoch: 32 total_train_loss: 0.648058 Total_test_loss: 0.603346 Total_BCE_test_loss: 0.527740 Total_KLD_test_loss: 0.006497 Total_CEP_test_loss: 0.069110\n",
      "====> Epoch: 33 total_train_loss: 0.648636 Total_test_loss: 0.602209 Total_BCE_test_loss: 0.526615 Total_KLD_test_loss: 0.006488 Total_CEP_test_loss: 0.069106\n",
      "====> Epoch: 34 total_train_loss: 0.646748 Total_test_loss: 0.602593 Total_BCE_test_loss: 0.527039 Total_KLD_test_loss: 0.006458 Total_CEP_test_loss: 0.069096\n",
      "====> Epoch: 35 total_train_loss: 0.652160 Total_test_loss: 0.603382 Total_BCE_test_loss: 0.527683 Total_KLD_test_loss: 0.006458 Total_CEP_test_loss: 0.069241\n",
      "====> Epoch: 36 total_train_loss: 0.649265 Total_test_loss: 0.602859 Total_BCE_test_loss: 0.527226 Total_KLD_test_loss: 0.006541 Total_CEP_test_loss: 0.069093\n",
      "====> Epoch: 37 total_train_loss: 0.647271 Total_test_loss: 0.600874 Total_BCE_test_loss: 0.525153 Total_KLD_test_loss: 0.006590 Total_CEP_test_loss: 0.069132\n",
      "====> Epoch: 38 total_train_loss: 0.646582 Total_test_loss: 0.600807 Total_BCE_test_loss: 0.525050 Total_KLD_test_loss: 0.006532 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 39 total_train_loss: 0.645036 Total_test_loss: 0.600974 Total_BCE_test_loss: 0.525192 Total_KLD_test_loss: 0.006529 Total_CEP_test_loss: 0.069254\n",
      "====> Epoch: 40 total_train_loss: 0.650244 Total_test_loss: 0.600183 Total_BCE_test_loss: 0.524414 Total_KLD_test_loss: 0.006565 Total_CEP_test_loss: 0.069205\n",
      "====> Epoch: 41 total_train_loss: 0.650912 Total_test_loss: 0.599953 Total_BCE_test_loss: 0.524164 Total_KLD_test_loss: 0.006634 Total_CEP_test_loss: 0.069154\n",
      "====> Epoch: 42 total_train_loss: 0.642683 Total_test_loss: 0.599955 Total_BCE_test_loss: 0.524150 Total_KLD_test_loss: 0.006600 Total_CEP_test_loss: 0.069205\n",
      "====> Epoch: 43 total_train_loss: 0.641862 Total_test_loss: 0.600486 Total_BCE_test_loss: 0.524647 Total_KLD_test_loss: 0.006614 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 44 total_train_loss: 0.647152 Total_test_loss: 0.599610 Total_BCE_test_loss: 0.523785 Total_KLD_test_loss: 0.006613 Total_CEP_test_loss: 0.069212\n",
      "====> Epoch: 45 total_train_loss: 0.646246 Total_test_loss: 0.600272 Total_BCE_test_loss: 0.524473 Total_KLD_test_loss: 0.006569 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 46 total_train_loss: 0.648748 Total_test_loss: 0.599582 Total_BCE_test_loss: 0.523817 Total_KLD_test_loss: 0.006548 Total_CEP_test_loss: 0.069217\n",
      "====> Epoch: 47 total_train_loss: 0.644445 Total_test_loss: 0.598624 Total_BCE_test_loss: 0.522864 Total_KLD_test_loss: 0.006549 Total_CEP_test_loss: 0.069211\n",
      "====> Epoch: 48 total_train_loss: 0.644988 Total_test_loss: 0.598633 Total_BCE_test_loss: 0.522899 Total_KLD_test_loss: 0.006546 Total_CEP_test_loss: 0.069188\n",
      "====> Epoch: 49 total_train_loss: 0.641625 Total_test_loss: 0.597597 Total_BCE_test_loss: 0.521831 Total_KLD_test_loss: 0.006525 Total_CEP_test_loss: 0.069241\n",
      "====> Epoch: 50 total_train_loss: 0.645408 Total_test_loss: 0.597366 Total_BCE_test_loss: 0.521610 Total_KLD_test_loss: 0.006543 Total_CEP_test_loss: 0.069213\n",
      "1e-05\n",
      "====> Epoch: 1 total_train_loss: 0.644254 Total_test_loss: 0.598073 Total_BCE_test_loss: 0.522389 Total_KLD_test_loss: 0.006477 Total_CEP_test_loss: 0.069207\n",
      "====> Epoch: 2 total_train_loss: 0.644386 Total_test_loss: 0.599125 Total_BCE_test_loss: 0.523435 Total_KLD_test_loss: 0.006463 Total_CEP_test_loss: 0.069228\n",
      "====> Epoch: 3 total_train_loss: 0.647662 Total_test_loss: 0.597050 Total_BCE_test_loss: 0.521306 Total_KLD_test_loss: 0.006515 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 4 total_train_loss: 0.644483 Total_test_loss: 0.598882 Total_BCE_test_loss: 0.523113 Total_KLD_test_loss: 0.006502 Total_CEP_test_loss: 0.069267\n",
      "====> Epoch: 5 total_train_loss: 0.650640 Total_test_loss: 0.599009 Total_BCE_test_loss: 0.523342 Total_KLD_test_loss: 0.006467 Total_CEP_test_loss: 0.069200\n",
      "====> Epoch: 6 total_train_loss: 0.646450 Total_test_loss: 0.598803 Total_BCE_test_loss: 0.523145 Total_KLD_test_loss: 0.006475 Total_CEP_test_loss: 0.069182\n",
      "====> Epoch: 7 total_train_loss: 0.645275 Total_test_loss: 0.597945 Total_BCE_test_loss: 0.522217 Total_KLD_test_loss: 0.006500 Total_CEP_test_loss: 0.069228\n",
      "====> Epoch: 8 total_train_loss: 0.644463 Total_test_loss: 0.599395 Total_BCE_test_loss: 0.523666 Total_KLD_test_loss: 0.006473 Total_CEP_test_loss: 0.069256\n",
      "====> Epoch: 9 total_train_loss: 0.640561 Total_test_loss: 0.598793 Total_BCE_test_loss: 0.523152 Total_KLD_test_loss: 0.006396 Total_CEP_test_loss: 0.069245\n",
      "====> Epoch: 10 total_train_loss: 0.644251 Total_test_loss: 0.597369 Total_BCE_test_loss: 0.521718 Total_KLD_test_loss: 0.006429 Total_CEP_test_loss: 0.069223\n",
      "====> Epoch: 11 total_train_loss: 0.649974 Total_test_loss: 0.599462 Total_BCE_test_loss: 0.523778 Total_KLD_test_loss: 0.006488 Total_CEP_test_loss: 0.069196\n",
      "====> Epoch: 12 total_train_loss: 0.648825 Total_test_loss: 0.599506 Total_BCE_test_loss: 0.523770 Total_KLD_test_loss: 0.006478 Total_CEP_test_loss: 0.069258\n",
      "====> Epoch: 13 total_train_loss: 0.647351 Total_test_loss: 0.597481 Total_BCE_test_loss: 0.521676 Total_KLD_test_loss: 0.006559 Total_CEP_test_loss: 0.069246\n",
      "====> Epoch: 14 total_train_loss: 0.644343 Total_test_loss: 0.597811 Total_BCE_test_loss: 0.522021 Total_KLD_test_loss: 0.006579 Total_CEP_test_loss: 0.069212\n",
      "====> Epoch: 15 total_train_loss: 0.644934 Total_test_loss: 0.597733 Total_BCE_test_loss: 0.521870 Total_KLD_test_loss: 0.006566 Total_CEP_test_loss: 0.069297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 16 total_train_loss: 0.642711 Total_test_loss: 0.597810 Total_BCE_test_loss: 0.522010 Total_KLD_test_loss: 0.006552 Total_CEP_test_loss: 0.069247\n",
      "====> Epoch: 17 total_train_loss: 0.642911 Total_test_loss: 0.598050 Total_BCE_test_loss: 0.522306 Total_KLD_test_loss: 0.006512 Total_CEP_test_loss: 0.069231\n",
      "====> Epoch: 18 total_train_loss: 0.645743 Total_test_loss: 0.597145 Total_BCE_test_loss: 0.521324 Total_KLD_test_loss: 0.006584 Total_CEP_test_loss: 0.069237\n",
      "====> Epoch: 19 total_train_loss: 0.647787 Total_test_loss: 0.597035 Total_BCE_test_loss: 0.521221 Total_KLD_test_loss: 0.006586 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 20 total_train_loss: 0.646643 Total_test_loss: 0.597722 Total_BCE_test_loss: 0.521967 Total_KLD_test_loss: 0.006565 Total_CEP_test_loss: 0.069190\n",
      "====> Epoch: 21 total_train_loss: 0.642298 Total_test_loss: 0.598518 Total_BCE_test_loss: 0.522748 Total_KLD_test_loss: 0.006574 Total_CEP_test_loss: 0.069196\n",
      "====> Epoch: 22 total_train_loss: 0.646632 Total_test_loss: 0.598645 Total_BCE_test_loss: 0.522857 Total_KLD_test_loss: 0.006560 Total_CEP_test_loss: 0.069228\n",
      "====> Epoch: 23 total_train_loss: 0.647688 Total_test_loss: 0.598193 Total_BCE_test_loss: 0.522383 Total_KLD_test_loss: 0.006577 Total_CEP_test_loss: 0.069232\n",
      "====> Epoch: 24 total_train_loss: 0.644644 Total_test_loss: 0.597694 Total_BCE_test_loss: 0.521940 Total_KLD_test_loss: 0.006548 Total_CEP_test_loss: 0.069205\n",
      "====> Epoch: 25 total_train_loss: 0.646060 Total_test_loss: 0.598849 Total_BCE_test_loss: 0.523052 Total_KLD_test_loss: 0.006552 Total_CEP_test_loss: 0.069245\n",
      "====> Epoch: 26 total_train_loss: 0.641087 Total_test_loss: 0.598223 Total_BCE_test_loss: 0.522498 Total_KLD_test_loss: 0.006494 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 27 total_train_loss: 0.646957 Total_test_loss: 0.597592 Total_BCE_test_loss: 0.521852 Total_KLD_test_loss: 0.006506 Total_CEP_test_loss: 0.069234\n",
      "====> Epoch: 28 total_train_loss: 0.646034 Total_test_loss: 0.598100 Total_BCE_test_loss: 0.522284 Total_KLD_test_loss: 0.006591 Total_CEP_test_loss: 0.069224\n",
      "====> Epoch: 29 total_train_loss: 0.643397 Total_test_loss: 0.596513 Total_BCE_test_loss: 0.520780 Total_KLD_test_loss: 0.006553 Total_CEP_test_loss: 0.069180\n",
      "====> Epoch: 30 total_train_loss: 0.646367 Total_test_loss: 0.598915 Total_BCE_test_loss: 0.523195 Total_KLD_test_loss: 0.006539 Total_CEP_test_loss: 0.069181\n",
      "====> Epoch: 31 total_train_loss: 0.642003 Total_test_loss: 0.598606 Total_BCE_test_loss: 0.522869 Total_KLD_test_loss: 0.006515 Total_CEP_test_loss: 0.069222\n",
      "====> Epoch: 32 total_train_loss: 0.644727 Total_test_loss: 0.596823 Total_BCE_test_loss: 0.521104 Total_KLD_test_loss: 0.006475 Total_CEP_test_loss: 0.069244\n",
      "====> Epoch: 33 total_train_loss: 0.644828 Total_test_loss: 0.597251 Total_BCE_test_loss: 0.521525 Total_KLD_test_loss: 0.006498 Total_CEP_test_loss: 0.069228\n",
      "====> Epoch: 34 total_train_loss: 0.644566 Total_test_loss: 0.597004 Total_BCE_test_loss: 0.521260 Total_KLD_test_loss: 0.006492 Total_CEP_test_loss: 0.069252\n",
      "====> Epoch: 35 total_train_loss: 0.643347 Total_test_loss: 0.598000 Total_BCE_test_loss: 0.522262 Total_KLD_test_loss: 0.006491 Total_CEP_test_loss: 0.069247\n",
      "====> Epoch: 36 total_train_loss: 0.640656 Total_test_loss: 0.597804 Total_BCE_test_loss: 0.522069 Total_KLD_test_loss: 0.006507 Total_CEP_test_loss: 0.069228\n",
      "====> Epoch: 37 total_train_loss: 0.642633 Total_test_loss: 0.597591 Total_BCE_test_loss: 0.521793 Total_KLD_test_loss: 0.006561 Total_CEP_test_loss: 0.069236\n",
      "====> Epoch: 38 total_train_loss: 0.645204 Total_test_loss: 0.597720 Total_BCE_test_loss: 0.521999 Total_KLD_test_loss: 0.006493 Total_CEP_test_loss: 0.069227\n",
      "====> Epoch: 39 total_train_loss: 0.640010 Total_test_loss: 0.598123 Total_BCE_test_loss: 0.522364 Total_KLD_test_loss: 0.006554 Total_CEP_test_loss: 0.069205\n",
      "====> Epoch: 40 total_train_loss: 0.644848 Total_test_loss: 0.598473 Total_BCE_test_loss: 0.522766 Total_KLD_test_loss: 0.006505 Total_CEP_test_loss: 0.069202\n",
      "====> Epoch: 41 total_train_loss: 0.641686 Total_test_loss: 0.598012 Total_BCE_test_loss: 0.522271 Total_KLD_test_loss: 0.006500 Total_CEP_test_loss: 0.069241\n",
      "====> Epoch: 42 total_train_loss: 0.647394 Total_test_loss: 0.598025 Total_BCE_test_loss: 0.522255 Total_KLD_test_loss: 0.006588 Total_CEP_test_loss: 0.069182\n",
      "====> Epoch: 43 total_train_loss: 0.646725 Total_test_loss: 0.598610 Total_BCE_test_loss: 0.522763 Total_KLD_test_loss: 0.006575 Total_CEP_test_loss: 0.069271\n",
      "====> Epoch: 44 total_train_loss: 0.641890 Total_test_loss: 0.597779 Total_BCE_test_loss: 0.522074 Total_KLD_test_loss: 0.006508 Total_CEP_test_loss: 0.069198\n",
      "====> Epoch: 45 total_train_loss: 0.642392 Total_test_loss: 0.598951 Total_BCE_test_loss: 0.523245 Total_KLD_test_loss: 0.006470 Total_CEP_test_loss: 0.069235\n",
      "====> Epoch: 46 total_train_loss: 0.644161 Total_test_loss: 0.599407 Total_BCE_test_loss: 0.523675 Total_KLD_test_loss: 0.006488 Total_CEP_test_loss: 0.069244\n",
      "====> Epoch: 47 total_train_loss: 0.641590 Total_test_loss: 0.599074 Total_BCE_test_loss: 0.523354 Total_KLD_test_loss: 0.006491 Total_CEP_test_loss: 0.069228\n",
      "====> Epoch: 48 total_train_loss: 0.647435 Total_test_loss: 0.598676 Total_BCE_test_loss: 0.522917 Total_KLD_test_loss: 0.006508 Total_CEP_test_loss: 0.069251\n",
      "====> Epoch: 49 total_train_loss: 0.640475 Total_test_loss: 0.597673 Total_BCE_test_loss: 0.521918 Total_KLD_test_loss: 0.006529 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 50 total_train_loss: 0.642430 Total_test_loss: 0.597722 Total_BCE_test_loss: 0.521954 Total_KLD_test_loss: 0.006540 Total_CEP_test_loss: 0.069228\n",
      "5e-06\n",
      "====> Epoch: 1 total_train_loss: 0.644215 Total_test_loss: 0.597610 Total_BCE_test_loss: 0.521843 Total_KLD_test_loss: 0.006554 Total_CEP_test_loss: 0.069214\n",
      "====> Epoch: 2 total_train_loss: 0.646625 Total_test_loss: 0.598046 Total_BCE_test_loss: 0.522320 Total_KLD_test_loss: 0.006544 Total_CEP_test_loss: 0.069183\n",
      "====> Epoch: 3 total_train_loss: 0.648496 Total_test_loss: 0.597658 Total_BCE_test_loss: 0.521935 Total_KLD_test_loss: 0.006525 Total_CEP_test_loss: 0.069199\n",
      "====> Epoch: 4 total_train_loss: 0.648260 Total_test_loss: 0.597556 Total_BCE_test_loss: 0.521840 Total_KLD_test_loss: 0.006522 Total_CEP_test_loss: 0.069195\n",
      "====> Epoch: 5 total_train_loss: 0.651084 Total_test_loss: 0.596694 Total_BCE_test_loss: 0.520943 Total_KLD_test_loss: 0.006522 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 6 total_train_loss: 0.644863 Total_test_loss: 0.598346 Total_BCE_test_loss: 0.522545 Total_KLD_test_loss: 0.006559 Total_CEP_test_loss: 0.069242\n",
      "====> Epoch: 7 total_train_loss: 0.642008 Total_test_loss: 0.597624 Total_BCE_test_loss: 0.521830 Total_KLD_test_loss: 0.006576 Total_CEP_test_loss: 0.069218\n",
      "====> Epoch: 8 total_train_loss: 0.642301 Total_test_loss: 0.596493 Total_BCE_test_loss: 0.520665 Total_KLD_test_loss: 0.006574 Total_CEP_test_loss: 0.069254\n",
      "====> Epoch: 9 total_train_loss: 0.644201 Total_test_loss: 0.598751 Total_BCE_test_loss: 0.522981 Total_KLD_test_loss: 0.006545 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 10 total_train_loss: 0.649640 Total_test_loss: 0.597530 Total_BCE_test_loss: 0.521729 Total_KLD_test_loss: 0.006579 Total_CEP_test_loss: 0.069221\n",
      "====> Epoch: 11 total_train_loss: 0.644480 Total_test_loss: 0.598102 Total_BCE_test_loss: 0.522239 Total_KLD_test_loss: 0.006645 Total_CEP_test_loss: 0.069218\n",
      "====> Epoch: 12 total_train_loss: 0.646382 Total_test_loss: 0.597923 Total_BCE_test_loss: 0.522095 Total_KLD_test_loss: 0.006573 Total_CEP_test_loss: 0.069255\n",
      "====> Epoch: 13 total_train_loss: 0.645472 Total_test_loss: 0.597417 Total_BCE_test_loss: 0.521585 Total_KLD_test_loss: 0.006586 Total_CEP_test_loss: 0.069246\n",
      "====> Epoch: 14 total_train_loss: 0.645032 Total_test_loss: 0.598489 Total_BCE_test_loss: 0.522683 Total_KLD_test_loss: 0.006572 Total_CEP_test_loss: 0.069234\n",
      "====> Epoch: 15 total_train_loss: 0.647469 Total_test_loss: 0.598158 Total_BCE_test_loss: 0.522439 Total_KLD_test_loss: 0.006490 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 16 total_train_loss: 0.646855 Total_test_loss: 0.596626 Total_BCE_test_loss: 0.520900 Total_KLD_test_loss: 0.006507 Total_CEP_test_loss: 0.069219\n",
      "====> Epoch: 17 total_train_loss: 0.642951 Total_test_loss: 0.597650 Total_BCE_test_loss: 0.521966 Total_KLD_test_loss: 0.006474 Total_CEP_test_loss: 0.069210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 18 total_train_loss: 0.641987 Total_test_loss: 0.598518 Total_BCE_test_loss: 0.522849 Total_KLD_test_loss: 0.006465 Total_CEP_test_loss: 0.069204\n",
      "====> Epoch: 19 total_train_loss: 0.643866 Total_test_loss: 0.597993 Total_BCE_test_loss: 0.522290 Total_KLD_test_loss: 0.006493 Total_CEP_test_loss: 0.069209\n",
      "====> Epoch: 20 total_train_loss: 0.645182 Total_test_loss: 0.596891 Total_BCE_test_loss: 0.521199 Total_KLD_test_loss: 0.006508 Total_CEP_test_loss: 0.069183\n",
      "====> Epoch: 21 total_train_loss: 0.642132 Total_test_loss: 0.597722 Total_BCE_test_loss: 0.522011 Total_KLD_test_loss: 0.006515 Total_CEP_test_loss: 0.069196\n",
      "====> Epoch: 22 total_train_loss: 0.645923 Total_test_loss: 0.597423 Total_BCE_test_loss: 0.521727 Total_KLD_test_loss: 0.006473 Total_CEP_test_loss: 0.069223\n",
      "====> Epoch: 23 total_train_loss: 0.644479 Total_test_loss: 0.597853 Total_BCE_test_loss: 0.522095 Total_KLD_test_loss: 0.006540 Total_CEP_test_loss: 0.069218\n",
      "====> Epoch: 24 total_train_loss: 0.644784 Total_test_loss: 0.598188 Total_BCE_test_loss: 0.522436 Total_KLD_test_loss: 0.006490 Total_CEP_test_loss: 0.069261\n",
      "====> Epoch: 25 total_train_loss: 0.645194 Total_test_loss: 0.597501 Total_BCE_test_loss: 0.521741 Total_KLD_test_loss: 0.006530 Total_CEP_test_loss: 0.069230\n",
      "====> Epoch: 26 total_train_loss: 0.641103 Total_test_loss: 0.598186 Total_BCE_test_loss: 0.522385 Total_KLD_test_loss: 0.006579 Total_CEP_test_loss: 0.069223\n",
      "====> Epoch: 27 total_train_loss: 0.644586 Total_test_loss: 0.596969 Total_BCE_test_loss: 0.521131 Total_KLD_test_loss: 0.006586 Total_CEP_test_loss: 0.069252\n",
      "====> Epoch: 28 total_train_loss: 0.647620 Total_test_loss: 0.597607 Total_BCE_test_loss: 0.521914 Total_KLD_test_loss: 0.006517 Total_CEP_test_loss: 0.069175\n",
      "====> Epoch: 29 total_train_loss: 0.644011 Total_test_loss: 0.596131 Total_BCE_test_loss: 0.520299 Total_KLD_test_loss: 0.006560 Total_CEP_test_loss: 0.069272\n",
      "====> Epoch: 30 total_train_loss: 0.644367 Total_test_loss: 0.597590 Total_BCE_test_loss: 0.521914 Total_KLD_test_loss: 0.006492 Total_CEP_test_loss: 0.069185\n",
      "====> Epoch: 31 total_train_loss: 0.649315 Total_test_loss: 0.597615 Total_BCE_test_loss: 0.521863 Total_KLD_test_loss: 0.006490 Total_CEP_test_loss: 0.069262\n",
      "====> Epoch: 32 total_train_loss: 0.643748 Total_test_loss: 0.596168 Total_BCE_test_loss: 0.520430 Total_KLD_test_loss: 0.006519 Total_CEP_test_loss: 0.069220\n",
      "====> Epoch: 33 total_train_loss: 0.648033 Total_test_loss: 0.597361 Total_BCE_test_loss: 0.521611 Total_KLD_test_loss: 0.006522 Total_CEP_test_loss: 0.069229\n",
      "====> Epoch: 34 total_train_loss: 0.643033 Total_test_loss: 0.598272 Total_BCE_test_loss: 0.522536 Total_KLD_test_loss: 0.006482 Total_CEP_test_loss: 0.069254\n",
      "====> Epoch: 35 total_train_loss: 0.644328 Total_test_loss: 0.598933 Total_BCE_test_loss: 0.523172 Total_KLD_test_loss: 0.006537 Total_CEP_test_loss: 0.069225\n",
      "====> Epoch: 36 total_train_loss: 0.643862 Total_test_loss: 0.597878 Total_BCE_test_loss: 0.522087 Total_KLD_test_loss: 0.006548 Total_CEP_test_loss: 0.069244\n",
      "====> Epoch: 37 total_train_loss: 0.647166 Total_test_loss: 0.596322 Total_BCE_test_loss: 0.520505 Total_KLD_test_loss: 0.006570 Total_CEP_test_loss: 0.069246\n",
      "====> Epoch: 38 total_train_loss: 0.643341 Total_test_loss: 0.596676 Total_BCE_test_loss: 0.520754 Total_KLD_test_loss: 0.006659 Total_CEP_test_loss: 0.069263\n",
      "====> Epoch: 39 total_train_loss: 0.645443 Total_test_loss: 0.598618 Total_BCE_test_loss: 0.522799 Total_KLD_test_loss: 0.006584 Total_CEP_test_loss: 0.069235\n",
      "====> Epoch: 40 total_train_loss: 0.646958 Total_test_loss: 0.598083 Total_BCE_test_loss: 0.522246 Total_KLD_test_loss: 0.006604 Total_CEP_test_loss: 0.069233\n",
      "====> Epoch: 41 total_train_loss: 0.645466 Total_test_loss: 0.597901 Total_BCE_test_loss: 0.522140 Total_KLD_test_loss: 0.006512 Total_CEP_test_loss: 0.069248\n",
      "====> Epoch: 42 total_train_loss: 0.638818 Total_test_loss: 0.597205 Total_BCE_test_loss: 0.521499 Total_KLD_test_loss: 0.006483 Total_CEP_test_loss: 0.069223\n",
      "====> Epoch: 43 total_train_loss: 0.641688 Total_test_loss: 0.597861 Total_BCE_test_loss: 0.522150 Total_KLD_test_loss: 0.006531 Total_CEP_test_loss: 0.069180\n",
      "====> Epoch: 44 total_train_loss: 0.643192 Total_test_loss: 0.597903 Total_BCE_test_loss: 0.522123 Total_KLD_test_loss: 0.006566 Total_CEP_test_loss: 0.069214\n",
      "====> Epoch: 45 total_train_loss: 0.643223 Total_test_loss: 0.598540 Total_BCE_test_loss: 0.522785 Total_KLD_test_loss: 0.006543 Total_CEP_test_loss: 0.069212\n",
      "====> Epoch: 46 total_train_loss: 0.640791 Total_test_loss: 0.597531 Total_BCE_test_loss: 0.521666 Total_KLD_test_loss: 0.006621 Total_CEP_test_loss: 0.069244\n",
      "====> Epoch: 47 total_train_loss: 0.648079 Total_test_loss: 0.597379 Total_BCE_test_loss: 0.521654 Total_KLD_test_loss: 0.006552 Total_CEP_test_loss: 0.069173\n",
      "====> Epoch: 48 total_train_loss: 0.644467 Total_test_loss: 0.599133 Total_BCE_test_loss: 0.523347 Total_KLD_test_loss: 0.006517 Total_CEP_test_loss: 0.069269\n",
      "====> Epoch: 49 total_train_loss: 0.643559 Total_test_loss: 0.598095 Total_BCE_test_loss: 0.522334 Total_KLD_test_loss: 0.006500 Total_CEP_test_loss: 0.069261\n",
      "====> Epoch: 50 total_train_loss: 0.641633 Total_test_loss: 0.598316 Total_BCE_test_loss: 0.522555 Total_KLD_test_loss: 0.006549 Total_CEP_test_loss: 0.069212\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "if model_tobe_trained:\n",
    "    lr=1e-2\n",
    "    print(lr)\n",
    "    obj1.model_training(epochs=100,learning_rate=lr)\n",
    "\n",
    "    lr=1e-3\n",
    "    print(lr)\n",
    "    #obj.model_training(epochs=70,learning_rate=lr)\n",
    "\n",
    "    lr=1e-3\n",
    "    print(lr)\n",
    "    #obj.model_training(epochs=200,learning_rate=lr)\n",
    "\n",
    "    obj1.model_save(address=save_address+\".pt\")\n",
    "    obj1.save_residuals(address=save_address+'_residuals.pkl')\n",
    "    lr=1e-3\n",
    "    print(lr)\n",
    "    #obj.model_training(epochs=70,learning_rate=lr)\n",
    "\n",
    "    lr=5e-4\n",
    "    print(lr)\n",
    "    obj1.model_training(epochs=50,learning_rate=lr)\n",
    "\n",
    "    obj1.model_save(address=save_address+\".pt\")\n",
    "    obj1.save_residuals(address=save_address+'_residuals.pkl')\n",
    "\n",
    "    lr=1e-5\n",
    "    print(lr)\n",
    "    obj1.model_training(epochs=50,learning_rate=lr)\n",
    "\n",
    "    lr=5e-6\n",
    "    print(lr)\n",
    "    obj1.model_training(epochs=50,learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5tsLzrBNa7E"
   },
   "source": [
    "# Save The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42YFEvnqbE9U",
    "outputId": "555826a8-f613-4331-b6a5-1acc5a1b82a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running the neural network\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "print(\"running the neural network\")\n",
    "#run(obj1,save_address)\n",
    "obj1.model_save(address=save_address+\".pt\")\n",
    "obj1.save_residuals(address=save_address+'_residuals.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUnPPyZ6NfDr"
   },
   "source": [
    "# Visualize Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "DStavVSXYRs5",
    "outputId": "047b7d45-2f98-4854-9ea2-17f3781d9842"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj1.plot_residuals(init_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkjkH6AjN5pq"
   },
   "source": [
    "# Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "DBW6HgBINu9v"
   },
   "outputs": [],
   "source": [
    "from ci_vae import ivae\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "#import umap\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqNZPHbPOkoh",
    "outputId": "35686f32-9d60-4ae3-b7b6-a634658bb1b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the code\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the code\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "##############################################################   \n",
    "##############################################################\n",
    "model_init=True\n",
    "model_tobe_trained=False\n",
    "\n",
    "model_init=True\n",
    "model_file_address='./bb.pt'\n",
    "save_address1=\"./\"\n",
    "\n",
    "df_XY=pd.read_csv('df_XY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oDqQbsnOO6d"
   },
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "fHFjOqpnigK_"
   },
   "outputs": [],
   "source": [
    "obj2 = ivae.IVAE(df_XY = df_XY,\n",
    "               reconst_coef = reconst_coef,\n",
    "               latent_size = 10,\n",
    "               kl_coef = kl_coef,\n",
    "               classifier_coef = classifier_coef,\n",
    "               test_ratio = 1)\n",
    "\n",
    "obj2.model_initialiaze()\n",
    "\n",
    "obj2.model_load(address=\"bb.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOUIzmGTOTyG"
   },
   "source": [
    "## Print the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-H3bybRp484",
    "outputId": "fce40859-ea30-4f75-b4b5-08284301f7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2493, -0.1095,  0.4846, -0.4739, -0.1411],\n",
      "        [ 0.0341,  0.2749,  0.0990,  0.3482, -0.3106],\n",
      "        [ 0.1437, -0.1378,  0.3645,  0.4824,  0.0913],\n",
      "        [-0.1414, -0.0091, -0.3382,  0.0394,  0.0310],\n",
      "        [ 0.0146, -0.2444,  0.2993, -0.0864,  0.0447],\n",
      "        [-0.0318, -0.0239, -0.2452,  0.5399,  0.0794],\n",
      "        [ 0.4466,  0.4944,  0.0060,  0.3506,  0.0892],\n",
      "        [ 0.0256,  0.0468,  0.1114,  0.4766, -0.0139],\n",
      "        [ 0.3566, -0.0108,  0.2777, -0.0228, -0.2241],\n",
      "        [ 0.5552,  0.0362,  0.1431, -0.3521, -0.1475],\n",
      "        [-0.3076, -0.0432,  0.2268,  0.0022, -0.2109],\n",
      "        [-0.0688,  0.1337, -0.2222, -0.5336, -0.1656],\n",
      "        [-0.3467, -0.1623, -0.1917,  0.5467, -0.1967],\n",
      "        [ 0.4804, -0.0426, -0.2008, -0.0439,  0.3148],\n",
      "        [ 0.0584,  0.2274, -0.0738,  0.4587,  0.3765],\n",
      "        [ 0.2613, -0.0295, -0.1573, -0.4522, -0.1060],\n",
      "        [-0.1524,  0.3930,  0.4669, -0.4833, -0.1047],\n",
      "        [ 0.3025, -0.3828,  0.3705,  0.1981,  0.2138],\n",
      "        [ 0.2630,  0.2203, -0.2221,  0.4516,  0.0370],\n",
      "        [-0.2437, -0.0049,  0.0937, -0.1650,  0.0850]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1705,  0.0642, -0.0703, -0.0452,  0.3936,  0.2960,  0.3019,  0.3514,\n",
      "        -0.1382, -0.2095,  0.0764,  0.2179,  0.5715, -0.0083, -0.2496, -0.1889,\n",
      "         0.1578,  0.4243, -0.1531,  0.4288], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9457, 1.0380, 0.9685, 0.9702, 1.0036, 0.9872, 1.0531, 1.0450, 1.0038,\n",
      "        0.9102, 1.1188, 0.9211, 1.0021, 0.9409, 0.9802, 1.0120, 0.9876, 1.0198,\n",
      "        1.0909, 0.9986], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0261,  0.0042, -0.1025, -0.0401,  0.0513,  0.0005, -0.0584,  0.0733,\n",
      "         0.1124,  0.0576, -0.0451, -0.0850,  0.0517,  0.0084, -0.0353,  0.0290,\n",
      "         0.0618, -0.0313, -0.0707, -0.0747], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0211, -0.0033, -0.1595, -0.0452,  0.2866,  0.0508,  0.1008,  0.0231,\n",
      "          0.1947,  0.0282, -0.2388, -0.1515, -0.1559,  0.2762, -0.0836,  0.1676,\n",
      "          0.1551, -0.0972,  0.0833,  0.0013],\n",
      "        [ 0.0176,  0.1235,  0.0174, -0.2827, -0.0630,  0.1354,  0.2751,  0.0146,\n",
      "         -0.0621, -0.1272, -0.0644,  0.0355,  0.1026, -0.0171,  0.0552,  0.0102,\n",
      "         -0.0445,  0.2355,  0.1894, -0.0653],\n",
      "        [ 0.1110,  0.0815,  0.0666,  0.1078,  0.0589, -0.0530, -0.0805,  0.1045,\n",
      "          0.2506,  0.1945, -0.1563, -0.1687, -0.1399,  0.1078, -0.2368, -0.1914,\n",
      "         -0.1406,  0.1487,  0.0228, -0.2031],\n",
      "        [-0.0444,  0.1006, -0.1881, -0.0338, -0.1234, -0.2222,  0.1439, -0.2506,\n",
      "          0.0107,  0.0368, -0.1998,  0.2418, -0.1430, -0.0921,  0.0645,  0.0367,\n",
      "          0.1083,  0.0449, -0.0801, -0.0937],\n",
      "        [-0.1716,  0.0564,  0.1866, -0.0505,  0.2002,  0.2231, -0.1047,  0.2250,\n",
      "         -0.0618,  0.0615, -0.0832, -0.2148,  0.0796, -0.0299, -0.2413, -0.1046,\n",
      "         -0.1290,  0.2311, -0.1651, -0.2142],\n",
      "        [-0.2740,  0.2392, -0.1661,  0.0031, -0.2526, -0.1099,  0.3099, -0.0592,\n",
      "          0.1740,  0.1610, -0.1521,  0.0628, -0.0147,  0.1866,  0.1728,  0.1232,\n",
      "         -0.1484, -0.0497, -0.0874,  0.0530],\n",
      "        [ 0.2604, -0.2624, -0.1441, -0.0958, -0.0420, -0.1869,  0.0622, -0.0560,\n",
      "          0.2609, -0.0353,  0.0791,  0.0080, -0.1176, -0.1348, -0.1101, -0.0796,\n",
      "          0.1603,  0.1918, -0.1623, -0.1344],\n",
      "        [-0.1243,  0.2488, -0.0315,  0.2186, -0.1472, -0.0485, -0.0360,  0.1374,\n",
      "          0.3056, -0.1261,  0.2591, -0.2393,  0.0593, -0.0345, -0.1358, -0.0974,\n",
      "          0.1350,  0.0083,  0.0224, -0.1712],\n",
      "        [-0.1757, -0.0617, -0.0226, -0.0355,  0.0786, -0.1561, -0.1707, -0.2288,\n",
      "          0.0698, -0.0574,  0.1774,  0.0318, -0.1207,  0.0812, -0.1376,  0.1289,\n",
      "          0.1627, -0.2293, -0.2252,  0.2880],\n",
      "        [-0.1619, -0.0937, -0.1204, -0.0274, -0.0017,  0.0761,  0.2538, -0.0330,\n",
      "          0.2236,  0.1905, -0.3935, -0.1721,  0.0500, -0.0906, -0.2783,  0.0733,\n",
      "          0.1717, -0.0091,  0.1109, -0.3570],\n",
      "        [ 0.0709, -0.0239, -0.1516, -0.2084, -0.1680, -0.1304,  0.1079, -0.0377,\n",
      "          0.1625, -0.0850, -0.2092, -0.0743, -0.1079,  0.1647, -0.1381, -0.0713,\n",
      "         -0.2550, -0.2654,  0.0061, -0.2940],\n",
      "        [-0.1657, -0.2206,  0.3787, -0.2698,  0.0127, -0.1006,  0.1198,  0.3286,\n",
      "         -0.0152, -0.0080, -0.1093, -0.1762, -0.0490,  0.0431, -0.0210, -0.0885,\n",
      "          0.0972,  0.1782,  0.0139,  0.1419],\n",
      "        [-0.2687,  0.2481,  0.0557, -0.0510, -0.2262,  0.0498,  0.0888,  0.2119,\n",
      "         -0.1579, -0.1932, -0.0797, -0.1105,  0.2966,  0.0610, -0.2086, -0.0615,\n",
      "         -0.0395, -0.0409,  0.0258, -0.3611],\n",
      "        [-0.0608,  0.2485,  0.1327, -0.1762, -0.0811, -0.0109,  0.2353,  0.0673,\n",
      "          0.2649, -0.1960,  0.0694, -0.1809, -0.0540,  0.0061, -0.0315, -0.0299,\n",
      "          0.2128, -0.0781,  0.0617,  0.1374],\n",
      "        [ 0.1177, -0.2196, -0.0867, -0.0025,  0.0169,  0.0601,  0.0322, -0.1723,\n",
      "          0.1909,  0.2935, -0.1389, -0.1377, -0.3515,  0.1312, -0.0982,  0.1578,\n",
      "         -0.2169, -0.1292, -0.3424,  0.0856],\n",
      "        [ 0.3086,  0.1505,  0.0608,  0.0397,  0.2385, -0.2878, -0.0983, -0.1265,\n",
      "         -0.0248,  0.2298, -0.2282,  0.0582, -0.3462,  0.0186, -0.0601, -0.0195,\n",
      "          0.0617,  0.0859, -0.2080, -0.0098],\n",
      "        [ 0.1154,  0.1183, -0.0337, -0.0223,  0.1063, -0.2663,  0.0032,  0.1619,\n",
      "          0.0908, -0.1498,  0.2930, -0.0776, -0.2146, -0.3270, -0.0788, -0.0534,\n",
      "          0.0295, -0.0761, -0.0277,  0.1547],\n",
      "        [ 0.1528,  0.1464,  0.2061, -0.2970,  0.0112, -0.1603,  0.0010,  0.2471,\n",
      "          0.0410,  0.0581,  0.0779, -0.2203, -0.0235, -0.1187,  0.1608, -0.1574,\n",
      "          0.1656,  0.0682, -0.1622, -0.0462],\n",
      "        [-0.0691,  0.0282,  0.2437,  0.0097, -0.2024,  0.2185, -0.0342,  0.3603,\n",
      "          0.0626,  0.1510, -0.0298, -0.1288, -0.1220,  0.0634,  0.2269,  0.0414,\n",
      "          0.0502, -0.1509,  0.1325,  0.0280],\n",
      "        [-0.0549, -0.0663, -0.1191,  0.0844, -0.1951,  0.0594,  0.1178,  0.1972,\n",
      "         -0.2280, -0.1147,  0.0306,  0.0293, -0.0381,  0.0167, -0.0613, -0.2446,\n",
      "         -0.3161, -0.2094,  0.2803, -0.0635]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0308,  0.0067,  0.0454,  0.1285, -0.0400,  0.2101, -0.0718,  0.1337,\n",
      "         0.0343,  0.1437,  0.1775,  0.2433, -0.0435, -0.0397,  0.0311,  0.1305,\n",
      "        -0.1124,  0.3308, -0.0234,  0.1145], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8598, 1.0487, 0.9210, 0.9540, 0.8702, 0.9373, 1.0605, 0.9224, 1.0981,\n",
      "        0.9719, 0.9086, 1.0819, 1.0666, 1.0997, 1.1348, 0.9696, 1.0121, 1.0321,\n",
      "        0.9980, 0.9945], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0379, -0.0079, -0.0356, -0.1535, -0.0554, -0.1130,  0.2231,  0.1552,\n",
      "        -0.0383, -0.0212,  0.0646, -0.0124,  0.1464, -0.1422, -0.0642,  0.0810,\n",
      "        -0.0625, -0.1458,  0.0568,  0.0101], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0990,  0.1505,  0.0024,  0.0716, -0.3117,  0.0636,  0.0025,  0.1415,\n",
      "         -0.3049,  0.1854,  0.3196, -0.2085, -0.0430,  0.0346, -0.2563, -0.1649,\n",
      "          0.1023,  0.1393,  0.0447,  0.1425],\n",
      "        [-0.1853,  0.1856,  0.0084,  0.0419,  0.1643, -0.1123,  0.2700,  0.1613,\n",
      "          0.1947, -0.1454,  0.0022, -0.0238, -0.0358,  0.0543, -0.1204,  0.0185,\n",
      "          0.0237,  0.1765,  0.1712, -0.1561],\n",
      "        [-0.0875, -0.1554, -0.1182,  0.0614, -0.2550, -0.0208,  0.0179, -0.0057,\n",
      "          0.1906, -0.1856,  0.0009, -0.0602,  0.0819,  0.0341,  0.0652,  0.1033,\n",
      "          0.0350, -0.2544,  0.1425, -0.2607],\n",
      "        [ 0.1544,  0.0853,  0.0645,  0.1223, -0.1734,  0.1260,  0.2692, -0.1612,\n",
      "          0.1275,  0.1472,  0.0281, -0.2046, -0.2609,  0.1613,  0.2053,  0.1301,\n",
      "         -0.1909, -0.0020, -0.0625, -0.2209],\n",
      "        [ 0.0478, -0.2986,  0.1844, -0.0710,  0.0677, -0.1611,  0.1509,  0.2291,\n",
      "         -0.0081, -0.0009,  0.2069, -0.0395, -0.2117, -0.0616, -0.0732,  0.1894,\n",
      "          0.0422,  0.0504, -0.1996, -0.0782],\n",
      "        [-0.0613, -0.2287, -0.1884, -0.1117,  0.0747, -0.1960,  0.0660,  0.1706,\n",
      "          0.2056, -0.1584, -0.1181, -0.2183,  0.1495, -0.0327, -0.1053, -0.0521,\n",
      "          0.1583, -0.0972, -0.0459,  0.1095],\n",
      "        [-0.2211,  0.0780,  0.1352,  0.0521,  0.2514,  0.0805, -0.1924,  0.1108,\n",
      "          0.0244,  0.2102,  0.0194, -0.0340,  0.3378,  0.0925, -0.0776,  0.0072,\n",
      "         -0.2098, -0.0634, -0.0987,  0.1115],\n",
      "        [ 0.0423, -0.2450, -0.0927,  0.1797, -0.1719, -0.0263,  0.1929,  0.0541,\n",
      "          0.0932, -0.0794,  0.0791,  0.0181, -0.2594, -0.2082,  0.3202,  0.2212,\n",
      "         -0.0358, -0.0513, -0.2080, -0.1958],\n",
      "        [ 0.2157, -0.1675, -0.0691,  0.0711,  0.0170,  0.0942,  0.0272, -0.1113,\n",
      "          0.2643, -0.2682,  0.1297, -0.1555, -0.2150,  0.0162,  0.1741,  0.1672,\n",
      "         -0.0808, -0.0801, -0.2116,  0.0377],\n",
      "        [-0.1432,  0.3149, -0.1408,  0.1581, -0.0880, -0.1167, -0.0441,  0.0603,\n",
      "         -0.2169, -0.1111, -0.0636,  0.1914,  0.2651,  0.1084,  0.0541, -0.2806,\n",
      "          0.1552,  0.1683,  0.0325, -0.0743],\n",
      "        [-0.0061, -0.2726,  0.0740,  0.0271, -0.0874, -0.0669,  0.0427, -0.1791,\n",
      "          0.0328,  0.1400, -0.0081, -0.1358, -0.0714, -0.1269,  0.1873, -0.0492,\n",
      "         -0.2700, -0.2103, -0.1121,  0.2399],\n",
      "        [-0.0052, -0.0159, -0.0363, -0.0437, -0.0728,  0.1274, -0.2752,  0.2576,\n",
      "          0.0154,  0.0962,  0.2517, -0.2171,  0.0129,  0.2566, -0.1103, -0.0247,\n",
      "         -0.1198,  0.0615,  0.0976,  0.1008],\n",
      "        [ 0.1160, -0.1725,  0.1748,  0.1232, -0.0191,  0.1453,  0.0408, -0.0943,\n",
      "         -0.1824,  0.3984,  0.1533,  0.0066, -0.0668, -0.1705,  0.2507,  0.0707,\n",
      "         -0.1073, -0.1523,  0.1853, -0.0362],\n",
      "        [-0.0220, -0.0081,  0.2620, -0.2151,  0.1834, -0.1146,  0.1706,  0.0156,\n",
      "         -0.1365,  0.0996,  0.1177,  0.1171,  0.0028,  0.0522, -0.0556,  0.0091,\n",
      "         -0.0856,  0.3279,  0.1876,  0.0025],\n",
      "        [ 0.0860, -0.2091, -0.0409, -0.3050, -0.0065, -0.1904,  0.0682,  0.1962,\n",
      "         -0.2247,  0.0768,  0.0098, -0.1551,  0.1624, -0.3401,  0.1739, -0.1320,\n",
      "         -0.2745, -0.2427,  0.0382, -0.0599],\n",
      "        [-0.0732,  0.0264, -0.1415, -0.1678, -0.1310,  0.1473,  0.1156, -0.1555,\n",
      "         -0.2052,  0.0107,  0.1715,  0.0544,  0.1056,  0.1118, -0.1154,  0.0618,\n",
      "         -0.1584, -0.0620,  0.2318,  0.3529],\n",
      "        [ 0.0185, -0.0241, -0.0698, -0.1446, -0.2089, -0.0514,  0.0962, -0.0694,\n",
      "         -0.0568, -0.0678,  0.0564, -0.0185, -0.2125,  0.0914, -0.1191,  0.1169,\n",
      "          0.2249,  0.2158, -0.2479, -0.0860],\n",
      "        [-0.0902, -0.1598,  0.0028, -0.0734,  0.1384, -0.0503,  0.0223, -0.2024,\n",
      "         -0.1316,  0.1189,  0.0597, -0.1401, -0.1441, -0.0311,  0.2644,  0.0458,\n",
      "         -0.0569,  0.1997, -0.1192, -0.2762],\n",
      "        [-0.0673, -0.2540, -0.1537,  0.2801, -0.0530,  0.2241, -0.0538,  0.0233,\n",
      "         -0.1035,  0.1188,  0.0316, -0.1177,  0.1101,  0.2332,  0.1930, -0.2978,\n",
      "         -0.0177, -0.1755, -0.1900,  0.0306],\n",
      "        [-0.0794,  0.1229, -0.1075,  0.0508, -0.1676,  0.0596, -0.2631,  0.0302,\n",
      "          0.0456,  0.0785,  0.0857, -0.3449, -0.1194, -0.2007, -0.1745,  0.0144,\n",
      "         -0.0631, -0.3283,  0.0790,  0.1360]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1370, -0.0526, -0.0999,  0.1837, -0.0173, -0.0859, -0.0141,  0.0997,\n",
      "         0.1963, -0.0440,  0.2651,  0.0172,  0.0666,  0.2092,  0.0020,  0.1221,\n",
      "         0.0478, -0.3130, -0.1554,  0.1237], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0135, 0.9278, 1.0033, 1.0460, 0.8456, 1.2037, 0.9423, 1.0565, 1.0148,\n",
      "        1.0079, 0.9680, 1.0752, 1.1177, 0.9650, 1.0053, 0.8772, 1.0511, 0.8436,\n",
      "        0.8055, 0.8399], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1008, -0.0731, -0.0673,  0.0223,  0.1256,  0.0010, -0.0930, -0.0675,\n",
      "        -0.0034,  0.1020, -0.0326,  0.1117, -0.0178,  0.0427,  0.1000, -0.0122,\n",
      "         0.0979,  0.0730,  0.0601,  0.0798], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 3.1122e-01, -6.3177e-02, -2.2934e-01,  3.5373e-02, -1.2958e-01,\n",
      "         -6.2755e-02, -2.3141e-01, -1.6696e-01,  5.7612e-02, -6.7687e-02,\n",
      "          7.9331e-02,  1.5467e-01,  2.9963e-01, -8.4248e-02,  5.6485e-02,\n",
      "          1.3069e-01, -9.6151e-03, -7.9607e-02,  8.6373e-02,  7.6344e-02],\n",
      "        [ 1.4830e-01, -6.9743e-02, -1.4042e-01,  6.3466e-02,  5.2813e-02,\n",
      "         -3.9305e-01, -3.1652e-03, -2.1102e-01,  1.0299e-01,  8.7437e-02,\n",
      "         -2.4556e-02,  2.6384e-01,  1.8350e-01,  3.6093e-02,  4.0549e-02,\n",
      "         -1.6605e-01,  2.8925e-02,  1.3830e-01,  2.2908e-01, -1.8450e-01],\n",
      "        [ 6.6912e-04, -3.1018e-01,  1.2208e-01,  5.5618e-02, -3.4587e-02,\n",
      "          3.7127e-02, -9.8408e-02,  1.8838e-01,  2.8762e-01,  1.2242e-01,\n",
      "          1.0710e-01, -2.2128e-01,  1.8606e-01, -8.5132e-02,  4.3386e-02,\n",
      "         -1.6001e-02,  1.6114e-01,  2.4860e-01,  1.1427e-01,  3.3251e-02],\n",
      "        [-2.3525e-01, -2.4689e-01,  1.4727e-01,  2.7470e-01,  2.3063e-02,\n",
      "         -1.6577e-01, -3.4632e-02, -1.9479e-03, -1.0085e-01,  2.1586e-02,\n",
      "          2.1330e-01, -1.8768e-02,  3.5756e-01,  4.3481e-02,  2.7948e-01,\n",
      "         -1.2932e-01,  1.7958e-02,  2.2102e-02, -1.2334e-01,  2.1488e-02],\n",
      "        [-1.4153e-01, -1.5376e-01,  1.8979e-02,  2.1101e-01, -1.0548e-01,\n",
      "          1.5908e-01, -9.2892e-02,  2.6248e-01,  3.2261e-01, -1.3507e-01,\n",
      "          1.7210e-01, -1.7284e-01,  7.5889e-02,  6.2598e-02,  3.5476e-02,\n",
      "         -6.2981e-02, -1.5493e-01,  5.8595e-02, -3.6645e-03,  1.2379e-01],\n",
      "        [ 1.4462e-01,  1.5416e-02, -1.7685e-01, -1.0097e-01,  2.3899e-01,\n",
      "          3.0784e-01, -1.2624e-01, -2.6410e-01, -3.8302e-02,  6.8622e-02,\n",
      "         -6.1956e-02, -1.0027e-01,  8.8639e-02,  1.4038e-01,  2.1055e-01,\n",
      "          8.9674e-02,  3.6276e-01, -7.8759e-02,  5.0820e-02,  1.4698e-01],\n",
      "        [-1.3462e-01,  1.5849e-01, -2.0436e-01, -5.3656e-02, -2.9406e-02,\n",
      "          1.8668e-01, -1.9542e-02,  6.6236e-02, -1.3993e-01,  1.7872e-01,\n",
      "          1.1567e-01,  1.2365e-01,  7.6865e-02,  1.2930e-01, -3.5590e-01,\n",
      "          1.1659e-01, -2.3744e-01,  2.4218e-03,  1.7343e-01,  1.4782e-02],\n",
      "        [ 2.1111e-02, -1.0242e-01, -7.5941e-02, -1.2125e-01,  1.6225e-02,\n",
      "          8.5029e-02,  2.0048e-01, -7.2659e-02, -1.7412e-01,  2.4295e-01,\n",
      "         -2.6400e-01,  2.3447e-01, -5.8065e-02,  2.1276e-01, -2.2455e-01,\n",
      "          9.4772e-02,  9.9038e-03, -2.1239e-01,  3.5353e-02,  6.2976e-02],\n",
      "        [-6.2576e-02, -1.1924e-01, -3.0196e-01, -2.7159e-01,  1.5733e-01,\n",
      "          1.1942e-01, -2.3281e-01, -2.2524e-01, -1.1113e-01, -2.1387e-01,\n",
      "          2.0041e-01,  3.2212e-02, -1.2623e-03, -1.8553e-01,  1.3083e-01,\n",
      "          1.4706e-01,  6.5068e-02, -1.6356e-01, -2.9062e-03,  2.4198e-01],\n",
      "        [ 1.8727e-01,  1.4194e-01,  2.1828e-02, -5.6070e-02,  1.3052e-01,\n",
      "         -1.3382e-01,  2.0572e-01, -1.0416e-01,  9.3852e-02,  1.4917e-01,\n",
      "          3.3772e-02,  2.5855e-01,  4.2790e-02,  1.6868e-01, -1.5857e-02,\n",
      "         -1.0953e-01, -4.1886e-02, -1.3565e-01,  1.1633e-01,  1.5384e-01],\n",
      "        [ 7.1195e-02,  1.1800e-01, -2.0884e-01,  1.9220e-02,  4.8746e-03,\n",
      "         -2.2714e-01,  4.9695e-02, -1.4551e-02, -3.5782e-02,  1.1126e-01,\n",
      "         -7.4975e-02, -2.0951e-01, -1.3680e-02,  2.0397e-01, -5.5425e-02,\n",
      "         -1.8931e-01, -5.0296e-02,  1.2284e-01, -1.8724e-01, -1.6047e-01],\n",
      "        [-2.4683e-02, -1.4718e-01, -9.3065e-03,  2.0344e-01,  1.3816e-01,\n",
      "         -2.5891e-01,  2.1934e-03,  2.3649e-01, -1.3268e-01,  3.3325e-02,\n",
      "          1.6843e-01, -5.2264e-02,  2.9735e-01,  1.6906e-01,  1.1794e-01,\n",
      "         -2.5574e-01, -1.1369e-01,  1.3294e-01, -1.5907e-01,  1.3354e-01],\n",
      "        [-1.1052e-01,  1.1024e-01, -8.4448e-02,  5.0927e-02,  1.9476e-01,\n",
      "         -9.1768e-02, -2.4988e-01,  1.2880e-01, -1.6076e-02,  3.9066e-02,\n",
      "          8.1543e-02, -2.2453e-01,  8.8351e-02, -4.4617e-02, -1.8608e-01,\n",
      "         -1.2950e-01,  2.5379e-01,  1.7995e-02, -3.3184e-04, -2.1681e-01],\n",
      "        [ 1.6574e-01, -1.8023e-01,  2.2166e-01, -6.9769e-02,  2.8349e-03,\n",
      "          1.0202e-01, -1.2494e-01, -6.9723e-02,  1.2792e-01, -8.2063e-02,\n",
      "          1.1246e-01,  1.7188e-01, -4.3642e-02, -2.5372e-01, -6.8888e-02,\n",
      "          1.5253e-02,  6.1883e-02, -1.1114e-01,  2.2875e-01,  2.0568e-01],\n",
      "        [ 2.3084e-02,  4.2382e-02, -2.0213e-01,  1.1237e-01,  9.8044e-02,\n",
      "          5.4779e-02,  1.9711e-01, -3.5479e-02, -1.3803e-01, -1.0224e-01,\n",
      "         -1.3200e-01, -5.2185e-02,  3.3826e-01, -1.4948e-01,  1.0509e-02,\n",
      "          1.1000e-01, -3.0494e-01,  2.2410e-02,  1.7010e-01,  1.6509e-01],\n",
      "        [-2.7307e-02,  6.9021e-02, -4.6013e-02,  1.5616e-01,  1.8949e-01,\n",
      "          1.2487e-01, -8.7850e-02,  1.5975e-01,  7.0785e-02, -7.0244e-02,\n",
      "         -1.0321e-01, -9.6939e-02,  5.2142e-02,  2.7309e-03,  7.6537e-02,\n",
      "         -4.2997e-02,  3.4511e-01, -6.1401e-02, -4.0647e-02, -6.8178e-03],\n",
      "        [ 3.2831e-01,  9.3496e-02, -5.5148e-02, -2.6176e-01,  5.8679e-03,\n",
      "         -1.9875e-01,  8.7691e-02,  6.8598e-02, -2.9985e-01,  1.6828e-01,\n",
      "          1.7498e-01,  6.4961e-02, -1.7111e-02, -8.8404e-02, -5.4197e-03,\n",
      "          1.6711e-01, -1.5699e-01,  2.3295e-02,  7.1908e-02, -3.9518e-02],\n",
      "        [-4.0356e-02, -1.0469e-01, -1.4928e-01, -2.6078e-01,  1.3705e-01,\n",
      "         -3.2212e-01, -5.2555e-02, -3.3961e-01, -1.9907e-01,  3.4423e-02,\n",
      "         -1.5419e-01,  1.2366e-01,  1.6368e-01,  2.0945e-01, -2.7380e-01,\n",
      "          1.1859e-01,  1.2092e-01, -9.8871e-02, -7.8133e-02, -1.1206e-01],\n",
      "        [ 2.5376e-01, -1.5211e-01, -1.3741e-01,  8.2680e-02,  1.3975e-02,\n",
      "         -2.6292e-01,  8.1752e-02,  7.1216e-02, -7.1001e-02, -8.2556e-02,\n",
      "          9.4141e-02,  1.3673e-01, -2.8065e-01, -1.3974e-01,  1.7853e-01,\n",
      "          9.9581e-02, -9.1609e-02,  6.9999e-02, -2.5114e-03,  2.2208e-01],\n",
      "        [-4.5244e-02, -2.0906e-02,  1.7691e-01,  1.4958e-01, -1.2301e-01,\n",
      "          2.6441e-01, -1.5169e-02, -7.9652e-03, -6.2400e-02,  1.7626e-01,\n",
      "         -1.1415e-01,  9.6593e-02, -2.9916e-01, -4.1333e-03,  8.3315e-02,\n",
      "         -1.4178e-01,  1.8752e-02, -7.0873e-02, -1.3337e-01,  9.3664e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1989,  0.1510,  0.0547, -0.0918,  0.2290,  0.0256,  0.0548,  0.0882,\n",
      "        -0.1257, -0.1142, -0.1362,  0.0557,  0.2511,  0.2893,  0.1462,  0.0053,\n",
      "        -0.0232, -0.1072,  0.1796,  0.2345], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9977, 1.0640, 1.0358, 0.9168, 1.1591, 0.9338, 0.7917, 0.8623, 0.9864,\n",
      "        0.9443, 1.1023, 1.0275, 1.1451, 1.0270, 0.9010, 0.9591, 0.9563, 1.0068,\n",
      "        0.9465, 0.8753], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0159, -0.0871, -0.0697, -0.1042, -0.1363,  0.1082,  0.0499, -0.0066,\n",
      "         0.0825,  0.0209, -0.0239, -0.0084, -0.0275,  0.1570,  0.0411,  0.0824,\n",
      "         0.0730,  0.0253, -0.1302, -0.0700], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.6681e-01,  3.5480e-02, -1.2112e-01,  2.9630e-02,  1.6908e-01,\n",
      "         -9.4373e-02,  7.8479e-02, -2.5684e-01, -1.8469e-01, -3.1305e-01,\n",
      "          7.9227e-02,  7.3072e-02,  1.2282e-01, -1.2757e-01,  9.8626e-02,\n",
      "          1.7997e-01, -3.0063e-02, -1.1165e-02,  4.1246e-02,  1.5257e-01],\n",
      "        [ 1.2219e-01,  2.5669e-01,  1.8144e-02, -2.0054e-01, -1.2815e-02,\n",
      "         -4.7842e-02,  1.2479e-02,  1.2098e-01, -3.3396e-02,  2.6886e-01,\n",
      "          2.2378e-01, -9.2385e-02,  1.4908e-01,  1.7580e-01,  4.0142e-02,\n",
      "         -1.0180e-01,  6.9477e-02, -3.1301e-02,  2.0079e-01, -1.3747e-01],\n",
      "        [-1.4521e-01,  3.6307e-03,  1.5536e-01, -8.6223e-02,  6.5396e-02,\n",
      "         -2.3626e-01, -1.7489e-01, -1.0800e-01, -1.2253e-01, -5.0144e-02,\n",
      "         -2.4097e-01,  1.7206e-01,  1.9305e-01, -8.6866e-02,  8.3241e-02,\n",
      "          1.8561e-01,  1.4422e-01, -7.0573e-02, -1.2776e-01, -2.5639e-01],\n",
      "        [-1.3775e-01, -7.0984e-02,  1.3589e-01,  9.9420e-02, -8.1066e-02,\n",
      "          1.1106e-01,  7.9268e-02, -2.7895e-02,  7.9709e-02, -1.2798e-02,\n",
      "          7.5775e-02,  1.0451e-01,  2.5875e-01, -5.8429e-02, -7.5662e-02,\n",
      "          1.5038e-01, -2.1939e-01,  1.7613e-01, -1.7986e-01, -1.4501e-01],\n",
      "        [ 1.0176e-01,  1.3545e-01,  6.8240e-02,  2.8979e-01,  1.6890e-01,\n",
      "         -1.1034e-01,  8.2404e-02,  1.9265e-02,  3.6898e-03,  5.9513e-02,\n",
      "         -4.1431e-02,  1.9762e-01,  7.9500e-02, -2.4802e-01, -7.8884e-04,\n",
      "          9.8245e-02, -7.0513e-02, -2.9296e-01,  7.1234e-03,  1.7555e-02],\n",
      "        [ 6.6795e-02,  1.5394e-01, -1.5228e-01, -2.7259e-02, -9.8490e-02,\n",
      "         -1.8932e-02,  1.3405e-01,  1.4869e-01, -3.0922e-02,  3.8736e-02,\n",
      "          3.8131e-01, -1.6150e-01, -1.3958e-01, -2.0495e-01,  2.6954e-02,\n",
      "          2.7735e-02,  1.0823e-01,  2.1098e-01, -9.7766e-02,  4.9709e-02],\n",
      "        [ 6.8834e-02, -1.3247e-01, -1.6932e-01, -1.4639e-01, -2.2007e-01,\n",
      "          1.5961e-01,  7.5883e-02,  9.1283e-02,  7.2765e-02, -4.8930e-02,\n",
      "          2.0166e-01, -2.0409e-01,  8.2178e-02,  1.7901e-02, -2.0364e-01,\n",
      "          2.2716e-01, -2.3526e-01, -6.8137e-02, -2.0779e-01,  1.6874e-01],\n",
      "        [ 1.8370e-01,  5.7097e-02, -1.4974e-01,  1.2434e-01,  1.3276e-01,\n",
      "         -2.8213e-02,  1.6076e-01,  9.5556e-03,  1.5571e-01, -1.8857e-02,\n",
      "          8.6923e-03,  3.5673e-02, -1.2487e-01,  2.2566e-01,  2.9247e-01,\n",
      "         -7.9622e-02,  8.4061e-02, -3.0916e-02, -1.5665e-01, -9.0372e-02],\n",
      "        [-4.4022e-02,  2.7695e-01, -1.6343e-01,  6.6725e-02, -1.6083e-01,\n",
      "         -1.2319e-01,  1.1621e-01,  1.5220e-01, -1.3981e-01,  2.1972e-01,\n",
      "         -2.0949e-02,  7.4078e-02, -1.7009e-01, -2.0025e-01,  9.0357e-02,\n",
      "         -2.4812e-01, -4.8914e-02,  1.8389e-02,  1.1064e-01,  9.1244e-02],\n",
      "        [ 6.9442e-02, -4.4123e-02, -1.0678e-01,  6.3313e-02, -2.8721e-01,\n",
      "          8.4819e-02, -5.2399e-03,  6.5287e-02, -6.5544e-02, -1.5356e-01,\n",
      "          1.1993e-01,  1.9814e-01,  4.0507e-01, -8.2527e-02, -5.7734e-02,\n",
      "          1.0231e-01, -6.3292e-02, -5.7246e-02, -2.5264e-02, -3.0352e-01],\n",
      "        [ 1.8830e-01,  2.6955e-01, -1.8538e-01,  2.2788e-01,  1.3960e-02,\n",
      "         -6.2283e-02,  6.1212e-02, -2.5943e-02,  2.9426e-01, -1.9784e-01,\n",
      "          9.3392e-02, -1.0633e-04, -6.7346e-02,  2.2030e-01,  2.9360e-01,\n",
      "          1.2778e-01, -7.6615e-02, -8.2542e-02, -3.2241e-02, -1.0082e-01],\n",
      "        [-6.8077e-02, -9.3632e-02,  1.6137e-01, -1.1288e-01, -3.8282e-02,\n",
      "         -9.5864e-02,  1.0478e-01, -3.9779e-02, -2.6482e-01, -1.0738e-01,\n",
      "         -2.3947e-01, -5.5956e-02,  2.4237e-01,  1.2816e-01, -2.9429e-01,\n",
      "          1.9296e-01,  1.2538e-01, -1.3762e-01, -1.3456e-01,  1.4046e-01],\n",
      "        [-3.0035e-01, -1.9949e-01, -2.3977e-02, -2.5265e-01, -2.1244e-01,\n",
      "         -2.2605e-01,  2.4075e-01, -3.1435e-02,  7.2844e-02,  1.0981e-01,\n",
      "          2.7431e-01, -1.0366e-01,  4.8044e-03, -1.4642e-01, -5.1621e-02,\n",
      "          1.4134e-01,  1.7414e-01,  8.9392e-02, -1.1522e-01, -1.3181e-01],\n",
      "        [ 1.2706e-01, -1.3921e-03, -9.3201e-02, -2.1710e-01, -4.2010e-01,\n",
      "          1.8870e-03,  9.9856e-02,  1.7639e-01, -1.4770e-01, -1.9984e-02,\n",
      "          2.5921e-02, -1.4320e-02,  8.4090e-02,  7.5344e-02,  5.7105e-02,\n",
      "          2.0480e-01,  1.4845e-01,  1.7405e-01,  3.0737e-02, -9.4370e-02],\n",
      "        [-1.1004e-01, -2.4640e-01, -6.6624e-02, -1.3258e-01,  1.8611e-01,\n",
      "          6.1622e-02, -5.3423e-03, -6.2355e-02, -3.2067e-02, -9.6610e-03,\n",
      "         -2.2515e-01, -1.6998e-01,  2.8310e-02,  8.2652e-02, -4.9762e-02,\n",
      "          2.2199e-01,  4.2621e-02, -3.1110e-01, -2.1090e-01,  1.0230e-01],\n",
      "        [ 1.8999e-01, -1.6718e-01, -2.1023e-01, -3.3183e-02, -2.3926e-01,\n",
      "          1.7596e-01,  2.1893e-01, -3.3130e-02,  1.4817e-01,  1.4166e-02,\n",
      "         -6.7775e-02,  8.5670e-02, -2.4043e-01, -8.3892e-02,  3.4940e-02,\n",
      "          2.5044e-02,  2.6986e-01,  6.0222e-02, -2.2985e-01, -4.7188e-03],\n",
      "        [ 2.0829e-01,  2.5037e-01,  1.5157e-01,  1.5314e-01, -1.0195e-01,\n",
      "         -1.0238e-01, -1.0335e-01, -1.3954e-01, -1.8499e-01,  7.1449e-02,\n",
      "         -1.9482e-01,  1.1483e-01,  3.7769e-02, -1.1348e-01,  1.1626e-01,\n",
      "         -1.1488e-01,  1.5091e-01, -1.9384e-01, -7.9640e-03, -3.1790e-01],\n",
      "        [-2.4016e-01, -1.2502e-01,  1.1812e-01,  1.0778e-01,  1.9907e-01,\n",
      "         -1.2922e-01, -7.4155e-02, -2.8404e-02, -8.6025e-02, -1.9110e-01,\n",
      "          1.8426e-01,  2.6476e-01, -5.9815e-02,  7.5026e-02,  6.4747e-02,\n",
      "         -1.9346e-01, -1.1567e-01, -2.6451e-01,  4.9398e-03, -1.3602e-01],\n",
      "        [ 1.5417e-01,  1.2996e-01,  3.2771e-02,  1.0237e-01,  4.9150e-03,\n",
      "          1.4156e-01, -3.1509e-02, -2.0953e-02, -1.6014e-01, -9.3860e-02,\n",
      "         -9.9306e-02,  2.2004e-01,  4.6376e-03, -2.8023e-01, -1.9607e-01,\n",
      "          2.2513e-01, -5.4029e-02, -1.8913e-01, -2.7585e-01,  3.4136e-02],\n",
      "        [-8.7851e-02, -1.1074e-01,  8.1483e-02,  3.3376e-02,  3.2970e-01,\n",
      "         -7.0421e-02,  1.0014e-01, -6.0886e-02, -2.3611e-02, -4.8744e-02,\n",
      "          6.9287e-02,  1.4890e-01,  4.0433e-02,  1.4759e-01,  7.8000e-02,\n",
      "         -1.1990e-01, -2.0244e-01, -3.0842e-01, -5.4916e-02,  1.0696e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0764, -0.0803,  0.1799,  0.3982, -0.1965,  0.0822,  0.1327,  0.2857,\n",
      "        -0.1888,  0.0610,  0.1884,  0.0874, -0.0149,  0.0544,  0.1449,  0.2226,\n",
      "         0.1002, -0.1542, -0.1673,  0.2013], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8877, 0.8277, 0.9899, 1.0142, 1.0593, 1.0037, 0.9340, 0.9139, 0.9813,\n",
      "        0.9427, 1.0202, 0.9504, 0.9997, 1.0536, 0.9937, 0.9663, 1.0104, 1.1121,\n",
      "        0.7985, 1.1789], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0355, -0.0695,  0.0532,  0.1923, -0.1179, -0.0441,  0.1522, -0.0065,\n",
      "        -0.1140,  0.2088, -0.0427,  0.1211,  0.0081,  0.0315,  0.0700,  0.0490,\n",
      "        -0.0340,  0.1157, -0.0387,  0.0228], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0049, -0.0310, -0.0908,  0.2701, -0.0157,  0.1875,  0.0893, -0.2170,\n",
      "         -0.0502,  0.2207,  0.0995, -0.1129,  0.2144, -0.0431, -0.0456, -0.0434,\n",
      "         -0.0995, -0.0023, -0.0926, -0.1143],\n",
      "        [ 0.0844,  0.0770, -0.0706, -0.0306,  0.0954,  0.1127, -0.0588, -0.0266,\n",
      "         -0.1855, -0.1749, -0.1109,  0.1369,  0.1156, -0.1613,  0.1340, -0.2381,\n",
      "          0.0582,  0.1324, -0.2553,  0.2510],\n",
      "        [ 0.2441, -0.0518,  0.1985,  0.1127, -0.0840, -0.1424, -0.0349, -0.2210,\n",
      "         -0.0311, -0.0980, -0.0297,  0.2693, -0.0849,  0.1414,  0.2055,  0.1151,\n",
      "          0.1678, -0.0717,  0.2205, -0.1549],\n",
      "        [ 0.1415, -0.2156,  0.2010,  0.0045,  0.2637, -0.0769, -0.0009, -0.1165,\n",
      "         -0.1577, -0.1122, -0.0116,  0.1233, -0.2159, -0.2836,  0.1129, -0.0242,\n",
      "          0.2237,  0.1918, -0.0231, -0.0065],\n",
      "        [-0.1491,  0.2307, -0.0172, -0.1965,  0.0124,  0.2035, -0.1775, -0.0205,\n",
      "          0.2160, -0.1213, -0.0911, -0.1637,  0.0665,  0.1242,  0.0755,  0.0136,\n",
      "         -0.1616, -0.1137, -0.0667,  0.0342],\n",
      "        [ 0.1232,  0.1301, -0.1684, -0.2533,  0.0327, -0.0320, -0.2453,  0.1147,\n",
      "          0.1925, -0.0186,  0.1925, -0.0887, -0.0503, -0.1372, -0.2474, -0.1500,\n",
      "          0.3140, -0.2522,  0.1827, -0.1365],\n",
      "        [-0.1305, -0.1208,  0.0677,  0.1078, -0.2267,  0.1353, -0.1064,  0.1628,\n",
      "          0.2837, -0.1447,  0.0205,  0.0018,  0.2023,  0.0453, -0.2237, -0.0046,\n",
      "          0.0691, -0.0922, -0.1386, -0.1904],\n",
      "        [ 0.1002, -0.0730,  0.1522, -0.1524,  0.1310, -0.1691,  0.2331, -0.0420,\n",
      "          0.1122,  0.1817, -0.2957,  0.2112, -0.0381, -0.2491,  0.2194,  0.0900,\n",
      "         -0.1610, -0.0396, -0.1771,  0.2361],\n",
      "        [ 0.0178,  0.0105, -0.1172,  0.2162, -0.2258, -0.1691,  0.2386,  0.0798,\n",
      "         -0.3113,  0.0568,  0.0411,  0.3329, -0.0790,  0.1409,  0.1764,  0.0067,\n",
      "         -0.0184, -0.2821,  0.0782, -0.0087],\n",
      "        [ 0.2088,  0.0092,  0.0880,  0.0078,  0.1204, -0.0963, -0.1481, -0.0438,\n",
      "         -0.1117,  0.1828, -0.0859, -0.1321, -0.1584, -0.2603, -0.1329,  0.1376,\n",
      "          0.0832, -0.1027,  0.0954, -0.0842],\n",
      "        [ 0.0074, -0.0830, -0.3449, -0.1971, -0.2305, -0.1258,  0.3187, -0.1939,\n",
      "         -0.0024,  0.0492,  0.0566, -0.0911, -0.1798, -0.2023,  0.1185,  0.1250,\n",
      "         -0.2045,  0.0390,  0.1225, -0.1005],\n",
      "        [ 0.1101, -0.1425,  0.1034,  0.1045, -0.0587,  0.0653,  0.1464, -0.1090,\n",
      "         -0.0569,  0.1260, -0.2047,  0.0461,  0.2263,  0.0524, -0.1287, -0.0809,\n",
      "         -0.2003, -0.1754,  0.0677, -0.1924],\n",
      "        [ 0.0937, -0.0730,  0.0294, -0.1863, -0.1359,  0.0793, -0.0974,  0.1032,\n",
      "         -0.2300, -0.1797,  0.1939, -0.1660,  0.1253, -0.0090, -0.1938,  0.1887,\n",
      "          0.0157, -0.1430,  0.0309, -0.3811],\n",
      "        [ 0.1026,  0.1477, -0.1213, -0.2337, -0.2278,  0.3090,  0.0221, -0.0624,\n",
      "          0.2389,  0.1578, -0.0228, -0.1839,  0.0698, -0.0390, -0.2206,  0.1222,\n",
      "          0.0142, -0.2330,  0.0474, -0.1648],\n",
      "        [-0.0721,  0.2253,  0.2689,  0.1861,  0.2067,  0.1404,  0.0938,  0.0626,\n",
      "         -0.0734,  0.2649, -0.2570,  0.1986,  0.2060, -0.1152, -0.1003, -0.1125,\n",
      "          0.1306,  0.2275,  0.0038, -0.1497],\n",
      "        [-0.0749,  0.0251, -0.0989,  0.1264, -0.0884,  0.1468, -0.2344,  0.3112,\n",
      "          0.1104, -0.2371,  0.2432,  0.0023,  0.0673, -0.0673, -0.0271,  0.2344,\n",
      "         -0.0050,  0.0736,  0.1552, -0.1058],\n",
      "        [ 0.0381, -0.1428,  0.1915,  0.1502,  0.1116, -0.1251, -0.1419,  0.0901,\n",
      "         -0.2389, -0.0465, -0.1930,  0.0795,  0.1000,  0.0105,  0.0212, -0.2694,\n",
      "          0.2697,  0.1769,  0.0851,  0.2031],\n",
      "        [ 0.1642, -0.0320, -0.0212, -0.1824,  0.2374,  0.0649,  0.0134,  0.1166,\n",
      "         -0.1500, -0.1820,  0.1036, -0.1492, -0.1882, -0.2051, -0.0097, -0.0331,\n",
      "         -0.1436,  0.1745,  0.0479,  0.3303],\n",
      "        [ 0.1989,  0.0176,  0.2102,  0.1329,  0.0728,  0.0024, -0.0913, -0.1214,\n",
      "         -0.1018,  0.0616,  0.1031,  0.1081,  0.0555, -0.2890, -0.0142, -0.3198,\n",
      "          0.0182,  0.0179,  0.1003, -0.0298],\n",
      "        [ 0.1896, -0.0630, -0.0413, -0.0394,  0.0865,  0.1090,  0.0301,  0.1128,\n",
      "         -0.0799,  0.2770,  0.3080, -0.0212, -0.0944,  0.1654, -0.1545, -0.0090,\n",
      "          0.1467,  0.1840, -0.1433,  0.0918]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2779,  0.0721,  0.0579,  0.1252, -0.2504, -0.1171,  0.1461, -0.0534,\n",
      "        -0.0473, -0.0606,  0.2341,  0.1514, -0.2439,  0.3330,  0.0625,  0.0385,\n",
      "        -0.1281,  0.2196,  0.1711,  0.0063], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0014, 0.9661, 0.9157, 0.9975, 0.9525, 1.1068, 1.0443, 0.9186, 0.9960,\n",
      "        0.9801, 0.9985, 1.1020, 0.9070, 1.1264, 0.9659, 0.8250, 0.9777, 1.0130,\n",
      "        0.9970, 0.9996], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0364, -0.0298,  0.0801, -0.0092,  0.0393,  0.0433,  0.1390,  0.0361,\n",
      "        -0.0144, -0.0374, -0.0580, -0.0416,  0.0513,  0.1541,  0.1036,  0.1760,\n",
      "        -0.0353, -0.0049,  0.2221, -0.0776], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1357,  0.2217,  0.2939,  0.2066, -0.2842, -0.0781, -0.0593,  0.1799,\n",
      "          0.0792, -0.0579, -0.2066, -0.0897, -0.0852,  0.0227,  0.0840, -0.2249,\n",
      "         -0.0358, -0.1215,  0.0029, -0.1831],\n",
      "        [ 0.0616,  0.1590,  0.2933,  0.0531, -0.1058,  0.0005,  0.0934,  0.0606,\n",
      "          0.3004, -0.1428,  0.1709,  0.0428, -0.0797, -0.2283, -0.1516,  0.0111,\n",
      "         -0.0703,  0.0157,  0.2124, -0.1402],\n",
      "        [-0.0539, -0.0381, -0.0804,  0.2104,  0.0492, -0.1354, -0.1538,  0.0313,\n",
      "         -0.1203, -0.2240,  0.2415, -0.2208,  0.1932,  0.0638,  0.0153,  0.1998,\n",
      "         -0.0911,  0.1339, -0.2280, -0.1008],\n",
      "        [ 0.0977, -0.1487, -0.0563, -0.0622, -0.0805, -0.1447,  0.2096,  0.1022,\n",
      "          0.0200,  0.1121, -0.1132,  0.1877, -0.1710,  0.0365,  0.2119, -0.1201,\n",
      "         -0.0285, -0.2329,  0.1181, -0.1805],\n",
      "        [-0.1511,  0.0278,  0.0854,  0.0251,  0.1017, -0.1516, -0.1631,  0.1556,\n",
      "         -0.0420,  0.0918, -0.1418, -0.0444, -0.0788, -0.2134, -0.1717, -0.1596,\n",
      "          0.2208,  0.1880,  0.1559,  0.2079],\n",
      "        [ 0.1227, -0.1810,  0.0439, -0.2049,  0.3106, -0.1894,  0.1324, -0.0474,\n",
      "         -0.1075,  0.0802, -0.1879,  0.1435,  0.0531,  0.1971, -0.1259,  0.0529,\n",
      "         -0.1207, -0.0522, -0.1396, -0.2495],\n",
      "        [ 0.1176,  0.0845,  0.0828,  0.2584,  0.2034,  0.1986, -0.1407, -0.0701,\n",
      "          0.0328,  0.2388,  0.0070,  0.0205, -0.0660, -0.2455,  0.0890,  0.0345,\n",
      "          0.2152,  0.0568,  0.3183, -0.1148],\n",
      "        [-0.1503,  0.0195,  0.1374, -0.1322,  0.2099,  0.1932, -0.0059, -0.0414,\n",
      "         -0.0343,  0.0758, -0.3081, -0.3135, -0.2099,  0.1560,  0.0090, -0.0424,\n",
      "         -0.1624, -0.0808, -0.0813,  0.1550],\n",
      "        [-0.2147, -0.2140, -0.1559,  0.1263, -0.0772,  0.3354, -0.1118, -0.1453,\n",
      "         -0.0930,  0.0779, -0.1606, -0.0318, -0.1403, -0.3160, -0.0635, -0.0939,\n",
      "          0.2010,  0.0427,  0.1550,  0.0891],\n",
      "        [-0.1279, -0.1594,  0.0229,  0.2416, -0.2372, -0.2464, -0.0574, -0.0063,\n",
      "          0.0005, -0.1583,  0.0665, -0.1984, -0.1085, -0.0995,  0.2898, -0.0379,\n",
      "         -0.0699, -0.0445,  0.2649, -0.1646],\n",
      "        [ 0.2135, -0.0324,  0.1321, -0.3723,  0.2502, -0.2399,  0.1160, -0.0866,\n",
      "          0.0864, -0.0716, -0.1696,  0.2183, -0.0370,  0.1835, -0.0550, -0.0316,\n",
      "         -0.1970,  0.0887,  0.0826,  0.0364],\n",
      "        [ 0.2439,  0.0147, -0.0346,  0.0062,  0.0929, -0.1287,  0.0646, -0.1534,\n",
      "         -0.2618,  0.3033,  0.1943,  0.2022, -0.1137,  0.1066,  0.1080,  0.0233,\n",
      "         -0.0112,  0.1224,  0.2227,  0.0715],\n",
      "        [-0.1071,  0.1231,  0.0305,  0.0163,  0.0307, -0.1254, -0.1378, -0.1171,\n",
      "         -0.1611,  0.0557,  0.1153, -0.2814, -0.2666, -0.0852,  0.1112,  0.0292,\n",
      "          0.1574,  0.1973, -0.0427,  0.1338],\n",
      "        [-0.0054, -0.0837, -0.2316,  0.1427,  0.1978, -0.0610,  0.1840, -0.1475,\n",
      "         -0.2101, -0.1504,  0.0941, -0.0628, -0.0448,  0.1660,  0.0459,  0.0246,\n",
      "         -0.1005, -0.1529,  0.1655, -0.3479],\n",
      "        [-0.3588, -0.1296, -0.1517, -0.1364,  0.0420,  0.1099,  0.0432, -0.0191,\n",
      "          0.0611, -0.0587, -0.0370, -0.3922,  0.0405, -0.0567, -0.1618,  0.1960,\n",
      "          0.0593, -0.1076, -0.2736,  0.0915],\n",
      "        [ 0.1170, -0.2026,  0.1664, -0.1157, -0.1505, -0.1855, -0.2217,  0.0643,\n",
      "          0.2560, -0.1159,  0.0611,  0.1220, -0.1589, -0.0359,  0.1430, -0.0151,\n",
      "         -0.0424,  0.0755, -0.0249,  0.0448],\n",
      "        [ 0.2664, -0.1647, -0.0803,  0.1365, -0.1180, -0.0668, -0.1576, -0.3446,\n",
      "         -0.1874,  0.1675, -0.1905, -0.1525, -0.0624, -0.3181,  0.0653,  0.0763,\n",
      "         -0.0081,  0.0030,  0.2240,  0.1887],\n",
      "        [-0.1900, -0.2054, -0.0941, -0.1440,  0.1204,  0.1859,  0.1596,  0.0640,\n",
      "         -0.2162, -0.0293, -0.0026,  0.1198,  0.0948,  0.0248, -0.2450,  0.1918,\n",
      "         -0.1442,  0.0893, -0.2940,  0.1989],\n",
      "        [ 0.0647,  0.0627,  0.1078, -0.2079,  0.0045, -0.1734,  0.2891, -0.0206,\n",
      "          0.1038, -0.1948, -0.1663, -0.0851,  0.1471,  0.2264, -0.0025,  0.1278,\n",
      "         -0.1614, -0.2076, -0.0223,  0.0856],\n",
      "        [ 0.2430, -0.3435,  0.0575, -0.0159,  0.1850,  0.3341,  0.0946,  0.0686,\n",
      "          0.0539,  0.1419,  0.1882, -0.1387,  0.0999, -0.0770,  0.0039,  0.0345,\n",
      "         -0.3514, -0.1434, -0.2101, -0.0635]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0573,  0.0759,  0.2793,  0.2435,  0.2554,  0.0270, -0.1984,  0.0058,\n",
      "         0.1510,  0.2353,  0.1369,  0.2554, -0.0352,  0.0647, -0.1058,  0.1858,\n",
      "        -0.1826, -0.0003, -0.0104,  0.2097], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9908, 0.9591, 0.8416, 0.9098, 1.0261, 1.0246, 0.9885, 1.0374, 1.0648,\n",
      "        0.9594, 1.1221, 0.9574, 0.9832, 1.0242, 0.8859, 1.0612, 1.0835, 0.9552,\n",
      "        0.9602, 1.0310], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1120,  0.0423, -0.0162,  0.1364,  0.0585,  0.0379,  0.1255, -0.0264,\n",
      "        -0.0395, -0.0620,  0.1513,  0.0676, -0.0066,  0.0814,  0.0390,  0.0127,\n",
      "         0.1093,  0.0482,  0.1063,  0.0945], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0066, -0.2873,  0.1089, -0.1271, -0.2670, -0.0164,  0.1064,  0.2699,\n",
      "          0.0094, -0.1116,  0.1520, -0.0742, -0.1780,  0.2721,  0.1500, -0.1476,\n",
      "         -0.0593,  0.0664,  0.0634, -0.1051],\n",
      "        [-0.1740, -0.1558, -0.0633, -0.0117,  0.1287,  0.1646, -0.0340,  0.0157,\n",
      "          0.0110, -0.1127,  0.2303,  0.1929, -0.3170,  0.1961,  0.0667, -0.0440,\n",
      "          0.0928, -0.0831,  0.1774, -0.1511],\n",
      "        [ 0.1245,  0.2969, -0.0725, -0.0617,  0.0796, -0.2926,  0.0067, -0.0796,\n",
      "         -0.0555,  0.1507, -0.0723, -0.1406, -0.2261, -0.0152, -0.0191,  0.1399,\n",
      "         -0.1143,  0.1243,  0.0344, -0.1517],\n",
      "        [ 0.1060, -0.0377,  0.0676, -0.1738,  0.1021, -0.3074,  0.2460, -0.1531,\n",
      "          0.2233, -0.1160, -0.2917, -0.1995,  0.1020, -0.0147,  0.1385, -0.1574,\n",
      "          0.1072,  0.0851,  0.0937, -0.2025],\n",
      "        [-0.1809,  0.0462,  0.2167, -0.1844, -0.1883, -0.3176, -0.0356,  0.1890,\n",
      "         -0.0943,  0.0695, -0.0887, -0.0231, -0.0083, -0.2547,  0.3672,  0.0613,\n",
      "         -0.2304,  0.0802, -0.0516,  0.1182],\n",
      "        [-0.1430, -0.1102, -0.1645, -0.1135, -0.1717, -0.1680,  0.0398,  0.1785,\n",
      "          0.2127, -0.1357, -0.2627,  0.0525, -0.1989,  0.0732, -0.0525, -0.0788,\n",
      "          0.0937, -0.0169, -0.2848,  0.1914],\n",
      "        [-0.1345,  0.2236, -0.2578,  0.2484,  0.0498, -0.0785,  0.0442,  0.0093,\n",
      "          0.0522,  0.0457,  0.2065,  0.1662, -0.2277, -0.1297, -0.2286,  0.1181,\n",
      "          0.1908, -0.2203,  0.1177, -0.0710],\n",
      "        [-0.1346, -0.0101, -0.2252,  0.0961,  0.2269,  0.0217, -0.0673,  0.1128,\n",
      "          0.0536, -0.1001, -0.2179,  0.1960,  0.1530, -0.2349, -0.1986,  0.0923,\n",
      "          0.2730, -0.0997, -0.0882, -0.0067],\n",
      "        [-0.0854,  0.0472,  0.0474, -0.1220,  0.0985,  0.3148,  0.1384,  0.1015,\n",
      "         -0.1355,  0.0731,  0.1462, -0.0298, -0.0786,  0.1547, -0.0132, -0.0335,\n",
      "          0.0433,  0.2087,  0.2632,  0.0084],\n",
      "        [ 0.1511,  0.0649, -0.2363, -0.0227,  0.0277, -0.1238,  0.1707,  0.0231,\n",
      "          0.2447,  0.1422,  0.0334,  0.2225, -0.0788, -0.0019, -0.2453, -0.0613,\n",
      "          0.2064, -0.1103,  0.0846,  0.0925],\n",
      "        [-0.1540, -0.1200, -0.0032,  0.1443, -0.1083, -0.1165, -0.2594, -0.1109,\n",
      "         -0.3192, -0.0573,  0.2087,  0.0845,  0.0533, -0.1070,  0.0812,  0.3538,\n",
      "          0.0524, -0.1237, -0.0166,  0.1705],\n",
      "        [ 0.0477, -0.1837,  0.0803,  0.0953,  0.1016,  0.0764,  0.2490,  0.1020,\n",
      "          0.2150,  0.2799, -0.1196,  0.1828, -0.0078, -0.0856,  0.1321, -0.0394,\n",
      "          0.3335, -0.0990,  0.2127, -0.1865],\n",
      "        [-0.1807, -0.3205,  0.0894, -0.1451,  0.1744,  0.0323,  0.2110,  0.0724,\n",
      "          0.1067,  0.1777, -0.1729,  0.1628,  0.2517, -0.2551,  0.0768, -0.1066,\n",
      "          0.0102, -0.0331, -0.1463, -0.2182],\n",
      "        [-0.2341,  0.0730, -0.2380,  0.0350, -0.1173,  0.2211, -0.0872,  0.1172,\n",
      "         -0.1692,  0.1570,  0.0685,  0.2374, -0.1395,  0.2535,  0.0455, -0.2927,\n",
      "          0.0350, -0.0195,  0.0557,  0.0835],\n",
      "        [-0.2512,  0.0612, -0.1084, -0.1576, -0.1340, -0.0565, -0.0148,  0.1949,\n",
      "          0.0455,  0.0163, -0.0557, -0.2124, -0.0962, -0.1820,  0.0444, -0.1373,\n",
      "         -0.0687,  0.1943,  0.1735,  0.1152],\n",
      "        [ 0.0181, -0.0289,  0.1420,  0.2223, -0.3570, -0.0976, -0.1507, -0.1935,\n",
      "         -0.1816,  0.0653,  0.1674,  0.2831, -0.1671,  0.1216, -0.0764,  0.0633,\n",
      "          0.2292,  0.1889,  0.2245,  0.0599],\n",
      "        [ 0.3088, -0.1152, -0.1313,  0.0967, -0.1138, -0.1248,  0.2372,  0.1155,\n",
      "          0.0797,  0.0290, -0.0421,  0.1061,  0.1205, -0.0786, -0.3360,  0.1792,\n",
      "          0.1803, -0.0445, -0.1894, -0.0549],\n",
      "        [ 0.0346, -0.0129,  0.0296, -0.0372,  0.0847,  0.2782, -0.1295,  0.2148,\n",
      "         -0.0683, -0.2542, -0.0132, -0.2574,  0.0949,  0.1006,  0.1282, -0.0668,\n",
      "          0.1116,  0.1864,  0.1827,  0.0347],\n",
      "        [-0.1636,  0.0872, -0.1414, -0.0375,  0.2201, -0.2204,  0.2169,  0.0926,\n",
      "          0.0279,  0.0238,  0.0253, -0.0292,  0.2070,  0.1572, -0.0062, -0.3211,\n",
      "          0.0866, -0.1633, -0.1371, -0.1244],\n",
      "        [-0.2673, -0.1418, -0.1571,  0.2182,  0.1109, -0.0725,  0.0115,  0.0817,\n",
      "          0.4321, -0.0944, -0.0922,  0.1005, -0.2267, -0.1536,  0.0504, -0.1242,\n",
      "          0.1845,  0.0501, -0.1887, -0.1671]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2740,  0.0778, -0.0602,  0.2268,  0.0273,  0.0297,  0.2135,  0.1030,\n",
      "         0.1335,  0.0271,  0.2414, -0.0035, -0.0745,  0.1356, -0.1949,  0.0477,\n",
      "        -0.2042, -0.0395,  0.1544, -0.1223], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0183, 0.9191, 1.0008, 1.0363, 1.0332, 0.9147, 0.9461, 0.9655, 0.9858,\n",
      "        0.8886, 0.9444, 1.0013, 0.9539, 0.9767, 0.9581, 0.8896, 1.0299, 0.9846,\n",
      "        1.1060, 0.9104], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0436,  0.0603, -0.0199,  0.0836, -0.1435, -0.0336,  0.2236, -0.0354,\n",
      "        -0.0744, -0.1567,  0.0449, -0.1273, -0.0297, -0.1275,  0.1168, -0.1373,\n",
      "         0.1569,  0.2075, -0.0981,  0.2147], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2655, -0.1037,  0.1622,  0.0923, -0.3038, -0.2057,  0.1383, -0.0564,\n",
      "         -0.2788, -0.0510, -0.0430,  0.1089,  0.2339, -0.0218, -0.0493, -0.3139,\n",
      "          0.2917, -0.3175,  0.1378,  0.2862],\n",
      "        [ 0.1316, -0.0399, -0.1394,  0.0544,  0.0332,  0.0709, -0.1019, -0.0610,\n",
      "         -0.0475, -0.2538, -0.0784, -0.2820,  0.0423, -0.1093,  0.2105, -0.0546,\n",
      "         -0.1626,  0.1714, -0.0992,  0.1170],\n",
      "        [-0.2894,  0.0509,  0.2576, -0.0176,  0.0962, -0.0761,  0.2168, -0.1067,\n",
      "         -0.0888, -0.0548,  0.0236, -0.2292, -0.1506, -0.1933,  0.0933, -0.0171,\n",
      "          0.2171, -0.1921, -0.2043, -0.2506],\n",
      "        [-0.0945, -0.2196, -0.0711,  0.3360,  0.2215,  0.1136, -0.0545, -0.1939,\n",
      "          0.0861, -0.1218, -0.0567, -0.0615, -0.0961, -0.1650,  0.3614,  0.0271,\n",
      "         -0.2026,  0.0227, -0.0892,  0.0744],\n",
      "        [ 0.1573,  0.2056, -0.2857, -0.1479, -0.0659,  0.2896, -0.0374,  0.0403,\n",
      "          0.1072, -0.0186, -0.1073, -0.1007, -0.1399,  0.0530,  0.0289,  0.0404,\n",
      "         -0.1052,  0.1435, -0.0212,  0.0122],\n",
      "        [ 0.0859,  0.0480,  0.1464, -0.0844,  0.1027, -0.1031,  0.1980, -0.0697,\n",
      "         -0.1717,  0.0166,  0.2753, -0.2859, -0.1715, -0.1242,  0.2836, -0.2540,\n",
      "         -0.2091,  0.0075, -0.2491,  0.0708],\n",
      "        [-0.1893,  0.0691, -0.0939, -0.1262, -0.2117,  0.1042,  0.2317, -0.1743,\n",
      "          0.0553, -0.1023,  0.2316, -0.1538, -0.1891,  0.0672, -0.1779,  0.1903,\n",
      "         -0.1259, -0.0319, -0.3553,  0.0809],\n",
      "        [ 0.0046, -0.1720,  0.0590,  0.2508, -0.2400,  0.0256,  0.0437,  0.2026,\n",
      "         -0.1740,  0.1554, -0.2792,  0.1194, -0.0028, -0.1998,  0.0883, -0.1043,\n",
      "          0.1017, -0.1026,  0.0975,  0.0674],\n",
      "        [ 0.0537,  0.0781, -0.2304, -0.1878, -0.1781,  0.1429,  0.2188,  0.2095,\n",
      "          0.0497,  0.1653,  0.0472, -0.0520, -0.1623, -0.0294, -0.1551,  0.0951,\n",
      "          0.0694,  0.0673,  0.0584,  0.2877],\n",
      "        [ 0.2364,  0.1124, -0.1354, -0.0720, -0.0648, -0.1555,  0.0883, -0.0242,\n",
      "          0.2580, -0.2268,  0.0113,  0.1833, -0.1001,  0.2519,  0.0956, -0.1044,\n",
      "         -0.1265,  0.1454, -0.0141, -0.0083]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2519,  0.4003,  0.3526, -0.1309,  0.2941,  0.2576,  0.0096,  0.1557,\n",
      "         0.3261,  0.3032], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.4291, 1.4412, 1.6528, 1.1860, 1.3576, 1.3013, 1.3993, 1.4189, 1.4036,\n",
      "        1.3892], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1734, -0.3869,  0.2285, -0.3306, -0.3371,  0.2585, -0.1548, -0.4334,\n",
      "         0.5947, -0.4377], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0466, -0.5468,  0.5426, -0.3839, -0.5693,  0.1600,  0.1976,  0.1951,\n",
      "          0.6191, -0.0778],\n",
      "        [-0.2693,  0.1954,  0.3587,  0.2666,  0.3361,  0.3843,  0.4183, -0.5459,\n",
      "         -0.0567, -0.1817],\n",
      "        [-0.5914,  0.6588, -0.4433,  0.3659,  0.1295,  0.0486, -0.1871, -0.6187,\n",
      "         -0.0984,  0.2626],\n",
      "        [-0.1884, -0.2040,  0.4610,  0.0800, -0.2450,  0.5010,  0.0897, -0.2228,\n",
      "          0.0151, -0.3184],\n",
      "        [ 0.2548, -0.2783,  0.0696, -0.1573, -0.6188, -0.1696,  0.2066, -0.1125,\n",
      "         -0.2003, -0.4579],\n",
      "        [ 0.0642,  0.2629,  0.7190,  0.4145, -0.2563,  0.2736, -0.3065, -0.1753,\n",
      "         -0.9639, -0.4061],\n",
      "        [-0.1579, -0.0304, -0.2868,  0.2376, -0.0278, -0.0716, -0.0429,  0.1685,\n",
      "         -0.1416, -0.1164],\n",
      "        [ 0.2445,  0.3036, -0.1482,  0.5338, -0.2933,  0.3899, -0.4337,  0.3529,\n",
      "         -0.3810, -0.0234],\n",
      "        [-0.3435, -0.3336,  0.2328, -0.1272,  0.1653,  0.3618,  0.7244, -0.4776,\n",
      "         -0.0522,  0.3772],\n",
      "        [ 0.7475, -0.4499,  0.1871,  0.0822, -0.5535, -0.1343, -0.2389,  0.2962,\n",
      "          0.2200, -0.5688],\n",
      "        [ 0.2872,  0.1139, -0.1817, -0.1420,  0.1378, -0.1833,  0.1176,  0.3413,\n",
      "         -0.2800,  0.2216],\n",
      "        [-0.0138,  0.1413, -0.2340, -0.0622,  0.2094, -0.0866,  0.1538,  0.0350,\n",
      "         -0.2008,  0.3196],\n",
      "        [-0.0069,  0.1542, -0.2255,  0.1819,  0.3892, -0.0461,  0.0342,  0.4384,\n",
      "         -0.0240,  0.3019],\n",
      "        [-0.0642, -0.0090, -0.1504,  0.1136,  0.1349,  0.0894, -0.1409,  0.1335,\n",
      "          0.0683,  0.2445],\n",
      "        [ 0.0342, -0.1257,  0.2139, -0.0208,  0.0172, -0.2849, -0.1428,  0.1802,\n",
      "          0.0862, -0.0467],\n",
      "        [-0.2092,  0.0108, -0.0231,  0.3032,  0.0240, -0.1637,  0.0115,  0.2131,\n",
      "         -0.0544,  0.2060],\n",
      "        [ 0.0889, -0.0760, -0.2093, -0.0499,  0.0764,  0.3247, -0.1425, -0.1047,\n",
      "          0.3452,  0.1585],\n",
      "        [ 0.1763,  0.0201, -0.0283, -0.0133,  0.1226, -0.2626,  0.1611,  0.0899,\n",
      "         -0.2681,  0.0105],\n",
      "        [-0.0020,  0.3761, -0.0350,  0.1949,  0.2658, -0.0260,  0.2169,  0.3964,\n",
      "         -0.0517,  0.1139],\n",
      "        [-0.2054,  0.1852, -0.1945, -0.0051,  0.2361, -0.0078,  0.2917,  0.5862,\n",
      "         -0.2826,  0.2123]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0283,  0.0291, -0.3768, -0.2390,  0.1488, -0.0893, -0.0414,  0.1649,\n",
      "         0.2784,  0.1554, -0.8191, -0.6134, -0.8855, -0.4051, -0.7078, -0.6035,\n",
      "        -0.1515, -0.3585, -0.6171, -1.2829], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2487,  0.2557, -0.2719, -0.0139,  0.0572, -0.0789, -0.2203, -0.2764,\n",
      "          0.3353, -0.0223],\n",
      "        [-0.2463,  0.0153, -0.0460,  0.0858, -0.1853, -0.3246, -0.2424, -0.2764,\n",
      "          0.2294, -0.2597],\n",
      "        [-0.0330, -0.2448, -0.1494, -0.0626,  0.2038,  0.2698,  0.2679, -0.0163,\n",
      "         -0.4301,  0.0323],\n",
      "        [ 0.2832,  0.1653, -0.2259,  0.2766, -0.0498,  0.0587,  0.0377,  0.1124,\n",
      "          0.1653,  0.3144],\n",
      "        [ 0.2538,  0.0798,  0.0171,  0.0139,  0.1012, -0.4478,  0.2312, -0.0990,\n",
      "          0.2367, -0.1897],\n",
      "        [-0.0243, -0.1458, -0.4174, -0.0925,  0.0332, -0.0487, -0.1108, -0.0474,\n",
      "         -0.2054,  0.3354],\n",
      "        [ 0.0381, -0.2157, -0.0033, -0.1234, -0.0233, -0.3795,  0.1150,  0.0981,\n",
      "         -0.2225,  0.2989],\n",
      "        [-0.2997,  0.2371, -0.0108, -0.1097, -0.3617, -0.1751,  0.0772,  0.2169,\n",
      "         -0.0742, -0.1918],\n",
      "        [-0.4050,  0.1057,  0.3144,  0.1838, -0.0839,  0.1068,  0.0197,  0.1510,\n",
      "          0.0349, -0.2108],\n",
      "        [ 0.1248, -0.2222,  0.1120, -0.3556, -0.3559, -0.1270,  0.1320, -0.2273,\n",
      "         -0.1912, -0.2810]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1880,  0.3648,  0.1881,  0.3676,  0.0133,  0.0617, -0.1287,  0.2580,\n",
      "         0.2921,  0.0382], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9004, 1.0343, 0.6768, 0.9826, 0.9829, 1.1288, 1.2132, 1.0737, 1.0138,\n",
      "        0.8515], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0522,  0.1997,  0.0520,  0.0934,  0.1814,  0.1556,  0.0391, -0.0664,\n",
      "        -0.0076,  0.0823], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2069, -0.2262,  0.1093,  0.0567, -0.2870,  0.3647, -0.2470,  0.3240,\n",
      "          0.0697, -0.0375],\n",
      "        [-0.0965, -0.1449, -0.1654, -0.0112,  0.0676, -0.0483,  0.2894,  0.2291,\n",
      "         -0.1874,  0.2615],\n",
      "        [ 0.2832,  0.3604,  0.1256,  0.0654, -0.1490,  0.1267, -0.2933,  0.3460,\n",
      "         -0.2305, -0.0421],\n",
      "        [ 0.0824, -0.3452,  0.2625,  0.0694, -0.1787, -0.0730,  0.3925,  0.2028,\n",
      "          0.0278,  0.0140],\n",
      "        [ 0.0408, -0.1212, -0.1921, -0.0946,  0.3662,  0.3210,  0.0033, -0.1050,\n",
      "         -0.1804, -0.0367],\n",
      "        [-0.1695,  0.1302,  0.0840, -0.0434, -0.1901, -0.0866,  0.3271, -0.2597,\n",
      "         -0.0337,  0.0142],\n",
      "        [-0.0232, -0.1609, -0.0114, -0.2288,  0.0605, -0.2265, -0.2328, -0.0395,\n",
      "          0.2441,  0.2261],\n",
      "        [-0.0579, -0.2458,  0.1404,  0.2007, -0.0228,  0.2876,  0.3457, -0.0305,\n",
      "         -0.3647,  0.0048],\n",
      "        [ 0.1450,  0.1422,  0.0652,  0.2634,  0.3591, -0.2947, -0.3195, -0.1600,\n",
      "         -0.4285,  0.0657],\n",
      "        [-0.0489,  0.2159, -0.1224, -0.1318,  0.0491, -0.2544, -0.2225,  0.1273,\n",
      "          0.0177,  0.1280],\n",
      "        [ 0.2448, -0.0344, -0.0302,  0.0044,  0.3411, -0.2106,  0.1590, -0.1773,\n",
      "          0.0427,  0.1745],\n",
      "        [-0.0768, -0.1957, -0.1438,  0.3012, -0.1154, -0.1818, -0.3492, -0.1995,\n",
      "         -0.3245, -0.0493],\n",
      "        [ 0.2426, -0.3244,  0.1221, -0.0518, -0.1933,  0.3630,  0.2013, -0.1891,\n",
      "         -0.0614,  0.1874],\n",
      "        [ 0.3564,  0.1203, -0.0680,  0.3977, -0.1032,  0.2372,  0.1216, -0.2281,\n",
      "         -0.2744, -0.2579],\n",
      "        [-0.0441,  0.2603, -0.1306,  0.0363, -0.0115,  0.4689,  0.0784, -0.0066,\n",
      "          0.2073,  0.3221],\n",
      "        [-0.0258,  0.2395, -0.0449, -0.1110,  0.1526,  0.1349, -0.0030,  0.3170,\n",
      "          0.1883,  0.1214],\n",
      "        [-0.0327, -0.1237, -0.0856,  0.0356,  0.0480, -0.3890, -0.1533,  0.1598,\n",
      "          0.3625, -0.1357],\n",
      "        [ 0.0781, -0.2062,  0.2879,  0.0819,  0.0811,  0.2868, -0.1508, -0.0814,\n",
      "         -0.1161, -0.3275],\n",
      "        [-0.0342, -0.3565,  0.1251,  0.1641, -0.1614, -0.2731, -0.4376,  0.0354,\n",
      "         -0.0115, -0.2729],\n",
      "        [-0.1464, -0.0216,  0.0205, -0.3754,  0.2110, -0.3955, -0.0242, -0.1331,\n",
      "         -0.0280, -0.0025]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1927,  0.1357, -0.0484, -0.2179, -0.2196,  0.4489, -0.1007, -0.0721,\n",
      "        -0.1539,  0.2216,  0.3253,  0.1871,  0.2891,  0.0401, -0.1927, -0.3520,\n",
      "         0.2287, -0.0357, -0.2371,  0.3486], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0960, 0.8850, 0.8718, 0.9418, 0.8525, 1.0204, 0.9173, 1.0527, 1.0207,\n",
      "        1.0903, 0.9842, 1.0275, 1.0037, 1.0414, 1.0241, 1.0459, 0.9481, 1.0080,\n",
      "        0.8630, 0.8641], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0313, -0.0046,  0.0954, -0.0366,  0.1138,  0.0575, -0.1468, -0.1374,\n",
      "         0.0483, -0.1367,  0.0117, -0.1134,  0.0371,  0.0944,  0.0654, -0.0371,\n",
      "        -0.0852,  0.0207,  0.0106, -0.0714], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1068, -0.1095,  0.0151,  0.1131,  0.0388,  0.0328,  0.0336, -0.2558,\n",
      "          0.0489,  0.2992,  0.0488, -0.0848, -0.1768, -0.1376,  0.2092,  0.1992,\n",
      "         -0.2273, -0.1902, -0.1886,  0.0874],\n",
      "        [ 0.2033,  0.0309, -0.1622,  0.0425, -0.0150, -0.0979,  0.1167, -0.0996,\n",
      "          0.0854,  0.0947, -0.1864, -0.1130,  0.1092, -0.1470, -0.0196,  0.2406,\n",
      "          0.2851, -0.1500,  0.0266, -0.1001],\n",
      "        [-0.1210, -0.1634,  0.1527,  0.0411,  0.0868, -0.0110,  0.1045,  0.0591,\n",
      "          0.0432, -0.1555,  0.0511,  0.1308, -0.2068,  0.3439, -0.0550, -0.1867,\n",
      "         -0.1736,  0.1421, -0.0741, -0.1227],\n",
      "        [-0.3331,  0.2195,  0.0695,  0.0273,  0.0994,  0.1667, -0.1255, -0.1278,\n",
      "         -0.1921,  0.0562,  0.2764,  0.0192,  0.2010,  0.1235,  0.0169,  0.0031,\n",
      "         -0.0924, -0.1089, -0.0547,  0.0556],\n",
      "        [-0.0352,  0.1852,  0.2693, -0.2728,  0.1440,  0.1292,  0.2136,  0.0576,\n",
      "         -0.1067,  0.3371, -0.0370, -0.0821, -0.3211,  0.0620,  0.2255,  0.0753,\n",
      "          0.0269, -0.2103,  0.0473, -0.1585],\n",
      "        [ 0.0873, -0.1568,  0.1330,  0.0846, -0.0810, -0.2262, -0.1913, -0.1493,\n",
      "          0.0852, -0.1336, -0.0704,  0.2033,  0.1440,  0.3647,  0.0143, -0.1882,\n",
      "         -0.1922,  0.1414, -0.0759, -0.0539],\n",
      "        [ 0.3200, -0.0111, -0.0330, -0.0635,  0.1815, -0.0806,  0.1894,  0.1869,\n",
      "          0.2590,  0.0013, -0.1756,  0.1040,  0.0717,  0.1160, -0.0148,  0.0123,\n",
      "          0.1664,  0.0818, -0.0744, -0.1444],\n",
      "        [ 0.1219, -0.2388, -0.0775, -0.0436, -0.1879,  0.1501, -0.1200, -0.2627,\n",
      "          0.0507, -0.0496, -0.1896,  0.3044,  0.0578,  0.0513, -0.1006, -0.2291,\n",
      "          0.1306, -0.2568,  0.2060,  0.1238],\n",
      "        [-0.0773, -0.2130,  0.0167, -0.1199,  0.0439, -0.1980,  0.0522, -0.0642,\n",
      "          0.1364,  0.1757,  0.3270,  0.1425, -0.0341,  0.0951, -0.0758, -0.0786,\n",
      "         -0.1596, -0.0990, -0.1657,  0.0094],\n",
      "        [ 0.1247,  0.0004, -0.0052, -0.1048,  0.2364,  0.1279, -0.2136, -0.0336,\n",
      "         -0.3331, -0.3123, -0.2238, -0.1258, -0.0016,  0.0257,  0.3351, -0.2243,\n",
      "         -0.0363,  0.2279, -0.1649, -0.1161],\n",
      "        [-0.2044,  0.0840, -0.0901, -0.1407,  0.1084, -0.1658, -0.2265, -0.1496,\n",
      "          0.1037, -0.1624,  0.1684,  0.1000,  0.0831,  0.0928, -0.2532, -0.1585,\n",
      "          0.0751,  0.1429,  0.1835, -0.3071],\n",
      "        [-0.0204, -0.0414, -0.0595,  0.1724, -0.0300, -0.0579, -0.1963,  0.0803,\n",
      "         -0.0523, -0.1333,  0.2005, -0.1501,  0.2345,  0.2259,  0.2630, -0.1957,\n",
      "          0.0693,  0.0936,  0.0654, -0.0573],\n",
      "        [-0.2120, -0.0201, -0.0332,  0.0991,  0.0209,  0.1766, -0.1213,  0.2675,\n",
      "          0.1248,  0.2766, -0.0370, -0.2998, -0.0718, -0.1370, -0.1468, -0.1319,\n",
      "         -0.1121, -0.3478,  0.0896,  0.1424],\n",
      "        [-0.1136,  0.1567,  0.1394, -0.3318,  0.0195, -0.1399, -0.0950, -0.1923,\n",
      "          0.2657,  0.0394,  0.1485, -0.1368,  0.0791, -0.0703, -0.1291,  0.0518,\n",
      "          0.0846, -0.0772, -0.3103, -0.0019],\n",
      "        [-0.2713, -0.1254,  0.0759, -0.1517,  0.2269, -0.1710, -0.1197, -0.2607,\n",
      "          0.2645, -0.0775,  0.0374, -0.0345, -0.1187,  0.0879, -0.1149, -0.1296,\n",
      "         -0.1720, -0.3427,  0.1075, -0.0400],\n",
      "        [-0.0845,  0.1448, -0.2190,  0.2890, -0.1535,  0.2147, -0.0423,  0.2533,\n",
      "         -0.0457, -0.0182,  0.1754, -0.0624,  0.0752, -0.1838, -0.1059, -0.0633,\n",
      "         -0.1057,  0.0401, -0.1788, -0.1323],\n",
      "        [ 0.0331,  0.3075, -0.1950, -0.0843,  0.0646, -0.1331, -0.2245,  0.1580,\n",
      "         -0.1299,  0.0249,  0.1625, -0.2187,  0.2262,  0.0589,  0.2732, -0.1499,\n",
      "         -0.2039, -0.0527, -0.1965,  0.1073],\n",
      "        [ 0.1634, -0.1205,  0.0563,  0.0517, -0.2106,  0.1520, -0.2060,  0.1066,\n",
      "         -0.0418, -0.3025, -0.2025,  0.2961,  0.1801, -0.1483,  0.0925, -0.1515,\n",
      "         -0.1183,  0.1355,  0.1295, -0.1798],\n",
      "        [-0.1671, -0.1239, -0.1834,  0.1289, -0.1912,  0.2086, -0.1644, -0.0837,\n",
      "          0.0515, -0.3004, -0.0062, -0.0799,  0.0622, -0.1578, -0.3348, -0.1016,\n",
      "         -0.2960, -0.0269,  0.1213,  0.0835],\n",
      "        [ 0.2574,  0.1329,  0.0276,  0.0730,  0.1379,  0.1174, -0.0404,  0.1078,\n",
      "          0.0039, -0.0455, -0.1515,  0.1464,  0.2811,  0.1297, -0.1033, -0.3018,\n",
      "         -0.3382, -0.0374,  0.0101, -0.1530]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1378, -0.0047,  0.0608,  0.0400, -0.1119, -0.0412, -0.2134, -0.0139,\n",
      "         0.2108,  0.1421,  0.1029,  0.2535, -0.0987,  0.0448,  0.0182, -0.1965,\n",
      "        -0.0734, -0.0502,  0.2741,  0.2983], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0431, 0.9535, 0.9195, 1.0114, 1.0046, 0.9216, 0.8816, 0.9038, 1.1317,\n",
      "        0.9475, 0.9763, 0.9620, 0.9241, 0.9952, 1.0146, 1.0154, 0.9574, 1.0021,\n",
      "        0.9264, 1.0649], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.4084e-01,  7.5142e-02, -2.0957e-04,  6.1031e-02,  6.6468e-02,\n",
      "        -4.8714e-02,  2.6047e-01, -1.4345e-01,  6.3142e-02,  1.7928e-01,\n",
      "        -2.4603e-02,  1.4657e-01,  2.2860e-02,  1.6422e-01, -4.1830e-02,\n",
      "         9.0139e-02,  7.1900e-02, -3.6144e-02, -9.8061e-04,  1.8773e-01],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.3223e-01, -3.5839e-01,  8.9408e-03,  1.7432e-02,  3.4082e-02,\n",
      "         -1.3692e-02, -2.7955e-02,  1.2466e-01,  1.6891e-01, -3.2591e-01,\n",
      "          1.7264e-01, -2.3598e-02, -2.8009e-02,  8.5780e-02,  2.1827e-01,\n",
      "         -1.9289e-01,  1.3933e-01,  5.8204e-02, -2.0306e-02, -1.4108e-01],\n",
      "        [-2.6565e-02, -2.3264e-01,  1.6243e-02,  2.7437e-02, -2.9442e-02,\n",
      "         -9.2292e-02,  1.0934e-01, -7.4776e-02, -1.9320e-01,  2.3280e-01,\n",
      "          1.7212e-02,  7.7292e-02,  1.8499e-01,  2.3823e-01, -1.3714e-01,\n",
      "          2.4909e-01,  1.8182e-01,  1.8572e-01,  1.3531e-01, -1.8608e-02],\n",
      "        [-3.8271e-02, -1.2959e-01, -5.5649e-02,  1.0696e-01, -1.7543e-01,\n",
      "          3.9092e-02, -1.1277e-02, -1.1411e-01, -9.8072e-02, -1.4186e-01,\n",
      "          6.5307e-02,  1.8146e-01,  8.9560e-02,  1.2022e-01, -1.5507e-01,\n",
      "          3.4158e-01,  2.7703e-01,  4.5735e-02,  1.4404e-01, -5.5565e-02],\n",
      "        [-1.4889e-01,  8.5826e-02,  1.3538e-01, -1.5883e-01, -1.8567e-02,\n",
      "          2.3773e-01,  1.4836e-01, -4.6548e-02,  2.3469e-01, -3.6115e-02,\n",
      "          2.0999e-01,  2.5117e-01, -2.1997e-01,  1.6459e-01,  1.9686e-01,\n",
      "         -1.3620e-02, -6.6493e-02, -1.8938e-01, -2.0704e-01, -9.1288e-02],\n",
      "        [ 2.3975e-01, -1.0318e-01, -1.7772e-01,  1.2868e-01,  3.1412e-01,\n",
      "          1.4381e-03,  2.8837e-02, -2.3906e-01, -1.8218e-01,  8.8849e-02,\n",
      "         -1.6404e-01,  5.3428e-02,  4.8169e-02,  8.4742e-02, -2.9438e-01,\n",
      "         -1.2246e-01,  4.1981e-02, -1.2498e-01,  6.6247e-02,  1.4302e-02],\n",
      "        [-1.6073e-01, -6.6815e-02,  1.2480e-01,  3.1479e-01, -1.7502e-01,\n",
      "         -2.6425e-01, -9.1972e-02, -6.3429e-02, -1.7943e-01, -1.3157e-02,\n",
      "          1.8471e-02, -2.9841e-02,  2.1056e-01, -7.2022e-02,  4.9279e-02,\n",
      "          2.9341e-01,  1.7797e-01,  1.3422e-01, -8.9230e-02,  3.7359e-02],\n",
      "        [-7.6628e-02,  2.6371e-01,  3.2986e-02,  7.3596e-02,  1.4830e-01,\n",
      "         -9.8583e-02,  5.4513e-02, -3.9452e-02,  8.0283e-02, -9.5486e-02,\n",
      "         -3.9544e-01, -2.4626e-01, -2.7153e-01,  2.4743e-01,  1.4891e-01,\n",
      "         -6.0739e-03, -4.8379e-02, -2.6585e-01, -4.6141e-02, -5.1389e-02],\n",
      "        [-1.9066e-01, -8.4357e-02,  2.0716e-01,  1.4913e-01, -7.3814e-02,\n",
      "          1.3997e-01,  2.1177e-01, -9.5829e-02,  5.2538e-02,  1.7969e-02,\n",
      "          1.9035e-01, -4.0213e-03, -1.4590e-02,  5.6058e-02,  1.3218e-02,\n",
      "         -5.2683e-02,  2.7330e-02, -1.5734e-01,  9.9724e-02,  1.2081e-01],\n",
      "        [ 2.4472e-01,  1.4582e-01, -1.6198e-01, -3.4279e-02,  8.6116e-02,\n",
      "         -1.5939e-01,  1.0629e-01, -1.5475e-01, -7.4580e-02, -1.2284e-01,\n",
      "         -2.3644e-01, -2.1400e-01,  1.7427e-01,  2.1066e-01, -1.7240e-01,\n",
      "         -2.3074e-01, -2.5569e-03, -2.2835e-02, -2.5801e-01, -1.8346e-01],\n",
      "        [ 2.0651e-01,  2.6656e-01, -9.7491e-03,  7.1336e-03,  7.8417e-02,\n",
      "         -3.1402e-02,  1.8404e-01, -1.2665e-01, -1.6973e-01,  1.3392e-01,\n",
      "         -1.1172e-01,  1.5654e-01, -4.8275e-02, -8.9164e-02, -2.3195e-01,\n",
      "          4.4392e-02,  4.4408e-02, -1.7963e-01, -2.3903e-01, -1.6951e-02],\n",
      "        [ 1.2603e-01,  3.9527e-02,  2.3766e-02,  8.1065e-02, -1.7228e-01,\n",
      "         -1.9583e-01,  7.9083e-02, -2.5905e-01, -1.5279e-01,  1.6807e-01,\n",
      "          1.9904e-01, -3.2323e-02,  8.5521e-02,  1.6091e-02,  2.0879e-01,\n",
      "         -1.0151e-01,  7.5892e-02, -2.7128e-01,  3.2619e-02,  1.0108e-01],\n",
      "        [ 1.3952e-01, -1.0602e-01,  6.5951e-02, -1.5643e-01, -3.8703e-02,\n",
      "          5.9081e-02,  5.1759e-02, -1.1315e-01, -1.3874e-01, -1.7962e-01,\n",
      "         -4.1139e-02,  1.1349e-01,  6.3380e-02, -1.3104e-01, -3.0409e-01,\n",
      "          2.8968e-01, -7.4286e-02,  3.8796e-02,  2.6147e-01,  1.5544e-01],\n",
      "        [ 1.7278e-01, -2.3154e-01,  2.0106e-01, -1.2936e-01,  1.9930e-02,\n",
      "          1.9276e-01,  1.8215e-01, -1.8571e-01, -1.1338e-01, -6.5201e-02,\n",
      "         -9.5515e-02, -2.8545e-04,  6.1219e-02, -2.1720e-01, -1.0021e-01,\n",
      "         -2.1665e-01, -1.1305e-01,  2.2563e-01, -3.8540e-01,  1.9613e-01],\n",
      "        [-2.2043e-01,  7.7969e-02,  2.7529e-01,  3.6577e-01,  1.5754e-01,\n",
      "          3.0812e-02,  5.8011e-02, -3.7068e-02, -7.6602e-02,  8.5085e-02,\n",
      "         -1.4373e-01,  2.5315e-01,  2.4235e-01, -6.5515e-02,  2.2993e-01,\n",
      "         -7.4225e-02,  1.1788e-01, -2.7153e-02, -7.6929e-02, -3.9025e-02],\n",
      "        [-1.5935e-01,  1.5865e-01, -2.6288e-01, -1.1432e-01, -3.2659e-02,\n",
      "         -1.1956e-01,  8.4776e-02,  1.0072e-01, -2.5764e-01,  2.2065e-02,\n",
      "         -2.5326e-01, -1.4186e-01, -5.4857e-02, -1.7368e-01, -2.4446e-01,\n",
      "          1.3418e-01,  8.2423e-02, -1.0581e-01,  3.1375e-02, -6.7982e-02],\n",
      "        [ 1.7095e-01,  8.9879e-02,  3.4141e-02,  8.6506e-02,  9.3487e-02,\n",
      "         -2.6848e-01, -5.4380e-02,  4.8921e-03,  3.9712e-01, -1.0184e-01,\n",
      "          3.1503e-02, -2.8011e-01,  5.0861e-02,  3.0989e-01,  1.9848e-01,\n",
      "          8.0376e-02,  2.9176e-02,  5.8946e-02, -1.9470e-01, -2.7896e-01],\n",
      "        [-9.0395e-02,  7.9041e-02,  4.7664e-02, -9.6785e-02, -2.2559e-01,\n",
      "          2.7355e-02,  1.9897e-01, -2.0457e-01, -1.0892e-01,  1.6360e-01,\n",
      "          2.9492e-02,  2.4948e-01, -5.3720e-02, -1.5252e-01, -1.9545e-01,\n",
      "          2.2467e-02,  9.4883e-02,  9.5045e-02, -1.8425e-01,  4.7433e-02],\n",
      "        [ 1.2914e-01,  1.1724e-01, -9.1932e-02,  8.1540e-02,  2.7998e-01,\n",
      "          4.9824e-02, -7.8676e-02,  3.2449e-02, -1.0921e-02, -1.8886e-01,\n",
      "         -1.7102e-01, -1.8577e-01,  6.9242e-02,  7.7838e-02,  1.9047e-02,\n",
      "         -1.3465e-01, -8.3205e-02, -3.2209e-01, -2.1587e-01, -2.3898e-01],\n",
      "        [-5.4169e-02, -3.9996e-02, -4.1547e-02, -1.0597e-01, -1.1455e-02,\n",
      "          1.9249e-01,  6.7279e-02,  9.4465e-02,  7.9183e-02,  2.0830e-01,\n",
      "          1.2033e-01,  1.1777e-01, -2.3609e-01, -2.3760e-01, -1.6362e-01,\n",
      "          1.0683e-01,  6.5353e-02,  7.3257e-02,  9.9022e-02,  2.2570e-01],\n",
      "        [-2.8496e-01,  2.1686e-01, -8.8760e-03, -2.9434e-02, -3.1215e-02,\n",
      "         -1.0406e-01,  1.1528e-01, -7.7611e-02, -1.8062e-01,  1.4367e-01,\n",
      "         -2.0000e-01,  2.5303e-01,  1.6388e-01, -7.1608e-02,  4.5648e-02,\n",
      "          1.4802e-01,  1.4494e-01, -1.7837e-02, -7.5227e-02,  2.4960e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2917,  0.2153, -0.2451, -0.2238,  0.1296, -0.1525,  0.0168, -0.1566,\n",
      "         0.0796,  0.0427,  0.1697,  0.0858, -0.0562, -0.0525,  0.0295,  0.0353,\n",
      "         0.0703,  0.3808,  0.1991,  0.1816], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0711, 0.8945, 0.9227, 0.9456, 1.0529, 0.8911, 0.9148, 0.9648, 0.9229,\n",
      "        1.0563, 0.9213, 0.8432, 0.8956, 0.9781, 0.9206, 1.0765, 0.9384, 1.0307,\n",
      "        1.0666, 1.0368], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1808,  0.0550,  0.0526,  0.0287, -0.0038, -0.0092, -0.0170,  0.0939,\n",
      "        -0.1258,  0.0570,  0.0697,  0.0172,  0.0109,  0.1034, -0.1484, -0.0357,\n",
      "         0.1282,  0.0093,  0.0662,  0.1465], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-5.7919e-02, -1.7872e-01, -5.8879e-02, -2.9012e-02, -1.6160e-01,\n",
      "          2.6698e-02,  2.1119e-01,  1.6732e-01,  9.8495e-03,  3.8340e-01,\n",
      "          8.7357e-02, -2.4184e-01, -2.6063e-01, -1.4472e-01,  8.8575e-02,\n",
      "          1.0972e-01, -1.1267e-02,  9.5579e-02, -2.5711e-01,  8.6439e-02],\n",
      "        [ 2.1346e-01, -2.9398e-01,  9.3063e-03, -1.7731e-02, -4.1606e-02,\n",
      "         -1.0812e-01, -1.9657e-01,  5.0206e-02, -1.7431e-01, -3.0703e-02,\n",
      "         -1.0117e-01, -3.3482e-02,  1.6942e-01, -5.2220e-02,  2.4035e-03,\n",
      "         -2.0051e-01, -2.7112e-02, -2.5671e-01,  5.3551e-02, -2.1790e-02],\n",
      "        [-1.1929e-01,  3.3385e-02,  2.2248e-01, -5.6906e-02,  2.1356e-02,\n",
      "          2.0493e-01,  6.8090e-02,  6.9170e-02,  1.7293e-01,  3.0420e-01,\n",
      "         -6.1786e-02,  5.9707e-02, -8.2860e-02,  1.7371e-01,  7.3235e-02,\n",
      "         -1.0916e-01, -1.2229e-01, -7.2625e-02,  6.2031e-02,  8.9647e-02],\n",
      "        [-1.5757e-01, -5.0645e-02, -3.9863e-01,  1.2944e-01,  1.8845e-01,\n",
      "         -1.3355e-01,  2.0497e-01, -1.7187e-01,  2.8722e-01,  2.3181e-01,\n",
      "         -3.9573e-02, -1.3762e-01,  2.2267e-01,  8.2372e-02,  1.3078e-01,\n",
      "          1.4954e-01,  9.8350e-02,  1.2841e-01,  6.4691e-02,  2.3812e-01],\n",
      "        [-1.5051e-01,  5.0520e-02,  5.8886e-02, -1.1502e-02,  3.0379e-01,\n",
      "         -3.7412e-02, -2.1651e-01,  3.3378e-04,  6.9679e-02,  1.7194e-02,\n",
      "          2.8320e-01, -2.0504e-01,  9.6962e-02,  2.2174e-03,  1.3666e-01,\n",
      "         -6.2615e-02, -9.5604e-02, -2.4353e-02,  1.8715e-02,  1.1905e-01],\n",
      "        [-1.2685e-01,  8.0320e-02,  6.4792e-02, -7.7196e-02, -3.3468e-02,\n",
      "          8.2551e-02, -1.2902e-01,  6.2480e-02, -9.5385e-02,  1.1673e-01,\n",
      "         -2.3726e-01, -7.6342e-02,  3.2690e-01,  7.5409e-02, -1.6068e-01,\n",
      "         -2.2562e-01,  1.3107e-01, -1.3796e-01,  2.7998e-01, -9.0489e-02],\n",
      "        [ 1.7874e-01,  3.2422e-02, -5.6507e-02,  2.0059e-01, -3.1417e-01,\n",
      "         -1.8033e-01, -1.1548e-02,  1.8150e-01, -3.0423e-01, -7.9163e-02,\n",
      "         -1.2505e-01, -1.2132e-01,  6.0044e-02,  9.3704e-03, -8.9741e-02,\n",
      "         -2.9808e-02, -2.3066e-01, -3.3210e-01, -5.5503e-02, -3.1982e-01],\n",
      "        [ 1.4445e-01,  3.8978e-02, -3.9878e-02,  3.9737e-02,  1.2866e-01,\n",
      "         -1.4905e-01, -6.2314e-02,  1.9898e-01,  9.2948e-03, -2.2799e-01,\n",
      "          2.5576e-01,  3.8547e-02, -5.9006e-02, -7.3082e-02, -1.7486e-01,\n",
      "          3.2535e-01, -6.9975e-02,  1.2697e-02, -4.6315e-02,  1.2899e-01],\n",
      "        [ 2.4694e-01, -2.0542e-01,  6.4042e-02,  5.2424e-02,  1.8980e-01,\n",
      "         -4.8470e-02,  1.4681e-01, -4.5807e-02, -1.2035e-02,  1.8604e-01,\n",
      "          1.7293e-02,  7.3674e-02,  7.6618e-03,  1.4187e-01, -9.3011e-02,\n",
      "          2.1698e-01, -1.4338e-01,  2.6803e-01, -2.8381e-01, -2.7629e-01],\n",
      "        [ 2.2871e-01, -7.3396e-02,  2.1463e-01, -6.3370e-02, -1.1042e-02,\n",
      "          2.3739e-01,  2.2234e-01, -1.9679e-01, -2.7490e-03, -1.5086e-01,\n",
      "          2.2616e-01, -1.1124e-02,  1.6827e-01,  7.5117e-02, -1.6070e-01,\n",
      "          2.6394e-01,  3.3287e-02,  7.0994e-02,  9.6830e-03, -1.0903e-01],\n",
      "        [ 1.2940e-01,  2.6548e-02, -3.3971e-01, -2.5592e-01,  2.7552e-01,\n",
      "          6.8078e-02,  1.2794e-01, -1.3960e-01,  1.0039e-01, -1.1932e-01,\n",
      "         -1.3627e-01, -6.2255e-02,  1.5080e-01, -4.9030e-02, -2.4277e-01,\n",
      "         -1.0299e-02, -2.9638e-02,  1.6290e-01, -2.0728e-01, -2.6586e-01],\n",
      "        [-2.6873e-01,  7.6159e-02,  1.3010e-01, -5.3725e-02,  6.5859e-02,\n",
      "          3.2383e-03, -2.1423e-01, -1.4950e-01, -2.8137e-01,  3.5820e-02,\n",
      "         -1.1728e-01,  2.4909e-02, -1.4206e-02,  7.5330e-02,  1.6893e-02,\n",
      "         -2.7394e-01,  1.9862e-01, -1.1676e-01,  1.9050e-01,  2.5193e-01],\n",
      "        [ 1.1760e-01, -6.5990e-02, -2.2003e-01,  1.8782e-01, -6.8531e-02,\n",
      "          5.7180e-02, -5.9817e-02,  1.3555e-01, -1.3467e-01, -3.5399e-01,\n",
      "          1.6375e-01, -1.8914e-01,  5.4129e-03,  1.9344e-01, -1.8426e-01,\n",
      "         -4.1402e-02,  9.6008e-02, -1.6337e-02, -8.8335e-02, -1.9546e-01],\n",
      "        [-2.5211e-01,  1.9106e-01,  1.4438e-01, -1.1548e-01, -3.1132e-02,\n",
      "         -4.8244e-02, -2.0891e-01,  7.8762e-02, -1.9264e-01, -1.7602e-01,\n",
      "          1.3915e-01,  5.4228e-02,  6.4482e-02,  1.8903e-01, -6.5846e-02,\n",
      "         -8.2973e-02,  1.6388e-01, -1.3403e-01,  2.8612e-02,  2.4319e-01],\n",
      "        [-2.3703e-03, -1.3165e-02, -4.0678e-02,  7.8866e-02, -2.3408e-01,\n",
      "          1.9657e-02, -7.6072e-02,  2.8913e-01, -2.2708e-01, -4.7328e-03,\n",
      "          7.1579e-02,  1.1886e-01,  2.1669e-01, -1.6836e-04, -1.4556e-01,\n",
      "         -1.1449e-01,  2.6219e-01, -3.0593e-01, -5.0254e-02,  2.0079e-01],\n",
      "        [ 2.4087e-01, -2.0027e-01,  6.2132e-02,  2.9499e-02,  5.1207e-02,\n",
      "          1.4616e-01, -1.5512e-01, -7.3790e-02,  2.4452e-01, -2.1331e-01,\n",
      "          1.0495e-02, -1.7783e-01, -1.1845e-02,  1.6542e-01,  1.8387e-02,\n",
      "          1.2677e-01, -3.3801e-01,  1.2576e-01, -2.9484e-01,  6.4328e-02],\n",
      "        [-6.8245e-02, -4.1796e-02,  6.3528e-02, -2.7040e-01,  1.1112e-01,\n",
      "          6.9460e-03, -9.2348e-02, -2.9500e-01, -9.6617e-02, -2.9513e-02,\n",
      "         -1.0979e-01,  5.7960e-02, -1.6323e-01, -2.2697e-01,  3.7140e-01,\n",
      "         -1.8258e-01, -6.9686e-02,  1.1143e-01, -1.4716e-01,  7.4627e-02],\n",
      "        [-1.1551e-01, -8.4902e-02,  1.7160e-01, -2.0063e-01,  1.6533e-01,\n",
      "          1.7655e-01, -1.2747e-01,  7.8544e-02, -1.2583e-01,  2.5285e-01,\n",
      "          2.0318e-01, -3.7275e-02,  3.4693e-02,  2.7586e-01,  4.7917e-02,\n",
      "         -5.6901e-02,  4.5385e-02,  1.1839e-01, -7.8823e-02,  1.9452e-01],\n",
      "        [-2.0254e-02, -1.7326e-01, -1.4652e-01,  1.3216e-01, -3.5343e-01,\n",
      "         -6.8395e-02,  6.0032e-03,  1.6489e-01,  1.1109e-01, -5.4664e-02,\n",
      "         -7.6425e-02, -2.1529e-01, -9.7765e-02,  1.7498e-01,  1.2289e-01,\n",
      "         -1.6564e-01, -1.3003e-01,  1.3592e-01, -2.9312e-01, -1.2091e-01],\n",
      "        [ 2.0880e-01,  2.2588e-01,  3.3469e-02,  1.4358e-01, -4.5715e-02,\n",
      "         -1.2978e-01,  6.3213e-02,  1.4446e-01, -4.8694e-02, -7.3775e-03,\n",
      "         -1.3280e-01, -1.2543e-01,  2.4991e-01,  8.7301e-02, -2.4754e-01,\n",
      "          2.2245e-01, -1.6658e-01,  1.5546e-01,  2.3870e-01, -1.0349e-03]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.0478e-01, -8.3839e-02,  9.7793e-02,  1.4094e-04, -1.5428e-01,\n",
      "         1.2682e-01,  2.5939e-01,  1.2498e-01, -7.7067e-02, -1.1163e-01,\n",
      "        -4.2423e-02,  1.8744e-02,  2.7223e-01,  9.0623e-02,  1.0937e-01,\n",
      "         1.2539e-01,  3.6685e-01, -7.0502e-02, -1.2919e-01,  1.6120e-01],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9304, 0.9560, 0.9632, 1.0644, 0.8794, 0.9837, 0.9058, 0.8522, 1.1335,\n",
      "        0.8502, 1.0450, 1.0308, 1.0558, 1.0806, 0.9954, 0.8672, 1.0469, 1.0179,\n",
      "        0.9019, 0.7262], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0861,  0.0212,  0.0444,  0.1399, -0.0820,  0.2560,  0.0951,  0.1734,\n",
      "         0.0049, -0.0161, -0.0850, -0.0150, -0.2203, -0.0809,  0.2878, -0.1078,\n",
      "        -0.0720,  0.0998,  0.0299, -0.0193], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-7.3844e-02,  5.7501e-02,  1.9877e-01, -3.5407e-02,  3.9066e-02,\n",
      "          3.6948e-01, -1.9849e-01, -5.1711e-02,  2.1134e-01,  5.0742e-02,\n",
      "          1.5343e-01,  1.2040e-02, -1.1799e-01,  5.3685e-02,  1.9299e-01,\n",
      "         -1.0213e-02, -1.1242e-01,  4.0923e-02, -2.1058e-01,  1.0647e-01],\n",
      "        [-1.8921e-01, -8.5717e-03,  1.8504e-02, -6.1908e-02, -1.1901e-02,\n",
      "          7.0705e-02, -2.5191e-01,  8.8261e-02, -2.4555e-01, -2.1815e-01,\n",
      "         -2.2941e-01,  1.6730e-01, -1.3675e-01, -2.6352e-02, -7.6214e-04,\n",
      "         -1.4902e-01,  2.9489e-01,  2.3486e-01, -9.8589e-02, -2.7413e-01],\n",
      "        [-4.2139e-01,  1.4980e-01, -1.1015e-01,  1.2463e-01, -2.5257e-01,\n",
      "          2.5479e-01, -4.9771e-02, -2.6350e-02,  5.1043e-02, -7.9521e-03,\n",
      "          7.8013e-02,  1.5410e-01, -2.0339e-01,  7.4551e-02,  1.9950e-01,\n",
      "         -1.4780e-02, -1.7902e-01,  4.2397e-02, -3.0992e-02,  1.7250e-01],\n",
      "        [-2.5858e-02,  3.8904e-03, -1.1377e-01, -9.5188e-04,  4.9832e-02,\n",
      "          6.9676e-02,  2.0677e-01,  2.5556e-01, -3.9460e-02,  1.5145e-01,\n",
      "         -1.2237e-02, -1.7369e-01,  2.3012e-01,  2.0846e-01,  2.7979e-01,\n",
      "         -4.0398e-02, -2.3894e-01,  1.4802e-01,  2.9721e-02,  2.3663e-01],\n",
      "        [-2.3244e-01,  2.5033e-01, -2.0794e-01, -2.3005e-01, -2.5643e-01,\n",
      "          9.4077e-02,  2.4908e-01, -1.0159e-01, -2.6541e-01, -4.8400e-02,\n",
      "         -1.5452e-02,  9.4237e-02, -1.2872e-01, -1.2677e-01,  1.6050e-01,\n",
      "          8.7114e-02,  8.1610e-02, -3.4103e-01, -1.9714e-02,  3.1506e-02],\n",
      "        [ 2.6229e-02, -5.2231e-02,  1.2031e-01,  2.4433e-02,  8.7411e-02,\n",
      "          1.1880e-01,  4.8854e-02, -1.1256e-02, -3.1412e-01,  7.6455e-02,\n",
      "         -7.5933e-02,  1.9271e-01, -1.6569e-01,  1.9864e-01,  1.0387e-01,\n",
      "         -1.1038e-01,  1.5266e-01,  2.0371e-01, -2.6599e-01, -9.9771e-02],\n",
      "        [ 9.6553e-02, -8.8157e-02,  1.7960e-01,  2.5467e-01,  2.3184e-01,\n",
      "          1.2139e-01, -2.7437e-01, -8.7028e-02,  2.9561e-01, -1.3696e-02,\n",
      "          1.3377e-01, -4.0045e-02, -2.5152e-01, -1.9918e-01, -4.3360e-02,\n",
      "          9.2584e-02,  9.1186e-02,  4.3339e-02,  1.4321e-01,  6.4630e-05],\n",
      "        [-2.1317e-01,  4.3256e-02,  1.0567e-01, -1.5677e-01,  1.8645e-01,\n",
      "         -4.5726e-02, -1.9589e-01,  4.4595e-02, -3.2839e-01,  6.1336e-02,\n",
      "          2.9137e-02,  1.8531e-01,  5.4909e-02,  2.1718e-01,  1.4174e-01,\n",
      "         -3.6796e-02, -9.0638e-02,  8.7460e-02, -3.9955e-02, -4.7656e-02],\n",
      "        [ 1.8357e-01, -1.2655e-01,  1.6180e-01,  1.7717e-01, -1.7716e-02,\n",
      "          6.9339e-02, -7.1346e-02, -3.1406e-02,  1.3383e-02, -1.0935e-01,\n",
      "         -1.4611e-01,  5.1457e-02, -2.9063e-01,  7.8689e-02,  1.7369e-01,\n",
      "         -2.7499e-01,  1.2153e-01,  1.1394e-01,  6.4638e-02, -1.0125e-01],\n",
      "        [ 2.6543e-02,  2.4099e-01, -1.6630e-01,  1.9327e-01, -1.5518e-01,\n",
      "          4.9958e-02, -8.3463e-02,  1.3382e-01,  1.8134e-01,  1.1776e-01,\n",
      "         -5.1493e-02,  1.0756e-01,  2.3907e-02,  8.9496e-02,  3.0119e-01,\n",
      "          1.8906e-01, -1.2942e-01, -1.0018e-02,  1.9661e-01,  1.7742e-01],\n",
      "        [ 1.2986e-01, -3.9859e-02, -2.0114e-01, -1.9983e-01,  3.9741e-02,\n",
      "         -1.8928e-01,  1.1498e-01, -3.8689e-02,  1.6868e-01, -9.6768e-02,\n",
      "         -1.9546e-01, -1.0178e-01,  3.4443e-01,  1.3741e-01,  4.1280e-02,\n",
      "          1.8392e-01, -1.6318e-01, -9.6990e-03,  1.3593e-01, -6.0082e-02],\n",
      "        [ 5.9450e-02, -1.7067e-01,  5.2975e-02, -1.9855e-01,  8.2923e-03,\n",
      "         -2.2422e-01,  8.1727e-02,  2.1868e-01,  1.9199e-02,  2.3885e-01,\n",
      "          8.1585e-02, -3.3723e-01,  1.6643e-02, -1.4839e-01, -1.5005e-01,\n",
      "          1.3424e-01,  1.0982e-01, -3.3447e-01,  1.1355e-01,  2.7201e-02],\n",
      "        [ 2.1868e-02, -8.3969e-02,  2.6337e-01,  2.4433e-01, -1.3006e-01,\n",
      "          2.6655e-01, -3.5622e-02, -6.3009e-02, -2.1012e-01, -1.2110e-03,\n",
      "         -1.0973e-01,  4.4727e-02,  7.0545e-02,  1.6981e-01,  8.6818e-03,\n",
      "         -6.2236e-03, -3.3059e-01,  1.3561e-01,  9.7994e-02,  9.6622e-02],\n",
      "        [ 9.2367e-02,  2.0680e-01, -1.8414e-02, -1.1937e-01, -2.4062e-01,\n",
      "          1.7073e-01,  3.2928e-01,  1.4554e-01, -6.0015e-02, -6.4784e-02,\n",
      "         -3.0932e-02, -1.6820e-01,  1.5287e-01, -2.7830e-01,  1.5255e-02,\n",
      "         -1.5213e-01, -1.9382e-02, -2.8264e-02, -3.7425e-02, -1.3913e-01],\n",
      "        [ 1.1944e-01,  2.2913e-02, -8.7728e-02,  2.0157e-01, -1.6416e-01,\n",
      "         -1.4529e-01, -9.8820e-02, -3.8122e-01, -1.4854e-01,  7.2289e-02,\n",
      "         -8.7234e-02,  5.0491e-02, -1.9259e-01, -1.0900e-01, -9.4804e-02,\n",
      "         -1.4516e-01,  2.4370e-01,  2.3590e-03,  1.0009e-01, -1.5354e-01],\n",
      "        [-2.9298e-01, -8.7257e-02,  9.9718e-03,  2.2917e-02,  1.4112e-01,\n",
      "          1.9736e-01,  1.1405e-01, -3.8617e-02, -2.8146e-01, -1.3735e-01,\n",
      "         -2.0249e-01,  2.1166e-01,  4.2786e-03,  2.3695e-01,  1.1796e-01,\n",
      "          2.7459e-02,  8.6894e-03, -4.3562e-02, -2.5326e-01, -1.2044e-01],\n",
      "        [ 1.5178e-02, -5.4260e-02, -1.6081e-03, -5.7543e-02, -1.1999e-01,\n",
      "         -2.7376e-01,  1.3539e-01, -1.8310e-01, -2.0768e-01, -1.9401e-02,\n",
      "          3.9635e-02, -4.8475e-04, -1.9050e-01, -1.2764e-01, -2.5631e-01,\n",
      "          2.5181e-01,  2.9983e-01, -2.9962e-01,  2.4744e-01, -2.5012e-01],\n",
      "        [-4.3384e-02,  1.8405e-02,  5.4549e-03, -1.1628e-01, -1.4959e-02,\n",
      "          1.0189e-01,  9.8249e-02, -8.0366e-02, -2.5941e-01, -1.4841e-01,\n",
      "         -2.4302e-01, -1.5523e-01, -9.7152e-02, -2.6328e-01,  2.7729e-02,\n",
      "         -6.1046e-02,  1.8731e-01, -2.3381e-01,  1.8413e-01,  9.3475e-02],\n",
      "        [-1.0724e-01, -1.1064e-01,  1.5167e-01,  1.0045e-01,  2.9526e-02,\n",
      "          1.5904e-01, -1.3905e-01, -1.5265e-01, -3.1387e-01,  1.3434e-01,\n",
      "         -2.2673e-02,  1.9566e-01, -3.1797e-03,  5.1756e-02,  1.7950e-02,\n",
      "          9.4359e-02, -1.5566e-01,  3.3644e-01,  5.7084e-02,  9.1807e-02],\n",
      "        [ 1.7815e-01, -1.7308e-01,  2.3198e-02,  2.3678e-01,  8.2943e-03,\n",
      "          4.9787e-02, -8.4529e-03,  3.5828e-02,  1.3649e-01, -1.3038e-01,\n",
      "          4.1859e-01, -1.8195e-01,  2.3617e-02, -2.2789e-01, -2.4871e-01,\n",
      "          2.1452e-01, -2.6667e-02,  1.0223e-01, -2.1789e-01, -1.2700e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1544, -0.0598,  0.3465,  0.3318,  0.1236,  0.0221,  0.0275,  0.0237,\n",
      "         0.2812, -0.0292, -0.1962,  0.0215,  0.0391,  0.3603,  0.0787,  0.2823,\n",
      "         0.0231,  0.0984, -0.1655,  0.1595], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9125, 0.9148, 1.0361, 0.9178, 1.0394, 0.9928, 1.0434, 0.9136, 1.0327,\n",
      "        0.9156, 0.9756, 0.9856, 0.9912, 0.9537, 0.8916, 0.9809, 0.8477, 0.7550,\n",
      "        1.0120, 1.0346], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0520, -0.0926,  0.0299, -0.0684, -0.1260, -0.1321, -0.1305, -0.0835,\n",
      "        -0.0560,  0.0526,  0.1856, -0.1209, -0.0108, -0.0028, -0.1728, -0.0903,\n",
      "         0.0810,  0.0213, -0.0668, -0.0967], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1729,  0.1488,  0.0912,  0.1096, -0.2949,  0.2177, -0.0333,  0.1750,\n",
      "          0.0248, -0.0246, -0.2035,  0.0019,  0.2530,  0.0252,  0.0624,  0.1273,\n",
      "          0.0004,  0.0550,  0.2491,  0.0256],\n",
      "        [-0.1035, -0.1844,  0.1352, -0.0461,  0.1305, -0.1534, -0.3668, -0.1046,\n",
      "         -0.3160, -0.0131,  0.1203, -0.0435, -0.1581,  0.1634, -0.1186, -0.1447,\n",
      "         -0.0007,  0.1138, -0.0553, -0.2392],\n",
      "        [-0.0879, -0.0214, -0.2605,  0.0861, -0.3218, -0.0646, -0.0712, -0.0858,\n",
      "         -0.1985,  0.1025,  0.1870,  0.1140,  0.0151, -0.0578, -0.2181,  0.1506,\n",
      "         -0.0831, -0.1266, -0.0850,  0.0961],\n",
      "        [ 0.1197, -0.1000, -0.0905, -0.1965, -0.2011,  0.1621,  0.1787,  0.1691,\n",
      "          0.3785, -0.1142,  0.1667, -0.0960,  0.1236, -0.0858,  0.1090, -0.0475,\n",
      "          0.0885, -0.0358,  0.0296, -0.2269],\n",
      "        [-0.1157, -0.1011, -0.0517,  0.1514, -0.0364, -0.2993,  0.1104, -0.0954,\n",
      "         -0.1646,  0.2508,  0.1206,  0.2206, -0.2483, -0.1390, -0.0579, -0.0443,\n",
      "         -0.1401,  0.0278, -0.2284,  0.1636],\n",
      "        [ 0.0566,  0.0766,  0.1387,  0.0801,  0.2261, -0.0780, -0.2963, -0.1615,\n",
      "         -0.1526,  0.0910,  0.2071, -0.2670,  0.0446,  0.1302, -0.0053,  0.0857,\n",
      "         -0.1868, -0.0787,  0.0072, -0.2190],\n",
      "        [-0.0825, -0.0341, -0.0446,  0.1575, -0.0207, -0.0319, -0.0037,  0.0339,\n",
      "         -0.2341,  0.1787, -0.0586,  0.2543, -0.1885,  0.0622, -0.1458, -0.1402,\n",
      "          0.2354, -0.0015, -0.1008, -0.0694],\n",
      "        [-0.2047, -0.2700, -0.1317,  0.0080, -0.1547, -0.3146, -0.1309, -0.0172,\n",
      "         -0.0024,  0.0878,  0.2362, -0.1096,  0.1706,  0.2129,  0.1360, -0.2860,\n",
      "          0.0884,  0.1624,  0.0607, -0.1704],\n",
      "        [ 0.1090, -0.2113,  0.1009, -0.0378, -0.2164, -0.0055,  0.1719, -0.3465,\n",
      "         -0.0406,  0.1164,  0.0141,  0.0834, -0.1282, -0.1763,  0.0241, -0.3555,\n",
      "          0.1389, -0.1202, -0.0005,  0.2454],\n",
      "        [ 0.0386,  0.0688,  0.0393,  0.1813, -0.3397,  0.1391,  0.1165,  0.1197,\n",
      "          0.0075,  0.0157, -0.1978,  0.1276, -0.0104, -0.1914, -0.3109, -0.0513,\n",
      "         -0.2524,  0.0232,  0.2696,  0.1148],\n",
      "        [-0.1707,  0.0087, -0.1100, -0.3162,  0.0917, -0.0411,  0.1361, -0.0450,\n",
      "          0.0218, -0.2271, -0.1320, -0.1758, -0.0163, -0.0463,  0.0483, -0.0801,\n",
      "          0.0596,  0.0303, -0.2890,  0.1067],\n",
      "        [ 0.0398,  0.1440,  0.2387, -0.0914,  0.0628,  0.1125, -0.2020,  0.0778,\n",
      "         -0.0186,  0.2345,  0.0953, -0.0849,  0.0049, -0.0226, -0.0175,  0.1055,\n",
      "         -0.1048, -0.1685,  0.0058, -0.2139],\n",
      "        [-0.2043, -0.1057, -0.3887, -0.0801,  0.1937, -0.0944, -0.3301, -0.1985,\n",
      "         -0.3527, -0.0693,  0.0101, -0.0669, -0.0478,  0.1531,  0.0053, -0.3394,\n",
      "          0.0031, -0.0092, -0.0589,  0.0270],\n",
      "        [ 0.0445,  0.2680, -0.2388, -0.1418, -0.0048, -0.0444, -0.1408, -0.1327,\n",
      "         -0.0293, -0.0841, -0.2483,  0.0768,  0.1121, -0.0407,  0.2009, -0.1059,\n",
      "          0.2648,  0.2381, -0.1058, -0.1783],\n",
      "        [ 0.0750, -0.2455,  0.0215,  0.2325,  0.0630, -0.2260, -0.0304,  0.0696,\n",
      "          0.1622,  0.2116,  0.0667, -0.0834,  0.2563,  0.0277, -0.3303,  0.0970,\n",
      "         -0.2672,  0.2612, -0.1854, -0.1956],\n",
      "        [-0.0660, -0.2546,  0.1269,  0.0967,  0.1927, -0.2480, -0.1260, -0.0672,\n",
      "         -0.2396, -0.0125,  0.0070, -0.0406, -0.0080,  0.3267, -0.0669, -0.0481,\n",
      "          0.0687, -0.0543, -0.0294, -0.1011],\n",
      "        [ 0.1715,  0.1606,  0.0433, -0.1016, -0.1918,  0.1470,  0.0663,  0.1200,\n",
      "          0.1245, -0.0461, -0.0655,  0.0524,  0.1690,  0.0785, -0.2390, -0.0006,\n",
      "          0.0648,  0.0235,  0.1897, -0.3021],\n",
      "        [ 0.0117,  0.0056,  0.1637,  0.0279, -0.1473,  0.1976, -0.2094, -0.0074,\n",
      "         -0.0621,  0.0127,  0.2781,  0.0841,  0.2310, -0.0806,  0.0524,  0.0864,\n",
      "         -0.1801, -0.0121,  0.2439, -0.1952],\n",
      "        [-0.1158, -0.0349, -0.3207,  0.0286, -0.0734, -0.2700, -0.0844, -0.0150,\n",
      "         -0.0464, -0.1067,  0.3566,  0.1830, -0.2896, -0.1809, -0.0499, -0.2486,\n",
      "          0.1638,  0.1484,  0.1765,  0.0722],\n",
      "        [-0.0580, -0.0401, -0.2117, -0.1987, -0.2520, -0.0870,  0.2748,  0.0992,\n",
      "          0.0300,  0.1659, -0.0660, -0.2410,  0.0874, -0.2039,  0.0423, -0.1424,\n",
      "         -0.0266, -0.2276,  0.0577,  0.2208]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0823,  0.3843, -0.1151,  0.1097,  0.3713,  0.2857,  0.1268, -0.0788,\n",
      "         0.1825,  0.1584,  0.4237,  0.2010,  0.0355,  0.1877,  0.1762,  0.0592,\n",
      "        -0.0525, -0.0147,  0.0248,  0.2010], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8837, 1.1095, 1.0051, 0.8844, 1.1374, 0.8917, 0.8864, 0.8912, 1.0595,\n",
      "        0.9697, 0.9863, 0.8275, 0.9128, 0.9115, 0.9444, 0.8585, 0.8322, 0.9169,\n",
      "        0.8648, 1.0176], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1709,  0.1619,  0.0317, -0.0071,  0.1327,  0.0776,  0.1610, -0.0513,\n",
      "         0.0219,  0.0337, -0.0742, -0.1322,  0.1176, -0.3706,  0.3515,  0.1373,\n",
      "        -0.0117,  0.1321, -0.4041, -0.0863], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2514, -0.3315,  0.1349, -0.0871, -0.0890, -0.3077, -0.1464, -0.2752,\n",
      "          0.1287,  0.1591, -0.0897, -0.0321,  0.1039,  0.0748,  0.0326,  0.0326,\n",
      "          0.1040,  0.1729, -0.2537,  0.0718],\n",
      "        [ 0.0407,  0.0116, -0.2773,  0.0485, -0.3207,  0.0840, -0.0434, -0.0677,\n",
      "         -0.2123, -0.1685,  0.1991, -0.0577,  0.0173,  0.0269, -0.0181, -0.1604,\n",
      "         -0.1482, -0.1231, -0.2187, -0.2958],\n",
      "        [-0.0476,  0.2974,  0.0928, -0.1423,  0.0288,  0.1982, -0.1094,  0.1045,\n",
      "         -0.0454, -0.1337, -0.0355, -0.0881,  0.0854, -0.0905,  0.3198,  0.1496,\n",
      "         -0.0344,  0.0868,  0.0331, -0.1183],\n",
      "        [ 0.0280, -0.1305, -0.1634, -0.1134, -0.3017,  0.0542, -0.0152, -0.0868,\n",
      "         -0.3856,  0.0288, -0.1773,  0.1905, -0.0628, -0.0558,  0.1871,  0.0960,\n",
      "          0.0717, -0.0041, -0.2896, -0.1388],\n",
      "        [ 0.0134, -0.2410, -0.1681,  0.2479,  0.0802, -0.3317, -0.2086,  0.1734,\n",
      "          0.1535,  0.0178,  0.1161, -0.1536, -0.2417, -0.0746,  0.0199, -0.1903,\n",
      "         -0.0509,  0.0652, -0.2370,  0.2003],\n",
      "        [-0.0454,  0.2566, -0.0288,  0.0105,  0.2025,  0.1240, -0.0458,  0.1338,\n",
      "         -0.2389, -0.1513, -0.0465, -0.0436,  0.0246, -0.1800,  0.3658,  0.1687,\n",
      "         -0.1893,  0.1634,  0.0034,  0.0261],\n",
      "        [-0.1896,  0.1113, -0.3249,  0.1286, -0.1678,  0.2413, -0.3025, -0.2092,\n",
      "          0.0632,  0.0938, -0.2633, -0.0786,  0.0495, -0.1769,  0.0886,  0.0816,\n",
      "         -0.0365,  0.0799,  0.0634, -0.2749],\n",
      "        [ 0.1993,  0.1387, -0.3132,  0.0632, -0.2374,  0.0167,  0.1105, -0.2006,\n",
      "         -0.2790,  0.2706,  0.1586,  0.0674,  0.2581,  0.1616,  0.0195,  0.1178,\n",
      "         -0.0160,  0.2012, -0.0366,  0.0409],\n",
      "        [ 0.1572, -0.0714, -0.0186, -0.0926,  0.0428, -0.0171, -0.0231, -0.3328,\n",
      "          0.1534,  0.0037,  0.1015, -0.0182, -0.1690, -0.3016, -0.0524, -0.2407,\n",
      "         -0.1642, -0.0279, -0.2854,  0.0903],\n",
      "        [-0.0174,  0.0843,  0.0678,  0.0458, -0.1423, -0.0520,  0.0392, -0.3040,\n",
      "         -0.3059, -0.0422, -0.1949, -0.0330, -0.1939, -0.1598,  0.2666,  0.2037,\n",
      "          0.1561,  0.0227, -0.0629, -0.3325],\n",
      "        [ 0.0832, -0.0972, -0.0348,  0.0887,  0.2773, -0.1292,  0.1633, -0.1512,\n",
      "         -0.0281,  0.1179, -0.3642,  0.2440, -0.1668,  0.0526,  0.1017, -0.2223,\n",
      "          0.0999, -0.1108,  0.0036, -0.0220],\n",
      "        [ 0.1838, -0.2496, -0.1812, -0.0593, -0.3883, -0.0216, -0.2680,  0.1281,\n",
      "         -0.0942, -0.0162,  0.0536,  0.2158, -0.2582, -0.1228,  0.1176, -0.2785,\n",
      "          0.2149,  0.1027, -0.2140,  0.1134],\n",
      "        [ 0.0773,  0.2001, -0.3701,  0.0687, -0.0053, -0.2242,  0.0342,  0.1133,\n",
      "         -0.1490, -0.0054,  0.1525, -0.1931,  0.2875,  0.2886,  0.0404,  0.1157,\n",
      "          0.1126, -0.1124,  0.0536, -0.1074],\n",
      "        [-0.2502,  0.2084,  0.1958, -0.2956,  0.0788,  0.1416,  0.2382,  0.1313,\n",
      "         -0.1363, -0.1886,  0.0604, -0.0834,  0.1639, -0.2131,  0.2263,  0.2011,\n",
      "          0.0444, -0.0173, -0.1137, -0.3286],\n",
      "        [ 0.0790,  0.1556,  0.1111,  0.0944,  0.0223,  0.2631, -0.0335,  0.0467,\n",
      "         -0.1070, -0.1931, -0.1915,  0.2574, -0.1915, -0.0293, -0.0076, -0.0235,\n",
      "          0.0058,  0.0841, -0.0305, -0.1967],\n",
      "        [ 0.0929,  0.2313, -0.1523, -0.3348, -0.1366, -0.0983, -0.0664,  0.0475,\n",
      "         -0.0111, -0.0895,  0.0267, -0.1333,  0.2996,  0.0139, -0.2584,  0.1946,\n",
      "         -0.2747, -0.2515, -0.2008, -0.2355],\n",
      "        [-0.0564,  0.1020, -0.2355, -0.2932,  0.0132,  0.1480, -0.0098,  0.0066,\n",
      "         -0.2840, -0.2075, -0.0289, -0.0971, -0.1168, -0.0459,  0.1652,  0.1030,\n",
      "         -0.1640, -0.3463, -0.2473, -0.1180],\n",
      "        [-0.2811,  0.0845,  0.1061, -0.0941,  0.2116, -0.0611,  0.1447, -0.1230,\n",
      "          0.1875,  0.1598, -0.1438, -0.2099,  0.2269, -0.2617,  0.0628,  0.0041,\n",
      "         -0.2383, -0.1397,  0.0130,  0.0536],\n",
      "        [ 0.1079, -0.0690,  0.2610, -0.0504,  0.1124,  0.0770,  0.3068,  0.0653,\n",
      "          0.1359,  0.1554, -0.3894, -0.1352,  0.0137, -0.1119,  0.2124,  0.0213,\n",
      "          0.0817,  0.0722, -0.0793, -0.0921],\n",
      "        [ 0.0842, -0.1304, -0.1577,  0.2561, -0.2215,  0.0834,  0.1115,  0.0104,\n",
      "         -0.1521, -0.0123, -0.2458,  0.1800,  0.0732, -0.2768, -0.0802, -0.0775,\n",
      "          0.0397,  0.2049, -0.0242,  0.0070]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0246,  0.4834,  0.4275,  0.1336,  0.3213,  0.2798,  0.3110, -0.0191,\n",
      "         0.4553,  0.3280, -0.1545,  0.1240,  0.2383,  0.2327,  0.2294,  0.0351,\n",
      "         0.2156,  0.3591,  0.3830, -0.1648], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7420, 1.0009, 0.8916, 0.9403, 1.0628, 0.8664, 0.8567, 0.8760, 0.9894,\n",
      "        0.8914, 0.8190, 0.9127, 0.8535, 1.1020, 0.9505, 0.9761, 1.0198, 1.2344,\n",
      "        1.1670, 0.8033], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2288, -0.0740,  0.0898,  0.0488, -0.1200,  0.3192,  0.1284,  0.0914,\n",
      "        -0.1231,  0.1967,  0.2079,  0.0614,  0.2123, -0.0137,  0.1588,  0.0055,\n",
      "         0.0467, -0.0219,  0.2052,  0.1971], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-6.3632e-02, -3.0725e-01,  3.5800e-01,  2.1259e-01,  1.1730e-03,\n",
      "          1.1373e-01, -2.4711e-02,  4.9108e-02, -2.7551e-01,  5.4941e-02,\n",
      "          7.6633e-02, -2.5072e-01, -9.6992e-02,  2.0101e-01, -6.8404e-02,\n",
      "         -7.5216e-02,  3.5450e-02,  7.9307e-02,  2.6416e-01,  1.3055e-02],\n",
      "        [-1.2993e-01, -3.4786e-02,  2.7403e-01,  5.8669e-02, -3.6098e-02,\n",
      "          3.2168e-01, -3.6715e-03, -9.0105e-02, -2.6317e-01,  6.1961e-02,\n",
      "          1.7586e-02,  6.6197e-02,  1.1738e-01,  1.8713e-01,  1.9502e-01,\n",
      "          6.7577e-02,  1.7384e-01, -1.0480e-01,  3.1234e-01, -8.7739e-02],\n",
      "        [ 7.6638e-02, -2.1858e-01, -1.9445e-01, -2.6510e-02,  1.8808e-01,\n",
      "          4.8570e-02, -6.9986e-02,  1.2109e-01,  1.3751e-01,  9.9510e-02,\n",
      "          1.6791e-01,  1.8463e-01, -7.0385e-02, -8.0848e-02, -6.3408e-02,\n",
      "         -3.4757e-01, -1.4318e-01, -1.4814e-01, -7.2068e-02,  7.4729e-02],\n",
      "        [ 2.6185e-02, -1.5477e-01, -2.1947e-01, -2.7670e-01, -2.0653e-01,\n",
      "         -5.1640e-02, -1.2790e-01, -7.5848e-02,  1.5329e-01, -7.7375e-02,\n",
      "          2.1406e-01, -1.5473e-01,  6.0740e-02, -1.2786e-01, -1.3112e-01,\n",
      "          5.9430e-03, -9.0101e-02,  2.6302e-01, -4.4549e-02, -2.4208e-01],\n",
      "        [-2.0158e-01,  3.1122e-01,  1.1526e-01,  6.8775e-02, -8.9106e-02,\n",
      "          7.9310e-02, -1.7487e-02,  1.9577e-01, -1.1327e-01,  2.8164e-02,\n",
      "         -2.5335e-01, -3.1344e-02,  1.0653e-01,  1.2371e-01, -1.9368e-01,\n",
      "          3.3231e-01,  2.7400e-01, -2.0502e-01, -1.4735e-01,  1.1472e-02],\n",
      "        [ 1.2268e-01,  3.4222e-02, -3.4642e-02, -1.2109e-01,  2.3377e-01,\n",
      "         -1.9380e-01,  8.1980e-02, -9.0160e-02,  3.8611e-01, -3.4645e-02,\n",
      "         -1.1350e-01, -1.6169e-01, -1.8074e-01, -1.1189e-01, -4.3822e-02,\n",
      "          1.4662e-01, -2.6861e-01,  2.2826e-01, -1.7872e-02, -6.9744e-02],\n",
      "        [-6.7612e-02,  1.7334e-01,  8.0949e-04, -2.6201e-01, -3.1130e-01,\n",
      "         -6.8615e-02, -6.3958e-02,  1.9003e-02, -2.4896e-01,  2.3649e-02,\n",
      "          1.0086e-01,  1.0489e-01,  2.0124e-01,  4.9029e-02, -2.0867e-01,\n",
      "          2.1683e-01,  2.4326e-01, -5.4697e-02, -5.6939e-02, -1.9853e-01],\n",
      "        [ 1.0645e-01, -1.2819e-02, -1.2285e-01,  3.1783e-01,  1.1779e-01,\n",
      "          7.9509e-02,  1.6174e-01, -7.5710e-02,  1.1396e-01,  3.9105e-01,\n",
      "          3.3322e-04,  2.3223e-01,  1.1710e-01, -2.1404e-01,  2.0214e-01,\n",
      "         -5.3374e-02, -1.1508e-01, -2.7343e-01,  1.4789e-03,  5.0978e-02],\n",
      "        [-3.8754e-02, -1.4586e-01,  1.0385e-02, -3.3989e-01,  9.7342e-02,\n",
      "         -7.0144e-02, -2.0147e-01,  9.4189e-03,  1.4791e-02, -3.2375e-01,\n",
      "          1.6486e-01, -3.6764e-01,  1.2996e-01, -2.3346e-01, -1.3632e-01,\n",
      "          4.3670e-02, -2.3572e-01, -1.3473e-01,  6.9812e-02, -1.8624e-01],\n",
      "        [ 6.3681e-02,  4.0233e-02,  1.0956e-01,  2.4462e-02, -2.7370e-01,\n",
      "          1.8710e-01,  2.8352e-01, -1.5291e-01, -1.2020e-01,  2.7109e-02,\n",
      "         -3.4993e-02, -2.2751e-01,  2.1827e-01,  1.2644e-01,  1.3832e-01,\n",
      "          1.1190e-01,  3.1791e-01, -2.6455e-02, -1.9007e-01, -7.1214e-02],\n",
      "        [-2.2453e-02, -1.6446e-01, -5.8341e-02, -1.2816e-02,  3.7497e-01,\n",
      "         -1.7746e-01, -9.0867e-03, -1.7203e-01,  2.5910e-02, -3.3387e-01,\n",
      "         -3.2205e-02, -7.5253e-02, -5.8893e-02, -9.7563e-02, -3.3668e-01,\n",
      "         -1.7567e-01,  6.7983e-02, -1.3368e-01, -2.0725e-01, -1.7150e-01],\n",
      "        [ 6.9469e-02,  2.7332e-01,  7.6032e-02, -1.8126e-01,  2.3099e-02,\n",
      "          3.1798e-02, -1.7738e-01, -5.0174e-02, -1.1558e-01, -1.4765e-01,\n",
      "         -1.0090e-01, -1.2532e-02,  2.4020e-01, -1.9844e-01, -8.7298e-02,\n",
      "          1.5146e-01, -1.8092e-01, -2.4418e-01, -2.5068e-01, -7.7709e-03],\n",
      "        [-4.3170e-02,  6.6983e-03,  1.9124e-02, -1.2917e-01, -2.2044e-01,\n",
      "          1.7852e-01, -9.4115e-02,  6.0580e-02, -2.4945e-01,  3.3232e-02,\n",
      "          2.5439e-02,  2.1949e-01, -3.1532e-03,  3.1133e-01,  6.2382e-02,\n",
      "          6.6255e-02,  3.0423e-01, -1.2778e-01,  1.7040e-01,  1.3322e-01],\n",
      "        [-2.0406e-01,  1.8013e-01, -2.7641e-01, -4.1122e-02,  1.6009e-01,\n",
      "         -9.8206e-02, -8.3896e-02, -2.0382e-01,  1.6414e-02, -1.8947e-02,\n",
      "         -2.9676e-01, -3.0559e-02, -9.6025e-03, -2.6086e-01,  2.3902e-02,\n",
      "         -7.1652e-02,  1.1534e-02, -3.3350e-01, -4.2926e-01, -7.4399e-02],\n",
      "        [ 2.3690e-01, -1.3001e-01, -1.4844e-01, -2.7269e-02,  7.7558e-02,\n",
      "          1.5618e-01,  7.8862e-02, -1.8686e-01,  1.8380e-01, -6.7403e-03,\n",
      "          1.3254e-01, -8.3035e-02, -2.7002e-01, -1.7146e-01, -8.7485e-02,\n",
      "         -1.9217e-01, -2.9357e-01,  1.8017e-01,  2.7672e-01,  1.4374e-01],\n",
      "        [-1.7558e-01, -2.9122e-01,  1.5920e-01, -2.0294e-01, -1.5340e-01,\n",
      "          8.3470e-02, -9.0218e-02, -2.9829e-01, -2.8835e-01,  3.1837e-02,\n",
      "          1.9532e-01,  7.1050e-03, -5.1538e-02,  1.4146e-01, -5.3863e-02,\n",
      "         -1.4503e-01,  2.2971e-02,  2.0223e-01,  3.1527e-01,  1.4621e-01],\n",
      "        [-2.3890e-01,  1.8269e-01,  3.1676e-02,  7.6267e-02, -3.1258e-01,\n",
      "          3.2251e-02,  2.1805e-01, -3.4801e-02,  2.4835e-01,  1.4684e-01,\n",
      "         -3.7326e-03, -1.8230e-02, -2.2563e-01, -3.3821e-02,  6.2111e-02,\n",
      "         -7.5768e-02,  1.2231e-01, -1.7144e-01, -1.1808e-01, -8.9341e-02],\n",
      "        [ 1.1251e-01, -8.7613e-02,  1.6264e-01,  1.6690e-01,  2.4194e-01,\n",
      "          2.0274e-01,  1.3487e-01,  8.8351e-02, -1.2638e-01,  1.2183e-01,\n",
      "         -4.3209e-02,  8.3941e-03,  7.0474e-02,  3.1405e-01,  1.9813e-01,\n",
      "          8.8405e-02,  2.6279e-01,  1.6642e-01,  2.3072e-01,  1.1222e-01],\n",
      "        [ 7.5414e-02,  4.9604e-02, -4.3473e-02, -2.7282e-02,  1.7704e-01,\n",
      "         -1.5427e-01,  1.6077e-01,  1.5134e-01,  1.7694e-01,  1.0221e-01,\n",
      "          2.1491e-01,  1.1021e-01,  5.7932e-03, -3.0207e-01, -6.3809e-02,\n",
      "         -1.8310e-01, -3.4591e-01, -1.4282e-01, -3.1136e-02,  1.7370e-01],\n",
      "        [ 1.4699e-01,  1.8292e-01, -6.4158e-02,  1.2453e-01,  7.0630e-02,\n",
      "         -2.3548e-01,  2.5979e-01,  1.1572e-02,  2.9417e-02, -2.5551e-02,\n",
      "         -2.6686e-02,  1.2104e-01, -1.2718e-01, -1.9523e-01,  2.7771e-01,\n",
      "          2.1762e-02, -1.3534e-02, -1.7193e-01, -2.0911e-01,  4.9327e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1455,  0.2256,  0.1970,  0.2828,  0.2580, -0.2396, -0.0454,  0.2812,\n",
      "         0.5621,  0.3080, -0.1425,  0.1700, -0.1808,  0.2608,  0.2987,  0.0618,\n",
      "         0.2497, -0.0009, -0.0099,  0.2469], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7955, 0.7298, 0.7854, 0.8193, 0.7614, 0.8630, 0.7497, 0.8279, 0.6724,\n",
      "        0.7904, 0.7901, 0.7695, 0.7003, 0.8784, 0.7467, 0.8204, 0.8106, 0.6632,\n",
      "        0.7848, 0.7491], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0925, -0.1581, -0.0544, -0.0428,  0.0913, -0.0066, -0.0807,  0.1039,\n",
      "         0.1059,  0.0630, -0.0190, -0.1003,  0.0778,  0.0051, -0.0775,  0.0917,\n",
      "         0.0412, -0.0876, -0.1097,  0.0420], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0843,  0.0085,  0.1455,  0.0280, -0.1921, -0.0186, -0.1109,  0.1170,\n",
      "          0.0047, -0.1354,  0.1405, -0.0121,  0.0208,  0.0484,  0.1011,  0.0455,\n",
      "         -0.1211,  0.0417,  0.1631,  0.1134],\n",
      "        [-0.0299, -0.0072,  0.0408, -0.0135, -0.0421,  0.1420, -0.0475, -0.0374,\n",
      "          0.0017,  0.0122,  0.2355, -0.0594,  0.0349,  0.1535, -0.0528, -0.0955,\n",
      "          0.0491,  0.0816,  0.0165, -0.0197],\n",
      "        [ 0.1257,  0.1460,  0.0236,  0.0206, -0.0449,  0.0624, -0.0492,  0.0299,\n",
      "         -0.0952,  0.0743, -0.0245, -0.1759,  0.0696, -0.2232,  0.0789,  0.1632,\n",
      "          0.0337,  0.1213,  0.0386, -0.0488],\n",
      "        [-0.0151, -0.0229, -0.0053,  0.2245,  0.0215,  0.1487,  0.0579, -0.1891,\n",
      "          0.1935, -0.0175,  0.0253,  0.0432,  0.0048, -0.1324,  0.1241,  0.0434,\n",
      "         -0.2095, -0.0314, -0.0293, -0.1533],\n",
      "        [-0.0013, -0.1067, -0.0782,  0.0868, -0.1033, -0.1734, -0.0682, -0.0178,\n",
      "          0.0491, -0.0874, -0.0683, -0.0098, -0.0832,  0.0432, -0.0494,  0.0978,\n",
      "          0.0234, -0.0269, -0.0344,  0.0193]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0143,  0.0317,  0.0158,  0.0068, -0.0324], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9629e-03,  1.8032e-05, -6.1006e-03,  5.3730e-04, -6.9592e-03,\n",
      "         -4.3097e-03,  2.5444e-03, -3.1141e-03, -1.1292e-03,  1.0365e-03],\n",
      "        [-2.6804e-03, -5.5672e-03,  9.2022e-03,  1.1145e-02, -2.5116e-03,\n",
      "          2.5168e-03, -1.7641e-04, -5.6640e-03, -6.5832e-05,  6.6166e-03]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0036, -0.0032], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for param in obj2.model.parameters():\n",
    "    print(param)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi3yqTDIOoui"
   },
   "source": [
    "# Make Prediction of All Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHcer1BPikHd",
    "outputId": "f72b5c62-5fd7-438d-818f-47f5dddaf3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "test data generated\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    obj2.model.eval()\n",
    "\n",
    "    #obj1.load_residuals(address='bb_residuals.pkl')\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    obj2.generate_test_results()\n",
    "    print(\"test data generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaKllEltPf16"
   },
   "source": [
    "# Comprehensive Checking of The Prediction Values vs. True Values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BK8l95VcvpJt",
    "outputId": "470c82e6-2b9a-4903-eaa1-732e46bd84c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7641,  0.4002,  0.9787,  2.2409,  1.8676],\n",
      "        [-0.9773,  0.9501, -0.1514, -0.1032,  0.4106],\n",
      "        [ 0.1440,  1.4543,  0.7610,  0.1217,  0.4439],\n",
      "        ...,\n",
      "        [-1.9519,  2.4412, -0.0173,  0.9123,  1.2397],\n",
      "        [-0.5734,  0.4249, -0.2713, -0.6836, -1.5374],\n",
      "        [-0.1014,  0.7467,  0.9292,  0.2294,  0.4144]])\n"
     ]
    }
   ],
   "source": [
    "print(obj2.x_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9ZitDT26ZXW",
    "outputId": "de963c21-10fd-4515-b6b5-b9a06eb3bd46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4280,  0.0405,  0.3710,  1.5154,  0.1070],\n",
      "        [-0.9722, -0.1590, -0.6005, -0.3170, -0.1335],\n",
      "        [-0.0510, -0.3346,  0.2090,  0.7465,  0.5017],\n",
      "        ...,\n",
      "        [ 0.3791,  0.4869, -0.0230,  1.1160, -0.0571],\n",
      "        [-0.8318, -0.0556, -0.2465, -0.7570, -0.0609],\n",
      "        [ 0.1368, -0.3935,  0.8197,  0.4716,  0.3434]])\n"
     ]
    }
   ],
   "source": [
    "print(obj2.x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ENQ8rtRHInw",
    "outputId": "959af6be-4ab0-4150-e843-b0d2297efc30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5220)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs(obj2.x_pred - obj2.x_last)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJJfodLhQmrD",
    "outputId": "1bc5cb45-60ba-4bc1-c812-fd51c64c41ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3360, -0.3596, -0.6078, -0.7255, -1.7606],\n",
       "        [ 0.0051, -1.1091, -0.4492, -0.2138, -0.5441],\n",
       "        [-0.1950, -1.7888, -0.5520,  0.6248,  0.0578],\n",
       "        ...,\n",
       "        [ 2.3310, -1.9543, -0.0057,  0.2038, -1.2967],\n",
       "        [-0.2585, -0.4804,  0.0247, -0.0734,  1.4766],\n",
       "        [ 0.2382, -1.1402, -0.1095,  0.2422, -0.0711]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(obj2.x_pred-obj2.x_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3q3XVFEvsEQ",
    "outputId": "4add0237-b89d-4803-983f-2d35cad6599d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(obj2.y_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Opj3sBJX6cQH",
    "outputId": "daedae9e-1edb-4243-efa3-e54976aaee6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0605, -0.0260],\n",
      "        [-0.0197,  0.0153],\n",
      "        [-0.0083, -0.0337],\n",
      "        ...,\n",
      "        [ 0.0069,  0.0171],\n",
      "        [-0.0129,  0.0164],\n",
      "        [ 0.0138, -0.0075]])\n"
     ]
    }
   ],
   "source": [
    "print(obj2.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "N-n9_o8nQxBa",
    "outputId": "08c51321-bbdc-4302-8c5d-c97c8700b590"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>Y</th>\n",
       "      <th>YY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>2.240893</td>\n",
       "      <td>1.867558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.977278</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144044</td>\n",
       "      <td>1.454274</td>\n",
       "      <td>0.761038</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.443863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333674</td>\n",
       "      <td>1.494079</td>\n",
       "      <td>-0.205158</td>\n",
       "      <td>0.313068</td>\n",
       "      <td>-0.854096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.552990</td>\n",
       "      <td>0.653619</td>\n",
       "      <td>0.864436</td>\n",
       "      <td>-0.742165</td>\n",
       "      <td>2.269755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.711489</td>\n",
       "      <td>-1.820816</td>\n",
       "      <td>0.163495</td>\n",
       "      <td>-0.813117</td>\n",
       "      <td>-0.605355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.327524</td>\n",
       "      <td>-0.644172</td>\n",
       "      <td>1.908883</td>\n",
       "      <td>-0.563545</td>\n",
       "      <td>1.082473</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.951911</td>\n",
       "      <td>2.441216</td>\n",
       "      <td>-0.017285</td>\n",
       "      <td>0.912282</td>\n",
       "      <td>1.239658</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.573367</td>\n",
       "      <td>0.424889</td>\n",
       "      <td>-0.271260</td>\n",
       "      <td>-0.683568</td>\n",
       "      <td>-1.537438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.101374</td>\n",
       "      <td>0.746666</td>\n",
       "      <td>0.929182</td>\n",
       "      <td>0.229418</td>\n",
       "      <td>0.414406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C         D         E  Y  YY\n",
       "0    1.764052  0.400157  0.978738  2.240893  1.867558  1   1\n",
       "1   -0.977278  0.950088 -0.151357 -0.103219  0.410599  0   0\n",
       "2    0.144044  1.454274  0.761038  0.121675  0.443863  0   0\n",
       "3    0.333674  1.494079 -0.205158  0.313068 -0.854096  1   0\n",
       "4   -2.552990  0.653619  0.864436 -0.742165  2.269755  0   1\n",
       "..        ...       ...       ...       ...       ... ..  ..\n",
       "995  1.711489 -1.820816  0.163495 -0.813117 -0.605355  0   0\n",
       "996 -1.327524 -0.644172  1.908883 -0.563545  1.082473  1   0\n",
       "997 -1.951911  2.441216 -0.017285  0.912282  1.239658  1   1\n",
       "998 -0.573367  0.424889 -0.271260 -0.683568 -1.537438  1   1\n",
       "999 -0.101374  0.746666  0.929182  0.229418  0.414406  0   1\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2Yzu9Eiis50",
    "outputId": "d909e107-e05b-41a0-f075-c48541287153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 5])\n",
      "tensor([[ 1.7641,  0.4002,  0.9787,  2.2409,  1.8676],\n",
      "        [-0.9773,  0.9501, -0.1514, -0.1032,  0.4106],\n",
      "        [ 0.1440,  1.4543,  0.7610,  0.1217,  0.4439],\n",
      "        ...,\n",
      "        [-1.9519,  2.4412, -0.0173,  0.9123,  1.2397],\n",
      "        [-0.5734,  0.4249, -0.2713, -0.6836, -1.5374],\n",
      "        [-0.1014,  0.7467,  0.9292,  0.2294,  0.4144]])\n",
      "(1000, 5)\n",
      "Full_data_reconstructed...\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    obj2.model.eval()\n",
    "    for x, y in obj2.testloader:\n",
    "      x = x.to(device)\n",
    "      print(x.size())\n",
    "      print(x)\n",
    "      # forward\n",
    "      x_hat,y_hat, mu, logvar,z = obj2.model(x)\n",
    "    \n",
    "    df_reconstructed = pd.DataFrame(x_hat.cpu().detach().numpy(), columns=obj1.df_XY.drop(columns=['Y']).columns)\n",
    "    print(df_reconstructed.shape)\n",
    "    df_latent=pd.DataFrame(z.cpu().detach().numpy())\n",
    "    \n",
    "    obj2.model.eval()\n",
    "    \n",
    "    df_reconstructed_decoder=pd.DataFrame(obj2.model.decoder(z).cpu().detach().numpy(), columns=obj1.df_XY.drop(columns=['Y']).columns)\n",
    "\n",
    "    df_reconstructed.to_csv('df_reconstructed.csv')\n",
    "    df_latent.to_csv('df_latent.csv')\n",
    "    df_reconstructed_decoder.to_csv('df_reconstructed_decoder.csv')\n",
    "    print(\"Full_data_reconstructed...\")\n",
    "    '''\n",
    "    print(\"========df_reconstructed========\")\n",
    "    print(df_reconstructed)\n",
    "    print(\"========df_reconstructed_decoder========\")\n",
    "    print(df_reconstructed_decoder)\n",
    "    print(\"========df_Original========\")\n",
    "    print(df_XY)\n",
    "     '''\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CciNZOW_Rc0n"
   },
   "source": [
    "# Checking Linear Separability of Data on Lower Dimensioanl Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHqfONTOlqSr",
    "outputId": "6a2fa0ee-b52d-49dd-f55a-f6cdae3ee20e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression analysis\n",
      "0.536\n"
     ]
    }
   ],
   "source": [
    "print(\"regression analysis\")\n",
    "obj2.regression_analysis(obj2.zs,df_XY['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBQlR5KERlL-"
   },
   "source": [
    "# Visualize Data on Lower Dimensional Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4SXZtQfoj93-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"calculate tsne_umap_pca\")\\ntsne_mat,umap_mat,pca_mat,Y=obj2.calculate_lower_dimensions(obj2.zs,obj2.y_last,N=100)\\nobj2.plot_lower_dimension(tsne_mat,Y,projection=\\'3d\\',save_str=\\'tsne3d.pdf\\')\\nobj2.plot_lower_dimension(tsne_mat,Y,projection=\\'2d\\',save_str=\\'tsne2d.pdf\\')\\nobj2.plot_lower_dimension(umap_mat,Y,projection=\\'3d\\',save_str=\\'umap3d.pdf\\')\\nobj2.plot_lower_dimension(umap_mat,Y,projection=\\'2d\\',save_str=\\'umap2d.pdf\\')\\nobj2.plot_lower_dimension(pca_mat,Y,projection=\\'3d\\',save_str=\\'pca3d.pdf\\')\\nobj2.plot_lower_dimension(pca_mat,Y,projection=\\'2d\\',save_str=\\'pca2d.pdf\\')\\n\\nprint(\"finished\")\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"calculate tsne_umap_pca\")\n",
    "tsne_mat,umap_mat,pca_mat,Y=obj2.calculate_lower_dimensions(obj2.zs,obj2.y_last,N=100)\n",
    "obj2.plot_lower_dimension(tsne_mat,Y,projection='3d',save_str='tsne3d.pdf')\n",
    "obj2.plot_lower_dimension(tsne_mat,Y,projection='2d',save_str='tsne2d.pdf')\n",
    "obj2.plot_lower_dimension(umap_mat,Y,projection='3d',save_str='umap3d.pdf')\n",
    "obj2.plot_lower_dimension(umap_mat,Y,projection='2d',save_str='umap2d.pdf')\n",
    "obj2.plot_lower_dimension(pca_mat,Y,projection='3d',save_str='pca3d.pdf')\n",
    "obj2.plot_lower_dimension(pca_mat,Y,projection='2d',save_str='pca2d.pdf')\n",
    "\n",
    "print(\"finished\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76ULT6UtRxU6"
   },
   "source": [
    "# Perform Interpolation across all groups (Y) and all features from YY=0 to YY=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dXtgbd1iJ0s",
    "outputId": "4710be7c-960f-4184-bdb5-931a5699dd5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "254 249\n",
      "[[ 0.12580968 -0.07195252 -0.19496354  0.26042969  0.05814468]\n",
      " [-0.02539625 -0.06927383 -0.27865477  0.22104094  0.03993221]\n",
      " [-0.12643555 -0.09443238 -0.16384764  0.07195315  0.07632201]\n",
      " [-0.12015577 -0.1120839  -0.02696849 -0.02722298  0.04039401]\n",
      " [ 0.05501729 -0.09485123  0.15530623 -0.1547517   0.01547468]]\n",
      "1\n",
      "241 256\n",
      "[[ 0.18625011 -0.03129818 -0.11721766  0.09899846  0.01713661]\n",
      " [ 0.03059371 -0.07800034 -0.17800655  0.1459643   0.0742396 ]\n",
      " [-0.18750221 -0.12100913 -0.18407308  0.15431524  0.07884356]\n",
      " [-0.1681532  -0.09418513 -0.21428944  0.07015768  0.0352643 ]\n",
      " [-0.03632057 -0.06511612 -0.16387677  0.00070119 -0.0218555 ]]\n"
     ]
    }
   ],
   "source": [
    "ff = obj2.traversal_all_groups(traversal_step=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyAzr8KSAgH"
   },
   "source": [
    "# See the interpolation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "lWzpnwK0g-8g"
   },
   "outputs": [],
   "source": [
    "with open('results_dict.pkl', 'rb') as f:\n",
    "    ff = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "p23aMsKEknL4",
    "outputId": "29141142-bd3d-4f66-c936-9479312bcba9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027005</td>\n",
       "      <td>0.080318</td>\n",
       "      <td>-0.134450</td>\n",
       "      <td>0.080789</td>\n",
       "      <td>0.015744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.102350</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>-0.174979</td>\n",
       "      <td>0.048735</td>\n",
       "      <td>0.029583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.162377</td>\n",
       "      <td>-0.008875</td>\n",
       "      <td>-0.162012</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>0.045393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.158741</td>\n",
       "      <td>-0.026901</td>\n",
       "      <td>-0.083093</td>\n",
       "      <td>-0.068336</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.048462</td>\n",
       "      <td>-0.011391</td>\n",
       "      <td>0.020488</td>\n",
       "      <td>-0.100044</td>\n",
       "      <td>-0.000777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E\n",
       "0  0.027005  0.080318 -0.134450  0.080789  0.015744\n",
       "1 -0.102350  0.037109 -0.174979  0.048735  0.029583\n",
       "2 -0.162377 -0.008875 -0.162012 -0.025289  0.045393\n",
       "3 -0.158741 -0.026901 -0.083093 -0.068336  0.021600\n",
       "4 -0.048462 -0.011391  0.020488 -0.100044 -0.000777"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff['med']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hMMGIGAslEoz",
    "outputId": "52e9d86d-dcb8-46c1-dfbf-1866da50861b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186250</td>\n",
       "      <td>-0.031298</td>\n",
       "      <td>-0.117218</td>\n",
       "      <td>0.098998</td>\n",
       "      <td>0.017137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030594</td>\n",
       "      <td>-0.078000</td>\n",
       "      <td>-0.178007</td>\n",
       "      <td>0.145964</td>\n",
       "      <td>0.074240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.187502</td>\n",
       "      <td>-0.121009</td>\n",
       "      <td>-0.184073</td>\n",
       "      <td>0.154315</td>\n",
       "      <td>0.078844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.168153</td>\n",
       "      <td>-0.094185</td>\n",
       "      <td>-0.214289</td>\n",
       "      <td>0.070158</td>\n",
       "      <td>0.035264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036321</td>\n",
       "      <td>-0.065116</td>\n",
       "      <td>-0.163877</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>-0.021856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E\n",
       "0  0.186250 -0.031298 -0.117218  0.098998  0.017137\n",
       "1  0.030594 -0.078000 -0.178007  0.145964  0.074240\n",
       "2 -0.187502 -0.121009 -0.184073  0.154315  0.078844\n",
       "3 -0.168153 -0.094185 -0.214289  0.070158  0.035264\n",
       "4 -0.036321 -0.065116 -0.163877  0.000701 -0.021856"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff['mean']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dc104fa0fc4fbd82dc53cf2b69cd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='celltypes', options=('0', '1'), value='0'), Dropdown(description='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_path(celltypes, genes)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, Dropdown\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_path(celltypes, genes):\n",
    "    # generate plot based on a and b\n",
    "    plt.plot(ff['mean'][celltypes][genes])\n",
    "    plt.xlabel('healthy to cancer')\n",
    "    plt.ylabel('normalized gene expression')\n",
    "    plt.title('Linear interpolation for cell-type '+celltypes+\" for gene \"+genes)\n",
    "    plt.show()\n",
    "\n",
    "# get the list of possible values for a and b\n",
    "a_values = ['0','1']\n",
    "b_values = ['A','B','C','D','E']\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# create the dropdown widgets\n",
    "a_widget = Dropdown(options=a_values)\n",
    "b_widget = Dropdown(options=b_values)\n",
    "\n",
    "# use the interact function to bind the widgets and the function\n",
    "output = interact(plot_path, celltypes=a_widget, genes=b_widget)\n",
    "\n",
    "# display the output in an HTML page\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCHBvdSESFRV"
   },
   "source": [
    "# Generate Synthetic Data for a Given Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZ_3NAgi2-6L",
    "outputId": "a11c8fd5-41de-40d3-dee2-91580cb322a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503 503\n"
     ]
    }
   ],
   "source": [
    "bb = obj2.synthetic_single_group(group_id=0,nr_of_synthetic=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E330szfA6BD7",
    "outputId": "a8687ace-e5b6-46d2-904d-e854e532d0d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey_yS1WZ3Os2",
    "outputId": "dbeb2f28-2746-4a69-beeb-a934f19eb8a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04858896, -0.32076725,  0.98552108,  0.23710041,  0.16742821],\n",
       "       [-0.02765739, -0.29073334,  1.03771734,  0.14631502,  0.07962467],\n",
       "       [-0.12955226, -0.27172098,  1.0779599 ,  0.06794976, -0.01797733],\n",
       "       ...,\n",
       "       [ 0.10392272, -0.28532603,  1.46111929, -0.01966902, -0.05349838],\n",
       "       [ 0.16841228, -0.32457072,  1.44001603,  0.0525848 , -0.00252923],\n",
       "       [ 0.20230265, -0.34832829,  1.40551233,  0.1198994 ,  0.04123786]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
